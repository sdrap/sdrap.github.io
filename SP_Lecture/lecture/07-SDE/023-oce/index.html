
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.4">
    
    
      
        <title>Expected Shortfall - Stochastics</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Mono:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto Mono";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="orange" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#expected-shortfall" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Stochastics" class="md-header__button md-logo" aria-label="Stochastics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Stochastics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Expected Shortfall
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="orange" data-md-color-accent="indigo"  aria-label="Switch to light"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../00-Introduction/000-notations/" class="md-tabs__link">
          
  
    
  
  Lecture

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Stochastics" class="md-nav__button md-logo" aria-label="Stochastics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Stochastics
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Lecture
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Lecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Introduction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../00-Introduction/000-notations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Notations
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Sets, Continuity and Measurability
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Sets, Continuity and Measurability
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-Sets-Functions/010-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-Sets-Functions/011-sets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-Sets-Functions/012-measurability-topology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Measurable/Topological Sapces
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../01-Sets-Functions/013-measurable-continuous-functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Measurability/Continuity
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Measure Theory, Construction
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Measure Theory, Construction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-Measure/020-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-Measure/021-measure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Measures
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-Measure/022-semi-ring-to-ring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    From Semi-Ring to Ring
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-Measure/023-ring-to-s-algebra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    From Ring to $\sigma$-Algebra
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Expectation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Expectation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-Integration/030-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction/Notations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-Integration/031-expectation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Expectation, Lebesgue's Convergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-Integration/032-lp-spaces-inequalities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    $L^p$-Spaces and Classical Inequalities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-Integration/033-radon-nikodym-cond-exp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Radon-Nykodym and Conditional Expectation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-Integration/034-independence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Independence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-Integration/035-fubini-tonelli/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fubini-Tonelli
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-Integration/036-uniform-integrability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Uniform Integrability
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Discrete Time Stochastic Processes, Martingales
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            Discrete Time Stochastic Processes, Martingales
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../04-Martingales/040-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../04-Martingales/041-discrete-time-processes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discrete Time Processes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../04-Martingales/042-martingale-doob/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Martingales
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../04-Martingales/043-martingale-as-convergence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Martingales Almost Sure Convergence
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../04-Martingales/044-martingale-lp-convergence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Martingales $L^p$ Convergence
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Markov Processes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            Markov Processes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-Markov/050-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-Markov/051-markov-extension/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markov Processes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-Markov/052-markov-discrete/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Markov Chains
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05-Markov/053-brownian/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Brownian Motion
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="expected-shortfall">Expected Shortfall</h1>
<p>We have thus far explored the fundamentals of risk assessment, focusing on the key principles it must satisfy to achieve sound quantification: <strong>monotonicity</strong>, <strong>diversification</strong>, and, for financial purposes, <strong>cash-invariance</strong>. This foundation has enabled us to highlight the fundamental flaws of mean-variance analysis and value at risk (VaR) in meeting these criteria. However, from a practical standpoint, we are still far from identifying a fully satisfactory approach.</p>
<p>When considering a risk quantification instrument <span class="arithmatex">\( R \)</span>, the following points are crucial:</p>
<ol>
<li><strong>Soundness:</strong> The instrument <span class="arithmatex">\( R \)</span> must satisfy the properties of <strong>diversification</strong> and <strong>monotonicity</strong> to ensure robust risk quantification.</li>
<li><strong>Understandability:</strong> <span class="arithmatex">\( R \)</span> should be intuitively comprehensible from a financial perspective, even for individuals not deeply versed in the intricacies of mathematics. Ultimately, you need to convince your boss, the regulator, and the public that the methodology you employ is sensible and reliable.</li>
<li><strong>Implementability:</strong> The computation of <span class="arithmatex">\( R \)</span> must be feasible. At the end of the day, you need to produce a quantifiable result. This means it should be possible to create a programmatic function, based on available data, to compute the value of your risk measure (prototyping).</li>
<li><strong>Efficiency and Robustness:</strong> The implementation of <span class="arithmatex">\( R \)</span> should meet industry standards—being fast, reliable, and free of bugs. Risk computations are not a one-time experiment; they need to be conducted daily. Large financial institutions, by regulatory requirement, must aggregate and assess vast and complex positions to provide timely results on a daily basis.</li>
</ol>
<p>As for now, our focus has been primarily on the first point—establishing the groundwork for soundness.
However, the other points are equally vital in practice.
Since the 2008 financial crisis, the shortcomings of value at risk (VaR) have been widely acknowledged.
While these shortcomings (particularly related to soundness) were long known to academics, addressing the other points took time before a new industry standard could emerge.
This standard is the <strong>expected shortfall</strong> (also known under equivalent terms such as <strong>average value at risk</strong> or <strong>conditional value at risk</strong>).</p>
<h2 id="expected-shortfall_1">Expected Shortfall</h2>
<p>As the main issue of value at risk being the fact that it only provides information at one point of the CDF and being blind beyond it, the idea is to consider the tail beyond value at risk</p>
<div class="admonition definition">
<p class="admonition-title">Definition: Expected Shortfall</p>
<p>The expected shortfall of a random variable (integrable) at level <span class="arithmatex">\(\alpha\)</span> is defined as</p>
<div class="arithmatex">\[
    ES_{\alpha}(L) = \frac{1}{\alpha}\int_0^\alpha V@R_{s}(L) ds = \frac{1}{\alpha}\int_{1-\alpha}^1 q_L(s) ds
\]</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <strong>Expected Shortfall (ES)</strong> was introduced by Artzner, Delbaen, Eber, and Heath in 1999 to address the shortcomings of Value at Risk (V@R).
Expected Shortfall is known by several other names (with equivalent definitions, modulo some subtleties), including:  </p>
<ul>
<li><strong>Average Value at Risk (AV@R)</strong>,  </li>
<li><strong>Conditional Value at Risk (CV@R)</strong>,  </li>
<li><strong>Expected Tail Loss (ETL)</strong>, and  </li>
<li><strong>Superquantile</strong>.</li>
</ul>
</div>
<p><img alt="Expected Shortfall" src="../../../images/ES_dark.svg#only-dark" />
<img alt="Expected Shortfall" src="../../../images/ES_white.svg#only-light" /></p>
<p>As shown in the figure, the <strong>expected shortfall (ES)</strong> addresses the shortcomings of <strong>value at risk (V@R)</strong> by considering the loss area beyond V@R.
Specifically, if two loss distributions, <span class="arithmatex">\( \tilde{L} \)</span> and <span class="arithmatex">\( L \)</span>, share the same V@R but <span class="arithmatex">\( \tilde{L} \)</span> exhibits larger losses beyond the V@R (i.e., has fatter tails than <span class="arithmatex">\( L \)</span>), then—even with identical V@R values—the expected shortfall (the area beyond V@R) of <span class="arithmatex">\( \tilde{L} \)</span> will exceed that of <span class="arithmatex">\( L \)</span>.</p>
<p>This observation addresses the second point on our wish list, as ES naturally rectifies V@R's limitations regarding tail risk.
However, it does not resolve the first issue on our list.
Specifically, while it is clear that V@R fails to satisfy <strong>diversification</strong>, it remains puzzling why ES should satisfy this property.
The desirable properties of V@R—<strong>monotonicity</strong>, <strong>law invariance</strong>, <strong>cash-invariance</strong>, and <strong>positive homogeneity</strong>—extend to ES through its integral formulation.
However, since V@R is not convex, it is unclear why ES should exhibit convexity based on this representation.</p>
<p>Furthermore, while this formulation satisfies the third point (as ES is computed as an integral of a quantifiable object), doubts remain about its efficiency.
Calculating the integral of the quantile involves evaluating numerous quantiles between <span class="arithmatex">\( 1-\alpha \)</span> and <span class="arithmatex">\( 1 \)</span>, which is computationally intensive and prone to error.
This challenge is especially pronounced for extreme quantiles (e.g., <span class="arithmatex">\( 99.999\% \)</span> or <span class="arithmatex">\( 99.99999\% \)</span>), where sampling the distribution in highly unlikely regions becomes unstable.</p>
<p>To address these issues, we now explore another class of risk assessment instruments introduced by operations research scientists Ben-Tal and Teboulle: the <strong>optimized certainty equivalent</strong>.</p>
<h2 id="optimized-certainty-equivalent">Optimized Certainty Equivalent</h2>
<p>At the core of the definition of the optimized certainty equivalent is a special penalization function called loss function.</p>
<div class="grid cards">
<ul>
<li>
<div class="admonition definition">
<p class="admonition-title">Definition: Loss Function</p>
<p>A function <span class="arithmatex">\(\ell \colon \mathbb{R} \to \mathbb{R}\)</span> is called a loss function if</p>
<ul>
<li><span class="arithmatex">\(\ell\)</span> is convex</li>
<li><span class="arithmatex">\(\ell\)</span> is increasing    </li>
<li>
<p class="annotate"><span class="arithmatex">\(\ell(0) = 0\)</span> and <span class="arithmatex">\(\ell^\prime(0) = 1\)</span>(1)</p>
<ol>
<li>Note that <span class="arithmatex">\(\ell\)</span> does not necessarily need to be differentiable such as <span class="arithmatex">\(\ell(x) = x^+/\alpha\)</span> for <span class="arithmatex">\(0&lt; \alpha &lt;1\)</span>. It just needs to have <span class="arithmatex">\(\ell^{\prime}_-(0) \leq 1 \leq \ell^\prime_+(0)\)</span> where <span class="arithmatex">\(\ell_-^\prime\)</span> and <span class="arithmatex">\(\ell^\prime_+\)</span> are the left and right derivative that always exists for convex functions.</li>
</ol>
</li>
<li>
<p><span class="arithmatex">\(\lim_{x \to \infty}\ell(x)/x &gt;1\)</span> and <span class="arithmatex">\(\lim_{x \to -\infty} \ell(x)/x &lt;1\)</span>.</p>
</li>
</ul>
</div>
<p>Classical examples following this definition</p>
<ul>
<li><em>piecewise linear:</em> <span class="arithmatex">\(\ell(x)= x^+/ \alpha\)</span> with <span class="arithmatex">\(0&lt; \alpha &lt;1\)</span>;</li>
<li><em>quadratic:</em> <span class="arithmatex">\(\ell(x)=x^++(x^+)^2/2\)</span>;</li>
<li><em>exponential:</em> <span class="arithmatex">\(\ell(x)=e^x-1\)</span></li>
</ul>
</li>
</ul>
<p class="card"><img align="align" alt="Loss Functions" src="../../../images/loss_dark.svg#only-dark" />
<img align="align" alt="Loss Functions" src="../../../images/loss_white.svg#only-light" /></p>
</div>
<p>The loss function penalizes a loss (losses are considered positive in our case) <span class="arithmatex">\( x \geq 0 \)</span> by assigning a value <span class="arithmatex">\( \ell(x) \geq x \)</span>.
For gains (negative values), it also penalizes by assigning an amount smaller than the gain itself.</p>
<p>Thus, given a loss profile <span class="arithmatex">\( L \)</span>, you compute <span class="arithmatex">\( E[\ell(L)] \geq E[L] \)</span>, which represents the penalized loss estimation of the loss profile.
The idea introduced by Ben-Tal and Teboulle is to reduce the value of these penalized losses by allocating some cash <span class="arithmatex">\( m \)</span>, transitioning from <span class="arithmatex">\( E[\ell(L)] \)</span> to <span class="arithmatex">\( E[\ell(L-m)] \)</span>.
However, in terms of total costs, you must account for the cash allocated, leading to the total cost valuation:</p>
<div class="arithmatex">\[
m + E[\ell(L-m)].
\]</div>
<p>With the decision variable being the amount of cash allocated, minimizing the total cost gives rise to the definition of the <strong>optimized certainty equivalent</strong>.</p>
<div class="admonition definition">
<p class="admonition-title">Definition: Optimized Certainty Equivalent</p>
<p>Given a loss function <span class="arithmatex">\( \ell \)</span>, the <strong>optimized certainty equivalent</strong> <span class="arithmatex">\( R \)</span> of a bounded random variable (under appropriate integrability conditions) is defined as:</p>
<div class="arithmatex">\[
  R(L) = \inf \left\{ m + E\left[ \ell(L - m) \right] \colon m \in \mathbb{R} \right\}.
\]</div>
</div>
<div class="admonition proposition">
<p class="admonition-title">Proposition</p>
<p>Given a loss function <span class="arithmatex">\( \ell \)</span>, the optimized certainty equivalent <span class="arithmatex">\( R \)</span> is a <strong>cash-invariant</strong> and <strong>law-invariant</strong> risk measure.</p>
<p>Furthermore, it holds that:</p>
<div class="arithmatex">\[
  R(L) = m^\ast + E\left[ \ell(L - m^\ast) \right],
\]</div>
<p class="annotate">where: (1)<br /></p>
<ol>
<li>
<p>If <span class="arithmatex">\( \ell \)</span> is not differentiable at <span class="arithmatex">\( 0 \)</span>, the condition changes to:</p>
<div class="arithmatex">\[
E[\ell^\prime_-(L-m^\ast)] \leq 1 \leq E\left[ \ell^\prime_+(L-m^\ast) \right],
\]</div>
</li>
</ol>
<div class="arithmatex">\[
    E[\ell^\prime(L - m^\ast)] = 1.
\]</div>
</div>
<details class="proof">
<summary>Proof</summary>
<p>We show that <span class="arithmatex">\( R \)</span>, as defined, is <strong>monotone</strong>, <strong>cash-invariant</strong>, and <strong>convex</strong>.</p>
<ul>
<li>
<p><strong>Monotonicity:</strong> 
    Suppose <span class="arithmatex">\( L_1(\omega) \geq L_2(\omega) \)</span> for all <span class="arithmatex">\( \omega \)</span>.
    Since <span class="arithmatex">\( \ell \)</span> is increasing:</p>
<div class="arithmatex">\[
    m + \ell\left( L_1 - m \right) \geq m + \ell\left( L_2 - m \right).
\]</div>
<p>Taking the expectation:</p>
<div class="arithmatex">\[
    m + E\left[\ell\left( L_1 - m \right)\right] \geq m + E\left[\ell\left( L_2 - m \right)\right].
\]</div>
<p>Since <span class="arithmatex">\( m + E[\ell(L_2 - m)] \geq R(L_2) \)</span>, it follows that:</p>
<div class="arithmatex">\[
    m + E\left[\ell\left( L_1 - m \right)\right] \geq R(L_2).
\]</div>
<p>Taking the infimum over <span class="arithmatex">\( m \)</span> yields:</p>
<div class="arithmatex">\[
    R(L_1) = \inf\left\{ m + E\left[\ell\left( L_1 - m \right)\right] \colon m \in \mathbb{R} \right\} \geq R(L_2).
\]</div>
</li>
<li>
<p><strong>Cash-Invariance:</strong>
    Let <span class="arithmatex">\( m \in \mathbb{R} \)</span>.
    Then:</p>
<div class="arithmatex">\[
    \begin{align*}
        R(L - m) &amp; = \inf\left\{ \tilde{m} + E\left[\ell\left( L - m - \tilde{m} \right)\right] \colon \tilde{m} \in \mathbb{R} \right\} \\
            &amp; = \inf\left\{ \hat{m} - m + E\left[\ell\left( L - \hat{m} \right)\right] \colon \hat{m} \in \mathbb{R} \right\} \quad \text{(change of variable \( \hat{m} = m + \tilde{m} \))} \\
            &amp; = R(L) - m.
    \end{align*}
\]</div>
</li>
<li>
<p><strong>Convexity:</strong>
  Let <span class="arithmatex">\( L_1 \)</span> and <span class="arithmatex">\( L_2 \)</span> be two loss profiles, and <span class="arithmatex">\( 0 \leq \lambda \leq 1 \)</span>.
    For <span class="arithmatex">\( m_1, m_2 \in \mathbb{R} \)</span>, define <span class="arithmatex">\( m = \lambda m_1 + (1-\lambda)m_2 \)</span> and <span class="arithmatex">\( L = \lambda L_1 + (1-\lambda)L_2 \)</span>.
    Since <span class="arithmatex">\( \ell \)</span> is convex:</p>
<div class="arithmatex">\[
    m + \ell(L - m) \leq \lambda\left( m_1 + E\left[ \ell(L_1 - m_1) \right] \right) + (1-\lambda)\left( m_2 + E[\ell(L_2 - m_2)] \right).
\]</div>
<p>Since <span class="arithmatex">\( R(L) \leq m + E[\ell(L - m)] \)</span>, taking the infimum over <span class="arithmatex">\( m_1 \)</span> and <span class="arithmatex">\( m_2 \)</span> sequentially yields:</p>
<div class="arithmatex">\[
    R(\lambda L_1 + (1-\lambda)L_2) = R(L) \leq \lambda R(L_1) + (1-\lambda)R(L_2).
\]</div>
</li>
<li>
<p><strong>Law-Invariance:</strong>
  Law-invariance follows directly, as <span class="arithmatex">\( R \)</span> depends only on the expectation <span class="arithmatex">\( E[\ell(\cdot)] \)</span>, which depends on the CDF of <span class="arithmatex">\( L \)</span>.</p>
</li>
</ul>
<p>To show the final assertion:
Define:</p>
<div class="arithmatex">\[
    g(m) = m + E\left[ \ell(L - m) \right],
\]</div>
<p>for which <span class="arithmatex">\( R(L) = \inf g(m) \)</span>.
Since <span class="arithmatex">\( \ell \)</span> is convex, <span class="arithmatex">\( g \)</span> is also convex.
It follows from <span class="arithmatex">\(\ell\)</span> being increasing and the asymptotic assumptions on <span class="arithmatex">\(\ell\)</span> that <span class="arithmatex">\(\ell(x) \geq a_1 x -c_1\)</span> for <span class="arithmatex">\(x\)</span> positively large enough with <span class="arithmatex">\(a_1&gt;1\)</span> and <span class="arithmatex">\(\ell(x)\geq a_2 x -c_2\)</span> for <span class="arithmatex">\(x\)</span> negatively large enough and <span class="arithmatex">\(a_2&lt;1\)</span>.
Since <span class="arithmatex">\(L\)</span> is bounded, it follows that for <span class="arithmatex">\(m\)</span> positively large enough (more than the bounds of <span class="arithmatex">\(L\)</span> at least) we have</p>
<div class="arithmatex">\[
    g(m) = m + E[\ell(L-m)] \geq m + a_2E\left[ L -m \right] - c_2 = \underbrace{(1-a_2)}_{&gt;0} \underbrace{m}_{&gt;0} + a_2 E[L] - c_2 \xrightarrow[m \to \infty]{} \infty
\]</div>
<p>The same argumentation for large enough negative values of <span class="arithmatex">\(m\)</span> yields</p>
<div class="arithmatex">\[
    g(m) = m + E[\ell(L-m)] \geq m + a_1E\left[ L -m \right] - c_1 = \underbrace{(1-a_1)}_{&lt;0} \underbrace{m}_{&lt;0} + a_1 E[L] - c_1 \xrightarrow[m \to -\infty]{} \infty
\]</div>
<p>All together, it shows that <span class="arithmatex">\(g(m) \to \infty\)</span> for <span class="arithmatex">\(m\to \pm \infty\)</span>, that is, in mathematical terms, <span class="arithmatex">\(g\)</span> is coercive.</p>
<p><img align="align" alt="Minimum convex" src="../../../images/ocefun_dark.svg#only-dark" />
<img align="align" alt="Minimum convex" src="../../../images/ocefun_white.svg#only-light" /></p>
<p>This ensures that <span class="arithmatex">\( g \)</span> attains its minimum at <span class="arithmatex">\( m^\ast \)</span>, satisfying the first-order condition:</p>
<div class="arithmatex">\[
    E\left[ \ell^\prime_-(L-m^\ast) \right] \leq 1 \leq E\left[ \ell^\prime_+(L-m^\ast) \right].
\]</div>
<p>If <span class="arithmatex">\( \ell \)</span> is differentiable, this simplifies to:</p>
<div class="arithmatex">\[
    E\left[ \ell^\prime(L - m^\ast) \right] = 1.
\]</div>
<p>This completes the proof.</p>
</details>
<p>This proposition provides several key takeaways:</p>
<ol>
<li>The optimized certainty equivalent (OCE) is a risk measure independent of the specific definition of <span class="arithmatex">\( \ell \)</span>, as long as <span class="arithmatex">\( \ell \)</span> is a valid loss function.  </li>
<li>By its definition and the convexity of the problem, the computation of OCE is straightforward, reducing to a one-dimensional unconstrained convex optimization problem. This allows for the application of efficient, state-of-the-art algorithms.  </li>
<li>The simplicity of this optimization problem allows for circumventing classical gradient descent by providing an explicit expression for the first-order condition.</li>
</ol>
<div class="admonition example">
<p class="admonition-title">The Exponential Function: Entropic Risk Measure</p>
<p>Consider the loss function <span class="arithmatex">\( \ell(x) = (e^{\gamma x} - 1)/\gamma \)</span>.
By the first-order condition:</p>
<div class="arithmatex">\[
  1 = E[\ell^\prime(L-m^\ast)] = E[e^{\gamma (L - m^\ast)}] = e^{-\gamma m^\ast}E\left[ e^{\gamma L} \right].
\]</div>
<p>Solving for <span class="arithmatex">\( m^\ast \)</span>:</p>
<div class="arithmatex">\[
  m^\ast = \frac{\ln\left(E[e^{\gamma L}]\right)}{\gamma}.
\]</div>
<p>Substituting <span class="arithmatex">\( m^\ast \)</span> back into <span class="arithmatex">\( R \)</span> yields:</p>
<div class="arithmatex">\[
  R(L) = \frac{1}{\gamma} \ln \left( E\left[ e^{\gamma L} \right] \right).
\]</div>
<p>Hence, for the exponential loss function, the OCE can be computed explicitly, and the resulting risk measure is known as the <strong>entropic risk measure</strong>.  </p>
<p>While this measure is prevalent in other domains (e.g., statistical mechanics, physics, and machine learning) and is computationally efficient, it is unsuitable as a financial risk measure.
The exponential penalization assigns extremely high values to large losses, making it impractical for scenarios with rare but severe losses.  </p>
<p>For example, consider the loss profile:</p>
<div class="arithmatex">\[
  \begin{cases}
      1,000,000,000 &amp; \text{with probability } 0.00001, \\
      -10,000 &amp; \text{otherwise}.
  \end{cases}
\]</div>
<p>Despite the low probability of the extreme loss, the exponential penalization makes the risk computation infeasible due to numerical instability and even with exact values, the resulting risk would be stratospherical.</p>
</div>
<div class="admonition example">
<p class="admonition-title">The Piecewise Linear Function</p>
<p>The exponential function example demonstrates how a strong penalization can lead to explicit representations but may not be practical for financial risk measures.
Let us now consider the opposite extreme: a function that penalizes less, specifically a <strong>piecewise linear loss function</strong>:</p>
<div class="arithmatex">\[
    \ell(x) = \frac{1}{\alpha}x^+,
\]</div>
<p>where <span class="arithmatex">\( 0 &lt; \alpha &lt; 1 \)</span>.  </p>
<p>Since <span class="arithmatex">\( \ell \)</span> is not differentiable, the characterization uses the left and right derivatives:</p>
<div class="arithmatex">\[
  \ell_-^\prime(x) = \frac{1}{\alpha} 1_{(0, \infty)}(x) = 
      \begin{cases}
        \frac{1}{\alpha} &amp; x &gt; 0, \\
        0 &amp; \text{otherwise}.
      \end{cases}
  \quad \text{and} \quad
  \ell_+^\prime(x) = \frac{1}{\alpha} 1_{[0, \infty)}(x) = 
      \begin{cases}
        \frac{1}{\alpha} &amp; x \geq 0, \\
        0 &amp; \text{otherwise}.
      \end{cases}
\]</div>
<p>Applying the first-order condition:</p>
<div class="arithmatex">\[
  E[\ell^\prime_-(L-m^\ast)] \leq 1 \leq E[\ell^\prime_+(L-m^\ast)].
\]</div>
<p>Substituting the derivatives:</p>
<div class="arithmatex">\[
  \frac{1}{\alpha}P[L &gt; m^\ast] \leq 1 \leq \frac{1}{\alpha}P[L \geq m^\ast].
\]</div>
<p>This simplifies to:</p>
<div class="arithmatex">\[
  P[L &lt; m^\ast] \leq 1-\alpha \leq P[L \leq m^\ast].
\]</div>
<p>Thus, <span class="arithmatex">\( m^\ast \)</span> is the <span class="arithmatex">\( 1-\alpha \)</span> quantile of <span class="arithmatex">\( L \)</span>:</p>
<div class="arithmatex">\[
  m^\ast = q_L(1-\alpha) = V@R_{\alpha}(L).
\]</div>
<p>Therefore, for the piecewise linear loss function:</p>
<div class="arithmatex">\[
    R(L) = \inf\left\{ m + \frac{1}{\alpha}E\left[ (L-m)^+ \right] \right\} = V@R_{\alpha}(L) + \frac{1}{\alpha}E\left.
\]</div>
</div>
<h2 id="expected-shortfall-and-optimized-certainty-equivalent">Expected Shortfall and Optimized Certainty Equivalent</h2>
<p>On one hand, we previously noted that it is not entirely clear how to show that <strong>Expected Shortfall (ES)</strong> is a risk measure when derived as the integral of V@R.
On the other hand, the optimized certainty equivalent (OCE) with a piecewise linear loss function shows some structural similarities to V@R.
It turns out that these two concepts are strongly connected, as demonstrated by the following proposition:</p>
<div class="admonition proposition">
<p class="admonition-title">Proposition</p>
<p>For bounded loss profiles (or even integrable ones), the <strong>Expected Shortfall</strong> with confidence level <span class="arithmatex">\( 0 &lt; \alpha &lt; 1 \)</span> coincides with the optimized certainty equivalent using a piecewise linear loss function with a factor of <span class="arithmatex">\( 1/\alpha \)</span>.  </p>
<p>In other words:</p>
<div class="arithmatex">\[
  ES_{\alpha}(L) = \frac{1}{\alpha}\int_{0}^\alpha V@R_{s}(L)ds = \inf \left\{ m +\frac{1}{\alpha}E[(L-m)^+] \colon m \in \mathbb{R} \right\} = V@R_{\alpha}(L) + \frac{1}{\alpha}E\left.
\]</div>
<p>In particular, Expected Shortfall is a <strong>cash-invariant</strong> and <strong>law-invariant</strong> risk measure.</p>
</div>
<p>This remarkable result addresses the key questions about ES: it confirms that ES is a sound risk measure and provides a computationally efficient approach.
Instead of directly computing the integral of the quantile (which can be computationally intensive and error-prone), ES can be expressed as the sum of V@R (already an industry standard) and the expected loss beyond V@R, which can be computed easily either using the PDF of <span class="arithmatex">\( L \)</span> or Monte Carlo methods with importance sampling.</p>
<details class="proof">
<summary>Proof</summary>
<p>The connection between ES and OCE arises from the fact that the quantile function <span class="arithmatex">\( q_L(s) \)</span> of <span class="arithmatex">\( L \)</span> shares the same CDF as <span class="arithmatex">\( L \)</span> itself.
Formally, given a loss profile (random variable) <span class="arithmatex">\( L \)</span> with CDF <span class="arithmatex">\( F_L(m) = P[L \leq m] \)</span> and quantile function <span class="arithmatex">\( q_L(s) = \inf\{m \colon F_L(m)\geq s\} \)</span>, the quantile <span class="arithmatex">\( q_L(s) \)</span> can be viewed as a random variable defined on the probability space <span class="arithmatex">\( (\tilde{\Omega}, \tilde{\mathcal{F}}, \tilde{P}) \)</span>, where:</p>
<ul>
<li><span class="arithmatex">\( \tilde{\Omega} = (0,1) \)</span>,  </li>
<li><span class="arithmatex">\( \tilde{\mathcal{F}} \)</span> is the <span class="arithmatex">\( \sigma \)</span>-algebra generated by intervals of <span class="arithmatex">\((0,1)\)</span>, and  </li>
<li><span class="arithmatex">\( \tilde{P} \)</span> is the Lebesgue measure <span class="arithmatex">\( dx \)</span> (the measure of interval lengths).</li>
</ul>
<p>It can be shown that <span class="arithmatex">\( q_L(s) \)</span> has the same CDF as <span class="arithmatex">\( L \)</span>, i.e., <span class="arithmatex">\( F_{q_L}(m) = F_L(m) \)</span>.
Indeed, by the definition of <span class="arithmatex">\( q_L(s) \)</span>:</p>
<div class="arithmatex">\[
(0, F_L(m)) \subseteq \{s \colon q_L(s) \leq m\} \subseteq (0, F_L(m)],
\]</div>
<p>and under <span class="arithmatex">\( \tilde{P} \)</span>, these sets yield:</p>
<div class="arithmatex">\[
    F_L(m) = \tilde{P}[(0, F_L(m))] \leq \tilde{P}[q_L \leq m] \leq \tilde{P}[(0, F_L(m)]] = F_L(m).
\]</div>
<p>Therefore, <span class="arithmatex">\( F_{q_L}(m) = F_L(m) \)</span>.</p>
<p>Using this fact, and noting that <span class="arithmatex">\( q_L(s) \geq q_L(1-\alpha) \)</span> for <span class="arithmatex">\( s \geq 1-\alpha \)</span>:</p>
<div class="arithmatex">\[
\begin{align*}
  ES_{\alpha}(L) &amp; = \frac{1}{\alpha} \int_{0}^\alpha V@R_{s}ds \\
    &amp; = \frac{1}{\alpha} \int_{1-\alpha}^1 q_L(s) ds \\
    &amp; = q_L(1-\alpha) + \frac{1}{\alpha}\int_{1-\alpha}^1 \left( q_L(s) - q_{L}(1-\alpha) \right)ds \\
    &amp; = V@R_{\alpha}(L) + \frac{1}{\alpha}\int_{\mathbb{R}} \left( m - V@R_{\alpha}(L) \right)^+ dF_{q_L}(m) \\
    &amp; = V@R_{\alpha}(L) + \frac{1}{\alpha}\int_{\mathbb{R}} \left( m - V@R_{\alpha}(L) \right)^+ dF_{L}(m) \\
    &amp; = V@R_{\alpha}(L) + \frac{1}{\alpha}E \left.
\end{align*}
\]</div>
</details>
<div class="admonition remark">
<p class="admonition-title">Remark on the Distribution of the Quantile and Random Sampling</p>
<p>This kind of <em>magic trick</em> to show the relationship between the piecewise linear optimized certainty equivalent and the expected shortfall relies on the fundamental fact that the distribution of a random variable <span class="arithmatex">\(X\)</span> on some probability space <span class="arithmatex">\((\Omega, \mathcal{F}, P)\)</span> is the same as the distribution of its quantile <span class="arithmatex">\(q_X\)</span> on <span class="arithmatex">\((\tilde{\Omega}, \tilde{\mathcal{F}}, \tilde{P})\)</span> where <span class="arithmatex">\(\tilde{\Omega} = (0,1)\)</span>, <span class="arithmatex">\(\tilde{F} = \mathcal{B}((0,1))\)</span> the <span class="arithmatex">\(\sigma\)</span>-algebra generated by intervals and <span class="arithmatex">\(\tilde{P}\)</span> is the lebesgue measure <span class="arithmatex">\(dx\)</span> that measure interval length, that it <span class="arithmatex">\(\tilde{P}[(a, b]] = b-a\)</span>.</p>
<p>This result is widely known and extensively used, particularly for random sampling.
Suppose you want to sample <span class="arithmatex">\( x_1, \ldots, x_N \)</span> from the distribution of a random variable <span class="arithmatex">\( X \)</span> (e.g., normal, Student's t, gamma).
A computer, however, generates (quasi-)random numbers <span class="arithmatex">\( u_1, \ldots, u_N \)</span> uniformly distributed between <span class="arithmatex">\( 0 \)</span> and <span class="arithmatex">\( 1 \)</span>.
By the equivalence between the distributions of <span class="arithmatex">\( X \)</span> and <span class="arithmatex">\( q_X \)</span>, defining <span class="arithmatex">\( x_n = q_X(u_n) \)</span> for <span class="arithmatex">\( n = 1, \ldots, N \)</span> produces a random sample <span class="arithmatex">\( x_1, \ldots, x_N \)</span> from the distribution of <span class="arithmatex">\( X \)</span>.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>      <span class="c1"># (1)</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">plotly.graph_objs</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">go</span>    <span class="c1"># (2)</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>             <span class="c1"># uniform sample</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="n">x0</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>                  <span class="c1"># quantile of normal distribution of u</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="n">x1</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>             <span class="c1"># sample from normal</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="c1"># Plot the two histograms</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="n">fig</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">x</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">histnorm</span><span class="o">=</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Quantile of Uniform Sample&#39;</span><span class="p">,</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="p">)</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="n">fig</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">x</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">histnorm</span><span class="o">=</span><span class="s1">&#39;probability&#39;</span><span class="p">,</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Standard Normal Sample&#39;</span><span class="p">,</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="p">)</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></div>
<ol>
<li>The <code>scipy.stats</code> library provides access to many distributions, including their <code>cdf</code>, <code>pdf</code>, and <code>ppf</code> (quantile function).  </li>
<li><code>plotly</code> is used here for plotting; alternatively, <code>matplotlib</code> can be used.</li>
</ol>
<p>This principle underpins <strong>Monte Carlo integration</strong>, where the goal is to compute <span class="arithmatex">\( E[f(X)] \)</span>.
By the <em>law of large numbers</em> and the <em>central limit theorem</em>, it holds that:</p>
<div class="arithmatex">\[
    \frac{1}{N}\sum_{n=1}^N f(x_n) \xrightarrow[N \to \infty]{} E[f(X)],
\]</div>
<p>where <span class="arithmatex">\( x_1, \ldots, x_N \)</span> is a random sample from the distribution of <span class="arithmatex">\( X \)</span>.
In practice, a random sample <span class="arithmatex">\( u_1, \ldots, u_N \)</span> is drawn from a uniform distribution on <span class="arithmatex">\( (0, 1) \)</span>, and then <span class="arithmatex">\( x_n = q_X(u_n) \)</span> is computed and used in the arithmetic mean of <span class="arithmatex">\( f(x_n) \)</span> for <span class="arithmatex">\( n = 1, \ldots, N \)</span>.</p>
</div>
<p>As of now, we know that <strong>Expected Shortfall (ES)</strong> is a sound risk measure: it is understandable, implementable, and, due to its representation, efficient to compute.
Prior to the introduction of ES, financial institutions commonly computed <span class="arithmatex">\( V@R \)</span>.
To transition to ES, they only need to compute the additional term <span class="arithmatex">\( E/\alpha \)</span>, which is computationally efficient (either analytically or via Monte Carlo methods).</p>
<p>The computation of ES in simple cases is demonstrated below:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span><span class="p">,</span> <span class="n">t</span>       <span class="c1"># Normal and Student&#39;s t distributions</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">root</span>       <span class="c1"># Root finding</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.integrate</span><span class="w"> </span><span class="kn">import</span> <span class="n">quad</span>      <span class="c1"># One-dimensional integration</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="kn">import</span><span class="w"> </span><span class="nn">plotly.graph_objs</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">go</span>        <span class="c1"># Plotting library</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="c1"># Define the basic computation of the quantile (X is a random variable)</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="k">def</span><span class="w"> </span><span class="nf">quantile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fun</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">-</span> <span class="n">s</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">root</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Find the root</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="c1"># Compute ES using the integral of quantile representation</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="k">def</span><span class="w"> </span><span class="nf">ES1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fun</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>        <span class="k">return</span> <span class="n">quantile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>    <span class="n">result</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">quad</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Integrate quantile between 1-alpha and 1</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    <span class="k">return</span> <span class="n">result</span> <span class="o">/</span> <span class="n">alpha</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a><span class="c1"># Compute ES using the OCE representation</span>
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a><span class="k">def</span><span class="w"> </span><span class="nf">ES2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>    <span class="n">var</span> <span class="o">=</span> <span class="n">quantile</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span>
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="__span-1-25"><a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>        <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">var</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-1-26"><a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>    <span class="n">result</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">quad</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span><span class="p">)</span>  <span class="c1"># Integrate beyond V@R</span>
</span><span id="__span-1-27"><a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>    <span class="k">return</span> <span class="n">var</span> <span class="o">+</span> <span class="n">result</span> <span class="o">/</span> <span class="n">alpha</span>
</span><span id="__span-1-28"><a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>
</span><span id="__span-1-29"><a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a><span class="c1"># Define distributions</span>
</span><span id="__span-1-30"><a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a><span class="n">X1</span> <span class="o">=</span> <span class="n">norm</span>
</span><span id="__span-1-31"><a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a><span class="n">X2</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Student&#39;s t distribution with df=2 (variance = 1)</span>
</span><span id="__span-1-32"><a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>
</span><span id="__span-1-33"><a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># Confidence level (1%)</span>
</span><span id="__span-1-34"><a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>
</span><span id="__span-1-35"><a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a><span class="c1"># Display results</span>
</span><span id="__span-1-36"><a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
</span><span id="__span-1-37"><a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a><span class="s2">V@R (Normal):</span><span class="se">\t</span><span class="si">{</span><span class="n">quantile</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="si">}</span>
</span><span id="__span-1-38"><a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a><span class="s2">ES (slow, Normal):</span><span class="se">\t</span><span class="si">{</span><span class="n">ES1</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="si">}</span>
</span><span id="__span-1-39"><a id="__codelineno-1-39" name="__codelineno-1-39" href="#__codelineno-1-39"></a><span class="s2">ES (fast, Normal):</span><span class="se">\t</span><span class="si">{</span><span class="n">ES2</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="si">}</span>
</span><span id="__span-1-40"><a id="__codelineno-1-40" name="__codelineno-1-40" href="#__codelineno-1-40"></a>
</span><span id="__span-1-41"><a id="__codelineno-1-41" name="__codelineno-1-41" href="#__codelineno-1-41"></a><span class="s2">V@R (Student):</span><span class="se">\t</span><span class="si">{</span><span class="n">quantile</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="si">}</span>
</span><span id="__span-1-42"><a id="__codelineno-1-42" name="__codelineno-1-42" href="#__codelineno-1-42"></a><span class="s2">ES (slow, Student):</span><span class="se">\t</span><span class="si">{</span><span class="n">ES1</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="si">}</span>
</span><span id="__span-1-43"><a id="__codelineno-1-43" name="__codelineno-1-43" href="#__codelineno-1-43"></a><span class="s2">ES (fast, Student):</span><span class="se">\t</span><span class="si">{</span><span class="n">ES2</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="si">}</span>
</span><span id="__span-1-44"><a id="__codelineno-1-44" name="__codelineno-1-44" href="#__codelineno-1-44"></a><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</span><span id="__span-1-45"><a id="__codelineno-1-45" name="__codelineno-1-45" href="#__codelineno-1-45"></a>
</span><span id="__span-1-46"><a id="__codelineno-1-46" name="__codelineno-1-46" href="#__codelineno-1-46"></a><span class="c1"># Exercise:</span>
</span><span id="__span-1-47"><a id="__codelineno-1-47" name="__codelineno-1-47" href="#__codelineno-1-47"></a><span class="c1"># Compare and plot the differences between V@R and ES for Normal and Student&#39;s t distributions for 0.0001 &lt; alpha &lt; 0.05.</span>
</span><span id="__span-1-48"><a id="__codelineno-1-48" name="__codelineno-1-48" href="#__codelineno-1-48"></a><span class="c1"># Use %timeit to compare the computation times of ES1 and ES2.</span>
</span></code></pre></div>
<p>We saw that the expected shortfall has multiple representations, and simple transformations can yield additional formulations.</p>
<div class="admonition proposition">
<p>The expected shortfall has the following representations</p>
<div class="arithmatex">\[
  \begin{align*}
    ES_{\alpha}(L)  &amp; = \frac{1}{\alpha}\int_0^\alpha V@R_{s}(L)ds &amp;&amp; \text{Quantile representation}\\
                    &amp; = \inf\{m + \frac{1}{\alpha}E[(L-m)^+]\colon m \in \mathbb{R}\} &amp;&amp; \text{OCE representation}\\
                    &amp; = V@R_{\alpha}(L) + \frac{1}{\alpha}E\left \\
                    &amp; = \frac{1}{\alpha}\int_{V@R_{\alpha}(L)}^\infty x dF_L(x)
  \end{align*}
\]</div>
<p>Furthermore, the expected shortfall is positive homogeneous, that is</p>
<div class="arithmatex">\[ ES_{\alpha}(\lambda L) = \lambda ES_{\alpha}(L)\]</div>
<p>for every <span class="arithmatex">\(\lambda&gt;0\)</span>.
In particular <span class="arithmatex">\(ES_{\alpha}(L_1 + L_2)\leq ES_{\alpha}(L_1) + ES_{\alpha}(L_2)\)</span>.</p>
</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.tabs.link", "content.code.copy", "content.code.annotate", "navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "toc.follow", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="../../../javascripts/node_modules/mathjax/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>