{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Stochastics","text":"<p>These lecture notes, still a work in progress, are for a course taught at Shanghai Jiao Tong University, for graduate students.</p>"},{"location":"#course-objective","title":"Course Objective","text":"<p>This lecture aims at the evolution over time of systems that are subject to uncertainty: stochastic processes.</p> <p>Throughout this lecture we will address the following fundamental concepts:</p> <ul> <li>Probability: probability space, probability measure, expectation, measure change, conditional expectation, stochastic kernel, independence as well as fundamental inequalities and relations.</li> <li>Discrete Martingales: discrete stochastic processes, information, stopping times, martingales and related fundamental results (convergence, law of large numbers, etc.)</li> <li>Markov Processes: concept of memoryless stochastic processes, discrete time results, construction of the Brownian motion.</li> <li>Ito-Integral and Calculus: construction of the stochastic integral, Ito-formula, applications.</li> <li>Stochastic Exponential: measure change, Girsanov formula and applications</li> <li>Stochastic Differential Equations: existence and uniqueness, strong vs weak solutions, ...</li> <li>SDE and PDE: Relation between PDE and SDE, Kolmogorov equation, Feynman-Kak formula and applications.</li> </ul>"},{"location":"#concrete-approach","title":"Concrete Approach","text":"<p>The theoretical lecture combines blackboard lectures with practical applications. Lecture notes will be provided and updated during the course. The evaluation of the lecture will consists of </p> <ul> <li>Homework: Once every two weeks to be handed out within two weeks by groups of 5-6</li> <li>Quizz: 3-4 quizz, in class, 30 min about the past lectures.</li> <li>Final Exam: 120 min final exam at the end of the semester.</li> </ul>"},{"location":"#prerequisite","title":"Prerequisite","text":"<p>The lecture suppose that students knows about basic algebra, analysis. A previous knowledge about measure theory might be of help but nor necessary.</p>"},{"location":"#literature","title":"Literature","text":"<p>The lecture follows the present lecture notes. However those are inspired by uncountably many textbooks on the topic from which we present a short selection:</p> <ul> <li>Rick Durret<sup>1</sup>: Excellent introduction to discrete stochastic processes (markov processesw and martingales and Brownian motion). No stochastic integral and SDEs</li> <li>Steve Shreve<sup>2</sup><sup>3</sup>: Both books with a focus on Finance. The first one is discrete the second continuous and both approchable.</li> <li>Olav Kallenberg<sup>4</sup>: Complete from probability to stochastic processes. General stochastic processes.</li> <li>Philip Protter<sup>5</sup>: Complete about general stochastic processes (w/wo jumps). Complex.</li> <li>Delacherie and Meyer<sup>6</sup><sup>7</sup>: The bible however machine typed and French</li> </ul>"},{"location":"#references","title":"References","text":"<ol> <li> <p>Rick Durrett. Probability: Theory and Examples. Cambridge Series in Statistical and Probabilistic Mathematics, 2010.\u00a0\u21a9</p> </li> <li> <p>Steven E. Shreve. Stochastic Calculus for Finance. Volume I of Springer Finance. Springer-Verlag, New York, 2004. ISBN 0-387-40100-8. The binomial asset pricing model.\u00a0\u21a9</p> </li> <li> <p>Steven E. Shreve. Stochastic Calculus for Finance. Volume II of Springer Finance. Springer-Verlag, New York, 2004. ISBN 0-387-40101-6. Continuous-time models.\u00a0\u21a9</p> </li> <li> <p>Olav Kallenberg. Foundations of Modern Probability. Probability and its Applications (New York). Springer-Verlag, New York, 2nd edition, 2002.\u00a0\u21a9</p> </li> <li> <p>Philip E. Protter. Stochastic Integration and Differential Equations. Springer, 2nd edition, 2005.\u00a0\u21a9</p> </li> <li> <p>Claude Dellacherie and Paul-Andr\u00e9 Meyer. Probabilities and Potential. A. Volume 29 of North-Holland Mathematics Studies. North-Holland Publishing Co., Amsterdam, 1978. ISBN 0-7204-0701-X.\u00a0\u21a9</p> </li> <li> <p>Claude Dellacherie and Paul Andr\u00e9 Meyer. Probabilities and Potential. B. Volume 72 of North-Holland Mathematics Studies. North-Holland Publishing Co., Amsterdam, 1982.\u00a0\u21a9</p> </li> </ol>"},{"location":"javascripts/node_modules/mathjax/","title":"MathJax","text":""},{"location":"javascripts/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"javascripts/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"javascripts/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"javascripts/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\n  loader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\n  const svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\n  console.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"javascripts/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"javascripts/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"},{"location":"lecture/00-Introduction/000-notations/","title":"Notations","text":""},{"location":"lecture/00-Introduction/000-notations/#mathematical-notations","title":"Mathematical Notations","text":"<p>The following notations will be used throughout the course:</p> <ul> <li>Natural Numbers: \\(\\mathbb{N} = \\{1, 2, \\ldots\\}\\), \\(\\mathbb{N}_0 = \\{0, 1, 2, \\ldots\\}\\).</li> <li>Integers: \\(\\mathbb{Z} = \\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\)</li> <li>Rational Numbers: \\(\\mathbb{Q} = \\{ p/q\\colon p \\in \\mathbb{Z}, q \\in \\mathbb{N}\\}\\)</li> <li>Real Numbers: \\(\\mathbb{R}\\)</li> <li>Vectors in \\(\\mathbb{R}^d\\) are denoted in bold font, \\(\\boldsymbol{x} = (x^1, \\dots, x^d)\\), and are assumed to be column vectors.  </li> <li>Vectors with positive components \\(\\mathbb{R}^d_+ = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k \\geq 0, k=1,\\ldots,d\\}\\) and vectors with strictly positive components \\(\\mathbb{R}^d_{++} = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k &gt; 0, k=1,\\ldots,d\\}\\).  </li> <li>Scalar Product: \\(\\boldsymbol{x} \\cdot \\boldsymbol{y} := \\sum x_k y_k\\) denotes the scalar product of \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\) in \\(\\mathbb{R}^d\\).  </li> <li>\\(\\beta \\boldsymbol{x} := (\\beta x_1, \\ldots, \\beta x_d)\\) represents the multiplication of \\(\\boldsymbol{x}\\) in \\(\\mathbb{R}^d\\) by a scalar \\(\\beta \\in \\mathbb{R}\\).  </li> <li>\\(\\boldsymbol{x} + \\boldsymbol{y} := (x_1 + y_1, \\ldots, x_d + y_d)\\) represents vector addition in \\(\\mathbb{R}^d\\).  </li> <li> <p>For scalars \\(x, y \\in \\mathbb{R}\\), the following notations are used:  </p> \\[   x \\vee y = \\max\\{x, y\\}, \\quad x \\wedge y = \\min\\{x, y\\}, \\quad x^+ = \\max\\{x, 0\\}, \\quad x^- = \\max\\{-x, 0\\}. \\] <p>Notably, \\(x = x^+ - x^-\\) and \\(|x| = x^+ + x^-\\).  </p> </li> </ul>"},{"location":"lecture/00-Introduction/000-notations/#colorenvironment-conventions","title":"Color/Environment conventions","text":"<p>Definition</p> <p>For a ... we define</p> <p>Remark</p> <p>Note that  </p> <p>Example</p> <p>As an example we consider </p> <p>Theorem</p> <p>Let \\((\\Omega, \\mathcal{F}, P)\\) be a probability space...</p> <p>Proposition</p> <p>Assuming no-arbitrage for the financial market, the followign assertions holds...</p> <p>Corollary</p> <p>As a corrolary to the previous proposition, it holds</p> <p>Lemma</p> <p>In the case where \\(P^\\ast\\) is equivalent to \\(P\\), it holds...</p> <p>Proof</p> <p>In a first step we show that \\((i)\\) implies \\((ii)\\)...</p> <p>Exercise</p>"},{"location":"lecture/01-Sets-Functions/010-introduction/","title":"Introduction","text":"<p>This Chapter is dedicated to the fundamentals behind measure theory. It covers and recall basic notions such as set theory, the algebraic properties of which. It defines the notion of measurable and topological spaces. It finally describe the properties of functions\u2014measurable and continuous\u2014that are compatibles with this algebraic set structures.</p> <ul> <li>Sets</li> <li>Measurable / Topological Spaces</li> <li>Measurable / Continuous Functions</li> </ul>"},{"location":"lecture/01-Sets-Functions/011-sets/","title":"Sets","text":"<p>This lecture will not cover the foundations of logic and the axiomatic approach to set theory. We stick to the naive set theory in the sense that we will not encounter \"too large objects\" for which paradox may arise if the objects are defined too naively\u2014see Russell's paradox. We refer to Jech<sup>1</sup> for a comprehensive overview of set theory.</p> <p>The language of set theory consists of the binary predicate \\(\\in\\) that describes the membership relation between objects, that is, \\(x\\in A\\) means that \\(x\\) is an element or a member of \\(A\\). A set is a collection of objects that belong to it. We usually denote sets with capital letters \\(A,B,\\ldots\\) and elements of these sets with lowercase letters \\(x,y,\\ldots\\). Note that sets can also be elements of other sets. We can define sets either by an explicit listing such as \\(A=\\{\\text{pig},\\text{horse},\\text{table}\\}\\), or by a \"property rule\" \\(P\\), i.e. \\(A=\\{x\\colon x\\text{ has property }P\\}\\). To avoid logical problems, we assume that this rule applies only to some elements of a given larger set. For instance,</p> \\[2\\mathbb{Z}:=\\{x\\in\\mathbb{Z}\\colon x\\text{ is even}\\}\\] <p>Typical sets we will use are:</p> <ul> <li>Natural numbers: \\(\\mathbb{N}=\\{1,2,3,\\ldots\\}\\) and \\(\\mathbb{N}_0=\\{0,1,2,\\ldots\\}\\);</li> <li>Integers: \\(\\mathbb{Z}=\\{\\ldots,-2,-1,0,1,2,\\ldots\\}\\);</li> <li>Rational numbers: \\(\\mathbb{Q}\\);</li> <li>Real numbers: \\(\\mathbb{R}\\);</li> <li>\\(\\mathbb{R}^d\\), the \\(d\\)-dimensional Euclidean space.</li> </ul> <p>Let us introduce the following operations or relations between sets:</p> <ul> <li>Inclusion \\(\\subseteq\\): Given two sets \\(A\\) and \\(B\\), we denote by \\(A\\subseteq B\\) that every element \\(x\\) in \\(A\\) also belongs to \\(B\\).     The inclusion defines a partial order (it is reflexive, transitive, and antisymmetric).</li> <li>Empty set \\(\\emptyset\\): The set containing no elements is called the empty set and is denoted by \\(\\emptyset\\).     It is the smallest set with respect to inclusion and is universal in this axiomatic system.</li> <li>Intersection \\(\\cap\\): The intersection of two sets \\(A\\) and \\(B\\), denoted by \\(A\\cap B\\), is defined as the largest set that is contained in both \\(A\\) and \\(B\\).     In other words, \\(A\\cap B=\\{x\\colon x\\in A\\text{ and }x\\in B\\}\\).     Two sets \\(A\\) and \\(B\\) are said to be disjoint if their intersection is empty, i.e. \\(A\\cap B=\\emptyset\\).</li> <li>Union \\(\\cup\\): The union of two sets \\(A\\) and \\(B\\), denoted by \\(A\\cup B\\), is defined as the smallest set that contains all elements of either \\(A\\) or \\(B\\).     In other words, \\(A\\cup B=\\{x\\colon x\\in A\\text{ or }x\\in B\\}\\).</li> <li>Complement \\({}^c\\): Given a set \\(X\\), the complement of a subset \\(A\\) (relative to \\(X\\)) is given by \\(A^c=\\{x\\in X\\colon x\\not\\in A\\}\\).</li> <li>Difference \\(\\setminus\\): Given two subsets \\(A\\) and \\(B\\) of a set \\(X\\), the difference \\(A\\setminus B\\) is defined as \\(\\{x\\colon x\\in A\\text{ and }x\\not\\in B\\}\\), which is equivalent to \\(A\\cap B^c\\).</li> <li>Symmetric difference \\(\\Delta\\) Given two subsets \\(A\\) and \\(B\\) of a set \\(X\\), the symmetric difference is defined as \\(A\\Delta B:=(A\\setminus B)\\cup(B\\setminus A)\\).</li> </ul> <p>Given a set \\(X\\), we can define its power set as \\(2^X:=\\{A\\subseteq X\\}\\). Note that the power set always contains both \\(X\\) and the empty set \\(\\emptyset\\). In particular, \\(2^\\emptyset=\\{\\emptyset\\}\\) is the set containing only the empty set.</p> <p>Proposition</p> <p>The power set \\(2^X\\) of a set \\(X\\), together with the operations \\(\\cup\\), \\(\\cap\\), \\({}^c\\), and the two distinguished elements \\(\\emptyset\\) and \\(X\\), satisfies the properties of a Boolean algebra.</p> <ol> <li>\\(\\emptyset^c=X\\) and \\(X^c=\\emptyset\\).</li> <li>Identity laws: \\(A\\cap\\emptyset=\\emptyset\\), \\(A\\cap X=A\\), \\(A\\cup\\emptyset=A\\), and \\(A\\cup X=X\\).</li> <li>Complement laws: \\(A\\cap A^c=\\emptyset\\) and \\(A\\cup A^c=X\\).</li> <li>Double complement law: \\((A^c)^c=A\\).</li> <li>Idempotent laws: \\(A\\cap A=A\\) and \\(A\\cup A=A\\).</li> <li>De Morgan laws: \\((A\\cap B)^c=A^c\\cup B^c\\) and \\((A\\cup B)^c=A^c\\cap B^c\\).</li> <li>Commutative laws: \\(A\\cap B=B\\cap A\\) and \\(A\\cup B=B\\cup A\\).</li> <li>Associative laws: \\(A\\cap(B\\cap C)=(A\\cap B)\\cap C\\) and \\(A\\cup(B\\cup C)=(A\\cup B)\\cup C\\).</li> <li>Distributive laws: \\(A\\cap(B\\cup C)=(A\\cap B)\\cup(A\\cap C)\\) and \\(A\\cup(B\\cap C)=(A\\cup B)\\cap(A\\cup C)\\).</li> </ol> Proof <p>Left as an exercise.</p> Remark: Boolean Ring <p>The power set \\(2^X\\) of a set \\(X\\), together with the operations \\(\\Delta\\), \\(\\cap\\), and the two distinguished elements \\(\\emptyset\\) and \\(X\\), satisfies the properties of a Boolean ring, that is:</p> <ol> <li>\\(\\Delta\\) and \\(\\cap\\) are associative and commutative.</li> <li>Identity law: \\(A\\Delta\\emptyset=A\\) and \\(A\\cap X=A\\).</li> <li>Inverse law: \\(A\\Delta A^c=X\\).</li> <li>Distributive law: \\(A\\cap(B\\Delta C)=(A\\cap B)\\Delta(A\\cap C)\\).</li> </ol> <p>The Cartesian product \\(A\\times B\\) of two sets \\(A\\) and \\(B\\) is the collection of ordered pairs \\((x,y)\\) such that \\(x\\in A\\) and \\(y\\in B\\).</p> <p>Given the Cartesian product, we can define functions:</p> <p>Definition: Functions</p> <p>A function \\(f:X\\to Y\\) is an ordered triple \\((X, Y, G)\\), where \\(G\\subseteq X\\times Y\\) is called the graph of \\(f\\) and satisfies the property that for every \\(x\\in X\\), there exists a unique \\(y\\in Y\\) such that \\((x,y)\\in G\\).(1)</p> <ol> <li>This definition requires \\(Y\\) to be non-empty if \\(X\\) is non-empty. If \\(X\\) is empty, then \\(G=\\emptyset\\), and this function is called the empty function.</li> </ol> <p>For \\(x\\in X\\), this unique element \\(y\\in Y\\) such that \\((x,y)\\in G\\) is denoted by \\(f(x)\\).</p> <p>A function is called</p> <ul> <li>injective if \\(x\\neq y\\) implies \\(f(x)\\neq f(y)\\);</li> <li>surjective if for every \\(y\\in Y\\), there exists \\(x\\in X\\) such that \\(f(x)=y\\);</li> <li>bijective if it is both injective and surjective.</li> </ul> <p>Given a set \\(I\\) and a non-empty set \\(X\\), a family of elements in \\(X\\) is a function \\(f:I\\to X\\), \\(i\\mapsto f(i)\\). We usually denote this function as \\((x_i)_{i\\in I}\\), where \\(x_i\\in X\\) for every \\(i\\).(1) If \\(I=\\mathbb{N}\\), we also call it a sequence or a countable family. If there is no risk of confusion, we use the notation \\((x_i)\\) for an arbitrary family of elements in \\(X\\) and \\((x_n)\\) for a countable family\u2014or sequence\u2014in \\(X\\).</p> <ol> <li>A family \\((x_i)_{i\\in I}\\) is different from the collection \\(\\{x_i: i\\in I\\}\\).   For instance, consider the family \\((x_n)_{n\\in\\mathbb{N}}\\) where \\(x_n=1\\) if \\(n\\) is odd and \\(x_n=0\\) if \\(n\\) is even.   Then \\(\\{x_n:n\\in\\mathbb{N}\\}=\\{0,1\\}\\), while \\((x_n)_{n\\in\\mathbb{N}}=(1,0,1,0,1,\\ldots)\\).}</li> </ol> <p>Given a family of sets \\((X_i)=(X_i)_{i\\in I}\\), we define the Cartesian product of these sets as the collection of families \\((x_i)=(x_i)_{i\\in I}\\) such that \\(x_i\\) is in \\(X_i\\) for every \\(i\\), denoted by</p> \\[ \\prod X_i=\\prod_{i\\in I}X_i=\\{(x_i)\\colon x_i\\in X_i \\text{ for every } i\\}. \\] <p>Proposition</p> <p>The Boolean algebra \\(2^X\\) is complete, meaning that for every family of sets \\((A_i)\\), there exists a minimum and a maximum with respect to inclusion in \\(2^X\\).(1)</p> <ol> <li>That is, there exist subsets \\(A\\) and \\(B\\) such that \\(A\\subseteq A_i\\subseteq B\\) for every \\(i\\), and if \\(\\tilde{A}\\) and \\(\\tilde{B}\\) also satisfy this property, then \\(\\tilde{A}\\subseteq A\\) and \\(B\\subseteq \\tilde{B}\\).</li> </ol> <p>We denote this minimum and maximum by</p> \\[ \\begin{align*}   \\bigcap A_i&amp;=\\{x\\in X\\colon x\\in A_i \\text{ for all } i\\}   &amp;   \\bigcup A_i&amp; =\\{x\\in X\\colon x\\in A_i \\text{ for some } i\\} \\end{align*} \\] <p>Furthermore, it holds that</p> \\[ \\begin{equation} \\left(\\bigcap A_i\\right)^c=\\bigcup A_i^c, \\quad \\left(\\bigcup A_i\\right)^c=\\bigcap A_i^c \\end{equation} \\] <p>as well as</p> \\[ \\begin{equation} C\\cap\\left(\\bigcup A_i\\right)=\\bigcup (C\\cap A_i), \\quad C\\cup\\left(\\bigcap A_i\\right)=\\bigcap (A_i\\cup C) \\end{equation} \\] Proof <p>Left to the reader.</p> <p>Given a function \\(f:X\\to Y\\) and subsets \\(A\\subseteq X\\) and \\(B\\subseteq Y\\), we define the</p> <ul> <li> <p>image: </p> \\[ \\begin{equation} f(A) := \\left\\{ y\\in Y\\colon y=f(x) \\text{ for some } x\\in A \\right\\}\\subseteq Y \\end{equation} \\] </li> <li> <p>pre-image:</p> \\[ \\begin{equation} f^{-1}(B) := \\left\\{ x\\in X\\colon f(x)\\in B \\right\\}\\subseteq X \\end{equation} \\] </li> </ul> <p></p> <p>Proposition</p> <p>The image and pre-image define functions from \\(2^X\\) to \\(2^Y\\) and \\(2^Y\\) to \\(2^X\\), respectively, with the following properties:</p> \\[ \\begin{align}   f(A_1) &amp;\\subseteq f(A_2), &amp; f^{-1}(B_1) &amp;\\subseteq f^{-1}(B_2)\\\\   f\\left(\\cup A_i\\right) &amp;= \\cup f(A_i), &amp; f^{-1}\\left(\\cup B_j\\right) &amp;= \\cup f^{-1}(B_j)\\\\   f\\left(\\cap A_i\\right) &amp;\\subseteq \\cap f(A_i), &amp; f^{-1}\\left(\\cap B_j\\right) &amp;= \\cap f^{-1}(B_j)\\\\   f(A^c) &amp;\\subseteq f(A)^c, &amp; f^{-1}(B^c) &amp;= \\left(f^{-1}(B)\\right)^c\\\\   A &amp;\\subseteq f^{-1}\\left(f(A)\\right), &amp; B &amp;\\subseteq f\\left(f^{-1}(B)\\right) \\end{align} \\] Proof <p>Left to the reader.</p> <p>Remark</p> <p>The pre-image function\u2014unlike the image function\u2014respects the Boolean operations of the power set. In other words, it is a morphism. Any structure defined on a subset of \\(2^Y\\) with intersection, union, and complementation will carry over to a substructure of \\(2^X\\) with the same properties via the pre-image function.</p> <p>As for the cardinality of sets, we say that a set \\(X\\) has cardinality smaller than \\(Y\\) if there exists an injective function \\(f:X\\to Y\\). Two sets have same cardinality if such a function is bijective. A set \\(X\\) is called </p> <ul> <li>finite if there exists \\(n\\) in \\(\\mathbb{N}\\) such \\(X\\) has the same cardinality as \\(\\{1, \\ldots, n\\}\\).   In this case \\(n\\) is the cardinality of this set.</li> <li>enumerable if \\(X\\) has the same cardinality as \\(\\mathbb{N}\\).   In this case we denote by \\(\\aleph_0\\) the cardinality of this set.</li> <li>countable if \\(X\\) is either finite or enumerable.</li> </ul> <p>The emptyset has cardinality \\(0\\) and is the only such set. If \\(X\\) is finite of cardinality \\(n\\) in \\(\\mathbb{N}\\), then the cardinality of \\(2^X\\) is \\(2^n\\). In general, the cardinality of \\(2^X\\) is always strictly greater than the cardinality of \\(X\\), that is, while there obviously exists an injective function \\(X \\ni x \\mapsto \\{x\\} \\in 2^X\\), the reverse is not true. The set of real numbers of any interval of real numbers has a cardinality that is striclty larger than \\(\\mathbb{N}\\). However, \\(\\mathbb{Z}\\) is obviously enumerable by the injective function \\(f\\colon \\mathbb{Z}\\to \\mathbb{N}\\) such that \\(n \\mapsto f(n)=2n\\) if \\(n\\) is positive and \\(n \\mapsto f(n) = -2n -1\\) if \\(n\\) is strictly negative. Classsical but less obvious is that \\(\\mathbb{Q}\\) has the same cardinality as \\(\\mathbb{N}\\).</p> <p>Proposition</p> <p>Let \\((X_n)\\) be a countable family of countable sets, then \\(\\cup X_n\\) is countable.</p> <p>In particular \\(\\mathbb{Q}\\) is countable.</p> Proof <p>Define \\(X = \\cup X_n\\). Without loss of generality, we can assume that the family is enumerable, that is \\((X_n) = (X_n)_{n=1, \\ldots}\\). Furthermore, up to redefining sequentially \\(Y_1 = X_1\\) and \\(Y_{n+1} = X_{n+1} \\setminus Y{n}\\) for which holds \\(\\cup Y_n = X\\), we can also assume that the \\((X_n)\\) are pairewize disjoint. Up to slight modification, we can also assume that each \\(X_n\\) is itself enumerable. Since each set is enumerable, we can write uniquely \\(X_n =\\{ x_{n,m}: m \\in \\mathbb{N}\\}\\) such that \\(X = \\{x_{n, m}\\colon n \\in \\mathbb{N} \\text{ and } m \\in \\mathbb{N}\\}\\) which has the same cardinality as \\(\\mathbb{N}\\times \\mathbb{N}\\). However \\(\\mathbb{N}\\times \\mathbb{N}\\) has the same cardinality as \\(\\mathbb{N}\\). Indeed, it is equal to the countable union of the disjoint finite sets \\(Y_k =\\{(m, n)\\colon m+n = k\\}\\) each being of cardinality \\(k\\) from which an injection can be built into \\(\\mathbb{N}\\).</p> <p>As for \\(\\mathbb{Q}\\), it is the countable union of the countable sets \\(X_n = \\{m / n\\colon m \\in \\mathbb{Z} \\}\\).</p> <p>Given a sequence \\((X_n)\\) of sets we define the \\(\\limsup\\) and \\(\\liminf\\) of this sequence as the sets:</p> \\[ \\begin{align*}   \\limsup X_n &amp;:= \\cap_n \\cup_{k\\geq n} X_k &amp; \\liminf X_n &amp;:= \\cup_n \\cap_{k \\geq n} X_k \\end{align*} \\] <p>In other term, the \\(\\limsup\\) represent the set of those elements \\(x\\) which are contained in infinitely many \\(X_n\\) while the \\(\\liminf\\) represent the set of those elements \\(x\\) that are contained in all but finitely many \\(X_n\\). For \\(x\\) in \\(\\liminf X_n\\), it follows that there exists \\(n_0\\) such that \\(x\\) belongs to any \\(X_n\\) for \\(n\\geq n_0\\).  Hence \\(x\\) is in \\(\\cup_{k\\geq n} X_k\\) for any \\(n\\) showing that \\(x\\) is in \\(\\limsup X_n\\). Therefore \\(\\liminf X_n \\subseteq \\limsup X_n\\). The sequence of sets converges if \\(\\liminf X_n = \\limsup X_n\\).</p> <p>Definition</p> <p>Given a subset \\(A\\) of \\(X\\), we define the indicator function of \\(A\\) as the function</p> \\[ \\begin{equation*}   \\begin{split}     1_A \\colon X &amp; \\longrightarrow \\mathbb{R}\\\\                x &amp; \\longmapsto 1_A(x) =                      \\begin{cases}                       1 &amp; \\text{if }x \\in A\\\\                       0 &amp; \\text{otherwize }                     \\end{cases}   \\end{split} \\end{equation*} \\] <p> </p> <p>Exercise</p> <ul> <li>Show that \\((0,1)\\) has the same cardinality as \\((0, 1]\\).</li> <li>Let \\(f\\colon \\mathbb{R} \\to \\mathbb{R}\\) be an increasing function.   Show that the set \\(X = \\{x \\in \\mathbb{R}\\colon \\lim_{y\\nearrow x} f(y) &lt; \\lim_{y\\searrow x} f(y)\\}\\) of discountinuity of \\(f\\) is countable.</li> <li>Show that \\((\\limsup X_n^c)^c = \\liminf X_n\\), \\(\\liminf X_n = \\{x \\in X\\colon \\liminf 1_{A_n}(x) = 1\\}\\) and \\(\\limsup X_n = \\{x \\in X \\colon \\limsup 1_{A_n}(x) = 1\\}\\).</li> <li>Show that \\(1_{\\cup A_n} = \\sum 1_{A_n}\\) whenever \\((A_n)\\) are disjoints.   Show that \\(1_{\\cap A_n} = \\prod 1_{A_n}\\).</li> </ul> <ol> <li> <p>Thomas Jech. Set Theory \u2013 The Third Millennium Edition, revised and expanded. Springer-Verlag Berlin Heidelberg, 2003.\u00a0\u21a9</p> </li> </ol>"},{"location":"lecture/01-Sets-Functions/012-measurability-topology/","title":"Measurability, Topology","text":""},{"location":"lecture/01-Sets-Functions/012-measurability-topology/#measured-spaces","title":"Measured Spaces","text":"<p>Given a set \\(X\\), we want to describe the class of sets that we intend to measure with the help of measure.</p> <p>Definition: \\(\\sigma\\)-Algebra</p> <p>A collection \\(\\mathcal{F}\\) of subsets of \\(X\\) is called a \\(\\sigma\\)-algebra if</p> <ol> <li>\\(\\emptyset\\) is in \\(\\mathcal{F}\\);</li> <li>for any \\(A\\) in \\(\\mathcal{A}\\) it follows that \\(A^c\\) (stable under complementation);</li> <li>for any countable family \\((A_n)\\) of elements of \\(\\mathcal{F}\\) it follows that \\(\\cap A_n\\) is in \\(\\mathcal{F}\\) (stable under countable intersection).</li> </ol> <p>Elements of \\(\\mathcal{F}\\) are usually refered to as measurable sets (or events in probability theory). A tuple \\((X, \\mathcal{F})\\) where \\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra is called a measurable space.</p> <p>By complementation stability and \\(\\emptyset\\) in \\(\\mathcal{F}\\), it follows that \\(X\\) belongs to \\(\\mathcal{F}\\). Note that due to De Morgan's law, it follows that a \\(\\sigma\\)-algebra is stable under countable union. Eventually, the third property can be replaced by stability under countable union.</p> <p>The most simple example of \\(\\sigma\\)-algebra are </p> <ul> <li>the trivial \\(\\sigma\\)-algebra: \\(\\mathcal{F} = \\{\\emptyset, X\\}\\)</li> <li>the power set: \\(\\mathcal{F} = 2^X\\)</li> </ul> <p>These coincide to the smallest and largest possible \\(\\sigma\\)-algebra, respectively, on \\(X\\). Indeed for any \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) it holds that \\(\\{\\emptyset, X\\} \\subseteq \\mathcal{F}\\subseteq 2^X\\). Even if \\(\\sigma\\)-algebra are conceptually simple objects, it is quite difficult to describe them in a meaningful way from simple components. This is in particular relevant when we want to define measure from simple events and extend it to the whole \\(\\sigma\\)-algebra. Therefore we introduce simpler class of sets that will serve as building blocks for \\(\\sigma\\)-algebra.</p> <p>Definition: Semi-Ring, Ring, Algebra, \\(\\pi\\)-system, \\(\\lambda\\)-system, Monotone Class</p> <p>A collection \\(\\mathcal{S}\\) of subsets of \\(X\\) is called a semi-ring if</p> <ul> <li>\\(\\emptyset\\) is in \\(\\mathcal{S}\\);</li> <li>for any \\(A\\) and \\(B\\) in \\(\\mathcal{S}\\) it follows that \\(A\\cap B\\) is in \\(\\mathcal{S}\\);</li> <li>for any \\(A\\) and \\(B\\) in \\(\\mathcal{S}\\), there exists disjoints \\(C_1, \\ldots, C_n\\) in \\(\\mathcal{S}\\) such \\(A\\setminus B = \\cup C_n\\).</li> </ul> <p>A collection \\(\\mathcal{R}\\) of subsets of \\(X\\) is called a ring if</p> <ul> <li>for any \\(A\\) and \\(B\\) in \\(\\mathcal{R}\\) it follows that \\(A\\cap B\\) is in \\(\\mathcal{R}\\);</li> <li>for any \\(A\\) and \\(B\\) in \\(\\mathcal{R}\\) if follows that \\(A\\Delta B\\) is in \\(\\mathcal{R}\\).</li> </ul> <p>A collection \\(\\mathcal{A}\\) of subsets of \\(X\\) is called an algebra if</p> <ul> <li>\\(\\emptyset\\) is in \\(\\mathcal{A}\\);</li> <li>for any \\(A\\) in \\(\\mathcal{A}\\) it follows that \\(A^c\\) is in \\(\\mathcal{A}\\); </li> <li>for any \\(A\\) and \\(B\\) in \\(\\mathcal{A}\\) it follows that \\(A\\cap B\\) is in \\(\\mathcal{A}\\).</li> </ul> <p>A collection \\(\\mathcal{P}\\) of subsets of \\(X\\) is called a \\(\\pi\\)-system if</p> <ol> <li>for any \\(A\\) and \\(B\\) in \\(\\mathcal{A}\\) it follows that \\(A\\cap B\\) is in \\(\\mathcal{P}\\)</li> </ol> <p>A collection \\(\\mathcal{L}\\) of subsets of \\(X\\) is called a \\(\\lambda\\)-system if</p> <ul> <li>\\(\\emptyset\\) is in \\(\\mathcal{L}\\)</li> <li>for any \\(A\\) in \\(\\mathcal{L}\\) it follows that \\(A^c\\) is in \\(\\mathcal{L}\\);</li> <li>for any disjoint countable family \\((A_n)\\) in \\(\\mathcal{L}\\) it follows that \\(\\cup A_n\\) is in \\(\\mathcal{L}\\).</li> </ul> <p>Clearly a \\(\\sigma\\)-algebra is an algebra. Furthermore, for a ring \\(\\mathcal{R}\\) it follows that \\(\\emptyset = A\\Delta A\\) belongs to \\(\\mathcal{R}\\) and from \\(A\\cup B = (A\\Delta B)\\Delta (A\\cap B)\\) it is stable under intersection. Hence if \\(\\mathcal{R}\\) contains \\(X\\), it is automatically an algebra. Reciprocally, an algebra is in particular a ring. Finally, a ring is in particular a semi-ring.</p> <p>Exercise</p> <ul> <li> <p>Show that the collection \\(\\mathcal{S}\\) of intervals of the form \\((a, b]\\) in \\(\\mathbb{R}\\) is a semi-ring.   Analogously, it also holds that the collection of products \\((a_1, b_1]\\times \\ldots \\times (a_n, b_n]\\) is a semi-ring in \\(\\mathbb{R}^n\\).</p> </li> <li> <p>Let \\(X = \\prod_{n \\in \\mathbb{N}} \\{-1, 1\\} = \\{-1, 1\\}^{\\mathbb{N}}\\) which is the set of sequences with values \\(\\pm 1\\).     We call sets of the form</p> \\[     C = C_1 \\times C_2 \\times \\ldots C_n \\times \\{-1, 1\\}\\times \\{-1, 1\\}\\times \\ldots \\] <p>where \\(n\\) is an integer and \\(C_k \\subseteq \\{-1, 1\\}\\) for \\(k=1, \\ldots, n\\) a finite cylinder.</p> <p>Show that the collection \\(\\mathcal{S}\\) of finite cylinders is a semi-ring.</p> </li> </ul> <p>Semi-rings are relatively easy to define from small building blocks. The reason why the other class are defined is that by explicit set operations, it is possible to go from one class to the next.</p> <p>Let us formulate first the notion of class generated by. In the following, we call a class \\(\\mathcal{Z}\\) a \\(z\\)-class where \\(z\\) is either a ring, algebra, \\(\\pi\\)-system, \\(\\lambda\\)-system, monotone class, \\(\\sigma\\)-algebra (any of them EXCEPT semi-ring).</p> <p>Proposition</p> <p>Let \\((\\mathcal{Z}_i)\\) be any arbitrary family of \\(z\\)-classes on \\(X\\), then it follows that \\(\\mathcal{Z} = \\cap \\mathcal{Z}_i\\) is a \\(z\\)-class.</p> <p>For any class \\(\\mathcal{C}\\) of subsets of \\(X\\), there exists a smallest \\(z\\)-class denoted by \\(z(\\mathcal{C})\\) that contains \\(\\mathcal{C}\\).(1)</p> <ol> <li>Smallest in terms of the inclusion, that is, if \\(\\mathcal{Z}\\) is a \\(z\\)-class containing \\(\\mathcal{C}\\), then it holds that \\(z(\\mathcal{C})\\subseteq \\mathcal{Z}\\).</li> </ol> <p>Proof</p> <p>We provide the proof for the case where \\(z\\) stands for ring, the other classes follows the same argumentation. Let \\(A\\) and \\(B\\) be elements of \\(\\cap \\mathcal{Z}_i\\), since \\(\\mathcal{Z}_i\\) is a ring for any \\(i\\), it follows that \\(A\\cap B\\) and \\(A\\Delta B\\) are in \\(\\mathcal{Z}_i\\) for any \\(i\\), thus in \\(\\cap \\mathcal{Z}_i\\) showing that it is a ring.</p> <p>Let now \\(\\mathcal{C}\\) be a class of subsets of \\(X\\) and consider the family \\((\\mathcal{Z}_i)\\) of all \\(z\\)-class on \\(X\\) that contains \\(\\mathcal{C}\\). This family is not empty as \\(2^X\\) belongs to the family. Taking the intersection per definition defines the smallest \\(z\\)-class containing \\(\\mathcal{C}\\).</p> <p>Semi-rings are not part of those results, however it is simple to describe the smallest ring generated by a semi-ring.</p> <p></p> <p>Proposition</p> <p>The ring \\(r(\\mathcal{S})\\) generated by a semi-ring \\(\\mathcal{S}\\) is precisely the sets of all finite unions \\(\\cup_{k=1}^n A_k\\) of disjoint elements \\(A_1, \\ldots, A_n\\) in \\(\\mathcal{S}\\).</p> <p>Proof</p> <p>Let \\(\\mathcal{R}\\) be the collection of finite unions of disjoint elements in \\(\\mathcal{S}\\). By definition, the ring generated by \\(\\mathcal{S}\\) contains finite unions of disjoint elements of \\(\\mathcal{S}\\), and therefore \\(\\mathcal{R}\\) is contained in the ring generated by \\(\\mathcal{S}\\). We are left to show that \\(\\mathcal{R}\\) is itself a ring.</p> <p>Let \\(A=\\cup_{1\\leq k\\leq n} A_k\\) and \\(B=\\cup_{1\\leq l\\leq m}B_l\\) be two elements of \\(\\mathcal{R}\\), where \\((A_k)_{1\\leq k\\leq n}\\) and \\((B_l)_{1\\leq l\\leq m}\\) are two finite families of pairwise disjoint sets in \\(\\mathcal{S}\\). By the distributivity of \\(\\cap\\) over \\(\\cup\\), it follows that</p> \\[ A\\cap B= \\cup_{1\\leq k\\leq n,1\\leq l\\leq m }A_k\\cap B_l. \\] <p>Since \\(\\mathcal{S}\\) is stable under intersection, it follows that \\(A\\cap B\\) is a finite union of pairwise disjoint elements \\((C_{kl})=(A_k\\cap B_l)\\) in \\(\\mathcal{S}\\), showing that \\(\\mathcal{R}\\) is stable under intersection.</p> <p>Let us now show that \\(A\\Delta B=(A\\setminus B)\\cup (B\\setminus A)\\) is in \\(\\mathcal{R}\\). It is enough to show that \\(A\\setminus B\\) is in \\(\\mathcal{R}\\). It holds</p> \\[ \\begin{equation} A\\setminus B=\\bigcap_{l=1}^m (A\\setminus B_l). \\end{equation} \\] <p>Since \\(\\mathcal{R}\\) is stable under intersection, it is enough to show that \\(A\\setminus C\\) is in \\(\\mathcal{R}\\) for every \\(C\\) in \\(\\mathcal{S}\\). It holds</p> \\[ \\begin{equation} A\\setminus C=\\bigcup_{k=1}^n \\left(A_k\\setminus C\\right). \\end{equation} \\] <p>Since \\(A_k\\) and \\(C\\) are elements of the semi-ring \\(\\mathcal{S}\\), it follows that</p> \\[ \\begin{equation} A_k\\setminus C=\\bigcup_{i=1}^{n_{k}} D_{ki} \\end{equation} \\] <p>for each \\(1\\leq k\\leq n\\), where \\((D_{ki})_{1\\leq i\\leq n_{k}}\\) is a finite disjoint family of elements in \\(\\mathcal{S}\\). Hence,</p> \\[ \\begin{equation} A\\setminus C =\\bigcup_{k=1}^n\\bigcup_{i=1}^{n_k} D_{ki} \\end{equation} \\] <p>is a finite union of pairwise disjoint elements in \\(\\mathcal{S}\\), which completes the proof.</p> <p>The following theorems are similar and show how to go up the ladder from simple classes (for instance rings) to \\(\\sigma\\)-algebra.</p> <p>Dynkin's \\(\\pi\\)-\\(\\lambda\\) Theorem</p> <p>Let \\(X\\) be a set and \\(\\mathcal{P}\\) be a \\(\\pi\\)-system. Then, the \\(\\lambda\\)-system generated by \\(\\mathcal{P}\\) is a \\(\\sigma\\)-algebra, that is \\(\\lambda(\\mathcal{P})=\\sigma(\\mathcal{P})\\).</p> Proof <p>We first show that if \\(\\mathcal{C}\\) is a \\(\\lambda\\)-system closed under finite intersection, then it is a \\(\\sigma\\)-algebra. By definition of a \\(\\lambda\\)-system, we just have to check the stability under arbitrary countable union. To this end, let \\((A_n)\\) be a sequence of elements in \\(\\mathcal{C}\\) and define</p> \\[ B_n=A_n\\setminus \\left(\\cup_{k&lt;n} A_k\\right)=A_n\\cap\\left(\\cap_{k&lt;n}A_k^c\\right), \\quad n&gt;1, \\quad B_1=A_1. \\] <p>As \\(\\mathcal{C}\\) is closed under complementation and we assumed that \\(\\mathcal{C}\\) is closed under finite intersection, it follows that \\((B_n)\\) is a sequence of elements in \\(\\mathcal{C}\\). From \\(\\cup B_n=\\cup A_n\\) and \\((B_n)\\) pairwise disjoint, it follows from the \\(\\lambda\\)-system assumption on \\(\\mathcal{C}\\) that \\(\\cup A_n=\\cup B_n\\) is in \\(\\mathcal{C}\\).</p> <p>Now, it clearly holds \\(\\lambda(\\mathcal{P})\\subseteq \\sigma(\\mathcal{P})\\). From what we just showed, we just have to check that \\(\\lambda(\\mathcal{P})\\) is closed under finite intersection, since then \\(\\lambda(\\mathcal{P})\\) would be a \\(\\sigma\\)-algebra containing \\(\\mathcal{P}\\) and so \\(\\sigma(\\mathcal{P})\\subseteq \\lambda(\\mathcal{P})\\). For \\(D \\in \\lambda(\\mathcal{P})\\), define</p> \\[ \\mathcal{D}_D=\\{A\\subseteq X\\colon A\\cap D \\in \\lambda(\\mathcal{P})\\} \\] <p>which is a \\(\\lambda\\)-system. Indeed, \\(\\emptyset\\in \\mathcal{D}_D\\). If \\(A \\in \\mathcal{D}_D\\), it follows that</p> \\[ A^c\\cap D=(A^c\\cup D^c)\\cap D=(A\\cap D)^c\\cap D=\\left( (A\\cap D)\\cup D^c\\right)^c. \\] <p>By assumption, \\(A\\cap D \\in \\lambda(\\mathcal{P})\\), and since \\(\\lambda(\\mathcal{P})\\) is stable under complementation and countable intersection of disjoint elements, it follows that \\(A^c\\cap D\\in \\lambda (\\mathcal{P})\\) and therefore \\(A^c \\in \\mathcal{D}_D\\). Let now \\((A_n)\\) be a sequence of pairwise disjoint elements in \\(\\mathcal{D}_D\\). From the stability of \\(\\lambda(\\mathcal{P})\\) under countable union of pairwise disjoint elements and the fact that \\((\\cup A_n)\\cap D=\\cup (A_n\\cap D)\\) it follows that \\(\\cup A_n \\in \\mathcal{D}_D\\). Hence, \\(\\mathcal{D}_D\\) is indeed a \\(\\lambda\\)-system.</p> <p>Since \\(\\mathcal{P}\\) is stable under finite intersection, it follows that \\(\\mathcal{P}\\subseteq \\mathcal{D}_B\\) for every \\(B\\) in \\(\\mathcal{P}\\). Hence \\(\\lambda(\\mathcal{P})\\subseteq \\mathcal{D}_B\\) for every \\(B\\) in \\(\\mathcal{P}\\). In particular, for every \\(A \\in \\lambda (\\mathcal{P})\\) and \\(B \\in \\mathcal{P}\\), it holds \\(A\\cap B\\) is in \\(\\lambda(\\mathcal{P})\\subseteq \\mathcal{D}_B\\). By definition, this also means that \\(B\\) is in \\(\\mathcal{D}_A\\) for every \\(B\\) in \\(\\mathcal{P}\\) and \\(A\\) in \\(\\lambda(\\mathcal{P})\\), showing that \\(\\mathcal{P}\\subseteq \\mathcal{D}_A\\) for every \\(A\\) in \\(\\lambda(\\mathcal{P})\\). Hence, \\(\\lambda(\\mathcal{P})\\subseteq \\mathcal{D}_A\\) for every \\(A \\in \\lambda(\\mathcal{P})\\). Thus, for \\(A,B \\in \\lambda(\\mathcal{P})\\) it holds \\(B\\in \\mathcal{D}_A\\), which by definition means \\(A\\cap B\\) is in \\(\\lambda(\\mathcal{P})\\), showing that \\(\\lambda(\\mathcal{P})\\) is closed under finite intersection and therefore, by the first step of the proof, a \\(\\sigma\\)-algebra.</p>"},{"location":"lecture/01-Sets-Functions/012-measurability-topology/#topological-spaces","title":"Topological Spaces","text":"<p>Similar to \\(\\sigma\\)-algebra that describes measurable sets, a topology is a description of the open sets of a set \\(X\\).</p> <p>Definition: Topology</p> <p>A collection \\(\\mathfrak{T}\\) of subsets of a set \\(X\\) is called a topology if:</p> <ul> <li>\\(\\emptyset\\) and \\(X\\) are in \\(\\mathfrak{T}\\).</li> <li>\\(\\mathfrak{T}\\) is closed under finite intersection.</li> <li>\\(\\mathfrak{T}\\) is closed under arbitrary union.</li> </ul> <p>A tuple \\((X, \\mathfrak{T})\\) is called a topological space.</p> <p>An element \\(O\\) in \\(\\mathcal{T}\\) is called an open set and the complement \\(F=O^c\\) of an open set \\(O\\) is called a closed set.</p> <p>A neighborhood of an element \\(x\\) in \\(X\\) is any subset \\(U\\subseteq X\\) such that \\(x \\in O \\subseteq U\\) for some open set \\(O\\).</p> <p>A topology is stable under arbitrary union and finite intersection but not under complementation. Like \\(\\sigma\\)-algebras, arbitrary intersection of topologies remains a topology which allows to define topologies generated by class of sets. Obviously, a topology can equivalently be defined by its collection of closed set that must contain \\(\\emptyset\\) and \\(X\\), be closed under finite union as well as arbitrary union.</p> <p>Proposition</p> <p>Let \\((\\mathfrak{T}_i)\\) be any arbitrary family of topologies on \\(X\\), then it follows that \\(\\mathfrak{T} = \\cap \\mathfrak{T}_i\\) is a topology.</p> <p>For any class \\(\\mathcal{B}\\) of subsets of \\(X\\), there exists a smallest topology denoted by \\(\\mathfrak{T}(\\mathcal{B})\\) that contains \\(\\mathcal{B}\\).</p> <p>Proof</p> <p>The proof follows exactly the same argumentation as for the \\(\\sigma\\)-algebra.</p> <p>Definition</p> <p>A collection \\(\\mathfrak{B}\\) of subsets of a set \\(X\\) is called a topological base if:</p> <ul> <li>\\(\\cup\\{O\\colon O\\in \\mathfrak{B}\\}=X\\).</li> <li>For every \\(x \\in O_1\\cap O_2\\) for \\(O_1,O_2 \\in \\mathfrak{B}\\), there exists \\(O_3 \\in \\mathfrak{B}\\) with \\(x \\in O_3\\) and such that \\(O_3\\subseteq O_1\\cap O_2\\).</li> </ul> <p>Just like the relation between a semi-ring and a ring, it holds:</p> <p>Proposition</p> <p>Let \\(\\mathfrak{B}\\) be a topological base, and \\(\\mathfrak{t}(\\mathfrak{B})\\) be the topology generated by \\(\\mathfrak{B}\\). Then, \\(\\mathfrak{t}(\\mathfrak{B})\\) is exactly the collection of arbitrary unions of elements in \\(\\mathfrak{B}\\).</p> Proof <p>Denote by \\(\\mathcal{U}(\\mathfrak{B})\\) the collection of arbitrary unions of elements in \\(\\mathfrak{B}\\). By definition of \\(\\mathfrak{t}(\\mathfrak{B})\\), it follows that:</p> \\[ \\mathfrak{B}\\subseteq \\mathcal{U}(\\mathfrak{B})\\subseteq \\mathfrak{t}(\\mathfrak{B}). \\] <p>Since \\(\\mathfrak{t}(\\mathfrak{B})\\) is the smallest topology containing \\(\\mathfrak{B}\\), we just have to show that \\(\\mathcal{U}(\\mathfrak{B})\\) is a topology itself. First, \\(X\\) belongs to \\(\\mathcal{U}(\\mathfrak{B})\\) due to the first assumption of a topological base. Since any union over an empty family is empty, it follows that \\(\\emptyset\\) is in \\(\\mathcal{U}(\\mathfrak{B})\\). By definition, \\(\\mathcal{U}(\\mathfrak{B})\\) is stable under arbitrary union. We are left to show that \\(\\mathcal{U}(\\mathfrak{B})\\) is stable under intersection. Let \\(\\tilde{O}_1=\\cup O_i,\\tilde{O}_2=\\cup O_j \\in \\mathcal{U}(\\mathfrak{B})\\) for families \\((O_i),(O_j)\\) of elements in \\(\\mathfrak{B}\\). It follows that:</p> \\[ \\begin{equation} \\tilde{O}_1\\cap\\tilde{O}_2=\\cup_{i,j} (O_i\\cap O_j). \\end{equation} \\] <p>By definition of a topological base, for every \\(i,j\\) and every \\(x\\) in \\(O_i\\cap O_j\\), there exists \\(O_{i,j}^x\\) in \\(\\mathfrak{B}\\) such that \\(x \\in O_{i,j}^x\\subseteq O_i\\cap O_j\\). Hence,</p> \\[ \\begin{equation} \\cup_{x \\in O_i\\cap O_j}O_{i,j}^x=O_i\\cap O_j. \\end{equation} \\] <p>From this, it follows that:</p> \\[ \\begin{equation} \\tilde{O}_1\\cap\\tilde{O}_2=\\cup_{i,j, x \\in O_i\\cap O_j} O_{i,j}^x \\in \\mathcal{U}(\\mathfrak{B}), \\end{equation} \\] <p>showing that \\(\\mathcal{U}(\\mathfrak{B})\\) is a topology.</p> <p>For a subset \\(A\\) of \\(X\\), we define the interior and closure of \\(A\\):</p> \\[ \\begin{align} \\text{Int}(A)&amp;=\\cup\\{O\\colon O\\text{ open with }O\\subseteq A\\}, &amp; \\text{Cl}(A)&amp;=\\cap\\{F\\colon F\\text{ closed and }A\\subseteq F\\}. \\end{align} \\] <p>Clearly, \\(A\\) is open or closed if, and only if, \\(A=\\text{Int}(A)\\) or \\(A=\\text{Cl}(A)\\), respectively. Furthermore, by De Morgan's law, it holds that \\((\\text{Int}(A^c))^c = \\text{Cl}(A)\\) while \\((\\text{Cl}(A^c))^c = \\text{Int}(A)\\).</p> <p>Let us succintly mention several definition related to specific topologies.</p> <ul> <li>Dense: A subset \\(Y\\) of \\(X\\) is called dense in \\(X\\) if \\(\\text{Cl}(Y) =X\\).</li> <li>Hausdorf: A topological space \\(X\\) is called Hausdorf if for any two distinct elements \\(x\\neq y\\) there exists open sets \\(O_x \\ni x\\) and \\(O_y \\ni y\\) with \\(O_x \\cap O_y = \\emptyset\\).</li> <li>Separable: A topological space \\(X\\) is called separable if there exists a countable dense subset \\(Y\\).     That is, there exists a sequence \\((x_n)\\) of elements in \\(X\\) such that any open set \\(O\\) contains at least one element of the sequence.</li> <li>First Countable: A topological space \\(X\\) is called first countable if for each element \\(x\\) there exists a countable family of open sets \\((O_n^x)\\) such that any neighborhood \\(U\\) of \\(x\\) there exists \\(n_0\\) with \\(x \\in O_{n_0}^x \\subseteq U\\).</li> <li>Second Countable: A topological space \\(X\\) is called second countable if it cna be generated by a countable topological basis.   Clearly, any second countable topological space is in particular first countable.</li> </ul> <p>Towards our goal, a very important example of topological space are metric space.</p> <p>Definition: Metric Space</p> <p>A tuple \\((X, d)\\) where \\(d\\colon X \\times X \\to [0, \\infty)\\) is called a metric space if the function \\(d\\) satisfies:</p> <ul> <li>\\(d(x, y) = 0\\) if and only if \\(x = y\\);</li> <li>Symetrie: \\(d(x, y) = d(y,x)\\) for any \\(x\\) and \\(y\\) in \\(X\\);</li> <li>Triangular Inequality: \\(d(x, z) \\leq d(x, y) + d(y, z)\\) for any \\(x\\), \\(y\\) and \\(z\\) in \\(X\\).</li> </ul> <p>Given a metric space, \\(x\\) in \\(X\\) and \\(\\varepsilon&gt;0\\), we define the (open) ball \\(B_{\\varepsilon}(x)\\) centered in \\(x\\) and of radius \\(\\varepsilon\\) as</p> \\[   B_{\\varepsilon}(x) = \\{y \\in X \\colon d(x, y)&lt;\\varepsilon\\} \\] <p>A sequence \\((x_n)\\) of elements in \\(X\\) is said to converge to \\(x\\) in \\(X\\) if \\(d(x_n , x)\\to 0\\).</p> <p>Due to the triangular inequality, it holds that the set \\(\\mathcal{B}\\) of all open balls is a topological basis and the resulting topology is called the metric topology. Furthermore, any metric space is Hausdorf. Indeed, for any two \\(x\\neq y\\), taking \\(\\epsilon = d(x,y)&gt;0\\) due to the first property, from the triangular inequality it follows that that \\(B_{\\varepsilon/3}(x)\\cap B_{\\varepsilon/3}(y) = \\emptyset\\). Clearly, any element \\(x\\) admits a countable neighborhood basis(1) from the balls \\(B_{1/n}(x)\\) for all integers \\(n\\). In other terms, any metric space is first countable. Finally, if \\(Y = (x_n)\\) is a countable dense subset of \\(X\\), then the countable family \\(\\mathfrak{B} = (B_{1/m}(x_n))_{m,n}\\) is a topological base. We summarize these properties into one proposition that also show that the topology of a metric space can be characterized by sequences.</p> <ol> <li>A neighborhood basis of an element \\(x\\) is a family of of neighborhoods \\(\\mathcal{V}(x)\\) of \\(x\\) such that for any neighborhood \\(U\\) of \\(x\\), there exists \\(V \\in \\mathcal{V}(x)\\) such that \\(V \\subseteq U\\).</li> </ol> <p>Proposition</p> <p>Any metric space is Hausdorf, first countable. Furthermore, if it is separable, then it it is second countable. Finally, a set \\(F\\) is closed if and only if for any converging sequence \\((x_n)\\) of elements of \\(F\\), the limit belongs to \\(F\\).</p> <p>Proof</p> <p>We are just left to show the equivalence of closedness with closedeness under sequential limits.</p> <p>Suppose that \\(F\\) is closed and let \\((x_n)\\) be a sequence of elements in \\(F\\) converging to \\(x\\). by contradiction, assume that \\(x\\) belongs to \\(F^c = O\\) which is open, in particular a neighborhood of \\(x\\). However, since \\(x_n \\to x\\), it follows that fall all \\(n\\) large enough, \\(x_n\\) is in \\(O = F^c\\) which is a contradiction with \\((x_n)\\subseteq F\\). Hence, if \\(F\\) is closed, any limit of converging sequence of elements in \\(F\\) belongs to \\(F\\).</p> <p>Reciprocally, suppose that \\(F\\) is stable under sequential limits of its elements. Let \\(x\\) be an element of \\(\\textrm{Cl}(F)\\). By definition, it follows that \\(B_{1/n}(x) \\cap F \\neq \\emptyset\\) for every \\(n\\). For each \\(n\\) select \\(x_n\\) in this intersection defining a sequence \\((x_n)\\) which converges to \\(x\\). By assumption \\(x\\) is therefore in \\(F\\) showing that \\(\\textrm{Cl}(F) \\subseteq F\\) which ends the proof.</p> <p>Example</p> <p>The real line is a metric space for the metric \\(d(x,y) = |x-y|\\). More generaly any norm defines a metric, therefore all the \\(p\\)-norms on \\(\\mathbb{R}^d\\) for instance.</p> <p>A sequence \\((x_n)\\) in a metric space is called Cauchy if for \\(\\varepsilon&gt;0\\), it holds that \\(d(x_n, x_m)\\leq \\varepsilon\\) for all \\(n\\) and \\(m\\) large enough. Clearly, due to the triangular inequality every converging sequence is Cauchy, the reciprocal is however not true, a classical example of which being \\(\\mathbb{Q}\\). We therefore call a metric space on which any Cauchy sequence is also converging a complete metric space.</p> <p>From a topology, it is possible to consider the \\(\\sigma\\)-algebra generated by the topological base</p> <p>Definition: Borel \\(\\sigma\\)-algebra</p> <p>Let \\((X,\\mathfrak{T})\\) be a topological space. The \\(\\sigma\\)-algebra generated by the open sets of \\(X\\) is called the Borel \\(\\sigma\\)-algebra and usually denoted by \\(\\mathcal{B}(X)\\).</p> <p>Exercise</p> <p>Show that the Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}\\) satisfies</p> \\[ \\begin{equation} \\mathcal{B}(\\mathbb{R})=\\sigma(\\mathcal{C}_k). \\end{equation} \\] <p>for \\(k=1,\\ldots,17\\), where:</p> \\[ \\begin{align}     \\mathcal{C}_1 &amp; =\\left\\{F\\colon F\\text{ closed subset of }\\mathbb{R}\\right\\}, \\\\     \\mathcal{C}_2 &amp; =\\left\\{]a,b[\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{R}\\right\\}, &amp; \\mathcal{C}_{10} &amp; =\\left\\{[a,b]\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{R}\\right\\}, \\\\     \\mathcal{C}_3 &amp; =\\left\\{]a,b]\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{R}\\right\\}, &amp; \\mathcal{C}_{11} &amp; =\\left\\{[a,b[\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{R}\\right\\}, \\\\     \\mathcal{C}_4 &amp; =\\left\\{]-\\infty,b]\\colon b\\in \\mathbb{R}\\right\\},                   &amp; \\mathcal{C}_{12} &amp; =\\left\\{]-\\infty,b[\\colon b\\in \\mathbb{R}\\right\\}, \\\\     \\mathcal{C}_5 &amp; =\\left\\{[a,\\infty[\\colon a\\in \\mathbb{R}\\right\\},                    &amp; \\mathcal{C}_{13} &amp; =\\left\\{]a,\\infty[\\colon a\\in \\mathbb{R}\\right\\}, \\\\     \\mathcal{C}_6 &amp; =\\left\\{]a,b[\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{Q}\\right\\}, &amp; \\mathcal{C}_{14} &amp; =\\left\\{[a,b]\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{Q}\\right\\}, \\\\     \\mathcal{C}_7 &amp; =\\left\\{]a,b]\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{Q}\\right\\}, &amp; \\mathcal{C}_{15} &amp; =\\left\\{[a,b[\\colon a\\leq b \\text{ with } a,b\\in \\mathbb{Q}\\right\\}, \\\\     \\mathcal{C}_8 &amp; =\\left\\{]-\\infty,b]\\colon b\\in \\mathbb{Q}\\right\\},                   &amp; \\mathcal{C}_{16} &amp; =\\left\\{]-\\infty,b[\\colon b\\in \\mathbb{Q}\\right\\}, \\\\     \\mathcal{C}_9 &amp; =\\left\\{[a,\\infty[\\colon a\\in \\mathbb{Q}\\right\\},                    &amp; \\mathcal{C}_{17} &amp; =\\left\\{]a,\\infty[\\colon a\\in \\mathbb{Q}\\right\\}. \\end{align} \\]"},{"location":"lecture/01-Sets-Functions/013-measurable-continuous-functions/","title":"Measurable/Continuous Functions, Initial-Product \\(\\sigma\\)-Algebra/Topology","text":"<p>The following subsection deals with the consequence of the properties of preimages. Generically, it works as follows. Let \\(f\\colon X\\to Y\\) be a function and \\(\\mathcal{C}\\) be a collection of subsets of \\(Y\\) that is stable under intersection, union, or complement. Then, by Pre-image Proposition, the collection \\(\\{f^{-1}(B)\\colon B\\in \\mathcal{C}\\}\\) inherits the same stability properties. This is why measurability, as well as continuity, is defined in terms of preimages.</p> <p>For ease of notation, given a collection \\(\\mathcal{C}\\) of subsets of \\(Y\\), we use the notation</p> \\[ \\begin{equation}     f^{-1}(\\mathcal{C})=\\{f^{-1}(B)\\colon B\\in \\mathcal{C}\\}. \\end{equation} \\] <p>Also, in probability theory, we use the following shorthand notation</p> \\[ \\begin{equation}     \\left\\{ f \\in A \\right\\}:=f^{-1}(A)=\\left\\{ x\\in X\\colon f(x)\\in A \\right\\}. \\end{equation} \\] <p>If \\(Y=\\mathbb{R}\\), we also use the notations</p> \\[ \\begin{equation}     \\left\\{ f\\leq t \\right\\}:=f^{-1}\\left( (-\\infty,t] \\right), \\quad \\left\\{ s &lt; f \\leq t \\right\\}:=f^{-1}\\left((s,t]\\right), \\quad \\text{etc.} \\end{equation} \\] <p>Definition: Measurability/Continuity</p> <p>Let \\((X,\\mathcal{F})\\) and \\((Y, \\mathcal{G})\\) be two measurable spaces. We say that a function \\(f:X\\to Y\\) is \\(\\mathcal{F}\\)-\\(\\mathcal{G}\\)-measurable if</p> \\[ \\begin{equation}     f^{-1}(B) \\in \\mathcal{F}, \\quad\\text{for every measurable set }B \\in \\mathcal{G}. \\end{equation} \\] <p>In other words, if and only if \\(f^{-1}(\\mathcal{G})\\subseteq \\mathcal{F}\\).</p> <p>Let \\((X,\\mathfrak{S})\\) and \\((Y,\\mathfrak{T})\\) be two topological spaces. We say that a function \\(f:X\\to Y\\) is \\(\\mathfrak{S}\\)-\\(\\mathfrak{T}\\)-continuous if</p> \\[ \\begin{equation}     f^{-1}(O) \\in \\mathfrak{S}, \\quad\\text{for every open set } O\\in \\mathfrak{T}. \\end{equation} \\] <p>In other words, if and only if \\(f^{-1}(\\mathfrak{T})\\subseteq \\mathfrak{S}\\).</p> <p>Lemma</p> <p>The composition of measurable/continuous functions is measurable/continuous, respectively.</p> Proof <p>We only prove that the composition of measurable functions is measurable, the continuous case being similar. Let \\((X,\\mathcal{F})\\), \\((Y,\\mathcal{G})\\), and \\((Z,\\mathcal{H})\\) be three measurable spaces and \\(f\\colon X\\to Y\\) and \\(g\\colon Y\\to Z\\) be two measurable functions and denote \\(h=g\\circ f\\). For every \\(C\\in \\mathcal{H}\\), it holds that</p> \\[ \\begin{equation}   h^{-1}(C)=f^{-1}(g^{-1}(C))=f^{-1}(B) \\quad \\text{where } B=g^{-1}(C). \\end{equation} \\] <p>Since \\(g\\) is measurable, it follows that \\(B=g^{-1}(C)\\in \\mathcal{G}\\). Further, the measurability of \\(f\\) implies that \\(h^{-1}(C)=f^{-1}(B)\\in \\mathcal{F}\\) showing that \\(h\\) is measurable.</p> <p>Lemma</p> <p>Let \\(f \\colon X\\to Y\\) be a function.  </p> <ul> <li>If \\((Y,\\mathcal{G})\\) is a measurable space, then \\(f^{-1}(\\mathcal{G})=\\{f^{-1}(B)\\colon B \\in \\mathcal{G}\\}\\) is a \\(\\sigma\\)-algebra called the \\(\\sigma\\)-algebra generated by \\(f\\) and denoted by \\(\\sigma(f)\\).  </li> <li>If \\((Y,\\mathfrak{T})\\) is a topological space, then \\(f^{-1}(\\mathfrak{T})=\\{f^{-1}(O)\\colon O\\in \\mathfrak{T}\\}\\) is a topology called the topology generated by \\(f\\) and denoted by \\(\\mathfrak{t}(f)\\).  </li> </ul> Proof <p>The proof is a straightforward application of Pre-image Proposition.</p> <p>If \\(f\\colon X\\to Y\\) is an \\(\\mathcal{F}\\)-\\(\\mathcal{G}\\)-measurable function where \\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra on \\(X\\), then it follows that \\(\\sigma(f)\\subseteq \\mathcal{F}\\). In other words, \\(\\sigma(f)\\) is the smallest \\(\\sigma\\)-algebra for which \\(f\\) is measurable. The same remark holds for continuous functions: \\(\\mathfrak{t}(f)\\) is the smallest topology for which \\(f\\) is continuous. More generally, let \\((f_i)\\) be a family of functions \\(f_i\\colon X \\to Y_i\\) where \\((Y_i,\\mathcal{G}_i)\\) is a family of measurable spaces. Then,</p> \\[ \\begin{equation}     \\sigma(f_i\\colon i)=\\sigma(\\{f_i^{-1}(B)\\colon B\\in \\mathcal{G}_i, i\\}) \\end{equation} \\] <p>is the smallest \\(\\sigma\\)-algebra such that each \\(f_i\\) is measurable. Similarly, when replacing \\(\\sigma\\)-algebra with topologies, the same holds. These are called the initial \\(\\sigma\\)-algebra or topology.</p> <p>Definition: Product \\(\\sigma\\)-algebra</p> <p>Let \\((X_i,\\mathcal{F}_i)\\) be a non-empty family of measurable spaces. The product \\(\\sigma\\)-algebra, denoted by \\(\\otimes \\mathcal{F}_i\\) on the product state space \\(X =\\prod X_i\\), is defined as the \\(\\sigma\\)-algebra generated by the family of projections:</p> \\[ \\begin{align}     \\pi_i\\colon X &amp;\\longrightarrow X_i, \\\\     x=(x_i)&amp;\\longmapsto x_i. \\end{align} \\] <p>That is,</p> \\[ \\begin{equation}     \\otimes \\mathcal{F}_i =\\sigma\\left(\\left\\{ \\pi^{-1}_i(A_i)\\colon A_i\\in \\mathcal{F}_i, \\text{ for any }i \\right\\}\\right). \\end{equation} \\] <p>Exercice</p> <p>In two dimensions, let \\((X,\\mathcal{F})\\) and \\((Y,\\mathcal{G})\\) be two measurable spaces, and define the projections:</p> \\[ \\begin{align}     \\pi_1 \\colon  X\\times Y &amp;\\longrightarrow X, &amp; \\pi_2\\colon  X\\times Y &amp; \\longrightarrow Y, \\\\     (x,y)&amp;\\longmapsto \\pi_1((x,y))=x, &amp; (x,y)&amp;\\longmapsto \\pi_2((x,y))=y. \\end{align} \\] <p>In particular, for \\(A\\) in \\(\\mathcal{F}\\) and \\(B\\) in \\(\\mathcal{G}\\), one has:</p> \\[ \\begin{equation}     \\begin{split}         \\pi^{-1}_1(A)&amp;=\\left\\{ (x,y)\\colon \\pi_1((x,y))=x \\in A \\right\\}=A\\times Y, \\\\         \\pi^{-1}_2(B)&amp;=\\left\\{ (x,y)\\colon \\pi_2((x,y))=y \\in B \\right\\}=X\\times B.     \\end{split} \\end{equation} \\] <p>It follows that:</p> \\[ \\begin{equation}     \\mathcal{F}\\otimes \\mathcal{G}=\\sigma\\left(\\left\\{ A\\times Y, X\\times B\\colon A \\in \\mathcal{F}, B \\in \\mathcal{G} \\right\\}\\right). \\end{equation} \\] <p>As an exercise, show that:</p> \\[ \\begin{equation}     \\mathcal{F}\\otimes \\mathcal{G}=\\sigma\\left(\\left\\{A\\times B\\colon A\\in \\mathcal{F}, B\\in \\mathcal{G}\\right\\}\\right). \\end{equation} \\] <p>Topologies and \\(\\sigma\\)-algebras are often complex abstract systems of sets. In practical terms, checking continuity or measurability for a function might, at first sight, seem like an impossible task. However, topologies and \\(\\sigma\\)-algebras are often described in terms of a simple collection of sets from which they are generated. The morphism properties of pre-images allows us to restrict the verification of continuity or measurability to this simpler generating set.</p> <p>Proposition</p> <p>Let \\(f:X\\to Y\\) be a function and \\(\\mathcal{C}\\), \\(\\mathfrak{C}\\) be collections of subsets of \\(Y\\). It follows that</p> \\[ \\begin{equation}     \\sigma(f)=f^{-1}\\left(\\sigma(\\mathcal{C})\\right)=\\sigma\\left( f^{-1}(\\mathcal{C})\\right)=\\sigma\\left(\\left\\{ f^{-1}(B)\\colon B \\in \\mathcal{C} \\right\\} \\right). \\end{equation} \\] <p>and</p> \\[ \\begin{equation}     \\mathfrak{t}(f)=f^{-1}\\left(\\mathfrak{t}(\\mathfrak{C})\\right)=\\mathfrak{t}\\left( f^{-1}(\\mathfrak{C})\\right)=\\mathfrak{t}\\left(\\left\\{ f^{-1}(B)\\colon B \\in \\mathfrak{C} \\right\\} \\right). \\end{equation} \\] <p>Proof</p> <p>Left as an exercise.</p> <p>Remark</p> <p>The use of this proposition is often as follows. Let \\(f:X\\to Y\\) be a function where \\((X,\\mathcal{F})\\) and \\((Y,\\mathcal{G})\\) are measurable spaces. Suppose that \\(\\mathcal{G}=\\sigma(\\mathcal{C})\\) for some collection \\(\\mathcal{C}\\) of subsets of \\(Y\\). It follows that \\(f\\) is measurable if and only if</p> \\[ \\begin{equation}     f^{-1}(B)\\in \\mathcal{F}, \\quad \\text{ for every }B\\in \\mathcal{C}. \\end{equation} \\] <p>In particular, if \\(Y=\\mathbb{R}\\) and \\(\\mathcal{G}=\\mathcal{B}(\\mathbb{R})\\) is the Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}\\), then \\(f\\) is measurable if and only if  </p> \\[ \\begin{equation}     \\{f\\leq t\\} \\in \\mathcal{F} \\end{equation} \\] <p>for every \\(t \\in \\mathbb{R}\\).</p> <p>Corollary</p> <p>Let \\((X,\\mathcal{F})\\) be a measurable space and \\((Y,\\mathfrak{T})\\) be a topological space. A function \\(f \\colon X \\to Y\\) is measurable with respect to the \\(\\sigma\\)-algebra if \\(f^{-1}(O)\\) is measurable for any open set \\(O\\).</p> <p>Furthermore, if the topology is generated by a countable basis \\(\\mathfrak{B}\\), we can consider only those \\(O\\) in the topological basis.</p> <p>In particular if \\(X\\) and \\(Y\\) are topological spaces endowed with their respective \\(\\sigma\\)-algebra, if \\(f\\) is continuous then it is measurable.</p> <p>Finally, if \\(Y = \\mathbb{R}\\) and \\(f\\) is lower/upper semi-continuous if follows that \\(f\\) is measurable.</p> <p>Proof</p> <p>The first assertion is a direct consequence of the previous results, the seond one follows from the fact that every open set \\(O\\) can be written as a countable union of elements in \\(\\mathfrak{B}\\).</p> <p>As for the third one, it follows from \\(f^{-1}(O)\\) is open henceforth measurable for any open set \\(O\\).</p> <p>As for the last one it follows from \\(f^{-1}(]-\\infty, t])\\) is closed for any \\(t\\) henceforth measurable.</p> <p>Proposition</p> <p>Let \\(f,g, f_n\\colon X\\to \\mathbb{R}\\) be measurable functions where \\((X,\\mathcal{F})\\) is a measurable space. It holds that:</p> <ul> <li>\\(af+bg\\) is measurable for every \\(a,b \\in \\mathbb{R}\\).</li> <li>\\(fg\\) is measurable.</li> <li>\\(\\max(f,g)\\) and \\(\\min(f,g)\\) are measurable.</li> <li> <p>\\(\\sup f_n\\) and \\(\\inf g_n\\) are extended real-valued measurable functions.(1)</p> <ol> <li>With respect to the Borel \\(\\sigma\\)-algebra on \\([-\\infty,\\infty]\\) generated by the metric \\(d(x,y)=|\\arctan(x)-\\arctan(y)|\\), which coincides with the Euclidean topology on \\(\\mathbb{R}\\).</li> </ol> </li> <li> <p>\\(\\liminf f_n:=\\inf_n\\sup_{k\\geq n}f_k\\) and \\(\\limsup f_n:=\\inf_n\\sup_{k\\geq n}f_k\\) are extended real-valued measurable functions.</p> </li> <li>\\(A:=\\{\\lim f_n \\text{ exists}\\}:=\\{\\omega \\colon \\lim f_n(\\omega)\\text{ exists}\\}=\\{\\liminf f_n=\\limsup f_n\\}\\) is measurable.</li> </ul> <p>Proof</p> <p>First, let \\(\\varphi:\\mathbb{R}\\times \\mathbb{R}\\to \\mathbb{R}\\) be a continuous function. It follows that the function \\(\\varphi(f,g)\\) is measurable for the following reason. First, the mapping \\(T:x \\to \\mathbb{R}\\times \\mathbb{R}\\), \\(x \\mapsto (f(x),g(x))\\) is measurable with respect to the product Borel \\(\\sigma\\)-algebra on \\(\\mathbb{R}\\times \\mathbb{R}\\). Indeed, for every two Borel sets \\(A, B\\) of the real line, it follows that</p> \\[ T^{-1}(A\\times B)=\\{f\\in A\\}\\cap\\{g\\in B\\} \\] <p>which is an element in \\(\\mathcal{F}\\) by the measurability of \\(f\\) and \\(g\\). Since the product sets \\(A\\times B\\) for \\(A,B\\) Borel sets in \\(\\mathbb{R}\\) generate the Borel product \\(\\sigma\\)-algebra on \\(\\mathbb{R}^2\\), it follows that \\(T\\) is measurable. By continuity of \\(\\varphi\\), it follows that \\(\\varphi\\) is measurable, and therefore \\(\\varphi\\circ T\\) is measurable. Taking \\(\\varphi(x,y)=ax+by\\), \\(\\varphi(x,y)=xy\\), \\(\\varphi(x,y)=\\max(x,y)\\), and \\(\\varphi(x,y)=\\min(x,y)\\), the first three points follow.</p> <p>Let \\(a \\in \\mathbb{R}\\). It holds that</p> \\[ \\{\\sup_n f_n \\leq a\\}=\\{f_n\\leq a\\colon \\text{ for every }n\\}=\\cap_n \\{f_n\\leq a\\} \\] <p>which is measurable since \\(\\{f_n\\leq a\\}\\) is measurable. Since \\((-\\infty,a]\\) generates the Borel \\(\\sigma\\)-algebra, it follows that \\(\\sup_n f_n\\) is measurable. The same argument applies to \\(\\inf f_n\\) using \\(\\{\\inf f_n\\geq a\\}\\).</p> <p>The measurability of \\(\\liminf f_n\\) follows by the same argument using countable intersection and union. The last point follows directly.</p>"},{"location":"lecture/02-Measure/020-introduction/","title":"Introduction","text":"<p>This Chapter introduce the notion of measure. From the definition on a \\(\\sigma\\)-algebra it goes forward to measure defined on simpler class of sets such as \"Lebesgue/Stieljes\" measure. How to extend those measures to larger class of sets such as ring. It finishes with Carath\u00e9odory's extension theorem that allows to extend those meaningfull measures to the \\(\\sigma\\)-algebra.</p> <ul> <li>Measures</li> <li>From Semi-Ring to Ring</li> <li>From Ring to \\(\\sigma\\)-Alegebra: Carath\u00e9odory's Extension Theorem</li> </ul>"},{"location":"lecture/02-Measure/021-measure/","title":"Measure","text":"<p>In the previous chapter, we described the class of sets that can be measures. This present chapter deals with how to measure these sets in a consistent way. Let us first discuss the most natural example, which is the Lebesgue measure on the real line.</p> <p>This function, historically denoted by \\(\\lambda\\), should provide the \"measure\" of subsets of the real line. It should have the following properties: the measure of an interval should be equal to its length. In other terms,</p> \\[ \\begin{equation}     \\lambda\\left[ (a,b] \\right]=b-a \\end{equation} \\] <p>for \\(a&lt;b\\) reals.</p> <p>It should also have an additive property, meaning that the length of disjoint intervals should equal their sum,</p> \\[ \\begin{equation}     \\lambda\\left[ (a_1,b_1]\\cup(a_2,b_2] \\right]=(b_1-a_1)+(b_2-a_2)=\\lambda\\left[ (a_1,b_1] \\right]+\\lambda\\left[ (a_2,b_2] \\right]. \\end{equation} \\] <p>Finally, if a subset \\(A=\\cup (a_n,b_n]\\) is a countable union of disjoint intervals \\((a_n,b_n]\\), then its measure should be equal to the limit of the total length of all intervals, that is,</p> \\[ \\begin{equation}     \\lambda\\left[ A \\right]=\\lambda\\left[ \\cup (a_n,b_n] \\right]=\\sum (b_n-a_n)=\\sum \\lambda\\left[ (a_n,b_n] \\right]. \\end{equation} \\] <p>This raises the following questions:</p> <ul> <li>First, on which subclass of sets of the real line should \\(\\lambda\\) be defined?</li> <li>Second, which continuity property should this set function satisfy?</li> </ul> <p>We saw that the collection of intervals of the form \\((a,b]\\) forms a semi-ring on which the Lebesgue measure can be defined easily. As for the additivity property of the measure, we then have to extend it to the ring it generates. Finally, as for the continuity property, we have to extend it to the \\(\\sigma\\)-algebra it generates since it is stable under finite union.``</p> <p>Throughout, given a class of sets \\(\\mathcal{C}\\) containing the emptyset and a set function \\(\\mu \\colon \\mathcal{C} \\to \\mathbb{R}\\cup\\{\\pm \\infty\\}\\) we say that \\(\\mu\\) is</p> <ul> <li>positive: if \\(\\mu[A]\\geq 0\\) for every \\(A\\);</li> <li>additive: if for any two disjoint sets \\(A\\) and \\(B\\) in \\(\\mathcal{C}\\) with \\(A\\cup B\\) in \\(\\mathcal{C}\\) it holds \\(\\mu[A\\cup B] = \\mu[A] + \\mu[B]\\);</li> <li> <p>sub-additive: if for any two sets \\(A\\) and \\(B\\) in \\(\\mathcal{C}\\) it holds \\(\\mu[A\\cup B] \\leq \\mu[A] + \\mu[B]\\);</p> </li> <li> <p>\\(\\sigma\\)-additive: if for any countable family of pairwize disjoint sets \\((A_n)\\) in \\(\\mathcal{C}\\) such that \\(\\cup A_n\\) is in \\(\\mathcal{C}\\), it holds \\(\\mu [\\cup A_n] = \\sum \\mu[A_n]\\);</p> </li> <li>\\(\\sigma\\)-sub-additive: if for any countable family of sets \\((A_n)\\) in \\(\\mathcal{C}\\) such that \\(\\cup A_n\\) is in \\(\\mathcal{C}\\), it holds \\(\\mu [\\cup A_n] \\leq  \\sum \\mu[A_n]\\);</li> </ul> <p>We say that a set function \\(\\tilde{\\mu}\\) defined on a \\(\\tilde{\\mathcal{C}}\\supseteq \\mathcal{C}\\) extends \\(\\mu\\) is they coincide on \\(\\mathcal{C}\\).</p> <p>Measure</p> <p>Let \\(\\mathcal{F}\\) be a \\(\\sigma\\)-algebra. A set function \\(\\mu \\colon \\mathcal{F} \\to [0, \\infty]\\) is called a measure if</p> <ul> <li>\\(\\mu[\\emptyset] = 0\\);</li> <li> <p>\\(\\sigma\\)-Additivity: for any countable family \\((A_n)\\) of pairwize disjoint sets in \\(\\mathcal{F}\\), it holds</p> \\[     \\mu\\left[ \\cup A_n \\right] = \\sum \\mu[A_n] \\] </li> </ul> <p>A triple \\((X, \\mathcal{F}, \\mu)\\) where \\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra on \\(X\\) and \\(\\mu\\) is a measure on \\(\\mathcal{F}\\) is called a measured space.</p> <p>Let \\(\\mathcal{S}\\) be a semi-ring. A set function \\(\\mu \\colon \\mathcal{S}\\to [0, \\infty]\\) is called a pre-measure if</p> <ul> <li>\\(\\mu[\\emptyset] = 0\\);</li> <li> <p>Additivity: for any two dijoints sets \\(A\\) and \\(B\\) in \\(\\mathcal{S}\\)  such that \\(A \\cup B\\) is in \\(\\mathcal{S}\\) it holds</p> \\[     \\mu\\left[ A \\cup B \\right] = \\mu[A] + \\mu[B] \\] </li> </ul> <p>In other terms, a measure on a \\(\\sigma\\)-algebra is a positive set function equal to \\(0\\) on the emptyset and \\(\\sigma\\)-additive, while a pre-measure on a ring is just with additivity.</p> <p>We say that a measure \\(\\mu\\) is </p> <ul> <li>finite if \\(\\mu[X]&lt;\\infty\\)</li> <li>\\(\\sigma\\)-finite: if \\(\\mu[A_n]&lt;\\infty\\) for some increasing sequence \\((A_n)\\) with \\(\\cup A_n = X\\).</li> </ul> <p>Remark</p> <p>This lecture is essentially about stochastics and we will therefore mainly consider finite measures \\(\\mu\\) normalized to \\(\\mu[X] = 1\\). Such a measure is called a probability measure.</p> <p>Example: Probability on a Countable set</p> <p>Suppose that \\(X=\\{x_1, \\ldots, x_N\\}\\) is a finite set with \\(\\sigma\\)-algebra \\(\\mathcal{F} = 2^X\\). Since any subset \\(A\\) of \\(X\\) can be written as a finite union of disjoint singletons</p> \\[     A = \\cup_{i \\in I}x_i \\] <p>for some \\(I\\subseteq \\{1, \\ldots, N\\}\\), from \\(\\sigma\\)-additivity, it holds</p> \\[     \\mu[A] = \\sum_{i \\in I}\\mu[\\{x_i\\}] \\] <p>the measure is equivalently given by a positive function \\(m\\colon X\\to [0, \\infty]\\) with \\(m(x_i) = \\mu[\\{x_i\\}]\\).</p> <p>Due to \\(\\sigma\\)-additivity, the same argumentation holds for \\(X = (x_n)\\) being a countable set where measures on \\(\\mathcal{F} = 2^X\\) are entirely described by functions \\(m\\colon X \\to [0, \\infty]\\) through \\(m(x_n) = \\mu[\\{x_n\\}]\\).</p> <p>Example: Dirac Measure</p> <p>Let \\((X, \\mathcal{F})\\) be a measurable space and \\(x_0\\) be an element of \\(X\\). The dirac measure \\(\\delta_{x_0}\\colon \\mathcal{F} \\to [0, 1]\\) is defined as</p> \\[    \\begin{equation}        \\delta_{x_0}[A]=        \\begin{cases}            1 &amp; \\text{if }x_0\\text{ is in } A\\\\            0 &amp; \\text{otherwise}        \\end{cases}    \\end{equation} \\] <p>for any \\(A\\) in \\(\\mathcal{F}\\). Straightforward inspection shows that it is a probability measure.</p> <p>Example: Counting Pre-Measure</p> <p>Let \\(\\mathcal{S}\\) be a semi-ring on \\(X\\). Define \\(\\mu\\colon \\mathcal{F}\\to [0, \\infty]\\) as</p> \\[    \\begin{equation}        \\mu[A]=        \\begin{cases}            \\# A &amp;\\text{if }A\\text{ is finite}\\\\            \\infty &amp; \\text{otherwise}        \\end{cases}, \\quad A \\in \\mathcal{F}.    \\end{equation} \\] <p>It is easy to check that \\(\\mu\\) is a pre-content, which is \\(\\sigma\\)-additive if and only if \\(A\\) is finite.</p> <p>Example: Normal Distribution</p> <p>For \\(X=\\mathbb{R}\\) and \\(\\mathcal{F} = \\mathcal{B}(\\mathbb{R})\\) the Borel \\(\\sigma\\)-algebra we define  </p> \\[    \\begin{equation}        \\mu[A]=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\int_A e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\lambda(dx), \\quad A \\in \\mathcal{F},    \\end{equation} \\] <p>where \\(\\lambda\\) is the Lebesgue measure on \\(\\mathbb{R}\\) (we do not yet know if such an object exists).</p> <p>This is the famous normal distribution, which is a probability measure on the real line.</p> <p>Another way to generate measures is to use measurable functions and by the pre-image properties can also transport forward (pushforward) measures through measurable functions</p> <p>Definition: Pullback Measure</p> <p>Let f\\colon X \\to Y$ be a measurable function for the \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) and \\(\\mathcal{G}\\) on \\(X\\) and \\(Y\\), respectively.</p> <p>Given a measure \\(\\mu\\) on \\(\\mathcal{F}\\), we can define the pushforward measure \\(\\mu_{\\#f} \\colon \\mathcal{G} \\to [0, \\infty]\\) as</p> \\[     \\mu_{\\# f}[B] = \\mu \\left[ f \\in B \\right] = \\mu\\left[ \\left\\{ x \\in X \\colon f(x) \\in B \\right\\} \\right]  \\] <p>for any \\(B\\) in \\(\\mathcal{G}\\).</p> <p>Easy inspection shows that \\(\\mu_{\\# f}\\) is indeed a measure on \\(\\mathcal{G}\\).</p>"},{"location":"lecture/02-Measure/022-semi-ring-to-ring/","title":"From Semi-Ring to Ring","text":"<p>The definition of measure is well and fine, but beyond the obvious countable sets, we want to be able to construct measure on more complex sets such as the Lebesgue measure on the Borel \\(\\sigma\\)-algebra. In other terms if such objects do really make sense.</p> <p>In view of the Lebesgue's measure, let us consider the slightly more general concept of Stieljes integral. Consider the real line \\(X = \\mathbb{R}\\) with the semi-ring \\(\\mathcal{S}\\) of half open intervals \\((a, b]\\) for \\(a\\leq b\\). Given any increasing function \\(F\\colon \\mathbb{R} \\to \\mathbb{R}\\), increasing and right continuous, that is, \\(F(x) = \\lim_{y \\searrow x} F(y)\\). We define the set function \\(\\mu \\colon \\mathcal{S}\\to [0, \\infty]\\) given by</p> \\[ \\begin{equation*}  \\mu[(a, b] ] = F(b)-F(a) \\quad \\text{for any }a\\leq b \\end{equation*} \\] <p>It is direct to check that this indeed defines a pre-measure on \\(\\mathcal{S}\\). The case of the Lebesgue's measure is by taking \\(F(x) = x\\).</p> <p>This represents the basic requirement we want to have given \\(F\\) for a measure. The first step to carry is whether this set function can be extended uniquely to a set function on the ring generated by \\(\\mathcal{S}\\).</p> <p></p> <p>Proposition</p> <p>Let \\(\\mu\\) be a pre-measure on a semi-ring \\(\\mathcal{S}\\). There exists a unique pre-measure extension of \\(\\mu\\) on the ring \\(\\mathcal{R}=r(\\mathcal{S})\\) generated by \\(\\mathcal{S}\\).</p> <p>Proof</p> <p>We know from the proposition on the relationship between semi-ring and rings that every element of \\(\\mathcal{R}\\) can be written as a finite union of disjoint elements of \\(\\mathcal{S}\\). Let \\(A=\\cup_{1\\leq k\\leq n}A_k\\) for a finite disjoint family \\((A_k)_{1\\leq k\\leq n}\\) and define</p> \\[ \\begin{equation}     \\nu\\left[ A \\right]=\\sum_{1\\leq k\\leq n} \\mu\\left[ A_k \\right]. \\end{equation} \\] <p>This definition does not depend on the choice of the disjoint family. Indeed, suppose \\(A=\\cup_{1\\leq l\\leq m}B_j\\) for another finite disjoint family \\((B_l)_{1\\leq l\\leq m}\\) of elements of \\(\\mathcal{S}\\). Since \\(A_k=\\cup_{1\\leq l\\leq m}A_k\\cap B_l\\) as well as \\(B_l=\\cup_{1\\leq k\\leq n}A_k\\cap B_l\\) are both disjoint unions of elements in \\(\\mathcal{S}\\) for every \\(k\\) and \\(l\\), it holds</p> \\[ \\begin{align}     \\nu\\left[ A \\right] &amp;= \\sum_{1\\leq k\\leq n}\\mu\\left[A_k\\right]\\\\     &amp;=\\sum_{1\\leq k\\leq n}\\sum_{1\\leq l\\leq m}\\mu\\left[ A_k\\cap B_l \\right]\\\\     &amp;=\\sum_{1\\leq l\\leq m}\\sum_{1\\leq k\\leq n} \\mu\\left[ A_k\\cap B_l \\right]\\\\     &amp;=\\sum_{1\\leq l\\leq m}\\mu\\left[ B_l \\right]. \\end{align} \\] <p>This shows that \\(\\nu\\) is well defined on \\(\\mathcal{R}\\). By definition, it clearly holds that \\(\\nu\\) is an extension of \\(\\mu\\). Let us show that it is a content. Clearly, \\(\\nu[\\emptyset]=\\mu[\\emptyset]=0\\). For \\(A=\\cup_{1\\leq k\\leq n}A_k\\), a finite disjoint union of elements in \\(\\mathcal{R}\\), we can write each \\(A_k=\\cup_{1\\leq l\\leq m_k}B_{lk}\\) as a finite union of elements in \\(\\mathcal{S}\\). It follows that \\(A=\\cup_{1\\leq k}\\cup_{1\\leq l\\leq m_l}B_{kl}\\) is a finite disjoint union of elements in \\(\\mathcal{S}\\). Hence</p> \\[ \\begin{equation}     \\nu\\left[ A \\right]=\\sum_{1\\leq k\\leq n}\\sum_{1\\leq l\\leq m_l}\\mu\\left[ B_{kl} \\right]=\\sum_{q\\leq k\\leq n}\\nu\\left[\\cup_{1\\leq l\\leq m_k}B_{kl}  \\right]=\\sum_{1\\leq k\\leq n}\\nu\\left[ A_k \\right]. \\end{equation} \\] <p>This proves finite additivity.</p> <p>As for the uniqueness of the extension as a content, it is immediate from the finite additivity and the fact that every element in \\(\\mathcal{R}\\) can be written as a disjoint union of finitely many elements in \\(\\mathcal{S}\\).  </p> <p>Before handling the extension under the additional assumption that \\(\\mu\\) is \\(\\sigma\\)-additive, let us treat some properties of contents.</p> <p></p> <p>Lemma</p> <p>Let \\(\\mu\\) be a pre-measure on a semi-ring \\(\\mathcal{S}\\). Then it holds:</p> <ul> <li>(i) \\(\\mu\\) is monotone, that is \\(\\mu[A]\\leq \\mu[B]\\) for every \\(A\\subseteq B\\) with \\(A,B\\) in \\(\\mathcal{S}\\).</li> <li>(ii) \\(\\mu\\) is sub-additive.</li> <li>(iii) \\(\\mu\\) is \\(\\sigma\\)-additive if and only if \\(\\mu\\) is \\(\\sigma\\)-sub-additive.</li> </ul> <p>Let \\(\\mu\\) be a pre-measure on a ring \\(\\mathcal{R}\\). Then it holds:</p> <ul> <li>(a) \\(\\mu[B\\setminus A]=\\mu[B]-\\mu[A]\\) for every \\(A\\subseteq B\\) with \\(A,B\\) in \\(\\mathcal{R}\\).</li> <li>(b) \\(\\mu[A\\cup B]+\\mu[A\\cap B]=\\mu[A]+\\mu[B]\\) for every \\(A,B\\) in \\(\\mathcal{R}\\).</li> <li>(c) \\(\\sum \\mu[A_n]\\leq \\mu[A]\\) for every sequence \\((A_n)\\) of mutually disjoint sets in \\(\\mathcal{R}\\) and \\(A\\in \\mathcal{R}\\) such that \\(\\cup A_n \\subseteq A\\).</li> </ul> Proof <p>(i) Let \\(A\\subseteq B\\) with \\(A\\) and \\(B\\) in \\(\\mathcal{S}\\). It follows that \\(B\\setminus A=\\cup_{1\\leq k\\leq n}C_k\\) for a disjoint family \\((C_k)_{1\\leq k\\leq n}\\) in \\(\\mathcal{S}\\). Due to the additivity and positivity of \\(\\mu\\), it follows  </p> \\[ \\begin{align}     \\mu[B] &amp; =\\mu[A\\cup B\\setminus A]=\\mu[A\\cup (\\cup_{1\\leq k\\leq n}C_k)]\\\\     &amp; =\\mu[A]+\\sum_{1\\leq k\\leq n}\\mu[C_k]\\geq \\mu[A]. \\end{align} \\] <p>(ii) Let \\((A_k)_{1\\leq k\\leq n}\\) be a countable family of elements in \\(\\mathcal{S}\\) and \\(A\\in \\mathcal{S}\\) be such that \\(A\\subseteq \\cup_{k\\leq n}A_k\\). Define \\(B_1=A_1\\) and \\(B_k=A_k\\setminus (\\cup_{1\\leq l&lt;k}A_l)=\\cap_{1\\leq l&lt;k}(A_k\\setminus (A_k\\cap A_l))\\). By definition of a semi-ring, there exists \\((C_{kl})_{1\\leq l\\leq r_k}\\), a disjoint family in \\(\\mathcal{S}\\), such that \\(B_k=\\cup_{1\\leq l\\leq r_k} C_{kl}\\). Note also that \\(B_k\\subseteq A_k\\). Since \\(A_k\\setminus B_k=\\cap_{1\\leq l\\leq c_k}(A_k\\setminus (A_k\\cap C_{kl}))\\), a similar argument yields the existence of \\((D_{kj})_{1\\leq j\\leq p_k}\\), a disjoint family in \\(\\mathcal{R}\\), such that \\(A_k\\setminus B_k =\\cup_{1\\leq j\\leq p_k} D_{kj}\\). By additivity, we deduce that</p> \\[ \\begin{align}     \\mu[A_k] &amp;= \\mu[A_k\\setminus B_k \\cup B_k]\\\\     &amp; =\\mu[(\\cup_{1\\leq j\\leq p_k}D_{kj})\\cup (\\cup_{1\\leq l\\leq r_k}C_{kl})]\\\\     &amp;=\\sum_{1\\leq j\\leq p_k}\\mu[D_{kj}]+\\sum_{1\\leq l\\leq r_k}\\mu[C_{kl}]\\\\     &amp; \\geq \\sum_{1\\leq l\\leq r_k}\\mu[C_{kl}]. \\end{align} \\] <p>Using this inequality, the monotonicity and additivity of \\(\\mu\\), as well as the fact that  </p> \\[ A=A\\cap (\\cup_{1\\leq k\\leq n}A_k)=A\\cap(\\cup_{1\\leq k\\leq n}B_k)=A\\cap (\\cup_{k\\leq n}\\cup_{1\\leq l\\leq r_k}C_{kl})=\\cup_{1\\leq k\\leq n}\\cup_{1\\leq l\\leq r_k}(A\\cap C_{kl}), \\] <p>it follows that</p> \\[ \\begin{align}     \\mu[A] &amp;= \\mu\\left[\\cup_{1\\leq k\\leq n}\\cup_{1\\leq l\\leq r_k}(A\\cap C_{kl})  \\right]\\\\     &amp; = \\sum_{1\\leq k\\leq n}\\sum_{1\\leq l\\leq r_k}\\mu[A\\cap C_{kl}]\\\\     &amp; \\leq \\sum_{1\\leq k\\leq n}\\sum_{1\\leq l \\leq r_k}\\mu[C_{kl}]\\\\     &amp; \\leq \\sum_{1\\leq k\\leq n}\\mu[A_k], \\end{align} \\] <p>showing the sub-additivity.</p> <p>(iii) Suppose that \\(\\mu\\) is \\(\\sigma\\)-additive. The fact that \\(\\mu\\) is \\(\\sigma\\)-sub-additive follows from the same argumentation with a family \\((A_n)\\) instead of \\((A_k)_{1\\leq k\\leq n}\\). Suppose therefore that \\(\\mu\\) is a \\(\\sigma\\)-sub-additive content, and let us show that \\(\\mu\\) is \\(\\sigma\\)-additive. Let \\((A_n)\\) be a disjoint family in \\(\\mathcal{S}\\) such that \\(\\cup A_n \\in \\mathcal{S}\\). Denote by \\(\\nu\\) the unique extension to the ring \\(\\mathcal{R}\\) generated by \\(\\mathcal{S}\\). Since \\(\\nu=\\mu\\) on \\(\\mathcal{S}\\) and \\(\\nu\\) is additive as well as monotone, it follows that</p> \\[ \\begin{align}     \\sum \\mu[A_n] &amp; =\\sup_n \\sum_{1\\leq k\\leq n}\\mu[A_k]\\\\     &amp;=\\sup_n \\sum_{1\\leq k\\leq n}\\nu[A_k]\\\\     &amp;=\\sup_n \\nu[\\cup_{1\\leq k\\leq n}A_k]\\\\     &amp;\\leq\\sup_n \\nu[\\cup A_n]\\\\     &amp;=\\nu[A]=\\mu[A]. \\end{align} \\] <p>The \\(\\sigma\\)-sub-additivity yields the reverse equality, showing \\(\\sigma\\)-additivity.</p> <p>(a) Let \\(A\\subseteq B\\) for \\(A,B\\) in \\(\\mathcal{R}\\). It follows that \\(B\\setminus A \\in \\mathcal{R}\\). Hence, additivity yields \\(\\mu[B]=\\mu[A\\setminus B\\cup B]=\\mu[B\\setminus A]+\\mu[A]\\).</p> <p>(b) For \\(A,B\\) in \\(\\mathcal{R}\\), it holds \\(A\\cup B=A\\cup (B\\setminus A)\\) and \\(B=A\\cap B\\cup (B\\setminus A)\\). Since all elements of the decomposition are in \\(\\mathcal{R}\\), we get \\(\\mu[A\\cup B]=\\mu[A]+\\mu[B\\setminus A]\\) and \\(\\mu[B]=\\mu[A\\cap B]+\\mu[B\\setminus A]\\), from which follows the assertion.</p> <p>(c) Let \\((A_n)\\) be a pairwise disjoint sequence of elements in \\(\\mathcal{R}\\) and \\(A\\in \\mathcal{R}\\) such that \\(\\cup A_n \\subseteq A\\). By monotonicity, additivity, and stability of \\(\\mathcal{R}\\) under finite union, it holds \\(\\sum_{1\\leq k\\leq n}\\mu[A_k]=\\mu[\\cup_{1\\leq k\\leq n} A_k]\\leq \\mu[A]\\) for every \\(n\\). Hence the assertion.</p> <p>Extending a content from a semi-ring to a ring is fairly straightforward. However, for the sake of the next extension to a \\(\\sigma\\)-algebra, it may be interesting to see if the same result holds for a pre-measure.  </p> <p>Proposition</p> <p>Let \\(\\mu\\) be a pre-measure on a semi-ring \\(\\mathcal{S}\\). Suppose that \\(\\mu\\) is either \\(\\sigma\\)-additive or \\(\\sigma\\)-sub-additive. Then the unique extension of \\(\\mu\\) as a pre-measure \\(\\nu\\) on \\(\\mathcal{R}\\) -- the ring generated by \\(\\mathcal{S}\\) -- is also \\(\\sigma\\)-additive.</p> <p>Proof</p> <p>The fact that we can assume that \\(\\mu\\) is either \\(\\sigma\\)-additive or \\(\\sigma\\)-sub-additive follows from the equivalence between both properties due to the previous Lemma. Assume therefore that \\(\\mu\\) is \\(\\sigma\\)-additive and let us show that \\(\\nu\\) is so too. Let \\((A_n)\\) be a family of pairwise disjoint elements in \\(\\mathcal{R}\\) such that \\(A=\\cup A_n\\) is in \\(\\mathcal{R}\\). Denote by \\(A=\\cup_{1\\leq l\\leq m}B_l\\) and \\(A_n=\\cup_{1\\leq k\\leq r_n} B_{nk}\\) with \\((B_l)_{1\\leq l\\leq n}\\) and \\((B_{nk})_{1\\leq k\\leq r_n}\\) pairwise disjoint families in \\(\\mathcal{S}\\). Defining \\(C_{lnk}=B_l\\cap B_{nk}\\), it follows that</p> \\[ B_l=\\cup_{n}\\cup_{1\\leq k\\leq r_n}C_{lnk}, \\quad \\text{and} \\quad B_{nk}=\\cup_{1\\leq l\\leq m} C_{lnk} \\] <p>are disjoint decompositions into sets in \\(\\mathcal{S}\\). By additivity of \\(\\mu\\), it follows that \\(\\mu[B_{nk}]=\\sum_{1\\leq l\\leq m}\\mu[C_{lnk}]\\) and by \\(\\sigma\\)-additivity of \\(\\mu\\), also \\(\\mu[B_l]=\\sum_{n}\\sum_{1\\leq k\\leq r_n}\\mu[C_{lnk}]\\). Since we can switch infinite sums of positive numbers, it follows that</p> \\[ \\begin{align}     \\nu\\left[ A \\right] &amp; =\\sum_{1\\leq l\\leq m}\\mu[B_l]=\\sum_{1\\leq l\\leq m}\\sum_{n}\\sum_{1\\leq k\\leq r_n}\\mu[C_{lnk}]\\\\     &amp; =\\sum_{n}\\sum_{1\\leq k\\leq r_n}\\sum_{1\\leq l\\leq m}\\mu[C_{lnk}]\\\\     &amp;=\\sum_{n}\\sum_{1\\leq k\\leq r_n}\\mu[B_{nk}]=\\sum_n \\nu[A_n] \\end{align} \\] <p>showing the \\(\\sigma\\)-additivity.</p> <p>Example: Lebesgue/Stieljes Measure</p> <p>Let us study the example of the Lebesgue/Stieljes measure presented in the introduction of this section. Given a right continuous increasing function \\(F:\\mathbb{R}\\to \\mathbb{R}\\), on the semi-ring \\(\\mathcal{S}=\\{(a,b]\\colon a\\leq b, a,b \\in \\mathbb{R}\\}\\), the Lebesgue/Stieljes pre-measure is defined as the set function \\(\\mu[(a,b] ]=F(b)-F(a)\\). Let us show that \\(\\mu\\) is indeed a pre-measure.</p> <ul> <li>\\(\\mu[\\emptyset]=\\mu[(a,a]]=F(a)-F(a)=0\\).</li> <li> <p>Let \\((a_k,b_k]\\) be disjoint intervals for \\(1\\leq k\\leq n\\) such that \\(\\cup_{1\\leq k\\leq n} (a_k,b_k]=(a,b] \\in \\mathcal{S}\\).     Up to reordering, without loss of generality, we can assume that \\(a_1\\leq b_1\\leq a_{2}\\leq b_2\\leq \\ldots \\leq a_n\\leq b_n\\) since the intervals are disjoint.     Furthermore, since \\(\\cup_{1\\leq k\\leq n} (a_k,b_k]=(a,b]\\) is an interval itself, it follows that \\(a_k=b_{k+1}\\) for every \\(k=1,\\ldots, n-1\\) and \\(a=a_1\\) and \\(b=b_n\\).     Hence  </p> \\[   \\sum_{1\\leq k\\leq n}\\mu[(a_k,b_k]]=\\sum_{1\\leq k\\leq n}F(b_k)-F(a_k)=F(b_n)-F(a_1)=F(b)-F(a)=\\mu[(a,b]] \\] <p>showing the additivity.  </p> </li> </ul> <p>We can extend \\(\\mu\\) to the ring generated by \\(\\mathcal{S}\\) as shown in a previous proposition.</p> <p>Interestingly though, \\(\\mu\\) is \\(\\sigma\\)-additive on this ring. The reason for which is strongly related to compactness arguments. According to the previous proposition and lemma, it is enough to show that \\(\\mu\\) is \\(\\sigma\\)-sub-additive on the semi-ring \\(\\mathcal{S}\\). Let \\((a,b]\\in \\mathcal{S}\\) and \\(((a_n,b_n])\\) be a countable family in \\(\\mathcal{S}\\) such that \\((a,b]\\subseteq \\cup (a_n,b_n]\\).</p> <p>Let \\(\\varepsilon&gt;0\\), and by right continuity of \\(F\\) choose some \\(a^\\varepsilon\\) in \\((a,b)\\) such that \\(F(a^\\varepsilon)-F(a)&lt;\\varepsilon/2\\). Also, using right continuity of \\(F\\), choose \\(b^\\varepsilon_n&gt;b_n\\) for every \\(n\\) such that \\(F(b_n^\\varepsilon)-F(b_n)\\leq \\varepsilon 2^{-n-1}\\). It follows that</p> \\[   [a^\\varepsilon,b]\\subseteq (a^\\varepsilon,b]\\subseteq (a,b]\\subseteq \\cup (a_n,b_n]\\subseteq (a_n,b_n^\\varepsilon). \\] <p>However, \\([a^\\varepsilon,b]\\) is a bounded closed interval, and therefore compact. Hence, the open covering \\(\\cup (a_n,b_n^\\varepsilon)\\) of \\([a^\\varepsilon,b]\\) can be chosen finite, that is, there exists \\(n_0\\) such that</p> \\[   (a^\\varepsilon,b]\\subseteq [a^\\varepsilon,b]\\subseteq \\cup_{1\\leq k\\leq n_0}(a_k,b_k^\\varepsilon)\\subseteq \\cup_{k\\leq n_0}(a_k,b_k^\\varepsilon]. \\] <p>Hence, since \\(\\mu\\) is sub-additive by means of of the previous lemms, it follows that  </p> \\[ \\begin{align}   \\mu[(a,b]]  &amp; = F(b)-F(a)\\\\               &amp; \\leq \\varepsilon/2 + F(b)-F(a^\\varepsilon)\\\\               &amp; \\leq \\varepsilon/2 + \\sum_{k=1}^{n_0}\\left(F(b_k^\\varepsilon)-F(a_k)\\right)\\\\               &amp; \\leq \\varepsilon/2 + \\varepsilon \\sum_{k=1}^{n_0}2^{-k-1} +\\sum_{k=1}^{n_0} \\left(F(b_n)-F(a_n)\\right)\\\\               &amp; \\leq \\varepsilon +\\sum \\left(F(b_n)-F(a_n)\\right)\\\\               &amp; =\\varepsilon+\\sum \\mu[(a_n,b_n]] \\end{align} \\] <p>Since \\(\\varepsilon\\) is arbitrarily small, it follows that \\(\\mu\\) is \\(\\sigma\\)-sub-additive, hence \\(\\sigma\\)-additive on the semi-ring \\(\\mathcal{S}\\).</p> <p>From the previous proposition, \\(\\mu\\) extends uniquely to a \\(\\sigma\\)-additive content on the ring generated by \\(\\mathcal{S}\\).</p> <p>The main question now is whether it is possible to extend the Lebesgue or Lebesgue-Stieltjes content to a measure on the \\(\\sigma\\)-algebra \\(\\mathcal{B}(\\mathbb{R})\\) which is generated by \\(\\mathcal{S}\\).  </p>"},{"location":"lecture/02-Measure/023-ring-to-s-algebra/","title":"From Ring to \\(\\sigma\\)-Algebra: Carath\u00e9odory's Theorem","text":"<p>As mentioned in the previous section, the question is whether a \\(\\sigma\\)-additive pre-measure on a ring \\(\\mathcal{R}\\) can be extended to the \\(\\sigma\\)-algebra it generates. In case such an extension exists, a further relevant question is whether such an extension is unique.</p> <p>Before assessing the extension, we first address some central properties of the \\(\\sigma\\)-additivity in terms of continuity.</p> <p>Lemma</p> <p>Let \\(\\mathcal{R}\\) be a ring and \\(\\mu:\\mathcal{R}\\to [0,\\infty]\\) a finite content, that is \\(\\mu[A]&lt;\\infty\\) for every \\(A \\in \\mathcal{R}\\). Then the following properties of \\(\\mu\\) hold:</p> <ol> <li>\\(\\sigma\\)-additivity</li> <li>\\(\\sigma\\)-sub-additivity</li> <li>Lower semi-continuity: \\(\\sup_n \\mu[A_n]= \\mu[\\cup A_n]\\) for every countable family \\((A_n)\\) of increasing elements in \\(\\mathcal{R}\\) such that \\(\\cup A_n\\) is in \\(\\mathcal{R}\\).</li> <li>Upper semi-continuity: \\(\\inf_n \\mu[A_n]= \\mu[\\cap A_n]\\) for every countable family \\((A_n)\\) of decreasing elements in \\(\\mathcal{R}\\) such that \\(\\cap A_n\\) is in \\(\\mathcal{R}\\).</li> <li>Continuous at \\(\\emptyset\\): \\(\\inf_n \\mu[A_n]= 0\\) for every countable family \\((A_n)\\) of decreasing elements in \\(\\mathcal{R}\\) such that \\(\\cap A_n=\\emptyset\\).</li> </ol> <p>Proof</p> <ul> <li>The equivalence between \\(\\sigma\\)-additivity and \\(\\sigma\\)-sub-additivity is already shown in a previous Lemma in the context of a semi-ring.</li> <li> <p>\\(\\sigma\\)-additivity implies lower semi-continuity:     Let \\((A_n)\\) be an increasing sequence of elements in \\(\\mathcal{R}\\) such that \\(A=\\cup A_n\\) is in \\(\\mathcal{R}\\).     Defining \\(B_n=A_n\\setminus \\cup_{k&lt;n}A_k=A_n\\setminus B_{n-1}\\) for \\(n&gt;1\\) and \\(B_1=A_1\\) provides a disjoint sequence of elements in \\(\\mathcal{R}\\).     Since \\(A_n=\\cup_{1\\leq k\\leq n} B_k\\) and \\(A=\\cup B_n\\), it follows from \\(\\sigma\\)-additivity that  </p> \\[ \\mu[A]=\\sum \\mu[B_n]=\\sup \\sum_{1\\leq k\\leq n}\\mu[B_k]=\\sup \\mu[\\cup_{1\\leq k\\leq n}B_k]=\\sup \\mu[A_n] \\] </li> <li> <p>Lower semi-continuity implies upper semi-continuity:     Let \\((A_n)\\) be a decreasing sequence of elements in \\(\\mathcal{R}\\) such that \\(A=\\cap A_n\\) is in \\(\\mathcal{R}\\).     It follows that \\(B_n=A_1\\setminus A_n\\) defines an increasing sequence such that \\(B=\\cup B_n=A_1\\setminus \\cap A_n=A_1\\setminus A \\in \\mathcal{R}\\).     Lower semi-continuity, additivity, and the properties of Lemma [lem-propcontentsemiring] imply that</p> \\[   \\mu[A_1]-\\inf \\mu[A_n]=\\sup (\\mu[A_1]-\\mu[A_n])=\\sup \\mu[A_1\\setminus A_n]=\\mu[\\cup A_1\\setminus A_n]=\\mu[A_1]-\\mu[A] \\] </li> <li> <p>Upper semi-continuity implies continuity at \\(\\emptyset\\) (immediate).</p> </li> <li> <p>Continuity at \\(\\emptyset\\) implies \\(\\sigma\\)-additivity:     Let \\((A_n)\\) be a sequence of mutually disjoint elements of \\(\\mathcal{R}\\) such that \\(A=\\cup A_n\\) is in \\(\\mathcal{R}\\).     By means of Lemma, it follows that  </p> \\[   \\sum \\mu[A_n]\\leq \\mu[A] \\] <p>It follows that \\(B_n=A\\setminus (\\cup_{1\\leq k\\leq n}A_k)\\) is a decreasing family of elements of \\(\\mathcal{R}\\) such that \\(\\cap B_n=\\emptyset\\). By additivity of \\(\\mu\\), we have</p> \\[ \\mu[A]=\\mu[B_n\\cup (\\cup_{1\\leq k\\leq n}A_k)]=\\mu[B_n]+\\sum_{1\\leq k\\leq n}\\mu[A_k] \\] <p>for every \\(n\\). Since \\(\\sum_{q\\leq k\\leq n}\\mu[A_k]\\to \\sum \\mu[A_n]\\) and by continuity at \\(\\emptyset\\), \\(\\mu[B_n]\\to 0\\), it follows that \\(\\mu[A]=\\sum \\mu[A_n]\\), hence the \\(\\sigma\\)-additivity.</p> </li> </ul> <p>We are now in position to formulate the central extension theorem of Carath\u00e9odory.</p> <p></p> <p>Theorem: Carath\u00e9odory's Extension Theorem</p> <p>Let \\(X\\) be a non-empty set, \\(\\mathcal{S}\\) a semi-ring such that \\(X=\\cup A_n\\) for some countable family \\((A_n)\\) of elements in \\(\\mathcal{S}\\). Suppose that \\(\\mu:\\mathcal{R}\\to [0,\\infty]\\) is a pre-measure such that:</p> <ol> <li>\\(\\mu[A_n]&lt;\\infty\\) for every \\(n\\).</li> <li>\\(\\mu\\) is \\(\\sigma\\)-sub-additive or equivalently \\(\\sigma\\)-additive.</li> </ol> <p>Then \\(\\mu\\) can be uniquely extended to a measure \\(\\nu\\) on \\(\\mathcal{F}=\\sigma(\\mathcal{S})\\).</p> <p>Remark</p> <p>We already know from the assumption of this theorem that according to a previous proposition there exists a unique extension \\(\\nu\\) to the ring \\(\\mathcal{R}\\) generated by \\(\\mathcal{S}\\) such that \\(\\nu\\) is a \\(\\sigma\\)-additive content. We can therefore assume for the proof of Carath\u00e9odory's theorem that \\(\\mu\\) is a \\(\\sigma\\)-additive content on a ring.</p> <p>The existence is the complex and lengthy part of the proof. However uniqueness can be adressed through the following proposition.</p> <p>Proposition</p> <p>Let \\((X,\\mathcal{F})\\) be a measurable space and \\(\\mathcal{P}\\) a \\(\\pi\\)-system on \\(X\\) that generates \\(\\mathcal{F}\\) and such that there exists a sequence \\((A_n)\\) of elements of \\(\\mathcal{P}\\) with \\(\\cup A_n=X\\). Let \\(\\mu\\) and \\(\\nu\\) be two measures on \\(\\mathcal{F}\\) that coincide on \\(\\mathcal{P}\\) and such that \\(\\mu(A_n)=\\nu(A_n)&lt;\\infty\\) for every \\(n\\). Then \\(\\mu=\\nu\\).</p> <p>Proof</p> <p>Let \\(n\\) be an integer and consider the collection of sets \\(\\mathcal{C}^n=\\{A \\in \\mathcal{F}\\colon \\mu[A\\cap A_n]=\\nu[A\\cap A_n]\\}\\). Then \\(\\mathcal{C}^n\\) is a \\(\\lambda\\)-system. Indeed</p> <ul> <li>\\(X\\) is in \\(\\mathcal{C}^n\\) since \\(\\mu[X\\cap A_n]=\\mu[A_n]=\\nu[A_n]=\\nu[A_n\\cap X]\\).</li> <li>Stability under relative complements: For \\(A\\subseteq B\\) with \\(A\\) and \\(B\\) in \\(\\mathcal{C}^n\\), it holds that \\(\\mu[(B\\setminus A)\\cap A_n]=\\mu[B\\cap A_n]-\\mu[A\\cap A_n]=\\nu[B\\cap A_n]-\\nu[A\\cap A_n]=\\nu[(B\\setminus A)\\cap A_n]\\), showing that \\(B\\setminus A\\) belongs to \\(\\mathcal{C}^n\\).</li> <li> <p>Stability under countable disjoint unions: If \\((B_m)\\) is a disjoint sequence in \\(\\mathcal{C}^n\\), then</p> \\[ \\mu[(\\cup B_m) \\cap A_n]=\\sum_m \\mu[B_m\\cap A_n]=\\sum_m \\nu[B_m\\cap A_n]=\\nu[(\\cup B_m)\\cap A_n] \\] <p>showing that \\(\\cup B_m \\in \\mathcal{C}^n\\).  </p> </li> </ul> <p>Since \\(\\mathcal{P}\\subseteq \\mathcal{C}^n\\), and \\(\\mathcal{P}\\) is stable under intersection, by means of the Dynkin Lemma, it follows that \\(\\mathcal{F}=\\sigma(\\mathcal{P})\\subseteq \\mathcal{C}^n\\subseteq \\mathcal{F}\\). Thus, \\(\\mu=\\nu\\).  </p> <p>Example: Lebesgue/Stieljes Measure</p> <p>The conditions of Carath\u00e9odory's Theorem are fulfilled in the case of the Lebesgue/Stieltjes measure. Therefore, it defines a unique measure on the Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}\\).</p> <p>We are left to show Carath\u00e9odory's extension theorem. The proof relies on the concept of outer measure. So far we tried to built measures from the bottom up, from simple class of sets and trying to reach \\(\\sigma\\)-algebra. The idea of outer measure is a top down approach hopping that both concepts would meet at the right place, that is, the \\(\\sigma\\)-algebra.</p>"},{"location":"lecture/02-Measure/023-ring-to-s-algebra/#outer-measure","title":"Outer Measure","text":"<p>Definition: Outer Measure</p> <p>A set function \\(\\mu^\\ast \\colon 2^X \\to [0, \\infty]\\) is called an outer measure if</p> <ul> <li>\\(\\mu^\\ast[\\emptyset] = 0\\);</li> <li> <p>\\(\\sigma\\)-sub-additivity: For any countable family \\((B_n)\\) of subsets of \\(X\\) and \\(A \\subseteq \\cup B_n\\) it holds</p> \\[   \\mu^\\ast[A] \\leq \\sum \\mu^\\ast[B_n] \\] </li> </ul> <p>A set \\(A\\subseteq X\\) is called \\(\\mu^\\ast\\)-measurable if </p> \\[   \\mu^\\ast[E] = \\mu^\\ast\\left[ E\\cap A \\right] + \\mu^\\ast \\left[ E\\cap A^c \\right] \\] <p>for every \\(E\\subseteq X\\).</p> <p>Note that the second condition implies that an outer measure is monotone, that is \\(\\mu[A] \\leq \\mu[B]\\) for any \\(A\\subseteq B\\). The notion of \\(\\mu^\\ast\\)-measurability of a set depends naturally of the outer measure. Clearly, due to subadditivity, for any subsets \\(E\\) and \\(A\\) of \\(X\\) it holds</p> \\[ \\mu^\\ast[E] \\leq \\mu^\\ast[E \\cap A] + \\mu^\\ast[E\\cap A^c] \\] <p>Hence, \\(A\\) is \\(\\mu^\\ast\\)-measurable if the reverse inequality holds for any set \\(E\\subseteq X\\). The denomination measurable is justified by the following theorem.</p> <p>Theorem</p> <p>Let \\(\\mu^\\ast\\) be an outer measure on \\(X\\). Then, the collection \\(\\mathcal{M}\\) of all \\(\\mu^\\ast\\)-measurable is a \\(\\sigma\\)-algebra. Furthermore, the restriction of \\(\\mu^\\ast\\) on this collection is a measure.</p> <p>Proof</p> <p>We show that \\(\\mathcal{M}\\) is a \\(\\sigma\\)-algebra.</p> <p>Step 1 - \\(\\emptyset\\) belongs to \\(\\mathcal{M}\\): Clearly, \\(\\emptyset\\) is obviously \\(\\mu^\\ast\\) measurable.</p> <p>Step 2 - Stability under complementation: For \\(A\\) in \\(\\mathcal{M}\\), then for any \\(E \\subseteq X\\) it holds that</p> \\[       \\mu^*(E) = \\mu^*(E \\cap A) + \\mu^*(E \\cap A^c). \\] <p>Interchanging \\(A\\) and \\(A^c\\) yields \\(A^c\\) belongs to \\(\\mathcal{M}\\).</p> <p>Step 3 - Stability under union: Let \\(A\\) and \\(B\\) be two \\(\\mu^\\ast\\)-measurable sets. For any set \\(E\\) it holds</p> \\[     \\mu^\\ast[E] = \\mu^\\ast[E \\cap A] + \\mu^\\ast[E \\cap A^c] \\] <p>In particular for \\(B\\) it holds</p> \\[       \\mu^\\ast[E\\cap A^c] = \\mu^\\ast[(E\\cap A^c) \\cap B] + \\mu^\\ast[(E\\cap A^c) \\cap B^c] \\] <p>Since by sub-additivity it holds that \\(\\mu^\\ast[E\\cap(A\\cup B)] \\leq \\mu^\\ast[E \\cap A] + \\mu^\\ast[E\\cap(A^c \\cap B)]\\). Hence, it holds that</p> \\[   \\begin{align*}     \\mu^\\ast[E] &amp; =  \\mu^*(E \\cap A) + \\mu^\\ast[(E\\cap A^c) \\cap B] + \\mu^\\ast[(E\\cap A^c) \\cap B^c]\\\\                 &amp; = \\mu^*(E \\cap A) + \\mu^\\ast[(E\\cap A^c) \\cap B] + \\mu^\\ast[(E\\cap (A\\cup B)^c]\\\\                 &amp; \\geq \\mu^\\ast[E\\cap (A\\cup B)] + \\mu^\\ast[E\\cap (A\\cup B)^c]    \\end{align*} \\] <p>showing that \\(A\\cup B\\) is \\(\\mu^\\ast\\)-measurable.</p> <p>In particular \\(\\mathcal{M}\\) is a ring.</p> <p>Step 4 - stability under countable union:  Since \\(\\mathcal{M}\\) is a ring, it is enough to show that \\(\\cup A_n\\) is \\(\\mu^\\ast\\)-measurable for any countable family \\((A_n)\\) of pairwise disjoints \\(\\mu^\\ast\\)-measurable sets. Let \\(B_n =\\cup_{k\\leq n} A_k\\) which is measurable for each \\(n\\). By induction, it holds that \\(\\mu^\\ast[E\\cap B_n] = \\sum_{k\\leq n} \\mu^\\ast[E\\cap A_k]\\) for any set \\(E\\subseteq X\\). Indeed \\(B_n\\) is \\(\\mu^\\ast\\)-measurable and \\(\\mu^\\ast[E \\cap B_{n+1}] = \\mu^\\ast[E\\cap B_{n+1}\\cap B_n ] + \\mu^\\ast[E \\cap B_{n+1}\\cap B_n^c] = \\mu^\\ast[E\\cap B_n] + \\mu^\\ast[E\\cap A_{n+1}]\\). By monotonicity, it also holds that</p> \\[   \\mu^\\ast[E \\cap A] \\geq \\sup_n \\mu^\\ast[E \\cap B_n] = \\sum \\mu^\\ast[E \\cap A_k] \\] <p>which together with sub-additivity yields \\(\\mu^\\ast[E\\cap A] = \\sum \\mu^\\ast[E\\cap A_n]\\). Hence, for any \\(E\\) we get</p> \\[   \\mu^\\ast[E] = \\mu^\\ast[E\\cap B_n] + \\mu^\\ast[E\\cap B_n^c]\\geq \\sum_{k\\leq n}\\mu^\\ast[E\\cap B_k]+\\mu^\\ast[E\\cap A^c] \\] <p>from which follows that \\(\\mu^\\ast[E]\\geq \\mu^\\ast[E\\cap A] + \\mu^\\ast[E\\cap A^c]\\) showing that \\(A = \\cup A_n\\) is \\(\\mu^\\ast\\)-measurable. Thus \\(\\mathcal{M}\\) is a \\(\\sigma\\)-Algebra.</p> <p>The fact that \\(\\mu^\\ast\\) restricted to \\(\\mathcal{M}\\) is immediate since it is \\(\\sigma\\)-sub-additive.</p>"},{"location":"lecture/02-Measure/023-ring-to-s-algebra/#caratheodorys-extension-theorem-proof","title":"Carath\u00e9odory's Extension Theorem Proof","text":"<p>We are now in position to show the proof of Carath\u00e9odory's extension theorem.</p> <p>Proof: Carath\u00e9odory's Extension Theorem</p> <p>From the previous results, we know that we can extend uniquely \\(\\mu\\) to a \\(\\sigma\\)-additive and finite measure to the ring \\(\\mathcal{R}\\) generated by \\(\\mathcal{S}\\).</p> <p>We define the set function</p> \\[   \\mu^\\ast[E]:= \\inf \\left\\{ \\sum \\mu^\\ast[A_n] \\colon E\\subseteq \\cup A_n \\colon (A_n) \\text{ is a countable family in }\\mathcal{R} \\right\\} \\] <p>By definition, \\(\\mu^\\ast\\) coincides with \\(\\mu\\) on \\(\\mathcal{R}\\). Let us show that \\(\\mu^\\ast\\) is an outer measure. Clearly, \\(\\mu^\\ast[\\emptyset] = 0\\). Let us show that \\(\\mu^\\ast\\) is \\(\\sigma\\)-sub-additive by taking a countable family \\((E_n)\\) and \\(E\\) of sets such that \\(E\\subseteq \\cup E_n\\). Since if \\(\\mu^\\ast[E_n] = \\infty\\) for some \\(n\\), then trivialy it holds that \\(\\mu^\\ast[E]\\leq \\sum \\mu^\\ast[E_n]\\), we can then assume that \\(\\mu^\\ast[E_n]&lt;\\infty\\) for any \\(n\\). Choose families \\((A_{nk})\\) in \\(\\mathcal{R}\\) such that \\(E_n \\subseteq_k A_{nk}\\) and \\(\\sum_k \\mu^\\ast[A_{nk}] \\leq \\mu^\\ast[E_n] + \\varepsilon 2^{-k}\\). It follows that \\(E\\subseteq \\cup_{nk}A_{nk}\\) and </p> \\[   \\mu^\\ast[E]\\leq \\sum_{nk}\\mu^\\ast[A_{nk}] \\leq \\sum \\mu^\\ast[E_n] + \\varepsilon \\] <p>which by arbitrariness of \\(\\varepsilon\\) show \\(\\sigma\\)-subadditivity.</p> <p>From the previous Theorem on outer measure, it follows that the set \\(\\mathcal{M}\\) of \\(\\mu^\\ast\\)-measurable sets is a \\(\\sigma\\)-algebra on which \\(\\mu^\\ast\\) is a measure. Since any element of \\(\\mathcal{R}\\) is \\(\\mu^\\ast\\)-measurable, it follows that \\(\\sigma(\\mathcal{R})\\subseteq \\mathcal{M}\\).</p> <p>Hence \\(\\mu^\\ast\\) defines a measure on \\(\\sigma(\\mathcal{R})\\) coinciding with \\(\\mu\\) on \\(\\mathcal{R}\\) which ends the proof.</p> <p>Example: Lebesgue/Stieljes measure</p> <p>From the previous derivation together with this extension theorem, we conclude that the Lebesgue/Stieljes measure is indeed a measure.</p>"},{"location":"lecture/02-Measure/024-polish/","title":"Measures On Polish Spaces","text":"<p>In this section we address how topological assumptions on the underlying state space interplay with the probability measure.</p> <p>Warning</p> <p>Throughout, \\(S\\) is a metric space<sup>1</sup> with distance \\(d\\) with corresponding Borel \\(\\sigma\\)-algebra \\(\\mathcal{S}=\\mathcal{B}(S)\\).</p> <p>With \\(B_\\delta(x) = \\{y \\in S\\colon d(x,y)&lt;\\delta\\}\\) we denote the open ball of size \\(\\delta\\) centered at \\(x\\).</p> <p>For a set \\(A\\) we define \\(d(x,A) = \\inf \\{d(x,y)\\colon y \\in A\\}\\) wich is the distance of \\(x\\) to \\(a\\). By triangular inequality it holds that \\(d(x, A)\\leq d(x, z) + d(z, A)\\) for any \\(z\\) showing that \\(|d(x, A)- d(z,A)|\\leq d(x,z)|\\), that is \\(x \\mapsto d(x, A)\\) is Lipshitz continuous.</p> <p>Definition: Tightness and Regularity</p> <p>A probability measure \\(P\\) on \\((S, \\mathcal{S})\\) is called</p> <ul> <li> <p>tight if for any \\(\\varepsilon&gt;0\\), there exists a compact \\(K\\) such that </p> \\[   P[S\\setminus K] \\leq \\varepsilon \\] </li> <li> <p>regular: if for every borel set \\(A\\) it holds</p> \\[   P[A] = \\sup \\left\\{ P[K]\\colon K\\subseteq A\\text{ and } K \\text{ compact} \\right\\} \\] </li> </ul> <p>Tightness shows that the metric space can be modulo \\(\\varepsilon\\) reduced in probability to a compact subset, while regularity shows that the measure of any complex Borel set can be approximated from inside by compacts.</p> <p>Theorem</p> <p>For a probability measure \\(P\\) on \\((S, \\mathcal{S})\\) the following are equivalent</p> <ul> <li>\\(P\\) is tight;</li> <li>\\(P\\) is regular;</li> </ul> Proof <p>Clearly, regularity implies tightness. Reciprocally, suppose that \\(P\\) is tight.</p> <ul> <li> <p>Step 1: We show that for any Borel set \\(A\\) it holds</p> \\[     P[A] = \\sup\\{P[F]\\colon F\\subseteq A \\text{ where }F \\text{ is closed.}\\}  \\] <ul> <li> <p>If \\(A\\) is an open set, define \\(F_n = \\{x \\colon d(x, A^c)\\geq 1/n\\}\\subseteq A\\) which is a closed set.     Indeed, \\(x \\mapsto d(x, A^c)\\) is Lipschitz continuous and \\(F_n = d(\\cdot , A^c)^{-1}([1/n, \\infty))\\) is the reciprocal image of a closed set, hence closed.     Furthermore \\(A = \\cup F_n\\) since \\(A^c\\) is closed.     Indeed, if there exists \\(x\\) in \\(A\\setminus \\cup F_n\\), it follows that \\(d(x, y_n)&lt;2/n\\) for some sequence \\((y_n)\\) in \\(A^c\\) showing that \\(y_n \\to x\\).     Since \\(A^c\\) is closed it follows that \\(x\\) is in \\(A^c\\) which is a contradiction.</p> <p>Since the sequence of sets \\(F_n\\) is increasing, by lower continuity of the probability measure it follows that</p> \\[   \\begin{align*}     \\sup\\left\\{ P[F]\\colon F\\subseteq A, F \\text{ closed} \\right\\}          &amp; \\leq P[A]\\\\         &amp; = P[\\cup F_n ]\\\\         &amp; = \\sup P[F_n]\\\\         &amp; \\leq \\sup\\left\\{ P[F]\\colon F\\subseteq A, F \\text{ closed} \\right\\}   \\end{align*} \\] </li> <li> <p>Define the collection \\(\\mathcal{C}\\) of those borel sets \\(A\\) such that \\(P[A]\\) and \\(P[A^c]\\) can be approximated from inside by closed sets.     Clearly any open set is member of \\(\\mathcal{C}\\), in particular \\(S\\) itself.     It is by definition closed under complementation.     Finally, it is closed under countable unions.     Indeed, let \\((A_n)\\) be a sequence in \\(\\mathcal{C}\\) and define \\(A = \\cup A_n\\).     Choose closed sets \\(F_n\\) and \\(G_n\\) such that \\(P[A_n\\setminus F_n]\\leq \\varepsilon/2^{n+1}\\) and \\(P[A_n^c \\setminus G_n]\\leq \\varepsilon/2^{n+1}\\).     Fix \\(m\\) such that \\(P[A\\setminus \\cup_{n \\leq m}A_n] \\leq \\varepsilon/2\\) and define \\(F = \\cup_{n\\leq m}F_n \\subseteq \\cup_{n\\leq m} A_n \\subseteq A\\).     It follows that</p> \\[   \\begin{align*}     P[A\\setminus F]        &amp; = P[A \\setminus \\cup_{n\\leq m} A_n] + P[\\cup_{n\\leq m}A_n \\setminus F]\\\\       &amp; \\leq \\frac{\\varepsilon}{2} + P\\left[ \\cup_{n \\leq m} A_n \\setminus F_n \\right]\\\\       &amp; \\leq \\frac{\\varepsilon}{2} + \\sum_{n \\leq m} \\frac{\\varepsilon}{2^{n+1}}        \\leq \\varepsilon   \\end{align*} \\] <p>Since \\(G = \\cap G_n\\) is closed, it follows that</p> \\[   \\begin{align*}     P\\left[ A\\setminus G \\right]        &amp; = P[\\cap A_n^c \\setminus \\cap G_n]\\\\       &amp; \\leq P\\left[ \\cup A_n^c \\setminus G_n \\right]\\\\       &amp; \\leq \\sum P[A_n^c \\setminus G_n] \\leq \\varepsilon   \\end{align*} \\] <p>showing that \\(\\mathcal{C}\\) is a \\(\\sigma\\)-algebra henceforth equal to \\(\\mathcal{S}\\) finishing the proof of the first step.</p> </li> </ul> </li> <li> <p>Step 2: We show the inner approximation with compacts.</p> <p>For a Borel set \\(A\\) choose a closed set \\(F\\) such that \\(P[A\\setminus F] \\leq \\varepsilon/2\\). By tightness, choose a compact \\(K\\) such that \\(P[S\\setminus K]\\leq \\varepsilon/2\\). The set \\(F\\cap K\\) is itself compact, and it holds</p> \\[   P[A \\setminus (F\\cap K)] \\leq P\\left[ A\\setminus F \\right] + P[A \\setminus K] \\leq \\frac{\\varepsilon}{2} + P[S\\setminus K] \\leq \\varepsilon \\] </li> </ul> <p>A metric space is automatically first countable, that is, each point has a countable basis of neighborhoods namely \\(B_{1/n}(x)\\). Most of the metric space we will encounter later have further properties that are useful from a measure viewpoint. Such metric spaces are called Polish.</p> <p>Definition: Polish Space</p> <p>A metric space \\(S\\) is called Polish if it is </p> <ul> <li>separable: there exists a countable dense subset \\((x_n)\\);</li> <li>complete: any Cauchy sequence is converging.</li> </ul> <p>Ulam's Theorem</p> <p>Any probability measure \\(P\\) on a Polish space \\((S, \\mathcal{S})\\) is tight, in particular, regular.</p> <p>Proof</p> <p>Recall that in a metric space a set \\(K\\) is compact if and only if it is closed, complete and totally bounded. Clearly if \\(K\\) is compact it is closed. Furthermore, as any sequence has a converging subsequence, if this sequence is Cauchy, it has a limit in \\(K\\), hence \\(K\\) is complete. Finally, for any \\(\\varepsilon&gt;0\\), \\(B_{\\varepsilon}(x)\\) for \\(x\\) in \\(K\\) is an open covering which can be reduce to a finite one because of compactness. Reciprocally, let \\((x_n)\\) be a sequence in the closed, complete and totally bounded set \\(K\\). For any integer \\(m\\) there exists a finite open covering of \\(K\\) by open balls of radius \\(1/m\\). Infinitely many elements of the sequence must belong to one of such ball. We can therefore construct a subsequence which is Cauchy which by completness will converge showing that \\(K\\) is compact.</p> <p>Let \\((x_n)\\) be a countable dense subset of \\(S\\). For any \\(m\\), since \\(S = \\cup_n \\bar{B}_{1/m}(x_n)\\) where \\(\\bar{B}_{1/m}(x_n)\\) is the closed ball of radius \\(1/m\\) centered in \\(x_n\\), choose \\(N_m\\) be such that \\(P[S \\setminus K_m]\\leq \\varepsilon/2^m\\) where \\(K_m = \\cup_{n\\leq N_m}\\bar{B}_{1/m}(x_n)\\). Clearly \\(K_m\\) is closed as finite union of closed sets and also complete as closed subset of a complete space. So is \\(K := \\cap_m K_m\\). Let us show that \\(K\\) is totally bounded. For \\(\\delta&gt;0\\) choose \\(m\\) such that \\(1/m&lt;\\delta\\). It follows that \\(K \\subseteq K_m =\\cup_{n\\leq N_m} \\bar{B}_{1/m}(x_n) \\subseteq \\cup_{n\\leq N_m}B_{\\delta}(x_n)\\) showing that \\(K\\) can be covered by finitely many balls of size \\(\\delta\\), hence is totally bounded. We deduce that \\(K\\) is compact. Finally it holds that</p> \\[   P[S \\setminus K] \\leq \\sum P[S\\setminus K_m] \\leq \\sum \\frac{\\varepsilon}{2^m} = \\varepsilon \\] <ol> <li> <p>The definition of tightness and regularity only requires a topological space but most of the interesting results we will address are for Polish spaces.\u00a0\u21a9</p> </li> </ol>"},{"location":"lecture/03-Integration/030-introduction/","title":"Introduction/Notations","text":"<p>After treating the notion of measurable spaces and measures, we will now address integration. However this lecture is about stochastics and therefore, even if many notions extends to more general theory we will stick to probability spaces. To do so, let us first fix the probabilistic historical jargon and notations.</p> <ul> <li> <p>\\((\\Omega, \\mathcal{F}, P)\\) is called a probability space if \\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra on \\(\\mathcal{F}\\) and \\(P\\) is a finite measure with \\(P[\\Omega] = 1\\);</p> </li> <li> <p>Elements of \\(\\Omega\\) are called states and usually denoted by \\(\\omega\\);</p> </li> <li>Elements of \\(\\mathcal{F}\\) are called events;</li> <li>The measure \\(P[A]\\) of an event \\(A\\) is called the **probability of ** \\(A\\).</li> <li>A random variable is a measurable function from \\(\\Omega\\) to \\(\\mathbb{R}\\) where \\(\\mathbb{R}\\) is endowed with the Borel \\(\\sigma\\)-algebra.      Usually, random variables are denoted with capital letters \\(X, Y, Z, \\cdots\\)</li> </ul> <p>As mentioned, the following does not change if you assume that \\(P\\) is a \\(\\sigma\\)-finite measure.  </p> <p>Throughout, we denote by \\(\\mathcal{L}^0:=\\mathcal{L}^0(\\Omega,\\mathcal{F})\\) the set of all random variables. Given a random variable \\(X\\), we also use the following shorthand notations for events:</p> \\[ \\begin{align*}   \\{X \\in B\\}   &amp; := \\{\\omega \\in \\Omega\\colon X(\\omega)\\in B\\}\\\\   \\{X \\leq t\\} &amp; := \\{\\omega \\in \\Omega\\colon X(\\omega)\\leq t\\}   \\ldots \\end{align*} \\] <p>for \\(B \\in \\mathcal{F}\\) and \\(t\\in \\mathbb{R}\\).  </p> <p>As for the measure of these events, we adopt the notations:</p> \\[ P[X \\in B] := P[\\{X \\in B\\}], \\quad P[X\\leq t]:= P[\\{X \\leq t\\}], \\dots \\] <p>Given an event \\(A\\) we define the indicator function \\(1_A\\) as the function:</p> \\[ \\begin{equation}   \\begin{split}      1_A\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}\\\\     \\omega &amp;\\longmapsto 1_A(\\omega)=     \\begin{cases}         1 &amp;\\text{if } \\omega \\in A\\\\         0 &amp;\\text{otherwise}     \\end{cases}   \\end{split} \\end{equation} \\] <p> </p> <p>Throughout, we will also deal with extended real-valued random variables, that is, functions \\(X:\\Omega \\to [-\\infty,\\infty]\\) which are measurable. We denote this set by \\(\\bar{\\mathcal{L}}^0\\).  </p> <p>Note that for \\(X \\in \\bar{\\mathcal{L}}^0\\), we can write:</p> \\[ X=-\\infty 1_A +Y1_B+\\infty1_C \\] <p>where \\(A\\), \\(B\\), and \\(C\\) are pairwise disjoint and \\(Y\\in \\mathcal{L}^0\\).</p> <p>Further, we denote by \\(\\mathcal{L}^0_+\\) or \\(\\bar{\\mathcal{L}}^0_+\\) the set of those random variables or extended real-valued random variables that are positive.  </p> <p>This chapter is divided as follows</p> <ul> <li>Expectation, Lebesgue's Convergence</li> <li>\\(L^p\\)-Spaces and Classical Inequalities</li> <li>Radon-Nykodym and Conditional Expectation</li> <li>Independence</li> <li>Funini-Tonelli</li> <li>Uniform Integrability</li> </ul>"},{"location":"lecture/03-Integration/031-expectation/","title":"Expectation","text":""},{"location":"lecture/03-Integration/031-expectation/#integration-lebesgue-convergence-theorem","title":"Integration, Lebesgue Convergence Theorem","text":"<p>Definition: Simple Random Variables</p> <p>A random variable \\(X\\) is said to be simple if there exists a finite family \\((A_k)_{1\\leq k\\leq n}\\) of pairwise disjoint events and real nonzero numbers \\((\\alpha_k)_{1\\leq k\\leq n}\\) such that:</p> \\[   X=\\sum_{k=1}^n \\alpha_k 1_{A_k} \\] <p>We denote by \\(\\mathcal{L}^{0,step}\\) the set of all simple random variables.</p> <p> </p> <p>Warning</p> <p>Clearly, \\(\\mathcal{L}^{0,step}\\) is a subset of \\(\\mathcal{L}^0\\). However, the decomposition of a simple random variable \\(X\\) into \\((A_k)_{1\\leq k\\leq n}\\) and \\((\\alpha_k)_{1\\leq k\\leq n}\\) is not unique. Indeed, let \\(A\\) and \\(B\\) be two elements of \\(\\mathcal{F}\\) such that \\(A\\subseteq B\\). It follows that \\(X=1_B=1_{B\\setminus A}+1_A\\).</p> <p>Lemma</p> <p>The spaces \\(\\mathcal{L}^0\\) as well as \\(\\mathcal{L}^{0,step}\\) are vector spaces.</p> <p>Proof</p> <p>The proof is left as an exercise.</p> <p>Let \\(X=\\sum_{1\\leq k\\leq n}\\alpha_k 1_{A_k}\\) and \\(Y=\\sum_{1\\leq l\\leq m}\\beta_l 1_{B_l}\\) be two simple random variables. It is possible to find a finite family \\((C_r)_{1\\leq j\\leq r}\\) of pairwise disjoint elements in \\(\\mathcal{F}\\) and two finite families \\((\\tilde{\\alpha_j})_{1\\leq j\\leq r}\\) and \\((\\tilde{\\beta}_j)_{1\\leq j\\leq r}\\) of nonzero numbers such that:</p> \\[  \\begin{equation}    X=\\sum_{1\\leq j\\leq r} \\tilde{\\alpha}_j 1_{C_j},\\quad Y=\\sum_{1\\leq j\\leq r} \\tilde{\\beta}_j 1_{C_j}  \\end{equation} \\] <p>Indeed, let \\(C_{kl}=A_k\\cap B_l\\), which constitutes a finite family of pairwise disjoint elements in \\(\\mathcal{F}\\). It follows that:</p> \\[  X=\\sum_{1\\leq k\\leq n}\\sum_{1\\leq l\\leq m} \\alpha_k 1_{C_{kl}},\\quad Y=\\sum_{1\\leq k\\leq n}\\sum_{1\\leq l\\leq m} \\beta_{l} 1_{C_{kl}} \\] <p>In other words, any two simple random variables can be decomposed on the same common family of pairwise disjoint elements.</p> <p>Definition: Expectation 1.0</p> <p>We define the expectation of a simple random variable \\(X=\\sum_{1\\leq k\\leq n}\\alpha_k 1_{A_k}\\) with respect to \\(P\\) as:</p> \\[   \\hat{E}[X]:=\\sum_{k\\leq n} \\alpha_k P[A_k] \\] <p> </p> <p>Exercise</p> <p>Show that the definition of expectation is a well-defined operator on \\(\\mathcal{L}^{0,step}\\).   Indeed, the decomposition of \\(X\\) is not unique.</p> <p>Proposition</p> <p>On \\(\\mathcal{L}^{0,step}\\), the following properties hold:</p> <ul> <li>Monotonicity: \\(\\hat{E}[X]\\leq \\hat{E}[Y]\\) whenever \\(X\\leq Y\\).</li> <li>Linearity: \\(\\hat{E}\\) is a linear operator on \\(\\mathcal{L}^{0,step}\\).</li> </ul> <p>Proof</p> <p>Let \\(X\\) and \\(Y\\) be two simple random variables.   Since those two simple random variables can be decomposed on a common set of events we can write:</p> \\[   X=\\sum_{k\\leq n} \\alpha_k 1_{A_k}, \\quad Y=\\sum_{k\\leq m}\\beta_k 1_{A_k} \\] <p>If \\(X\\leq Y\\), it follows that \\(\\alpha_k=X(\\omega)\\leq Y(\\omega)=\\beta_k\\) for every state \\(\\omega\\) in \\(A_{k}\\).   Hence:</p> \\[   \\hat{E}[X]=\\sum_{k\\leq n}\\alpha_k P[A_{k}]\\leq \\sum_{k\\leq n} \\beta_k P[A_{k}]=\\hat{E}[Y] \\] <p>For real numbers \\(a\\) and \\(b\\), it holds:</p> \\[   \\hat E[a X+bY]=\\sum_{k\\leq n} (a\\alpha_k+b\\beta_k)P[A_k]=a\\sum_{k\\leq n} \\alpha_k P[A_k]+b\\sum_{k\\leq n} \\beta_k P[A_k]=a\\hat E[X]+b\\hat E[Y] \\] <p>This proposition is important in so far that ir shows that the expectation is a linear operator which is monotone. This monotonicity property allows to extends naturally from below the expectation to the class of positive random variables.</p> <ul> <li> <p>First Approximation</p> <p> </p> </li> <li> <p>Second Approximation</p> <p> </p> </li> </ul> <p>Definition: Expectation 2.0</p> <p>For any positive extended random variable \\(X\\) in \\(\\bar{\\mathcal{L}}^0_+\\), we define the expectation of which as</p> \\[     E[X]:=\\sup \\left\\{ \\hat E[Y]\\colon Y\\leq X,Y \\in \\mathcal{L}^{0,step}_+ \\right\\} \\] <p>A random variable \\(X\\) is called integrable if \\(E[X^+]&lt;\\infty\\) and \\(E[X^-]&lt;\\infty\\). The set of integrable random variables is denoted by \\(\\mathcal{L}^1\\) and the expectation of which is defined as</p> \\[   E[X]:= E[X^+] - E[X^-] \\] <p>Remark</p> <ul> <li>Show as an exercise that for a positive extended random variable \\(X\\) where \\(P[X=\\infty]&gt;0\\), then it follows that \\(E[X]=\\infty\\);</li> <li>Clearly \\(\\mathcal{L}^{0,step}\\subseteq \\mathcal{L}^1\\);</li> <li>Also, by definition and monotonicity of \\(\\hat{E}\\), for every \\(X \\in \\mathcal{L}^{0,step}\\), it holds that \\(E[X]=\\hat{E}[X]\\).   In other terms, \\(E\\) is an extension of \\(\\hat{E}\\) to the space \\(\\bar{\\mathcal{L}}^0_+\\).   We therefore remove the hat on the top of the expectation symbol everywhere.</li> </ul> <p>Lemma</p> <p>For every \\(X\\) and \\(Y\\) in \\(\\bar{\\mathcal{L}}^0_+\\) and \\(a,b\\) positive numbers, it holds:</p> <ul> <li>\\(E[X]\\leq E[Y]\\) whenever \\(X\\leq Y\\).</li> <li>\\(E\\left[ aX+b Y \\right]=a E\\left[ X \\right]+b E\\left[ Y \\right]\\).</li> </ul> <p>Proof</p> <p>The proof is left as an exercise.</p> <p>Theorem: Lebegue's Monotone Convergence Theorem</p> <p>Let \\((X_n)\\) be an increasing sequence of positive random variables. Denote by \\(X = \\lim X_n = \\sup X_n\\) the resulting extended positive random variable limit of the sequence. Then it holds</p> \\[     E[X] = E[\\lim X_n] = \\lim E[X_n] \\] <p>Proof</p> <p>By monotonicity, we clearly have \\(E[X_n]\\leq E[X]\\) for every \\(n\\), therefore \\(\\sup E[X_n]\\leq E[X]\\). Reciprocally, suppose that \\(E[X]&lt;\\infty\\) and pick \\(\\varepsilon&gt;0\\) and some simple positive random variable \\(Y\\) such that \\(Y\\leq X\\) and \\(E[X]-\\varepsilon\\leq E[Y]\\). For \\(0&lt;c&lt;1\\) define the sets \\(A_n=\\{X_n\\geq cY\\}\\). Since \\(X^n\\) is increasing to \\(X\\), it follows that \\(A_n\\) is an increasing sequence of events. Furthermore, since \\(cY\\leq Y\\leq X\\) and \\(cY&lt;X\\) on \\(\\{X&gt;0\\}\\), it follows that \\(\\cup A_n=\\Omega\\).  By non-negativity of \\(X_n\\) and monotonicity, it follows that</p> \\[ cE[1_{A_n}Y]\\leq E[1_{A_n}X_n]\\leq E[X_n] \\] <p>and so</p> \\[ c\\sup E[1_{A_n}Y]\\leq \\sup E[X_n] \\] <p>Since \\(Y=\\sum_{l\\leq k} \\alpha_l 1_{B_l}\\) for \\(\\alpha_1,\\ldots,\\alpha_k \\in \\mathbb{R}_+\\) and \\(B_1,\\ldots, B_k\\in \\mathcal{F}\\), it follows that</p> \\[ E\\left[ 1_{A_n}Y \\right]=\\sum_{l\\leq k}\\alpha_l P[A_n\\cap B_l]. \\] <p>However, since \\(P\\) is a probability measure, and \\(A_n\\) is increasing to \\(\\Omega\\), it follows from the lower semi-continuity of probability measures that \\(P[A_n\\cap B_l]\\nearrow P[\\Omega\\cap B_l]=P[B_l]\\), and so</p> \\[ \\sup E[1_{A_n}Y]=\\sum_{l\\leq k}\\alpha_l \\sup P[A_n\\cap B_l]=\\sum \\alpha_l P[B_l]=E[Y]. \\] <p>Consequently</p> \\[ E[X]\\geq \\lim E[X_n]=\\sup E[X_n]\\geq cE[Y] \\geq cE[X]-c\\varepsilon \\] <p>which by letting \\(c\\) converging to \\(1\\) and \\(\\varepsilon\\) to \\(0\\) yields the result. The case where \\(E[X]=\\infty\\) is similar and left to the reader.</p> <p>As the previous figure suggests, it is actually possible to construct by hand a sequential approximation of positive random variables by simple ones.</p> <p>Proposition: Approximation by Simple Random Variables</p> <p>For any positive random variabel \\(X\\), there exists an increasing sequence of simple positive random variables \\((X_n)\\) such that \\(X_n(\\omega)\\nearrow X(\\omega)\\) and uniformly on each set \\(\\{X\\leq M\\}\\) where \\(M\\in \\mathbb{R}\\).</p> <p>Proof</p> <p>Let \\(A_k^n=\\{(k-1)/2^n\\leq X&lt;k/2^n\\}\\) for \\(k=1,\\ldots, n2^n\\) and define</p> \\[ X_n:=\\sum_{k=1}^{n2^n} \\frac{k-1}{2^n}1_{A_k^n}+n1_{\\{X&gt;n\\}} \\] <p>From the definition, it follows that \\(X_n\\leq X\\) for every \\(n\\) and \\(X(\\omega)-2^{-n}\\leq X_n(\\omega)\\) for every \\(\\omega \\in \\{X\\leq n\\}\\). This, along with the monotonicity, concludes the proof.</p> <p>Proposition</p> <p>For \\(X\\) and \\(Y\\) in \\(\\mathcal{L}^1\\), a real number \\(a\\) and two disjoint events \\(A,B\\) in \\(\\mathcal{F}\\). The following assertions hold:</p> <ol> <li>\\(1_A X\\), \\(X+Y\\), \\(aX\\) and \\(|X+Y|\\) are integrable.</li> <li>\\(E[(1_A+1_B)X]=E[1_AX]+E[1_B Y]\\).</li> <li>\\(E[X+Y]=E[X]+E[Y]\\) and \\(E[aX]=aE[X]\\).</li> <li>\\(E[X]\\leq E[Y]\\) whenever \\(X\\leq Y\\).</li> <li>If \\(X\\geq 0\\) and \\(E[X]=0\\), then \\(P[X=0]=1\\).</li> <li>If \\(P[X\\neq Y]=0\\), then \\(E[X]=E[Y]\\).</li> <li>If \\(Z\\) is a random variable such that \\(|Z|\\leq X\\), then \\(Z\\) is integrable.</li> </ol> <p>Remark</p> <p>In particular, \\(\\mathcal{L}^1\\) is a vector space and the expectation operator \\(E:\\mathcal{L}^1\\to \\mathbb{R}\\) is a monotone, positive, and linear functional.</p> <p>Proof</p> <ol> <li> <p>It holds \\(|X+Y|\\leq |X|+|Y|\\).     According to Lemma \\ref{lem:linearityL0+}, it follows that \\(E[|X+Y|]\\leq E[|X|+|Y|]=E[|X|]+E[|Y|]&lt;\\infty\\), showing that \\(X+Y\\) and \\(|X+Y|\\) are integrable.     The argumentation for \\(1_AX\\) and \\(aX\\) follows the same line.</p> </li> <li> <p>It holds \\(\\left( 1_A+1_B \\right)X=(1_A+1_B)X^+-(1_A+1_B)X^-\\).     From the linearity on \\(\\mathcal{L}^0_+\\), it follows that \\(E[(1_A+1_B)X^\\pm]=E[1_AX^\\pm]+E[1_BX^\\pm]\\), showing that \\(E[(1_A+1_B)X]=E[1_AX]+E[1_BX]\\).</p> </li> <li> <p>Without loss of generality, assume that \\(a\\geq 0\\).     Here again, it follows from \\(aX=aX^+-aX^-\\) and from the linearity on \\(\\mathcal{L}_+^0\\) that \\(E[aX^\\pm]=aE[X^{\\pm}]\\).     Also, since \\(X+Y=(X^++Y^+)-(X^-+Y^-)=(X+Y)^+-(X+Y)^-\\), it follows that \\((X^++Y^+)+(X+Y)^-=(X^-+Y^-)+(X+Y)^+\\).     However, again from the linearity on \\(\\mathcal{L}_0^+\\), it holds \\(E[(X^++Y^+)+(X+Y)^-]=E[X^+]+E[Y^+]+E[(X+Y)^-]\\) and \\(E[(X^-+Y^-)+(X+Y)^+]=E[X^-]+E[Y^-]+E[(X+Y)^+]\\), showing that \\(E[X+Y]=E[(X+Y)^+]-E[(X+Y)^-]=E[X^+]-E[X^-]+E[Y^+]-E[Y^-]=E[X]+E[Y]\\).</p> </li> <li> <p>If \\(X\\leq Y\\), it follows that \\(0\\leq Y-X\\).     According to the proposition stating the approximation from below, let \\((Z_n)\\) be an increasing sequence of positive simple random variables such that \\(Z_n\\nearrow Y-X\\).     It follows from the monotone convergence Theorem that \\(0\\leq E[Z^n]\\leq \\sup E[Z_n]=E[Y-X]\\).     Applying the previous point, we get \\(E[Y-X]=E[Y]-E[X]\\), yielding the assertion.</p> </li> <li> <p>Let \\(A_n=\\{X\\geq 1/n\\}\\) which is an increasing sequence of events such that \\(\\cup A_n=\\{X&gt;0\\}\\).     It follows that \\(1_{A_n}1/n\\leq 1_{A_n}X\\leq X\\) since \\(X\\) is positive.     Monotonicity from the previous point yields \\(P[A_n]/n\\leq E[1_{A_n}X]\\leq E[X]=0\\), showing that \\(P[A_n]=0\\) for every \\(n\\).     By the lower semi-continuity property of measures, it follows that \\(P[A]=\\sup P[A_n]=0\\), showing that \\(P[X&gt;0]=0\\).</p> </li> <li> <p>Suppose that \\(P[X\\neq 0]=0\\) and define \\(X_n=|X|1_{\\{X=0\\}}+(|X|\\wedge n)1_{A_n}\\) where \\(A_n=\\{|X|\\geq 1/n\\}\\).     On the one hand, by definition, \\(A_n\\) is an increasing sequence such that \\(\\cup A_n=\\{|X|\\neq 0\\}\\).     Hence, \\(0\\leq X_n\\nearrow |X|\\), which by the monotone convergence Theorem implies that \\(E[X_n]\\nearrow E[|X|]\\).     On the other hand, \\(A_n\\subseteq \\{X\\neq 0\\}\\), which by monotonicity of the measure implies that \\(P[A_n]=0\\) for every \\(n\\).     Hence, \\(E[X_n]\\leq nP[A_n]=0\\) for every \\(n\\).     We conclude that \\(E[|X|]=0\\), which implies that \\(E[X]=0\\).</p> </li> <li> <p>Follows directly from the linearity on \\(\\mathcal{L}_+^0\\).</p> </li> </ol> <p>Remark</p> <p>Note that for \\(X \\in \\bar{\\mathcal{L}}^{0}\\) with \\(X^- \\in \\mathcal{L}^1\\), and \\(Y \\in \\mathcal{L}^1\\), the same argumentation as above yields that:</p> \\[   \\begin{equation}         -\\infty&lt;E[X-Y]=E[X^+-X^--Y]=E[X^+]-E[X^-]-E[Y]=E[X]-E[Y]       \\end{equation} \\] <p>We finish this section with two of the most important assertions of integration theory.</p> <p>Theorem: Fatou's Lemma and Lebegue's Dominated Convergence</p> <p>Let \\((X_n)\\) be a sequence in \\(\\mathcal{L}^0\\).</p> <ul> <li> <p>Fatou's Lemma: Suppose that \\(X_n\\geq Y\\) for some \\(Y \\in \\mathcal{L}^1\\).     Then it holds</p> \\[   \\begin{equation}   E\\left[ \\liminf X_n \\right]\\leq \\liminf E\\left[ X_n \\right]. \\end{equation} \\] </li> <li> <p>Dominated Convergence Theorem: Suppose that \\(|X_n|\\leq Y\\) for some \\(Y \\in \\mathcal{L}^1\\) and \\(X_n(\\omega)\\to X(\\omega)\\) for any state \\(\\omega\\).     Then it holds</p> \\[ \\begin{equation}   E\\left[ X \\right]=\\lim E\\left[ X_n \\right]. \\end{equation} \\] </li> </ul> <p>Proof</p> <p>By linearity, up to the variable change \\(X_n-Y\\), we can assume that \\(X_n\\) is positive since \\(E[\\liminf X_n-Y]=E[\\liminf X_n]-Y\\) and \\(E[X_n-Y]=E[X_n]-Y\\) for every \\(n\\). Let \\(Y_n=\\inf_{k\\geq n}X_n\\), which is an increasing sequence of positive random variables that converges to \\(\\liminf X_n=\\sup_n \\inf_{k\\geq n}X_k\\). Notice also that \\(Y_n\\leq X_k\\) for every \\(k\\geq n\\), and therefore by monotonicity of the expectation \\(E[Y_n]\\leq \\inf_{k\\geq n}E[X_k]\\). We conclude Fatou's lemma with the monotone convergence theorem as follows:</p> \\[ \\begin{equation}     E\\left[ \\liminf X_n \\right]=\\lim E\\left[ Y_n \\right]=\\sup E\\left[ Y_n \\right]\\leq \\sup_n\\inf_{k\\geq n}E[X_k]=\\liminf E[X_n]. \\end{equation} \\] <p>A simple sign change shows that Fatou's lemma holds in the other direction. That is, if \\(X_n\\leq Y\\) for some \\(Y \\in \\mathcal{L}^1\\), then it holds</p> \\[ \\begin{equation}     \\limsup E\\left[ X_n \\right]\\leq E\\left[ \\limsup X_n \\right]. \\end{equation} \\] <p>Now the dominated convergence theorem assumptions yield that \\(-Y\\leq X_n\\leq Y\\) for some \\(Y \\in \\mathcal{L}^1\\). Hence, since \\(X=\\lim X_n=\\liminf X_n=\\limsup X_n\\), it follows that</p> \\[ \\begin{equation}     \\limsup E\\left[ X_n \\right]\\leq E\\left[ \\limsup X_n \\right]=E\\left[ X \\right]=E\\left[ \\liminf X_n \\right]\\leq \\liminf E\\left[ X_n \\right]. \\end{equation} \\] <p>However, \\(\\liminf E\\left[ X_n \\right]\\leq \\limsup E[X_n]\\), showing that \\(E[X_n]\\) converges, and</p> \\[ \\begin{equation}     E[X]=\\liminf E[X_n]=\\limsup E[X_n]=\\lim E[X_n]. \\end{equation} \\] <p>which ends the proof.</p> <p>Example: Defining a Probability Measure from a Density</p> <p>The concept of density is quite often used in statistics as it defines new measures. Let us formalize it using dominated convergence.</p> <p>On a probability space \\((\\Omega, \\mathcal{F}, P)\\), consider a positive integrable random variable \\(Z\\) such that \\(E[Z]=1\\). We define the set function </p> \\[     \\begin{split}         Q\\colon \\mathcal{F} &amp; \\longmapsto [0,1]\\\\                 A &amp; \\longmapsto Q[A] = E[Z1_A]     \\end{split} \\] <p>which is clearly well defined and mapping to \\([0,1]\\) since \\(Z\\) is positive and \\(E[Z 1_A]\\leq E[Z]=1\\).</p> <p>It follows that \\(Q\\) defined as such is a new probability measure. Indeed</p> <ul> <li>\\(Q[\\emptyset] = E[Z1_{\\emptyset}]=E[0] =0\\), \\(Q[\\Omega] = E[Z1_{\\Omega}] = E[Z] = 1\\);</li> <li> <p>\\(\\sigma\\)-additivity: Let \\((A_n)\\) be a sequence of disjoint events.     It follows that</p> \\[     1_{\\cup_{k\\leq n}A_k} = \\sum_{k\\leq n} 1_{A_k} \\nearrow \\sum 1_{A_n} = 1_{\\cup A_n} \\] <p>By monotone convergence</p> \\[     \\begin{align*}         \\sum Q[A_n] &amp; = \\lim \\sum_{k\\leq n} Q[A_k]\\\\                     &amp; = \\lim \\sum_{k\\leq n}E[Z 1_{A_k}]\\\\                     &amp; = \\lim E\\left[ Z \\sum_{k\\leq n} 1_{A_k} \\right]\\\\                     &amp; = E\\left[ Z \\sum 1_{A_n} \\right]\\\\                     &amp; = E[Z 1_{\\cup A_n}] = Q[\\cup A_n]     \\end{align*} \\] </li> </ul> <p>It can be shown using step functions that integration under \\(P\\) and \\(Q\\) are related through the formula</p> \\[     E^Q[X] = E^P\\left[ Z X \\right] \\] <p>for any bounded random variable \\(X\\) or any \\(X\\) with sufficient integrability under \\(Q\\).</p> <p>Another particular property of the probability measure \\(Q\\) so defined is that it is absolutely continuous with respect to \\(P\\) in the sense that</p> \\[     P[A] = 0 \\quad \\text{implies} \\quad Q[A] = 0 \\]"},{"location":"lecture/03-Integration/032-lp-spaces-inequalities/","title":"\\(L^p\\)-Spaces and Classical Inequalities","text":""},{"location":"lecture/03-Integration/032-lp-spaces-inequalities/#lp-spaces","title":"\\(L^p\\)-Spaces","text":"<p>One important property of the Lebesgue integral is that it is independent of the null sets on which functions may differ.</p> <p>Proposition</p> <p>Let \\(X\\) and \\(Y\\) be two integrable random variables or two elements of \\(\\mathcal{L}_+^0\\). Suppose that \\(X\\geq Y\\) \\(P\\)-almost surely, that is \\(P[X\\geq Y]=1\\), then it follows that \\(E[X]\\geq E[Y]\\).</p> <p>In particular, if \\(X=Y\\) \\(P\\)-almost surely, then it holds \\(E[X]=E[Y]\\). Also, if \\(X\\geq 0\\) \\(P\\)-almost surely and \\(E[X]=0\\), then it follows that \\(X=0\\) \\(P\\)-almost surely.</p> <p>Proof</p> <p>Suppose that \\(X\\geq Y\\) \\(P\\)-almost surely and define \\(A=\\{X&lt;Y\\}\\), which is a negligible set, that is, an event of \\(0\\) probability.   It follows that \\((X-Y)1_{A^c} \\in \\mathcal{L}^0_+\\), and so \\(E[(X-Y)1_{A^c}]=E[X1_{A^c}]-E[Y1_{A^c}]\\geq 0\\) by monotonicity.</p> <p>On the other hand, \\((Y-X)1_{A} \\in \\mathcal{L}^0_+\\), and let \\(Z^n=\\sum \\alpha_k 1_{B_k^n}\\) be an increasing sequence of step random variables that converges to \\((Y-X)1_{A}\\). Since \\((Y-X)1_{A}=0\\) on \\(A^c\\), it follows that \\(B_k^n\\subseteq A\\) for every \\(k,n\\) and therefore \\(P[B_k^n]\\leq P[A]=0\\) for every \\(k,n\\).   We deduce that \\(E[Z^n]=0\\) for every \\(n\\) and by Lebesgue monotone convergence, it follows that \\(E[(Y-X)1_{A}]=0\\).</p> <p>We conclude by noticing that \\((X-Y)=(X-Y)1_{A^c}-(Y-X)1_{A}\\).</p> <p>This proposition allows in the monotone convergence theorem, Fatou's lemma, as well as dominated convergence, to replace convergence of random variables and inequalities by \\(P\\)-almost sure convergence and \\(P\\)-almost sure inequalities.</p> <p>On \\(\\mathcal{L}^1\\), we can define the operator \\(X\\mapsto \\|X\\|_1=E[|X|]\\). Verify that:</p> <ul> <li>\\(X=0\\) implies \\(\\|X\\|_1=0\\).</li> <li>\\(\\|X+Y\\|_1\\leq \\|X\\|_1+\\|Y|_1\\).</li> <li>\\(\\|\\lambda X\\|_1=|\\lambda|\\|X\\|_1\\).</li> </ul> <p>In other words, \\(\\|\\cdot\\|\\) is \"almost\" a norm if in the first point we had equivalence and not only implication. However, as the previous proposition shows, it actually holds:</p> <ul> <li>\\(\\|X\\|_1=0\\) if and only if \\(X=0\\) \\(P\\)-almost surely.</li> </ul> <p>We therefore proceed as in Algebra. Inspection shows that \\(X\\sim Y\\) on \\(\\mathcal{L}^0\\) if and only if \\(X=Y\\) \\(P\\)-almost surely is an equivalence relation.<sup>1</sup> We can therefore define the quotient of equivalence classes \\(L^0=\\mathcal{L}^0/\\sim\\). We can work there just as in \\(\\mathcal{L}^0\\) in the \\(P\\)-almost sure sense, that is, \\(X=Y\\) means \\(X=Y\\) \\(P\\)-almost surely, even if \\(X\\) is actually just a representative of its equivalence class. Inequality is also compatible with the equivalence relation, and therefore \\(X\\geq Y\\) means \\(X\\geq Y\\) \\(P\\)-almost surely. Every operation that is blind with respect to null measure sets can be carried over to \\(L^0\\). This is the case for the expectation on \\(L^0_+\\). Similarly, we can define \\(L^1\\) as the set of equivalence classes of integrable random variables that coincide \\(P\\)-almost surely.</p> <p>Also, since the operator \\(\\left\\Vert\\cdot\\right\\Vert_1\\) does not take into account objects defined on negligible sets, it carries over to \\(L^1\\) as a true norm, making \\((L^1,\\left\\| \\cdot \\right\\| )\\) a normed space. We can further define, for \\(1\\leq p\\leq \\infty\\), the following operators on \\(L^0\\):</p> \\[ \\begin{equation}     \\left\\Vert X\\right\\Vert_p=     \\begin{cases}         E\\left[ \\left\\vert X\\right\\vert^p \\right]^{1/p}, &amp; \\text{if } p&lt;\\infty, \\\\         \\inf\\left\\{ m\\colon P\\left[ \\left\\vert X\\right\\vert\\leq m \\right] =1\\right\\}, &amp; \\text{if } p=\\infty.     \\end{cases} \\end{equation} \\] <p>that give rise to the spaces</p> \\[ \\begin{equation}     L^p :=\\left\\{ X \\in L^0\\colon \\left\\Vert X\\right\\Vert_p&lt;\\infty \\right\\}. \\end{equation} \\] <p>Even if \\(L^1\\) is a normed space for \\(\\|\\cdot \\|\\) it is not clear that \\(L^p\\) is a normed space for \\(\\|\\cdot \\|_p\\) as we do not know if it is subadditive.</p>"},{"location":"lecture/03-Integration/032-lp-spaces-inequalities/#jensen-holder-minkowsky-and-markov-inequalities","title":"Jensen, H\u00f6lder, Minkowsky and Markov Inequalities","text":"<p>Due to the linearity and monotonicity of the expectation several central inequalities can be derived.</p> <p>Theorem: Jensen's inequality</p> <p>Let \\(\\varphi:\\mathbb{R}\\to \\mathbb{R}\\) be a convex function and \\(X\\) be an integrable random variable. It holds</p> \\[ \\begin{equation}     \\varphi\\left( E\\left[ X \\right] \\right)\\leq E\\left[ \\varphi(X) \\right]. \\end{equation} \\] <p>Proof</p> <p>Let \\(x_0=E[X]\\). Since \\(\\varphi\\) is a convex real-valued function, the existence of a sub-derivative for convex functions implies the existence of \\(a\\) and \\(b\\) in \\(\\mathbb{R}\\) such that</p> \\[ \\begin{equation}     \\varphi(x)\\geq ax +b, \\text{ for all any }x \\quad \\text{and} \\quad \\varphi(x_0)=ax_0+b \\end{equation} \\] <p>Hence,</p> \\[ \\begin{equation}     E\\left[ \\varphi(X) \\right]\\geq aE[X]+b=ax_0+b=\\varphi\\left( E[X] \\right). \\end{equation} \\] <p>which ends the proof.</p> <p>Exercise</p> <p>Using Jensen's inequality, prove that \\((\\prod a_i)^{1/n}\\leq \\frac{1}{n} \\sum a_i\\) where \\(a_1, \\dots, a_n&gt;0\\).</p> <p>Theorem: H\u00f6lder and Minkowski Inequalities</p> <p>Let \\(1\\leq p,q \\leq \\infty\\) be convex conjugate, that is, such that \\(1/p+1/q=1\\).</p> <p>For every \\(X\\) in \\(L^p\\) and \\(Y\\) in \\(L^q\\), the H\u00f6lder inequality reads as follows:</p> \\[ \\begin{equation}     \\left\\Vert XY\\right\\Vert_1=E\\left[ \\left\\vert XY\\right\\vert \\right]\\leq  E\\left[ \\left\\vert X\\right\\vert^p \\right]^{1/p}E\\left[ \\left\\vert Y\\right\\vert^q \\right]^{1/q}=\\left\\Vert X\\right\\Vert_p\\left\\Vert Y\\right\\Vert_q. \\end{equation} \\] <p>For every \\(X\\) and \\(Y\\) in \\(L^p\\), the Minkowski inequality reads as follows:</p> \\[ \\begin{equation}     \\left\\Vert X+Y\\right\\Vert_p=E\\left[ \\left\\vert X+Y\\right\\vert^p \\right]^{1/p}\\leq  E\\left[ \\left\\vert X\\right\\vert^p \\right]^{1/p}+E\\left[ \\left\\vert Y\\right\\vert^p \\right]^{1/p}=\\left\\Vert X\\right\\Vert_p+\\left\\Vert Y\\right\\Vert_p. \\end{equation} \\] <p>Proof</p> <p>As for the H\u00f6lder inequality, in the case where \\(p=1\\) and \\(q=\\infty\\), the inequality follows from \\(\\left\\vert XY\\right\\vert\\leq \\left\\vert X\\right\\vert\\left\\Vert Y\\right\\Vert_\\infty\\). Suppose therefore that \\(p,q\\) are conjugate with values in \\((1,\\infty)\\). Without loss of generality, we may assume that \\(X\\) and \\(Y\\) are positive. It holds</p> \\[ \\begin{equation}     E[XY]=E[Y^q]\\int XY^{1-q}\\frac{Y^qdP}{E[Y^q]}=E[Y^q]E_Q\\left[XY^{1-q} \\right] \\end{equation} \\] <p>where \\(E_Q\\) is the expectation operator under the measure \\(Q\\) where the density is given by \\(dQ:=Y^qdP/E[Y^q]\\).<sup>2</sup> Defining the convex function \\(x\\mapsto \\varphi(x)=x^p\\), Jensen's inequality together with the fact that \\(p(1-q)+q=0\\) and \\(1-1/p=1/q\\) yields</p> \\[ \\begin{align}     E[XY]&amp;=E[Y^q]E_Q[X Y^{1-q}] \\\\     &amp;=E[Y^q]\\varphi(E_Q[XY^{1-q}])^{1/p} \\\\     &amp;\\leq E[Y^q]E_Q\\left[ \\varphi(XY^{1-q}) \\right]^{1/p} \\\\     &amp;=E[Y^q]E_Q\\left[X^p Y^{p(1-q)}\\right]^{1/p} \\\\     &amp;=E[Y^q]E\\left[X^p Y^{p(1-q)}Y^q/E[Y^q] \\right]^{1/p} \\\\     &amp;=E[X^p]^{1/p}E[Y^q]^{1-1/p} \\\\     &amp;=E[X^p]^{1/p}E[Y^q]^{1/q}. \\end{align} \\] <p>As for the Minkowski inequality, in the case where \\(p=1\\), it follows from \\(\\left\\vert x+y\\right\\vert\\leq \\left\\vert x\\right\\vert+\\left\\vert y\\right\\vert\\). The case where \\(p=\\infty\\) is also easy. Suppose therefore that \\(1&lt;p&lt;\\infty\\). First, notice that by convexity it holds \\(\\left\\vert x+y\\right\\vert^p\\leq \\frac{1}{2} \\left\\vert2x\\right\\vert^p+\\frac{1}{2}\\left\\vert2y\\right\\vert^p=2^{p-1}\\left(\\left\\vert x\\right\\vert^p+\\left\\vert y\\right\\vert^p\\right)\\). This inequality ensures that \\(L^p\\) is a vector space. Now, using the triangle inequality and H\u00f6lder's inequality for \\(q=p/(p-1)\\), we get</p> \\[ \\begin{align}     \\left\\Vert X+Y\\right\\Vert_p^p &amp;=E\\left[ \\left\\vert X+Y\\right\\vert^p \\right] \\\\     &amp; \\leq E\\left[ \\left\\vert X\\right\\vert\\left\\vert X+Y\\right\\vert^{p-1} \\right]+E\\left[ \\left\\vert Y\\right\\vert\\left\\vert X+Y\\right\\vert^{p-1} \\right] \\\\     &amp;\\leq \\left(E\\left[ \\left\\vert X\\right\\vert^p \\right]^{1/p}+E\\left[ \\left\\vert Y\\right\\vert^p \\right]^{1/p}\\right)E\\left[ \\left\\vert X+Y\\right\\vert^{p} \\right]^{1-1/p} \\\\     &amp;= \\left( \\left\\Vert X\\right\\Vert_p+\\left\\Vert Y\\right\\Vert_p \\right)\\left\\Vert X+Y\\right\\Vert_p^{p-1}. \\end{align} \\] <p>If \\(\\left\\Vert X+Y\\right\\Vert_p=0\\), the inequality is trivial. Otherwise, divide both sides by \\(\\left\\Vert X+Y\\right\\Vert^{p-1}\\).</p> <p>It follows in particular that \\(L^p\\) is a vector space and that \\(\\left\\Vert\\cdot\\right\\Vert_p\\) is a norm on \\(L^p\\). We say that \\(X_n \\to X\\) in \\(L^p\\) for \\((X_n),X\\) in \\(L^p\\) if \\(\\left\\Vert X_n-X\\right\\Vert_p\\to 0\\). The \\(L^p\\) spaces are not only normed space but also Banach spaces (that is complete).</p> <p>Theorem: The \\(L^p\\) Spaces are Banach Spaces</p> <p>Let \\(1\\leq p\\leq \\infty\\) and \\((X_n)\\) be a Cauchy sequence in \\(L^p\\). Then it follows that \\(X_n \\to X\\) in \\(L^p\\) for some \\(X\\) in \\(L^p\\).</p> <p>In particular \\((L^p, \\|\\cdot \\|_p)\\) is a Banach space.</p> <p>Proof</p> <p>We do the proof for \\(p&lt;\\infty\\). Let \\((X_n)\\) be a Cauchy sequence. By Cauchy property, we can take a subsequence \\((Y_n)\\) of \\((X_n)\\) such that \\(\\left\\vert Y_{n+1}-Y_n\\right\\vert\\leq 2^{-n}\\) and define \\(Z_n=\\left\\vert Y_1\\right\\vert+\\sum_{k\\leq n-1} \\left\\vert Y_{k+1}-Y_k\\right\\vert\\) which is an increasing sequence of positive random variables converging to \\(Z=\\sup Z_n\\). Hence, the monotone convergence theorem shows that \\(E[Z^p]=\\lim E[Z_n^p]\\). By Minkowski inequality it holds</p> \\[ \\begin{equation*}     E\\left[ Z_n^p \\right]=\\left\\Vert Z_n\\right\\Vert_p^p\\leq \\left( \\left\\Vert Y_1\\right\\Vert_p+\\sum_{k\\leq n-1}\\left\\Vert Y_{k+1}-Y_k\\right\\Vert_p \\right)^p\\leq \\left( \\left\\Vert Y_1\\right\\Vert_p+1 \\right)^p \\end{equation*} \\] <p>The right-hand side being independent of \\(n\\), it follows by passing to the limit that \\(Z \\in L^p\\) and therefore \\(Z&lt;\\infty\\) \\(P\\)-almost surely.</p> <p>On the other hand, since the absolute series, \\(\\sum \\left\\vert Z_{k+1}-Z_k\\right\\vert\\) converges, it follows that \\(Y_n=Y-1+\\sum_{k\\leq n-1}Y_{k+1}-Y_k\\) converges \\(P\\)-almost surely to some \\(Y\\). Hence, \\(Y=\\lim Y_n\\) is in \\(L^p\\) since \\(\\left\\vert Y\\right\\vert=\\lim \\left\\vert Y_n\\right\\vert\\leq Z \\in L^p\\). We make use of dominated convergence on \\((Y_n)\\) since \\(Y_n^p\\to Y^p\\) \\(P\\)-almost surely and \\(\\left\\vert Y_n\\right\\vert^p\\leq Z^p\\in L^p\\), which implies that \\(E[\\left\\vert Y_n-Y\\right\\vert^p]\\to 0\\). It shows that a subsequence \\((Y_n)\\) of \\((X_n)\\) converges in \\(L^p\\) to some \\(Y\\).</p> <p>As an exercise, using the Cauchy property, show that \\(X_n\\to Y\\) in \\(L^p\\).</p> <p>Definition</p> <p>Let \\((X_n)\\) be a sequence of random variables and \\(X\\) a random variable.</p> <p>We say that</p> <ul> <li>\\(X_n\\to X\\) \\(P\\)-almost surely if \\(P[\\limsup X_n=\\liminf X_n]=1\\).</li> <li>\\(X_n\\to X\\) in probability if \\(\\lim P[\\left\\vert X_n-X\\right\\vert&gt;\\varepsilon]=0\\) for every \\(\\varepsilon&gt;0\\).</li> <li>\\(X_n\\to X\\) in \\(L^p\\) if \\(\\left\\Vert X_n-X\\right\\Vert_p\\to 0\\).</li> </ul> <p>Proposition</p> <p>Let \\((X_n)\\) be a sequence of random variables and \\(X\\) a random variable.   The following assertions hold:</p> <ol> <li>\\(X_n\\to X\\) \\(P\\)-almost surely implies \\(X_n\\to X\\) in probability.</li> <li>\\(X_n\\to X\\) in probability implies that \\(Y_n\\to X\\) \\(P\\)-almost surely for some subsequence \\((Y_n)\\) of \\((X_n)\\).</li> <li>\\(X_n\\to X\\) in \\(L^p\\) implies that \\(Y_n\\to X\\) \\(P\\)-almost surely for some subsequence \\((Y_n)\\) of \\((X_n)\\).</li> <li>\\(X_n\\to X\\) in probability and \\(\\left\\vert X_n\\right\\vert\\leq Y\\) for some \\(Y \\in L^1\\) implies \\(X_n\\to X\\) in \\(L^1\\).</li> </ol> <p>Proof</p> <p>Homework sheet.</p> <p>Theorem: Chebyshev/Markov Inequality</p> <p>Let \\(X\\) be a random variable and \\(\\varepsilon&gt;0\\). For every \\(0&lt;p&lt;\\infty\\), the Chebyshev inequality reads</p> \\[ \\begin{equation*}     P\\left[ \\left\\vert X\\right\\vert\\geq \\varepsilon \\right]\\leq \\frac{1}{\\varepsilon^p}E\\left[ \\left\\vert X\\right\\vert^p \\right]. \\end{equation*} \\] <p>In the case where \\(p=1\\), the inequality is due to Markov.</p> <p>Proof</p> <p>Define \\(A_{t}=\\{\\left\\vert X\\right\\vert\\geq t\\}\\) and \\(g(x)=x^p\\) which is an increasing function, so that consequently yields \\(0\\leq g(\\varepsilon)1_{A_\\varepsilon}\\leq g(\\left\\vert X\\right\\vert)1_{A_\\varepsilon}\\).</p> <p>Thus, \\(0\\leq g(\\varepsilon)P[A_\\varepsilon]=E[g(\\varepsilon)1_{A_\\varepsilon}]\\leq E[g(\\left\\vert X\\right\\vert)1_{A_\\varepsilon}]\\leq E[g(\\left\\vert X\\right\\vert)]\\) which ends the proof.</p> <p>Remark</p> <p>Note the proof of Markov's inequality shows that the following inequality holds</p> \\[ \\begin{equation*}     P\\left[ \\left\\vert X\\right\\vert\\geq \\varepsilon \\right]\\leq \\frac{1}{g(\\varepsilon)}E\\left[g\\left( \\left\\vert X\\right\\vert \\right)  \\right] \\end{equation*} \\] <p>for every increasing and measurable function \\(g:\\mathbb{R}\\to \\mathbb{R}\\) such that \\(g(\\varepsilon)&gt;0\\).</p> <ol> <li> <p>An equivalence relation \\(\\sim\\) is a binary relation that is symmetric, that is, \\(x\\sim y\\) if and only if \\(y\\sim x\\), reflexive, that is, \\(x\\sim x\\), and transitive, that is, \\(x\\sim y\\) and \\(y\\sim z\\) implies \\(x\\sim z\\).\u00a0\u21a9</p> </li> <li> <p>Verify that defined as such, \\(Q\\) is a probability measure, that is, \\(Q(A)=\\int_A dQ=\\int_A Y^q/E[Y^q]dP=E[1_A Y^q/E[Y^q]]\\) is a \\(\\sigma\\)-additive measure and it holds \\(E_Q[Z]=E[Z Y^q/E[Y^q]]\\). See las exercise of the previous section.\u00a0\u21a9</p> </li> </ol>"},{"location":"lecture/03-Integration/033-radon-nikodym-cond-exp/","title":"Radon-Nykodym and Conditional Expectation","text":""},{"location":"lecture/03-Integration/033-radon-nikodym-cond-exp/#radon-nykodym-change-of-measure","title":"Radon-Nykodym Change of Measure","text":"<p>In this section, we will make use of a central theorem of Functional Analysis applied in the special case of Hilbert spaces.</p> <p>Note</p> <p>A (real) Hilbert space is a vector space with a bilinear form \\(\u27e8\\cdot,\\cdot\u27e9:H\\times H \\to \\mathbb{R}\\), that is linear in the first as well as in the second argument, such that \\(\u27e8x,y\u27e9 =\u27e8y,x\u27e9\\) and \\(\u27e8x,x\u27e9 \\geq 0\\) with equality if and only if \\(x=0\\).</p> <p>Hence, \\(\\left\\Vert x\\right\\Vert=\\left\\vert\\langle x,y\\rangle\\right\\vert^{1/2}\\) defines a norm on \\(H\\) due to the Cauchy-Schwarz inequality that states that \\(\\left\\vert\\langle x,y\\rangle\\right\\vert\\leq \\left\\Vert x\\right\\Vert\\left\\Vert y\\right\\Vert\\).</p> <p>The finite-dimensional vector space \\(\\mathbb{R}^d\\) is a Hilbert space for the dot product \\(\\langle x,y\\rangle=\\sum_{k\\leq d} x_ky_k\\) and defines the Euclidean norm \\(\\left\\Vert x\\right\\Vert=\\sqrt{\\sum_{k\\leq d}x_k^2}\\).</p> <p>More importantly in our case, given a finite measure \\(P\\), the space \\(L^2\\) with the bilinear form \\(\u27e8X,Y\u27e9=\\int XY dP\\) is, due to H\u00f6lder's inequality</p> \\[ \\int \\left\\vert XY\\right\\vert dP\\leq \\left( \\int \\left\\vert X\\right\\vert^2dP \\right)^{1/2} \\left( \\int \\left\\vert Y\\right\\vert^2dP \\right)^{1/2}, \\] <p>a Hilbert space with resulting norm \\(\\left\\Vert X\\right\\Vert_{L^2(P)}=\\left(\\int X^2 dP\\right)^{1/2}\\), which is the \\(L^2\\) norm as defined before.</p> <p>Recall that a linear functional \\(T:H\\to \\mathbb{R}\\) where \\((H,\\langle \\cdot,\\cdot\\rangle)\\) is a Hilbert space is continuous if and only if</p> \\[ \\sup_{\\left\\Vert x\\right\\Vert=\\langle x,x\\rangle \\leq 1}\\left\\vert T(x)\\right\\vert&lt;\\infty \\] <p>Riesz Representation Theorem</p> <p>Let \\(H\\) be a Hilbert space, and \\(T:H\\to \\mathbb{R}\\) be a continuous linear functional. Then there exists \\(y\\) in \\(H\\) such that \\(T(x)=\\langle y,x\\rangle\\) for every \\(x\\) in \\(H\\).</p> <p>This theorem allows us to treat the following central theorem of measure theory in a rather simple way.</p> <p>Radon-Nikodym Theorem</p> <p>Let \\((\\Omega, \\mathcal{F})\\) be a measurable space and \\(P, Q\\) two finite measures on \\(\\mathcal{F}\\) such that \\(Q \\ll P\\). Then there exists a \\(P\\)-almost surely unique and positive random variable \\(Z\\) in \\(L^1(P)\\) such that</p> \\[ Q\\left( A \\right)=\\int_{A}Z dP, \\quad \\text{for every }A \\in \\mathcal{F} \\] <p>The random variable \\(Z\\) is called the Radon-Nikodym derivative of \\(Q\\) with respect to \\(P\\) and denoted by \\(dQ/dP\\).</p> <p>In particular, it holds</p> \\[ \\int X dQ = \\int X \\frac{dQ}{dP} dP, \\quad \\text{for every }X \\text{ in }L^1(Q). \\] <p>Proof</p> <p>The proof is based on the argumentation of John von Neumann. The measure</p> \\[ \\tilde{Q}[A]=P[A]+Q[A] \\quad \\text{for } A \\in \\mathcal{F} \\] <p>is such that \\(\\tilde{Q}\\) is equivalent to \\(P\\). Indeed, for any event \\(A\\), on the one hand, \\(P[A]=0\\) implies that \\(Q[A]=0\\) and therefore \\(\\tilde{Q}[A]=P[A]+Q[A]=0\\). On the other hand, the positivity of \\(Q\\) and \\(P\\) implies \\(P[A]=0\\) whenever \\(\\tilde{Q}[A]=0\\), showing \\(P\\sim \\tilde{Q}\\). The equivalence between \\(P\\) and \\(\\tilde{Q}\\) implies in particular that two random variables \\(X\\) and \\(Y\\) agree \\(P\\)-almost surely if and only if they agree \\(Q\\)-almost surely. Hence, \\(L^0(P)=L^0(\\tilde{Q})\\). For any random variable \\(X\\) in \\(L^0(P)=L^0(\\tilde{Q})\\), it holds</p> \\[ \\left\\Vert X\\right\\Vert_{L^2(P)}^2= \\int X^2 dP\\leq \\int X^2 d(P+Q)=\\left\\Vert X\\right\\Vert_{L^2(\\tilde{Q})}^2 \\] <p>showing that \\(L^2(\\tilde{Q})\\subseteq L^2(P)\\).</p> <p>Define now the linear functional</p> \\[ T\\colon L^2(\\tilde{Q})\\to \\mathbb{R}, \\quad X \\mapsto T(X)=\\int X dP \\] <p>which is well-defined since \\(L^2(\\tilde{Q})\\subseteq L^2(P)\\). Using Jensen's inequality and the fact that \\(\\tilde{Q}/\\tilde{Q}(\\Omega)\\) is a probability measure, it holds</p> \\[ \\left| T(X) \\right|\\leq \\sqrt{\\tilde{Q}(\\Omega)}\\left\\Vert X\\right\\Vert_{L^2(\\tilde{Q})}. \\] <p>As a consequence,</p> \\[ \\sup_{X \\in L^2(\\tilde{Q}), \\left\\Vert X\\right\\Vert_{L^2(\\tilde{Q})}\\leq 1} \\left\\vert T(X)\\right\\vert\\leq \\sqrt{\\tilde{Q}(\\Omega)}&lt;\\infty, \\] <p>showing that \\(T\\) is a continuous linear functional on the Hilbert space \\(L^2(\\tilde{Q})\\). Applying the Riesz Representation Theorem, there exists \\(Y\\) in \\(L^2(\\tilde{Q})\\) such that</p> \\[ T(X)=\\langle X, Y\\rangle = \\int XY d\\tilde{Q},\\quad \\text{for every }X\\in L^2(\\tilde{Q}). \\] <p>Taking \\(X=1_A\\) for \\(A=\\{Y\\leq 0\\}\\), it follows that \\(P[A]=0\\), showing that \\(Y&gt;0\\) \\(P\\)-almost surely. Similarly, we obtain \\(0&lt;Y\\leq 1\\) \\(\\tilde{Q}\\)- and \\(P\\)-almost surely. Defining \\(Z=1/Y-1\\), which is a positive measurable function in \\(L^1(P)\\), it follows that</p> \\[ Q\\left( A \\right)=\\tilde{Q}(A)-Q(A)=\\int_A Z dP, \\quad \\text{for every } A \\in \\mathcal{F} \\] <p>which ends the proof of existence.</p> <p>Uniqueness is left as an exercise.</p>"},{"location":"lecture/03-Integration/033-radon-nikodym-cond-exp/#conditional-expectation","title":"Conditional Expectation","text":"<p>The Radon-Nikodym Theorem allows us to prove easily the existence of conditional expectations.</p> <p>Theorem: Conditional Expectation</p> <p>Let \\((\\Omega,\\mathcal{F},P)\\) be a probability space and \\(\\mathcal{G}\\subseteq \\mathcal{F}\\) be a sub-\\(\\sigma\\)-algebra. For every integrable random variable \\(X\\), there exists a \\(P\\)-almost surely unique \\(\\mathcal{G}\\)-measurable and integrable random variable \\(Y\\) such that</p> \\[ E\\left[ 1_A X \\right]=E\\left[ 1_A Y \\right],\\quad \\text{for every }A \\in \\mathcal{G} \\] <p>Denoting \\(E[X|\\mathcal{G}]:=Y\\), provided all the following random variables are all in \\(L^1\\), it holds:</p> <ol> <li>\\(X\\mapsto E[X | \\mathcal{G}]\\) is linear, monotone, and \\(E[c|\\mathcal{G}]=c\\) for every constant.</li> <li>\\(E[X|\\mathcal{G}]=E[X]\\) if \\(\\mathcal{G}=\\{\\emptyset, \\Omega\\}\\).</li> <li>\\(E[X_n|\\mathcal{G}]\\nearrow E[X|\\mathcal{G}]\\) whenever \\(0\\leq X_n\\nearrow X\\).</li> <li>\\(E[YX|\\mathcal{G}]=YE[X|\\mathcal{G}]\\) and \\(E[Y|\\mathcal{G}]=Y\\) whenever \\(Y\\) is \\(\\mathcal{G}\\)-measurable.</li> <li>\\(E[E[X|\\mathcal{G}_2]|\\mathcal{G}_1]=E[X|\\mathcal{G}_1]\\) for every two \\(\\sigma\\)-algebras \\(\\mathcal{G}_1\\subseteq \\mathcal{G}_2\\subseteq \\mathcal{F}\\).</li> <li>\\(\\varphi(E[X|\\mathcal{G}])\\leq E[\\varphi(X)|\\mathcal{G}]\\) if \\(\\varphi\\) is convex with \\(\\varphi(X)\\in L^1\\).</li> <li>\\(E[\\left\\vert E[X|\\mathcal{G}]\\right\\vert]\\leq E[\\left\\vert X\\right\\vert]\\).</li> <li>\\(E[\\liminf X_n|\\mathcal{G}]\\leq \\liminf E[X_n|\\mathcal{G}]\\) if \\(X_n\\geq Y \\in L^1\\) and \\(\\liminf X_n \\in L^1\\).</li> <li>\\(E[X|\\mathcal{G}]=\\lim E[X_n |\\mathcal{G}]\\) if \\(X_n \\to X\\) almost surely and \\(|X_n|\\leq Y\\in L^1\\).</li> <li>\\(E[XE[Y|\\mathcal{G}]]=E[E[X|\\mathcal{G}]Y]=E[E[X|\\mathcal{G}]E[Y|\\mathcal{G}]]\\).</li> </ol> <p>This unique random variable is called the \\(\\mathcal{G}\\)-conditional expectation of \\(X\\), and is denoted by \\(E[X|\\mathcal{G}]\\).</p> <p>Proof</p> <p>For \\(X\\) in \\(L^1\\), it defines two finite measures on \\(\\mathcal{G}\\) given by</p> \\[ Q^{\\pm}(A)=E\\left[ 1_A X^{\\pm}\\right], \\quad A \\in \\mathcal{G} \\] <p>which are by definition both absolutely continuous with respect to \\(P\\). It follows from the Radon-Nikodym Theorem {#thm:radonnikodym} that there exist two \\(P\\)-almost surely unique positive \\(\\mathcal{G}\\)-measurable random variables \\(Z^{\\pm}\\in L^1(\\mathcal{G})\\) such that</p> \\[ Q^{\\pm}(A)=E[1_A Z^{\\pm}]. \\] <p>Defining \\(E\\left[ X|\\mathcal{G} \\right]=Z^+-Z^-\\in L^1(\\mathcal G)\\) as the conditional expectation ends the proof of existence and uniqueness.</p> <p>In the following, we assume that the integrability conditions are sufficient for the assertions.</p> <ul> <li>Point 1: Follows immediately from the linearity and monotonicity of the expectation.</li> <li>Point 2: Let \\(Y=E[X|\\mathcal{G}]\\). Since \\(\\mathcal{G}\\) is the trivial \\(\\sigma\\)-algebra, it follows that \\(Y\\) is constant. Furthermore, \\(E[Y1_\\Omega]=E[X1_{\\Omega}]=E[X]\\), hence \\(Y=E[X]\\) per definition of the conditional expectation.</li> <li> <p>Point 3: For \\(X_n \\nearrow X\\) almost surely, by monotonicity of the conditional expectation, it follows that \\(E[X_n|\\mathcal{G}]\\leq E[X|\\mathcal{G}]\\) and is an increasing sequence whose limit is denoted by \\(Y\\).     For \\(A=\\{Y &lt; E[X|\\mathcal{G}]\\}\\), which is in \\(\\mathcal{G}\\), we have by monotone convergence</p> \\[ E[ 1_A (E[ X|\\mathcal{G} ]-Y) ]=\\lim E[ 1_A E[X-X_n|\\mathcal{G}] ]=\\lim E[ X-X_n]=0 \\] <p>showing that \\(P[A]=0\\) since \\(E[X|\\mathcal{G}]\\geq Y\\).</p> </li> <li> <p>Point 4: For \\(Y=1_A\\) with \\(A \\in \\mathcal{G}\\), it holds</p> \\[ E[ 1_BE[ YX|\\mathcal{G} ]]=E[ 1_B YX ]=E[ 1_{B\\cap A}X ]=E[ 1_{B\\cap A}E[ X|\\mathcal{G} ]]=E[1_B YE[ X|\\mathcal{G} ]]. \\] <p>Since \\(YE[X|\\mathcal{G}]\\) is \\(\\mathcal{G}\\)-measurable, by uniqueness of the conditional expectation, we get \\(YE[X|\\mathcal{G}]=E[YX|\\mathcal{G}]\\) for every \\(Y\\) of the form \\(Y=1_A\\) with \\(A\\) in \\(\\mathcal{G}\\). By linearity of the conditional expectation, it holds for every simple step \\(\\mathcal{G}\\)-measurable \\(Y\\). By approximating from below by simple step functions and using Point 3, it holds for any positive \\(\\mathcal{G}\\)-measurable random variable \\(Y\\).</p> <p>The general case follows from the linearity of the conditional expectation and the decomposition \\(Y=Y^+-Y^-\\).</p> </li> <li> <p>Point 5: Let \\(A\\) in \\(\\mathcal{G}_1\\subseteq \\mathcal{G}_2\\).     By the definition of the conditional expectation applied twice, it follows that</p> \\[ E[1_A E[E[X|\\mathcal{G}_2]|\\mathcal{G}_1]]=E[1_A E[ X|\\mathcal{G}_2]]=E[1_AX] \\] <p>showing that \\(E[E[X|\\mathcal{G}_2]|\\mathcal{G}_1]=E[X|\\mathcal{G}_1]\\).</p> </li> <li> <p>Point 6: This follows from Jensen's inequality using the fact that the conditional expectation is linear and monotone, plus monotone convergence from Point 3.</p> </li> <li>Point 7: Applying Point 6 for \\(\\varphi(x)=|x|\\).</li> <li>Point 8: For the Fatou assertion, it follows from Point 3 by considering the increasing sequence \\(Z_n=\\sup_{k\\geq n}X_k\\).</li> <li>Point 9: Follows from the dominated convergence theorem.</li> </ul> <p>For your interest, here is the proof of the existence of conditional expectation using Hilbert projections.</p> <p>Proof</p> <p>Suppose first that \\(X \\in L^2(\\mathcal{F})\\). Note that \\(L^2(\\mathcal{F})\\) is a Hilbert space for the norm \\(\\left\\Vert\\cdot\\right\\Vert_2\\) and \\(L^2(\\mathcal{G})\\) is a closed linear subspace of \\(L^2(\\mathcal{F})\\). Hence, by Hilbert's projection theorem, there exists a unique \\(Y \\in L^2(\\mathcal{G})\\) such that \\(X-Y\\) is orthogonal to \\(L^2(\\mathcal{G})\\). Since \\(1_A \\in L^2(\\mathcal{G})\\) for every \\(A \\in \\mathcal{G}\\), it follows that</p> \\[ E\\left[ (X-Y)1_A \\right]=\\langle X-Y,1_A\\rangle=0, \\quad A \\in \\mathcal{G} \\] <p>showing the main assertion.</p>"},{"location":"lecture/03-Integration/034-independence/","title":"Independence","text":"<p>Unlike the previous section that do hold in large part for measures without considering the special case of probability, independence is a concept that is genuinly cored into probability.</p> <p>Throughout we fix a probability space \\((\\Omega, \\mathcal{F}, P)\\).</p> <p>Definition: Independence</p> <ul> <li> <p>Independence of families:     A family \\((\\mathcal{C}^i)\\) of collections of events is called independent if for every finite collection \\((A_{i_k})_{k\\leq n}\\) with \\(A_{i_k}\\) event in \\(\\mathcal{C}^{i_k}\\) for every \\(k=1,\\ldots, n\\), it holds</p> \\[ P\\left[ A_{i_1}\\cap \\cdots\\cap A_{i_n} \\right]=\\prod_{k\\leq n} P\\left[ A_{i_k} \\right]. \\] </li> <li> <p>Independence of events:     A family of events \\((A_i)\\) is called independent if the family \\((\\{A_i\\})\\) is independent.</p> </li> <li> <p>Independence of random variables:     A family of random variables \\((X_i)\\) is called independent if \\((\\sigma(X_i))\\) are independent.</p> </li> </ul> <p>Remark</p> <p>A family \\((\\mathcal{C}^i)\\) is called pairwise independent if</p> \\[ P[A_{i_1}\\cap A_{i_2}]=P[A_{i_1}]P[A_{i_2}] \\] <p>for every \\(A_{i_1}\\in \\mathcal{C}^{i_1}\\), \\(A_{i_2}\\in \\mathcal{C}^{i_2}\\), which is a weaker version of independence. As an exercise, find three sets \\(A,B\\) and \\(C\\) on some probability space which are pairwise independent but not independent.</p> <p>Proposition</p> <p>The following assertions hold:</p> <ol> <li>Let \\(\\mathcal{P}_1, \\ldots, \\mathcal{P}_n\\) be a finite family of independent \\(\\pi\\)-systems.    Then \\(\\sigma(\\mathcal{P}_1), \\ldots,\\sigma(\\mathcal{P}_n)\\) are also independent.</li> <li> <p>Let \\(X,Y\\) be two independent random variables, either positive or such that \\(X,Y, XY \\in L^1\\), then it follows that</p> \\[ E[XY]=E[X]E[Y] \\] </li> <li> <p>Let \\(X\\) be a random variable independent of a sigma-algebra \\(\\mathcal{G}\\).     Then it holds</p> \\[   E\\left[ X|\\mathcal{G} \\right]=E\\left[ X \\right] \\] </li> </ol> <p>Proof</p> <ol> <li> <p>We show the case \\(n=2\\), the general one is done by induction.     Let \\(\\mathcal{C}_1\\) be the collection of elements \\(A_1\\) in \\(\\sigma(\\mathcal{P}_1)\\) for which it holds</p> \\[ P\\left[ A_1\\cap A_2 \\right]=P[A_1]P[A_2] \\quad \\text{for every }A_2 \\in \\mathcal{P}_2. \\] <p>Let us show that \\(\\mathcal{C}_1\\) is a \\(\\lambda\\)-system. Clearly, \\(\\Omega \\in \\mathcal{C}_1\\). Let \\(A_1 \\in \\mathcal{C}_1\\) and \\(A_2\\in \\mathcal{P}_2\\).</p> <p>It follows that</p> \\[ P[A_1^c\\cap A_2]=P\\left[ A_2\\right]-P[A_1\\cap A_2]=P[A_2]-P[A_1]P[A_2]=(1-P[A_1])P[A_2]=P[A_1^c]P[A_2], \\] <p>showing that \\(A_1^c\\in \\mathcal{C}_1\\). Finally, let \\((A_1^n)\\) be a sequence of pairwise disjoint elements in \\(\\mathcal{C}_1\\) and \\(A_2\\) in \\(\\mathcal{P}_2\\). By \\(\\sigma\\)-additivity of probability measures, it holds</p> \\[   P\\left[ \\left( \\cup A_1^n \\right)\\cap A_2 \\right]=\\sum P\\left[ A_1^n\\cap A_2 \\right]=\\sum P[A_1^n]P[A_2]=\\left(\\sum P[A_1^n]\\right)P[A_2]=P\\left[ \\cup A_1^n \\right]P[A_2], \\] <p>showing that \\(\\cup A_1^n\\in \\mathcal{C}_1\\). We deduce that \\(\\mathcal{C}_1\\) is a \\(\\lambda\\)-system containing the \\(\\pi\\)-system \\(\\mathcal{P}_1\\). Since \\(\\sigma(\\mathcal{P}_1)\\subseteq \\sigma(\\mathcal{C}_1)=\\mathcal{C}_1\\subseteq \\sigma(\\mathcal{P}_1)\\), it follows that \\(\\mathcal{C}_1=\\sigma(\\mathcal{P}_1)\\). Now let \\(\\mathcal{C}_2\\) be the set of those \\(A_2\\) in \\(\\sigma(\\mathcal{P}_2)\\) such that</p> \\[   P\\left[ A_1\\cap A_2 \\right]=P[A_1]P[A_2] \\quad \\text{for every }A_1 \\in \\sigma(\\mathcal{P}_1). \\] <p>Since \\(\\sigma(\\mathcal{P}_1)\\) is independent of \\(\\mathcal{P}_2\\), the same argumentation as above shows that \\(\\mathcal{C}_2\\) is a \\(\\lambda\\)-system.</p> <p>Therefore, \\(\\mathcal{C}_2=\\sigma(\\mathcal{P}_2)\\) showing that \\(\\sigma(\\mathcal{P}_1)\\) is independent of \\(\\sigma(\\mathcal{P}_2)\\).</p> </li> <li> <p>By assumption, \\(\\sigma(X)\\) is independent of \\(\\sigma(Y)\\).     Assume that \\(X\\) and \\(Y\\) are positive.     Let \\(\\tilde{X}=\\sum_{k\\leq n} \\alpha_k 1_{A_k}\\) and \\(\\tilde{Y}=\\sum_{l\\leq m}\\beta_l 1_{B_l}\\) for \\(\\alpha_k,\\beta_l\\) positives and \\(A_k\\in \\sigma(X)\\) and \\(B_l\\in \\sigma(Y)\\).     It follows that</p> \\[   E\\left[ \\tilde{X}\\tilde{Y} \\right]=\\sum_{k\\leq n,l\\leq m}\\alpha_k \\beta_l P[A_k\\cap B_l]=\\sum_{k\\leq n,l\\leq m}\\alpha_k\\beta_l P[A_k]P[B_l]. \\] <p>Since there exist sequences \\(\\tilde{X}_n,\\tilde{Y}_n\\) such that \\(\\tilde{X}_n\\nearrow X\\) and \\(\\tilde{Y}_n\\nearrow Y\\), it follows from Lebesgue's monotone convergence that</p> \\[   E\\left[ XY \\right]=\\lim E\\left[ \\tilde{X}_n\\tilde{Y}_n \\right]=\\lim E\\left[ \\tilde{X}_n \\right]E\\left[ \\tilde{Y}_n \\right]=E[X]E[Y]. \\] <p>The case where \\(X,Y,XY\\) are in \\(L^1\\) follows by separating positive and negative parts.</p> </li> <li> <p>Let \\(X\\) be an integrable random variable independent of the \\(\\sigma\\)-algebra \\(\\mathcal{G}\\).     For every \\(A\\in \\mathcal{G}\\), it follows that \\(1_A\\) and \\(X\\) are independent, and therefore, from the previous point, it holds</p> \\[   E\\left[ X1_{A} \\right] = E\\left[ X \\right]E\\left[ 1_A \\right]. \\] <p>But on the other hand,</p> \\[ E\\left[ E\\left[ X \\right]1_{A} \\right]=E\\left[ X \\right]E\\left[ 1_A \\right]. \\] <p>Since \\(E[X]\\) is a constant and \\(\\mathcal{G}\\)-measurable, it follows from the uniqueness of the conditional expectation that</p> \\[   E[X|\\mathcal{G}]=E[X]. \\] </li> </ol>"},{"location":"lecture/03-Integration/035-fubini-tonelli/","title":"Fubini-Tonelli, Stochastic Kernel","text":"<p>The theorem of Fubini-Tonelli is concerned with the definition of sound product measures on finite product spaces and their properties. To do so, we will make use of Carath\u00e9odory's extension Theorem. In the following, we consider the two-dimensional case.</p> <p>Let \\((\\Omega_1,\\mathcal{F}_1)\\) and \\((\\Omega_2, \\mathcal{F}_2)\\) be two measurable spaces and define \\(\\Omega =\\Omega_1 \\times \\Omega_2\\) endowed with the product \\(\\sigma\\)-algebra \\(\\mathcal{F}=\\mathcal{F}_1\\otimes \\mathcal{F}_2\\).</p> <p>Proposition</p> <p>Let \\(A\\) be an event in the product \\(\\sigma\\)-algebra \\(\\mathcal{F}=\\mathcal{F}_1\\otimes \\mathcal{F}_2\\) and \\(X\\colon \\Omega \\to \\mathbb{R}\\) be a measurable function. Define</p> \\[ \\begin{align}     A_{\\omega_1} &amp; :=\\{\\omega_2\\in \\Omega_2\\colon (\\omega_1,\\omega_2)\\in A\\}\\subseteq \\Omega_2,  &amp;\\quad A_{\\omega_2} &amp; :=\\{\\omega_1\\in \\Omega_1\\colon (\\omega_1,\\omega_2)\\in A\\}\\subseteq \\Omega_1,\\\\     X_{\\omega_1} &amp; :=X(\\omega_1,\\cdot):\\Omega_2\\to \\mathbb{R},  &amp;\\quad X_{\\omega_2} &amp; :=X(\\cdot,\\omega_2):\\Omega_1\\to \\mathbb{R}. \\end{align} \\] <p>Then it holds that \\(A_{\\omega_1}\\) and \\(A_{\\omega_2}\\) are events in \\(\\mathcal{F}_2\\) and \\(\\mathcal{F}_1\\) respectively. Furthermore, \\(X_{\\omega_1}\\) is \\(\\mathcal{F}_2\\)-measurable, and \\(X_{\\omega_2}\\) is \\(\\mathcal{F}_1\\)-measurable.</p> <p>Proof</p> <p>Let \\(\\mathcal{C}\\) be the collection of those \\(A\\in\\mathcal{F}\\) such that \\(A_{\\omega_2}\\times A_{\\omega_1}\\) is in \\(\\mathcal{F}_1\\times \\mathcal{F}_2\\). It clearly holds that \\(\\mathcal{F}_1\\times \\mathcal{F}_2\\subseteq \\mathcal{C}\\). Direct inspection shows that \\(\\mathcal{C}\\) is a \\(\\sigma\\)-algebra, and therefore </p> \\[   \\mathcal{F}=\\sigma(\\mathcal{F}_1\\times \\mathcal{F}_2)\\subseteq \\mathcal{C}\\subseteq \\mathcal{F}, \\] <p>showing the first assertion.</p> <p>As for the second point, let \\(B\\) be a Borel set in \\(\\mathbb{R}\\). It follows that \\(\\{X_{\\omega_1}\\in B\\}=\\{X\\in B\\}_{\\omega_1}\\), which is an element of \\(\\mathcal{F}_2\\) by what has just been shown. Hence, \\(X_{\\omega_1}\\) is \\(\\mathcal{F}_2\\)-measurable. The same argumentation holds for \\(X_{\\omega_2}\\).</p> <p>Definition: Stochastic Kernel</p> <p>A stochastic kernel on \\(\\Omega_1\\times \\mathcal{F}_2\\) is a function \\(K\\colon \\Omega_1\\times \\mathcal{F}_2\\to [0,1]\\) such that</p> <ol> <li>\\(\\omega_1\\mapsto K(\\omega_1,A_2)\\) is \\(\\mathcal{F}_1\\)-measurable for every event \\(A_2\\) in \\(\\mathcal{F}_2\\).</li> <li>\\(A_2\\mapsto K(\\omega_1,A_2)\\) is a probability measure on \\(\\mathcal{F}_2\\) for every \\(\\omega_1 \\in \\Omega_1\\).</li> </ol> <p>A stochastic kernel is, in some sense, a measurable family of probability measures on \\(\\mathcal{F}_1\\), one for each state \\(\\omega_1\\) in \\(\\Omega_1\\). A special case of a stochastic kernel is the constant one \\(K(\\omega_1,\\cdot)=P_2\\) for all states \\(\\omega_1\\) in \\(\\Omega_1\\), where \\(P_2\\) is a probability measure on \\(\\mathcal{F}_2\\).</p> <p>Given a probability measure \\(P_1\\) on \\(\\mathcal{F}_1\\), we want to define a probability measure \\(P\\) on the product \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) such that</p> \\[ P[A]=\\int_{\\Omega_1}\\left( \\int_{\\Omega_2}1_A(\\omega_1,\\omega_2)K(\\omega_1,d\\omega_2) \\right)P_1(d\\omega_1). \\] <p>This is the subject of the following theorem.</p> <p>Stochastic variant of Tonelli's Theorem</p> <p>Let \\(P_1\\) be a measure on \\(\\mathcal{F}_1\\) and \\(K\\) a stochastic kernel on \\(\\Omega_1\\times \\mathcal{F}_2\\). Then there exists a unique probability measure \\(P\\) on \\(\\mathcal{F}\\) such that for every positive random variable \\(X\\colon \\Omega \\to \\mathbb{R}\\), it holds</p> \\[   E_P\\left[ X \\right]=\\int_{\\Omega_1}\\left( \\int_{\\Omega_2} X(\\omega_1,\\omega_2)K(\\omega_1,d\\omega_2) \\right)P_1(d\\omega_1) \\] <p>In particular,</p> \\[   P[A]=\\int_{\\Omega_1}K(\\omega_1, A_{\\omega_1})P_1(d\\omega_1) \\] <p>for any event \\(A\\) in \\(\\mathcal{F}\\).</p> <p>Proof</p> <p>Define \\(\\mathcal{R}=\\mathcal{F}_1\\times \\mathcal{F}_2\\) and the set function \\(P\\colon \\mathcal{R}\\to [0,1]\\) given by</p> \\[   P[A]=\\int_{A_1}K(\\omega_1,A_2)P_1(d\\omega_1) \\] <p>For any element \\(A_1 \\times A_2\\) in $\\mathcal{R}. Inspection shows that \\(\\mathcal{R}\\) is a semi-ring that contains \\(\\Omega\\). To apply Carath\u00e9odory\u2019s extension Theorem, we must show that \\(P\\) is a \\(\\sigma\\)-additive pre-measure.</p> <p>It clearly holds that \\(P[\\emptyset]=0\\) and </p> \\[   P[\\Omega]=\\int_{\\Omega_1}K(\\omega_1,\\Omega_2)P_1[d\\omega_1]=\\int_{\\Omega_1}P_1[d\\omega_1]=1. \\] <p>Let \\((A_1^n\\times A_2^n)\\) be a sequence of pairwise disjoint elements of \\(\\mathcal{R}\\) such that \\(\\cup A_1^n\\times A_2^n=A_1\\times A_2\\) in \\(\\mathcal{R}\\) for some \\(A_1\\in \\mathcal{F}_1\\) and \\(A_2 \\in \\mathcal{F}_2\\) and define the functions</p> \\[ \\begin{aligned}     X_n(\\omega_1)&amp;:=1_{A_1^n}(\\omega_1)K(\\omega_1,A_2^n)=\\int_{\\Omega_2}1_{A_1^n\\times A_2^n}(\\omega_1,\\omega_2)K(\\omega_1,d\\omega_2),\\\\     X(\\omega_1)&amp;:=1_{A_1}(\\omega_1)K(\\omega_1,A_2)=\\int_{\\Omega_2}1_{A_1\\times A_{2}}(\\omega_1,\\omega_2)K(\\omega_1,d\\omega_2). \\end{aligned} \\] <p>Furthermore, due to the pairwise disjointness of \\((A_1^n\\times A_2^n)\\), as well as monotone convergence, it follows that</p> \\[ \\sum X_n(\\omega_1)=\\int_{\\Omega_1}\\sum 1_{A_1^n\\times A_2^n}(\\omega_1,\\omega_2)K(\\omega_1,d\\omega_2)=\\int_{\\Omega_2}1_{\\cup A_1^n\\times A_2^n}K(\\omega_1,d\\omega_2)=X(\\omega_1) \\] <p>for any state \\(\\omega_1\\) in \\(\\Omega_1\\).   Hence, once again, monotone convergence yields</p> \\[   P[A_1\\times A_2]=\\int_{\\Omega_1}X(\\omega_1)P_1(d\\omega_1)=\\sum\\int_{\\Omega_1}X_n(\\omega_1)P_1(d\\omega_1)=\\sum P[A_1^n\\times A_2^n]. \\] <p>showing the \\(\\sigma\\)-additivity.</p> <p>It follows that we can apply Carath\u00e9odory's extension Theorem, ensuring the existence of a unique measure \\(P\\) on \\(\\mathcal{F}\\) satisfying</p> \\[   P[A_1\\times A_2]=\\int_{A_1}K(\\omega_1,A_2)P_{1}(d\\omega_1), \\quad A_1 \\times A_2 \\in \\mathcal{F}_1\\times \\mathcal{F}_2. \\] <p>Let us now show that</p> \\[   P[A]=\\int_{\\Omega_1}K(\\omega_1, A_{\\omega_1})P_1(d\\omega_1) \\] <p>holds. Define the collection \\(\\mathcal{C}\\) of those events \\(A\\) in \\(\\mathcal{F}\\) such that this relation holds.   For \\(A=A_1\\times A_2\\), it follows that \\(A_{\\omega_1}=A_2\\) if \\(\\omega_1 \\in A_1\\) and \\(\\emptyset\\) otherwise. It follows that </p> \\[   K(\\omega_1,A_{\\omega_1})=1_{A_1}(\\omega_1)K(\\omega_1,A_2), \\] <p>showing that \\(\\mathcal{F}_1\\times \\mathcal{F}_2\\subseteq \\mathcal{C}\\).   In particular, \\(\\Omega \\in \\mathcal{C}\\). Furthermore, for every pairwise disjoint sequence \\((A^n)\\) of elements in \\(\\mathcal{C}\\), denoting \\(A=\\cup A^n\\), it follows from monotone convergence that </p> \\[ \\begin{align}     P\\left[ A\\right]&amp;=\\sum P[A^n]     =\\int_{\\Omega_1}\\sum K(\\omega_1,A_{\\omega_1}^n)P_1(d\\omega_1)\\\\     &amp;=\\int_{\\Omega_1}K(\\omega_1,\\cup A_{\\omega_1}^n)P(d\\omega_1)     =\\int_{\\Omega_1}K(\\omega_1,A_{\\omega_1})P(d\\omega_1) \\end{align} \\] <p>showing that \\(A \\in \\mathcal{C}\\). Finally, for \\(A \\in \\mathcal{C}\\), it follows that</p> \\[   P[A^c]=1-P[A] =\\int_{\\Omega_1} \\left( 1-K(\\omega_1,A_{\\omega_1}) \\right)P(d\\omega_1) =\\int_{\\Omega_1} K(\\omega_1,A_{\\omega_1}^c)P(d\\omega_1) \\] <p>showing that \\(A^c \\in \\mathcal{C}\\). Hence, \\(\\mathcal{C}\\) is a \\(\\lambda\\)-system that contains the \\(\\pi\\)-system \\(\\mathcal{F}_1\\times \\mathcal{F}_2\\). Hence, by Dynkin's \\(\\pi\\)-\\(\\lambda\\) lemma, it follows that</p> \\[ \\sigma(\\mathcal{F}_1\\times \\mathcal{F}_2)\\subseteq \\mathcal{C}\\subseteq \\mathcal{F}=\\sigma(\\mathcal{F}_1\\times \\mathcal{F}_2) \\] <p>showing that \\(\\mathcal{C}=\\mathcal{F}\\), that is, showing that the second equation of the Theorem holds for any event \\(A\\) in \\(\\mathcal{F}\\).</p> <p>As for expectation equality from the theorem, it follows from the fact that every positive random variable \\(X\\colon\\Omega \\to \\mathbb{R}\\) can be approximated by step functions, ending the proof.</p> <p>Definition: Product Measure</p> <p>With the notations of Theorem the previous theorem, we denote this unique measure by \\(P=P_1\\otimes K\\).</p> <p>In the case where \\(K(\\omega_1,\\cdot)=P_2\\) for all \\(\\omega_1 \\in \\Omega_1\\) for some measure \\(P_2\\) on \\(\\mathcal{F}_2\\), then \\(P\\) is called the product measure of \\(P_1\\) and \\(P_2\\) on the product space and is denoted by \\(P=P_1\\otimes P_2\\).</p> <p>In the case of a product measure, due to symmetry, it holds in particular</p> \\[ \\int_{\\Omega}X(\\omega)P(d\\omega)=\\int_{\\Omega_1}\\left( \\int_{\\Omega_2}X(\\omega_1,\\omega_2) P_2(d\\omega_2)\\right)P_1(d\\omega_1)=\\int_{\\Omega_2}\\left( \\int_{\\Omega_1}X(\\omega_1,\\omega_2) P_1(d\\omega_1)\\right)P_2(d\\omega_2). \\] <p>Corollary</p> <p>Let \\(X\\) be a positive random variable on some probability space \\((\\Omega,\\mathcal{F},P)\\). Then it holds</p> \\[ E[X]=\\int_{0}^\\infty P\\left[ X&gt;x \\right]\\lambda(dx), \\] <p>where \\(\\lambda\\) is the Lebesgue measure on \\(\\mathbb{R}\\).</p> <p>Proof</p> <p>For almost all state \\(\\omega\\) in \\(\\Omega\\), we have \\(X(\\omega)\\geq 0\\), and therefore</p> \\[   X(\\omega)=\\int_{0}^{X(\\omega)}\\lambda(dx)=\\int_{0}^{\\infty}1_{\\{X(\\omega)&gt;x\\}}\\lambda(dx), \\] <p>where \\(\\lambda\\) is the Lebesgue measure on \\(\\mathbb{R}\\). Since \\((\\omega,x)\\mapsto 1_{\\{X(\\omega)&gt;x\\}}\\) is a \\(\\mathcal{F}\\otimes \\mathcal{B}(\\mathbb{R}_+)\\)-measurable function, by Fubini-Tonelli for the product measure \\(P\\otimes \\lambda\\), it holds</p> \\[ \\begin{align}     E\\left[ X \\right] &amp;=\\int_{\\Omega} \\left(\\int_{0}^{\\infty} 1_{\\{X(\\omega)&gt;x\\}}\\lambda(dx)\\right)P(d\\omega) \\\\     &amp;=\\int_{\\Omega\\times \\mathbb{R}_+} 1_{\\{X(\\omega)&gt;x\\}}P\\otimes \\lambda(d\\omega dx) \\\\     &amp;=\\int_{0}^{\\infty} \\left(\\int_{\\Omega} 1_{\\{X(\\omega)&gt;x\\}}P(d\\omega)\\right)\\lambda(dx) \\\\     &amp;=\\int_{0}^{\\infty} E\\left[ 1_{\\{X&gt;x\\}} \\right]\\lambda(dx) \\\\     &amp;=\\int_{0}^{\\infty} P\\left[ X&gt;x \\right]\\lambda(dx). \\end{align} \\] <p>We now address the stochastic variant of Fubini's theorem since we considered a stochastic kernel instead of a simple probability measure. Let \\(X\\) and \\(Y\\) be two random variables on some probability space \\((\\Omega,\\mathcal{F},P)\\). We consider the probability measure \\(P_{(X,Y)}\\) on the product Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}^2\\) given by</p> \\[   P_{(X,Y)}[B]=P\\left[ (X,Y)\\in B \\right] \\] <p>for any Borel set \\(B\\) on \\(\\mathbb{R}^2\\). We suppose that this joint distribution \\(P_{(X,Y)}\\) can be decomposed into \\(P_1\\otimes K\\) for some probability measure \\(P_1\\) on \\(\\mathcal{B}(\\mathbb{R})\\) and a stochastic kernel \\(K\\) on \\(\\mathbb{R}\\times \\mathcal{B}(\\mathbb{R})\\). We will see later that this is always the case. Note that by Tonelli's Theorem, it holds</p> \\[ \\begin{align}     P_X[B_1]&amp;=P[X\\in B_1]=P\\left[ (X,Y)\\in B_1\\times \\mathbb{R} \\right]=P_{(X,Y)}[B_1\\times \\mathbb{R}]\\\\     &amp;=\\int_{\\mathbb{R}}1_{B_1}(x)K(x,\\mathbb{R})P_1(dx)=\\int_{\\mathbb{R}}1_{B_1}(x)P_1(dx)=P_1[B_1] \\end{align} \\] <p>showing that \\(P_X=P_1\\), justifying therefore the notation \\(P_{(X,Y)}=P_X\\otimes K_{Y|X}\\).</p> <p>Theorem</p> <p>Let \\(X\\) and \\(Y\\) be two random variables whose joint distribution is given by \\(P_X\\otimes K_{Y|X}\\), where \\(P_X\\) is the distribution of \\(X\\) and \\(K_{Y|X}\\) is a stochastic kernel on \\(\\mathbb{R}\\times \\mathcal{B}(\\mathbb{R})\\).</p> <p>For every positive random variable \\(g\\colon \\mathbb{R}^2\\to \\mathbb{R}_+\\) such that \\(g(X,Y)\\) is integrable, it holds</p> \\[   E\\left[ g(X,Y)|\\sigma(X) \\right]=\\int_{\\mathbb{R}}g(X,y)K_{Y|X}(X,dy) \\] <p>\\(P\\)-almost surely.</p> <p>This relation means that for \\(P\\)-almost all \\(\\omega \\in \\Omega\\), it holds</p> \\[ E\\left[ g(X,Y)|\\sigma(X) \\right](\\omega)=\\int_{\\mathbb{R}}g(X(\\omega),y)K_{Y|X}(X(\\omega),dy). \\] <p>Proof</p> <p>From Tonelli's Theorem's proof, the function \\(x\\mapsto h(x):=\\int_{\\mathbb{R}}g(x,y)K_{Y|X}(x,dy)\\) for \\(x\\) in \\(\\mathbb{R}\\), is measurable, and therefore </p> \\[   h(X)=\\int_{\\mathbb{R}}g(X,y)K_{Y|X}(X,dy) \\] <p>is a positive random variable. Let \\(A\\) be an event in \\(\\sigma(X)\\).  It follows that \\(A=X^{-1}(B)\\) for some Borel set \\(B \\in \\mathbb{R}\\). Therefore,</p> \\[ \\begin{align}     E\\left[ 1_{A}g(X,Y) \\right] &amp;= E\\left[ 1_{B}(X)g(X,Y) \\right] \\\\     &amp;=\\int_{\\mathbb{R}^2} 1_{B}(x)g(x,y)P_X\\otimes K_{Y|X}(dx,dy) \\\\     &amp;=\\int_{\\mathbb{R}}\\left( \\int_{\\mathbb{R}}1_B(x)g(x,y) K_{Y|X}(x,dy)\\right)P_X(dx) \\\\     &amp;=\\int_{\\mathbb{R}}1_{B}(x)\\left( \\int_{\\mathbb{R}}g(x,y) K_{Y|X}(x,dy)\\right)P_X(dx) \\\\     &amp;=\\int_{\\mathbb{R}}1_B(x)h(x)P_{X}(dx) \\\\     &amp;=E\\left[ 1_A h(X) \\right]. \\end{align} \\] <p>This concludes the proof.</p> <p>Remark</p> <p>As in the previous theorem, let \\(X\\) and \\(Y\\) be two random variables whose joint distribution is given by \\(P_{(X,Y)}\\). Suppose that \\(P_{(X,Y)}\\) is absolutely continuous with respect to the Lebesgue measure on \\(\\mathbb{R}^2\\). It follows that there exists a Lebesgue-almost surely unique positive function \\(f_{(X,Y)}\\colon \\mathbb{R}^2\\to \\mathbb{R}\\) with expectation \\(1\\) such that</p> \\[ E\\left[ g(X,Y) \\right]=\\int_{\\mathbb{R}^2} g(x,y)f_{(X,Y)}(x,y)dxdy. \\] <p>It follows that the density of \\(X\\) and \\(Y\\) are respectively given by</p> \\[ f_X(x)=\\int_{\\mathbb{R}} f_{(X,Y)}(x,y)dy\\quad \\text{and}\\quad f_{Y}(y)=\\int_{\\mathbb{R}} f_{(X,Y)}(x,y)dx. \\] <p>By defining</p> \\[ f_{Y|X}(x,y)=\\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}1_{\\{f_X(x)&gt;0\\}}+f_{Y}(y)1_{\\{f_X(x)=0\\}}, \\] <p>inspection shows that</p> \\[ K_{Y|X}(x,A):=\\int_{A} f_{Y|X}(x,y)dy \\] <p>defines a kernel. It holds</p> \\[ \\begin{align}     P_X\\otimes K_{Y|X}[A\\times B]&amp;=\\int_{\\mathbb{A}} \\left(\\int_{B} \\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}1_{\\{f_X(x)&gt;0\\}}+f_{Y}(y)1_{\\{f_X(x)=0\\}} dy\\right)f_{X}(x)dx\\\\     &amp;=\\int_{\\mathbb{A}} \\int_{B} f_{(X,Y)}(x,y) dydx=P_{(X,Y)}[A\\times B] \\end{align} \\] <p>for every \\(A\\) and \\(B\\) in \\(\\mathcal{B}(\\mathbb{R})\\). From the uniqueness assumption of Fubini-Tonelli's theorem, it follows that </p> \\[ P_{(X,Y)}=P_X\\otimes K_{Y|X}. \\] <p>And following the theorem, it follows that</p> \\[   E\\left[ g(X,Y) \\right]=\\int_{\\mathbb{R}^2} g(x,y)f_{(X,Y)}(x,y)dxdy=\\int_{\\mathbb{R}} \\left(\\int_{\\mathbb{R}} g(x,y)f_{Y|X}(x,y)dy\\right)f_{X}(x)dx. \\]"},{"location":"lecture/03-Integration/036-uniform-integrability/","title":"Uniform Integrability","text":"<p>In the integration section, we saw the dominated convergence theorem stating that for every sequence \\((X_n)\\) such that \\(X_n \\to X\\) in probability, if \\(|X_n| \\leq Y\\) for \\(Y\\) in \\(L^1\\), then \\(X_n \\to X\\) in \\(L^1\\). The reciprocal is however not true in the sence that under convergence in probability the convergence in \\(L^1\\) does not implies uniform boundedness by an element in \\(L^1\\).</p> <p>This fact is related to a deeper issue with \\(L^1\\) that is not encountered for any other \\(L^p\\) spaces for \\(1&lt;p&lt;\\infty\\). The following concept of uniform integrability is the correct way to describe those sets that are stable under \\(L^1\\) convergence.</p> <p>Note first that if \\(X\\) is in \\(L^1\\), then it holds that \\(E[|X|1_{X&gt;n}] \\to 0\\) as \\(n\\) goes to \\(\\infty\\). Uniform integrability brings this concept to whole families.</p> <p>Definition: Uniformly Integrable Families</p> <p>A subset \\(\\mathcal{H}\\) of \\(L^1\\) is called uniformly integrable if </p> \\[   \\sup_{X \\in \\mathcal{H}}E\\left[ \\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert\\geq n \\}}\\right]\\longrightarrow 0. \\] <p>We first state two additional equivalent way to state that a family is uniformly integrable. The second one\u2014Boundedness and Tightness\u2014is sometimes refered to as the \\(\\varepsilon\\)-\\(\\delta\\)-criteria. The third one is refered to as the De la Vallee-Poussin criteria.</p> <p>Proposition</p> <p>For a subsets \\(\\mathcal{H}\\) of \\(L^1\\), the following assertions are equivalent:</p> <ol> <li>Uniform Integrability: \\(\\mathcal{H}\\) is uniformly integrable.</li> <li> <p>Boundedness and Tightness:</p> <ul> <li> <p>\\(\\mathcal{H}\\) is bounded in \\(L^1\\), that is, </p> \\[ \\sup_{X \\in \\mathcal{H}}E[\\left\\vert X\\right\\vert]&lt;\\infty. \\] </li> <li> <p>For every \\(\\varepsilon&gt;0\\), there exists \\(\\delta&gt;0\\) such that</p> \\[ E\\left[ \\left\\vert X\\right\\vert1_A \\right]\\leq \\varepsilon \\] <p>for all \\(X\\) in \\(\\mathcal{H}\\) and event \\(A\\) such that \\(P[A]\\leq \\delta\\).</p> </li> </ul> </li> <li> <p>De la Vallee Poussin:     There exists a Borel measurable function \\(\\varphi\\colon \\mathbb{R}_+\\to \\mathbb{R}_+\\) such that \\(\\varphi(x)/x\\to \\infty\\) as \\(x \\to \\infty\\) for which</p> \\[ \\sup_{X \\in \\mathcal{H}}E\\left[ \\varphi(\\left\\vert X\\right\\vert) \\right]&lt;\\infty. \\] <p>This function \\(\\varphi\\) can be chosen increasing and convex.</p> </li> </ol> <p>Proof</p> <p>Step 1: Uniform integrability implies boundedness and tightness:</p> <p>For sufficiently large \\(n\\), we have \\(E[|X| 1_{\\{|X|\\geq n\\}}]\\leq 1\\) for all \\(X\\) in \\(\\mathcal{H}\\). Hence, \\(E[|X|]\\leq n+1\\) for all \\(X\\) in \\(\\mathcal{H}\\), showing that \\(\\mathcal{H}\\) is bounded in \\(L^1\\). Let further \\(\\varepsilon&gt;0\\) and choose \\(n\\) large enough such that \\(E[| X|1_{\\{|X|\\geq n\\}}]\\leq \\varepsilon/2\\) for every \\(X\\) in \\(\\mathcal{H}\\). Setting \\(\\delta=\\varepsilon/(2n)\\), for every event \\(A\\) in \\(\\mathcal{F}\\) such that \\(P[A]\\leq \\delta\\), it follows that</p> \\[ \\begin{equation}     E\\left[ \\left\\vert X\\right\\vert1_A \\right] =E\\left[ \\left\\vert X\\right\\vert1_A1_{\\{\\left\\vert X\\right\\vert\\geq n\\}} \\right]+E\\left[ \\left\\vert X\\right\\vert1_A1_{\\{\\left\\vert X\\right\\vert&lt; n\\}} \\right]      \\leq nP[A]+\\varepsilon/2\\leq \\varepsilon, \\end{equation} \\] <p>showing that uniform integrability implies boundedness and tightness.</p> <p>Step 2: Boundedness and tightness implies uniform integrability:</p> <p>Denote by \\(M=\\sup_{X\\in \\mathcal{H}} E[|X|]&lt;\\infty\\) and let \\(\\varepsilon &gt;0\\). There exists \\(\\delta&gt;0\\) such that \\(E[|X|1_A]\\leq \\varepsilon\\) for any event \\(A\\) in \\(\\mathcal{F}\\) with \\(P[A]\\leq \\delta\\) and every \\(X\\) in \\(\\mathcal{H}\\). Then for any \\(n\\) greater than \\(M/\\delta\\) and any \\(X\\) in \\(\\mathcal{H}\\), Markov's inequality yields</p> \\[   P\\left[ \\left\\vert X\\right\\vert\\geq n \\right]\\leq \\frac{E[\\left\\vert X\\right\\vert]}{n}\\leq \\frac{M}{n}\\leq \\delta. \\] <p>Hence, \\(\\sup_{X\\in \\mathcal{H}}E\\left[ \\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert\\geq n\\}} \\right]\\leq \\varepsilon\\) showing the uniform integrability of \\(\\mathcal{H}\\).</p> <p>Step 3: De la Vallee-Poussin criteria implies uniform integrability:</p> <p>Denote by \\(M=\\sup_{X \\in \\mathcal{H}}E[\\varphi(|X|)]\\). For \\(\\varepsilon&gt;0\\), there exists \\(n_\\varepsilon\\) such that \\(\\varphi(x)\\geq x M/\\varepsilon\\) for every \\(x\\geq n_\\varepsilon\\). Hence,</p> \\[ \\begin{align}     M &amp;\\geq \\sup_{X \\in \\mathcal{H}}E\\left[ \\varphi(|X|) \\right]      \\geq \\sup_{X \\in \\mathcal{H}}E\\left[ \\varphi(\\left\\vert X\\right\\vert)1_{\\{\\left\\vert X\\right\\vert\\geq n_\\varepsilon\\}} \\right]      \\geq \\frac{M}{\\varepsilon}\\sup_{X \\in \\mathcal{H}}E \\left[ \\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert\\geq n_\\varepsilon\\}} \\right] \\end{align} \\] <p>showing that</p> \\[ \\sup_n \\sup_{X \\in \\mathcal{H}}E\\left[ \\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert \\geq n\\}} \\right]\\leq \\sup_{X \\in \\mathcal{H}}E\\left[ \\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert \\geq n_\\varepsilon\\}} \\right]\\leq \\varepsilon \\] <p>and so the uniform integrability of \\(\\mathcal{H}\\).</p> <p>Step 4: Uniform integrability implies de la Valle-Poussin criteria: Choose a sequence \\((c_n)\\), which can always be chosen increasing, such that </p> \\[   \\sup_{X \\in \\mathcal{H}}E[\\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert\\geq c_n\\}}]\\leq 1/n^3. \\] <p>Define the function \\(\\varphi:\\mathbb{R}_+\\) as a piecewise linear function, equal to \\(0\\) on \\([0,c_1]\\) and with derivative equal to \\(n\\) on \\([c_{n},c_{n+1}]\\), which implies that \\(\\varphi(x)/x \\to \\infty\\) as \\(x\\to \\infty\\). Note that this function is convex and increasing. It follows that</p> \\[ \\begin{equation}     E[\\varphi(\\left\\vert X\\right\\vert)] =\\sum E\\left[\\varphi(\\left\\vert X\\right\\vert)1_{\\{c_n\\leq \\left\\vert X\\right\\vert\\leq c_{n+1}\\}}\\right]      =\\sum n\\left( E\\left[\\left\\vert X\\right\\vert\\wedge c_{n+1}\\right]-E\\left[\\left\\vert X\\right\\vert\\wedge c_n\\right] \\right). \\end{equation} \\] <p>However</p> \\[ \\begin{align}     E\\left[\\left\\vert X\\right\\vert\\wedge c_{n+1}\\right]-E\\left[\\left\\vert X\\right\\vert\\wedge c_n\\right]     &amp; =E\\left[\\left\\vert X\\right\\vert1_{\\{c_{n}\\leq \\left\\vert X\\right\\vert&lt; c_{n+1}\\}}\\right]+E\\left[c_{n+1}1_{\\{\\left\\vert X\\right\\vert\\geq c_{n+1}\\}}\\right] -E\\left[c_n1_{\\{\\left\\vert X\\right\\vert\\geq c_n\\}}\\right]\\\\     &amp; \\leq E\\left[\\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert\\geq c_n\\}}\\right]+E\\left[\\left\\vert X\\right\\vert1_{\\{\\left\\vert X\\right\\vert\\geq c_{n+1}\\}}\\right]\\\\     &amp; \\leq 2/n^3  \\end{align} \\] <p>showing that \\(\\sup_{X \\in \\mathcal{H}}E[\\varphi(|X|)]\\leq \\sum 2n/n^3&lt;\\infty\\).</p> <p>Theorem</p> <p>Let \\((X_n)\\) be a sequence of integrable random variables such that \\(X_n\\to X\\) in probability.(1)</p> <ol> <li>That is, \\(P[\\left\\vert X_n-X\\right\\vert\\geq \\varepsilon]\\to 0\\) for every \\(\\varepsilon\\).</li> </ol> <p>Then, the following assertions are equivalent:</p> <ol> <li>The sequence is uniformly integrable;</li> <li>\\(X_n\\to X\\) in \\(L^1\\);</li> <li>\\(\\|X_n\\|_1\\to \\|X\\|_1\\).</li> </ol> <p>Proof</p> <p>Step1: Uniform integrability implies \\(L^1\\) convergence: We know that we can find a subsequence \\((Y_n)\\) of \\((X_n)\\) that converges \\(P\\)-almost surely to \\(X\\). In particular, \\((Y_n)\\) is uniformly integrable. Using Fatou's lemma and the \\(L^1\\) boundedness of the family \\((X_n)\\), it follows that </p> \\[   E[\\left\\vert X\\right\\vert]\\leq \\liminf E[\\left\\vert Y_n\\right\\vert]\\leq \\sup_n E[\\left\\vert Y_n\\right\\vert]&lt;\\infty, \\] <p>showing that \\(X \\in L^1\\). It follows that the sequence \\((X_n-X)\\) is uniformly integrable, and therefore, without loss of generality, we can assume that \\((X_n)\\) is a uniformly integrable family converging in probability to \\(0\\). For \\(\\varepsilon&gt;0\\), it holds</p> \\[   E\\left[\\left\\vert X_n\\right\\vert\\right]=E\\left[\\left\\vert X_n\\right\\vert1_{\\{\\left\\vert X_n\\right\\vert\\leq \\varepsilon/2\\}}\\right]+E\\left[\\left\\vert X_n\\right\\vert1_{\\{\\left\\vert X_n\\right\\vert&gt; \\varepsilon/2\\}}\\right]\\leq \\varepsilon/2+E\\left[\\left\\vert X_n\\right\\vert1_{\\{\\left\\vert X_n\\right\\vert&gt; \\varepsilon/2\\}}\\right]. \\] <p>By uniform integrability of the family \\((X_n)\\) and making use of the \\(\\varepsilon\\)-\\(\\delta\\) criteria, let \\(\\delta&gt;0\\) such that </p> \\[   \\sup_n E[\\left\\vert X_n\\right\\vert1_A]\\leq \\varepsilon/2 \\] <p>for every \\(A\\in \\mathcal{F}\\) with \\(P[A]\\leq \\delta\\). Further, by the convergence of \\((X_n)\\) in probability to \\(0\\), there exists \\(n_0\\) such that </p> \\[   P[\\left\\vert X_n\\right\\vert&gt; \\varepsilon/2]\\leq \\delta \\] <p>for every \\(n\\geq n_0\\). Thus, for every \\(n\\geq n_0\\), it holds </p> \\[ E[\\left\\vert X_n\\right\\vert]\\leq \\varepsilon/2+\\sup_{k\\geq n_0} E[\\left\\vert X_n\\right\\vert1_{\\{ \\left\\vert X_n\\right\\vert&gt;\\varepsilon/2\\}}]\\leq \\varepsilon, \\] <p>showing that \\(X_n\\) converges to \\(0\\) in \\(L^1\\).</p> <p>Step 2: Convergence in \\(L^1\\) implies the convergence of the norms: This step is trivial from </p> \\[   \\left\\vert\\left\\vert x\\right\\vert-\\left\\vert y\\right\\vert\\right\\vert\\leq \\left\\vert x-y\\right\\vert. \\] <p>Step 3: Convergence of the norms implies uniform integrability: For \\(M&gt;0\\), define \\(\\varphi_M\\) as the identity on \\([0,M-1]\\), \\(0\\) on \\([M,\\infty)\\), and linearly interpolated elsewhere. Let \\(\\varepsilon&gt;0\\). Using the dominated convergence theorem, choose \\(M\\) such that </p> \\[   E[\\left\\vert X\\right\\vert]-E[\\varphi_M(\\left\\vert X\\right\\vert)]\\leq \\varepsilon/2, \\] <p>since \\(\\varphi_M(\\left\\vert X\\right\\vert)\\) converges to \\(|X|\\) and is dominated by \\(\\left\\vert X\\right\\vert \\in L^1\\). By continuity of \\(\\varphi_M\\), it follows that </p> <p>[   \\varphi_M(\\left\\vert X_n\\right\\vert)\\to \\varphi_M(\\left\\vert X\\right\\vert) ] in probability. Since \\(\\varphi_M(\\left\\vert X_n\\right\\vert)\\leq M\\) for every \\(n\\), the dominated convergence theorem yields </p> \\[   E[\\varphi_M(\\left\\vert X_n\\right\\vert)]\\to E[\\varphi_M(\\left\\vert X\\right\\vert)]. \\] <p>Hence, together with \\(E[\\left\\vert X_n\\right\\vert]\\to E[\\left\\vert X\\right\\vert]\\), there exists some integer \\(n_0\\) such that</p> \\[   E[\\left\\vert X_n\\right\\vert]-E[\\left\\vert X\\right\\vert]\\leq \\varepsilon/4\\quad \\text{and}\\quad E[\\varphi_M(\\left\\vert X\\right\\vert)]-E[\\varphi_M(\\left\\vert X_n\\right\\vert)]\\leq \\varepsilon/4 \\] <p>for every \\(n\\geq n_0\\). Henceforth,</p> \\[ E\\left[\\left\\vert X_n\\right\\vert1_{\\{\\left\\vert X_n\\right\\vert\\geq M\\}}\\right]\\leq E[\\left\\vert X_n\\right\\vert]-E[\\varphi_M(\\left\\vert X_n\\right\\vert)]\\leq \\varepsilon/2+E[\\left\\vert X\\right\\vert]-E[\\varphi_M(\\left\\vert X\\right\\vert)]\\leq \\varepsilon \\] <p>for every \\(n\\geq n_0\\). Increasing the value of \\(M\\) ensures this inequality remains true for the remaining \\(n\\geq n_0\\), concluding the uniform integrability of \\((X_n)\\).</p> <p>Theorem</p> <ul> <li> <p>Let \\(X\\) be an integrable random variable and \\((\\mathcal{F}_i)\\) an arbitrary family of \\(\\sigma\\)-algebras \\(\\mathcal{F}_i\\subseteq \\mathcal{F}\\).     Then, \\((E[X|\\mathcal{F}_i])\\) is uniformly integrable.</p> </li> <li> <p>Let \\((X_i)\\) be a family of random variables bounded in \\(L^p\\) for \\(1&lt;p\\leq \\infty\\).     Then, \\((X_i)\\) is uniformly integrable.</p> </li> </ul> <p>Proof</p> <p>Since \\(X\\) is integrable, it is in particular uniformly integrable. Therefore, there exists a convex function \\(\\varphi\\) with \\(\\varphi(x)/x\\to \\infty\\) such that \\(E[\\varphi(|X|)]&lt;\\infty\\). By the conditional version of Jensen's inequality and the tower property, it follows that</p> \\[ E\\left[ \\varphi\\left( \\left| E[X|\\mathcal{F}_i] \\right| \\right) \\right]\\leq E\\left[ \\varphi\\left( E\\left[ |X||\\mathcal{F}_i \\right] \\right) \\right]\\leq E\\left[ E\\left[ \\varphi(|X|)|\\mathcal{F}_i \\right] \\right]=E\\left[ \\varphi\\left( |X| \\right) \\right], \\] <p>showing by de la Vall\u00e9e Poussin's criterion that \\((E[X|\\mathcal{F}_i])\\) is uniformly integrable.</p> <p>If \\((X_i)\\) is bounded in \\(L^p\\), then \\(\\sup E[|X_i|^p]&lt;\\infty\\) which, for \\(\\varphi(x)=x^p\\) satisfying \\(\\varphi(x)/x\\to \\infty\\), satisfies de la Vall\u00e9e Poussin's criterion. Hence, \\((X_i)\\) is uniformly integrable.</p> <p>We finish this section with an extension of Fatou's lemma for conditional expectation. While in the classical case the sequence must be bounded from below by an integrable random variable, in the conditional case, the negative part of the sequence of conditional expectation must be uniformly integrable.</p> <p>Conditional Fatou's Lemma for Uniformly Integrable Lower Bound</p> <p>Let \\((X_n)\\) be a sequence of random variables and \\(\\mathcal{G}\\subseteq \\mathcal{F}\\) be a sub-\\(\\sigma\\)-algebra. Suppose that \\((X_n^-)\\) is uniformly integrable conditionally with respect to \\(\\mathcal{G}\\), in the sense that for every \\(\\varepsilon&gt;0\\), there exists \\(M&gt;0\\) such that</p> \\[ E\\left[ X_n^- 1_{\\{X_n^-&gt;M\\}} \\big | \\mathcal{G}\\right]\\leq \\varepsilon \\quad \\text{ for all }n. \\] <p>Then it holds</p> \\[ E\\left[ \\liminf X_n |\\mathcal{G} \\right]\\leq \\liminf E\\left[ X_n |\\mathcal{G} \\right]. \\] <p>Remark</p> <p>Note that this is an extension of Fatou's Lemma for a uniformly integrable negative part of the sequence by taking \\(\\mathcal{G}\\) as the trivial \\(\\sigma\\)-algebra.</p> <p>Furthermore, note that the conditional expectation can be defined for every positive random variable by conditional monotone convergence. It can also be defined for any random variable bounded from below by some positive random variable.</p> <p>In this case, \\((X_n^-)\\) is in particular uniformly integrable. It follows that \\(\\liminf X_n^-\\) is integrable so that the inequality is well defined.</p> <p>Proof</p> <p>Let \\(X = \\liminf X_n\\) and \\(\\varepsilon &gt;0\\). By uniform conditional integrability of \\((X_n^-)\\), let \\(M&gt;0\\) such that</p> \\[ E\\left[ X_n^- 1_{\\{X_n^-&gt;M\\}} \\big |\\mathcal{G}\\right]\\leq \\varepsilon \\quad \\text{ for all }n. \\] <p>Using Fatou's Lemma for conditional expectation for positive random variables, and the fact that \\(X + M \\leq \\liminf (X_n+M)^+\\), it follows that</p> \\[ E\\left[ X+M\\big |\\mathcal{G} \\right]\\leq E\\left[ \\liminf (X_n+M)^+ \\big |\\mathcal{G}\\right]\\leq \\liminf E\\left[ (X_n+M)^+\\big |\\mathcal{G} \\right]. \\] <p>Since \\((X_n+M)^+=(X_n+M)+(X_n+M)^-\\leq X_n+M+X_n^-1_{\\{X_n^-&gt;M\\}}\\), it follows that</p> \\[ E\\left[ X \\big|\\mathcal{G} \\right]\\leq \\liminf E\\left[ X_n\\big |\\mathcal{G} \\right]+\\varepsilon. \\] <p>This completes the proof.</p>"},{"location":"lecture/04-Martingales/040-introduction/","title":"Discrete Time Processes, Martingales","text":"<p>We are now interested in \"time\" dependent random outcomes. In this chapter we consider discrete time, that is an ordered countable index. This could be anything from a finite set \\(\\{0, 1, \\ldots, T\\}\\) or at the other extreme \\(\\mathbb{Q}\\). We will however generically consider \\(\\mathbb{N}_0\\) as the standard index for time and denote different times by \\(s\\) or \\(t\\). The results in this chapter all holds for any countable ordered set. In the case where a specific different index shall be considered we will precise it.</p> <p>Throughout we fix a probability space \\((\\Omega, \\mathcal{F}, P)\\).</p> <ul> <li>Discrete Time Processes (filtration, adapted processes, stopping times.)</li> <li>Martingales (martingale, stochastic integral, doob's optional sampling theorem)</li> <li>Martingales: Almost Sure Convergence (Doob's upcrossing lemma, martingale convergence, Borel-Cantelli)</li> <li>Martingales: \\(L^p\\)-convergence (\\(L^p\\)-convergence, law of large numbers)</li> </ul>"},{"location":"lecture/04-Martingales/041-discrete-time-processes/","title":"Discrete Time Stochastic Processes","text":""},{"location":"lecture/04-Martingales/041-discrete-time-processes/#stochastic-process-filtration-adaptiveness","title":"Stochastic Process, Filtration, Adaptiveness","text":"<p>Definition</p> <p>A *stochastic process is a family \\(X=(X_t)\\) of random variables \\(X_t:\\Omega \\to \\mathbb{R}\\) indexed by \\(t\\) in \\(\\mathbb{N}_0\\).</p> <p>For a given state \\(\\omega\\), the mapping \\(t \\mapsto X_t(\\omega)\\) describing the evolution in state \\(\\omega\\) of the process is called a sample path or trajectory.</p> <p>A stochastic process \\(X=(X_t)_{t=0,\\ldots, T}\\) may also be viewed as:</p> <ul> <li> <p>A single random variable</p> \\[ \\begin{aligned}   X\\colon\\Omega \\times \\mathbb{N}_0 &amp;\\longrightarrow \\mathbb{R}\\\\   (\\omega,t)&amp;\\longmapsto X(t, \\omega)  X_t(\\omega) \\end{aligned} \\] <p>where the \\(\\sigma\\)-algebra on \\(\\Omega \\times \\{0,1, \\ldots \\}\\) is given by the product \\(\\sigma\\)-algebra \\(\\mathcal{F}\\otimes 2^{N_0}\\).</p> </li> <li> <p>A measurable function with values in the sample space</p> \\[ \\begin{aligned}     X\\colon\\Omega &amp;\\longrightarrow \\mathbb{R}^{\\mathbb{N}_0}\\\\     \\omega &amp;\\longmapsto X(\\omega) = (X_0(\\omega), X_1(\\omega), \\ldots) \\end{aligned} \\] </li> </ul> <p>where the \\(\\sigma\\)-algebra on the sample space is the product Borel \\(\\sigma\\)-algebra on \\(\\mathbb{R}^{\\mathbb{N}_0}\\).</p> <p>Exercice</p> <p>Show that the three definitions of a stochastic process in finite discrete time are equivalent.</p> <p>Example: Random Walk</p> <p>Consider now our example of coin tossing but infinitely many times. To do so consider a sequence \\((Y_t)_{t=1, 2, \\ldots}\\) of iid random variables with</p> \\[   P[Y_t = 1] = P[Y_1 = 1] = p\\quad \\text{and}\\quad P[Y_t = -1] = P[Y_1 = -1] = 1-p \\] <p>for \\(0\\leq p\\leq 1\\), in other terms the sequence are iid binary random variables.</p> <p>We define the random walk \\(S=(S_t)\\)</p> \\[ S_0=s_0 \\quad \\text{ and }\\quad S_t= S_{t-1} + Y_t = s_0+\\sum_{s=1}^t Y_s, \\quad t =1, \\ldots \\] <p>where \\(s_0\\) in \\(\\mathbb{R}\\) is the start value of the random walk.</p> <p> </p> <p>As such, a process is nothing else than an arbitrary family of random variables indexed by time. However, our intuitive understanding of a process rather corresponds to observing the outcome of which as times goes by. In other terms \\(X_s\\) \"is providing less information\" than \\(X_t\\) whenever \\(s\\leq t\\). To model this intuition, we use an increasing set of information.</p> <p>Definition: Filtration, Adapted Processes</p> <p>A filtration \\(\\mathbb{F}=(\\mathcal{F}_t)\\) is a family of \\(\\sigma\\)-algebras on \\(\\Omega\\)</p> \\[   \\mathcal{F}_0 \\subseteq \\mathcal{F}_1 \\subseteq \\ldots \\subseteq \\mathcal{F}_t \\subseteq \\ldots \\subseteq \\mathcal{F} \\] <p>A measurable space together with a filtration is called a filtered space and denoted by the tuple \\((\\Omega, \\mathcal{F}, \\mathbb{F},P)\\).</p> <p>We call a stochastic process \\(X\\) adapted if \\(X_t\\) is \\(\\mathcal{F}_t\\)-measurable for every \\(t\\).</p> <p>The \\(\\sigma\\)-algebras in a filtration become finer and finer due to the inclusion. It means that the considered events at time \\(t\\) provide more information than those at previous times.</p> <p>Filtrations can be given, but also generated by stochastic processes. Indeed, given a stochastic process \\(X\\), we can define the filtration generated by the information revealed by \\(X\\) over time, that is</p> \\[ \\mathcal{F}_t^X=\\sigma(X_0, X_1, \\ldots, X_t) \\] <p>for every time \\(t\\). It is clearly a filtration called filtration generated by \\(X\\) and denoted by \\(\\mathbb{F}^X\\). Note that \\(X\\) by definition \\(X\\) is adapted to \\(\\mathbb{F}^X\\). It is in fact the smallest filtration to which \\(X\\) is adapted to. That is, if \\(X\\) is adapted to any other filtration \\(\\mathbb{F}\\) then it holds that \\(\\mathbb{F}^X \\subseteq \\mathbb{F}\\).</p> <p>Example</p> <p>In our random walk example, we did not specify a filtration, but we can consider the following sequences of \\(\\sigma\\)-algebras</p> <ul> <li>\\(\\mathcal{F}^X_t\\);</li> <li>\\(\\mathcal{F}^S_t\\);</li> <li>\\(\\mathcal{G}_t:=\\sigma(S_t)\\);</li> <li>\\(\\mathcal{H}_t:=\\sigma(X_t)\\).</li> </ul> <p>As an exercise, try to figure out which sequence of \\(\\sigma\\)-algebras is a filtration.</p>"},{"location":"lecture/04-Martingales/041-discrete-time-processes/#stopping-time","title":"Stopping Time","text":"<p>A further important notion in the theory of stochastic processes is the so-called stopping time. Before diving into the definition and properties, let us consider the following game.</p> <p>Example: Strategic Betting?</p> <p>You have \\(100\\) renminbi and you are offered a choice between the following games:</p> <ul> <li> <p>Game 1: toss a coin 100 times and every time you get \\(1\\) you increase by 1 renminbi while if you get \\(-1\\) you loose \\(1\\) renminbi. (all in strategy)</p> </li> <li> <p>Game 2: toss a coin 100 times and every time you get \\(1\\) you increase by 1 renminbi while if you get \\(-1\\) you loose \\(1\\) renminbi.     However, as soon as your total amount of money drops to \\(70\\) renminbi you are allowed to quit playing. (stop loss strategy)</p> </li> <li> <p>Game 3: toss a coin 100 times and every time you get \\(1\\) you increase by 1 renminbi while if you get \\(-1\\) you loose \\(1\\) renminbi.     However, as soon as your total amount of money reaches a value of \\(120\\) renminbi you are allowed to stop playing. (stop gain strategy)</p> </li> <li> <p>Game 4: toss a coin 100 times and every time you get \\(1\\) you increase by 1 renminbi while if you get \\(-1\\) you loose \\(1\\) renminbi.     However, as soon as your total amount of money reaches a value of \\(120\\) or drop to \\(70\\) renminbi you are allowed to stop playing. (stop loss-gain strategy)</p> </li> <li> <p>Game 5: don't play and keep your 100 renminbi. (coward strategy)</p> </li> </ul> <p>The coin is fair, now which game would you choose? After your decision, suppose that I scale the game by \\(10000\\) (start value and $100% rmb per coin toss), would you choose the same game? Why?</p> <p>The random walk \\(S= (S_t)\\) starting at \\(100\\) is clearly well suited to model it. In the case of the first game your outcome is given by \\(S_{100}(\\omega)\\) where \\(\\omega = (\\omega_t)_{t=1,\\ldots, 100}\\) represents the outcomes of the coin toss \\(\\pm 1\\). In the case of the last game the outcome is \\(S_0 = 100\\). We are stilll facing the following questions</p> <ul> <li>What about the other games? The time at which you quit the game is random depending on the evolution of the stochastic process.</li> <li>Which game delivers in expectation the largest outcome?</li> </ul> <p>We therefore introduce the notion of a random time which intuitively provides information about when a random event occurs.</p> <p>Definition: Stopping Time</p> <p>A random time is a measurable mapping \\(\\tau :\\Omega \\to \\mathbb{N}_0 \\cup \\{\\infty\\}\\).</p> <p>A random time is a stopping time if \\(\\{\\tau \\leq t\\}\\) is an event in \\(\\mathcal{F}_t\\) for every \\(t=0, 1, \\ldots\\).</p> <p>Remark</p> <p>Since we are working in discrete time, for a random time \\(\\tau\\) to be a stopping time, it is equivalent to require \\(\\{\\tau = t\\}\\) being an event in \\(\\mathcal{F}_t\\) for all \\(t\\). Indeed, it follows from \\(\\mathbb{F}\\) being a filtration and</p> \\[   \\{\\tau \\leq t\\} = \\cup_{s=0}^t \\{\\tau = s\\} \\quad \\text{and}\\quad \\{\\tau = t\\} = \\{\\tau \\leq t\\} \\cap \\{\\tau \\leq t-1\\}^c \\] <p>The notion of stopping time just precises that the event to stop before a given time only depends on the information up to time \\(t\\). Stopping times are truly complex object conceptually as they are inherently depending on the whole past history. However, it is relatively easy to construct stopping times: Let \\(X=(X_t)\\) be a stochastic process and \\(B \\subseteq \\mathbb{R}\\). We define the function</p> \\[ \\tau_B(\\omega) = \\inf\\{t \\colon X_t(\\omega) \\in B\\} \\] <p>This function is called a hitting time or entry time and is well defined. However, it requires further assumption so as to be a random time let alone a stopping time.</p> <p>Proposition</p> <p>If \\(B\\) is a Borel set, then \\(\\tau_B\\) is a random time. If additionally \\(X\\) is adapted then \\(\\tau_B\\) is a stopping time.</p> <p>Proof</p> <p>For any \\(t\\) it holds that \\(\\{\\tau \\leq t\\} = \\cup_{s=0}^t\\{X_s \\in B\\}\\) showing that if \\(B\\) is borel, the right hand side is a finite union of events. If additionally \\(X\\) is adapted, each event in the finite union belongs to some \\(\\mathcal{F}_s \\subseteq \\mathcal{F}_t\\) for \\(s\\leq t\\).</p> <p>Let us collect some standard properties of stopping times.</p> <p>Proposition</p> <p>The following assertions hold:</p> <ol> <li>Every deterministic time \\(\\tau \\equiv t\\) is a stopping time;</li> <li> <p>\\(\\tau+\\sigma\\), \\(\\tau \\vee \\sigma\\) and \\(\\tau\\wedge \\sigma\\) are stopping times as soon as \\(\\tau,\\sigma\\) are stopping times;</p> </li> <li> <p>\\(\\lim \\tau^n\\) is a stopping time as soon as \\((\\tau^n)\\) is an increasing sequence of stopping times.</p> </li> <li> <p>If \\(\\tau\\) is a stopping time, then the collection \\(\\mathcal{F}_\\tau=\\{A \\in \\mathcal{F}: A\\cap \\{\\tau\\leq t\\}\\in \\mathcal{F}_t\\}\\) is a \\(\\sigma\\)-algebra and \\(\\tau\\) is \\(\\mathcal{F}_{\\tau}\\)-measurable.</p> </li> <li> <p>For any two stopping times, it holds \\(\\mathcal{F}_{\\sigma}\\cap \\{\\sigma\\leq \\tau\\}\\subseteq \\mathcal{F}_{\\sigma \\wedge \\tau}=\\mathcal{F}_{\\sigma}\\cap \\mathcal{F}_{\\tau}\\).     For every integrable random variable \\(X\\) with respect to some probability on \\(\\mathcal{F}\\), it holds</p> \\[ E[E[X\\,|\\,\\mathcal{F}_{\\sigma}]\\,|\\, \\mathcal{F}_{\\tau}]=E[X\\,|\\, \\mathcal{F}_{\\sigma \\wedge \\tau}] \\] </li> </ol> <p>Proof</p> <ol> <li> <p>Define \\(\\tau \\equiv t_0\\) for some given time.     From \\(\\{\\tau \\leq t\\} = \\emptyset\\) if \\(t&lt;t_0\\) or \\(\\Omega\\) otherwize, it follows that \\(\\tau\\) is a stopping time.</p> </li> <li> <p>Follows from</p> \\[   \\begin{align}     \\left\\{\\tau+\\sigma \\leq t\\right\\} &amp;= \\cup_{q=0}^t\\left\\{\\sigma\\leq t-q\\right\\}\\cap \\left\\{\\tau \\leq q\\right\\}\\\\     \\left\\{\\tau\\vee \\sigma \\leq t\\right\\} &amp;= \\left\\{\\tau \\leq t\\right\\}\\cap \\left\\{\\sigma \\leq t\\right\\}\\\\     \\left\\{\\tau\\wedge \\sigma \\leq t\\right\\} &amp;= \\left\\{\\tau \\leq t\\right\\}\\cup \\left\\{\\sigma \\leq t\\right\\}.   \\end{align} \\] <p>all right-hand sides being finite union of events contained in \\(\\mathcal{F}_t\\).</p> </li> <li> <p>Follows from</p> \\[ \\left\\{\\lim \\tau^n\\leq t\\right\\}=\\left\\{\\tau^n\\leq t:\\text{ for all }n\\right\\}=\\cap\\left\\{\\tau^n \\leq t\\right\\} \\] </li> <li> <p>Clearly, \\(\\emptyset\\) and \\(\\Omega\\) belong to \\(\\mathcal{F}_\\tau\\).     For \\(A \\in \\mathcal{F}_\\tau\\) it holds</p> \\[   A^c \\cap \\left\\{\\tau\\leq t\\right\\}=(A \\cup \\left\\{\\tau &gt;t\\right\\})^c=[(A\\cap \\left\\{\\tau \\leq t\\right\\})\\cup \\left\\{\\tau\\leq t\\right\\}^c]^c \\in \\mathcal{F}_t. \\] <p>Finally, for \\((A_n)\\subseteq \\mathcal{F}_{\\tau}\\) it holds</p> \\[   (\\cup A_n)\\cap \\left\\{\\tau \\leq t\\right\\}=\\cup (A_n \\cap \\{\\tau \\leq t\\}) \\in \\mathcal{F}_t. \\] </li> <li> <p>Let \\(A \\in \\mathcal{F}_{\\sigma}\\).     For every \\(t\\), it holds</p> \\[   A\\cap \\left\\{ \\sigma \\leq \\tau \\right\\}\\cap \\left\\{ \\tau \\leq t \\right\\} =\\left( A\\cap \\left\\{\\sigma \\leq t \\right\\} \\right)\\cap \\left\\{ \\tau \\leq t \\right\\}\\cap \\left\\{ \\sigma \\wedge t\\leq \\tau \\wedge t \\right\\}, \\] \\[   A\\cap \\left\\{ \\sigma \\leq \\tau \\right\\}\\cap \\left\\{ \\sigma \\leq t \\right\\} =\\left( A\\cap \\left\\{\\sigma \\leq t \\right\\} \\right)\\cap \\left\\{ \\sigma \\wedge t\\leq \\tau \\wedge t \\right\\}. \\] <p>Both of these are in \\(\\mathcal{F}_t\\) since \\(\\sigma \\wedge t\\) and \\(\\tau\\wedge t\\) are \\(\\mathcal{F}_t\\)-measurable. Hence, \\(\\mathcal{F}_{\\sigma}\\cap \\{\\sigma\\leq \\tau\\}\\subseteq \\mathcal{F}_{\\sigma}\\cap \\mathcal{F}_\\tau\\).</p> <p>We now show that \\(\\mathcal{F}_{\\sigma}\\cap \\mathcal{F}_{\\tau}=\\mathcal{F}_{\\sigma \\wedge \\tau}\\). Let \\(A \\in \\mathcal{F}_\\sigma\\cap \\mathcal{F}_{\\tau}\\). It follows that \\(A\\cap \\{\\sigma\\leq t\\} \\in \\mathcal{F}_t\\) and \\(A\\cap \\{\\tau \\leq t\\} \\in \\mathcal{F}_t\\) for every \\(t\\). Hence,</p> \\[   (A\\cap \\{\\sigma \\leq t\\})\\cup(A\\cap \\{\\tau \\leq t\\})=A\\cap(\\{\\sigma \\leq t\\}\\cup\\{\\tau\\leq t\\})=A\\cap \\{\\sigma\\wedge \\tau \\leq t\\} \\] <p>showing that \\(A \\in \\mathcal{F}_{\\sigma\\wedge \\tau}\\) and therefore \\(\\mathcal{F}_{\\sigma}\\cap \\mathcal{F}_{\\tau}\\subseteq \\mathcal{F}_{\\sigma\\wedge \\tau}\\).</p> <p>Conversely, let \\(A \\in \\mathcal{F}_{\\sigma\\wedge \\tau}\\). It follows that</p> \\[   A\\cap (\\{\\sigma\\leq t\\}\\cup \\{\\tau \\leq t\\})= (A\\cap \\{\\sigma \\leq t\\})\\cup(A\\cap \\{\\tau \\leq t\\})\\in \\mathcal{F}_t \\] <p>for every \\(t\\). Since \\(\\{\\sigma \\leq t\\}\\) is in \\(\\mathcal{F}_t\\), it follows that</p> \\[   (A\\cap \\{\\sigma \\leq t\\})\\cup(A\\cap \\{\\tau \\leq t\\})\\cap \\{\\sigma \\leq t\\}=A\\cap \\{\\sigma \\leq t\\} \\] <p>is also in \\(\\mathcal{F}_t\\) for every \\(t\\). Hence, \\(A\\) is in \\(\\mathcal{F}_\\sigma\\). Similarly, \\(A\\) is in \\(\\mathcal{F}_\\tau\\), and therefore \\(A\\) is in \\(\\mathcal{F}_{\\sigma}\\cap \\mathcal{F}_{\\tau}\\), showing that \\(\\mathcal{F}_{\\sigma\\wedge \\tau}=\\mathcal{F}_{\\sigma}\\cap \\mathcal{F}_{\\tau}\\). Note that \\(\\{\\sigma \\leq \\tau\\}\\) and \\(\\{\\tau \\leq \\sigma\\}\\) are both in \\(\\mathcal{F}_{\\sigma\\wedge \\tau}\\). Hence, for \\(X\\) integrable, it follows that</p> \\[   E[E[X|\\mathcal{F}_{\\sigma}]|\\mathcal{F}_\\tau]=E[E[X|\\mathcal{F}_\\sigma]1_{\\{\\sigma \\leq \\tau\\}}|\\mathcal{F}_{\\tau}]+E[E[X|\\mathcal{F}_\\sigma]|\\mathcal{F}_{\\tau}]1_{\\{\\tau&lt;\\sigma\\}}. \\] <p>From \\(\\mathcal{F}_{\\sigma}\\cap \\{\\sigma \\leq \\tau\\}\\subseteq \\mathcal{F}_{\\sigma \\wedge \\tau}\\), it follows that \\(E[X|\\mathcal{F}_\\sigma]1_{\\{\\sigma \\leq \\tau\\}}\\) is \\(\\mathcal{F}_{\\sigma \\wedge \\tau}\\)-measurable, and so is \\(E[E[X|\\mathcal{F}_\\sigma]1_{\\{\\sigma \\leq \\tau\\}}|\\mathcal{F}_{\\tau}]\\). A similar argument applies to \\(E[E[X|\\mathcal{F}_\\sigma]|\\mathcal{F}_{\\tau}]1_{\\{\\tau &lt;\\sigma\\}}\\), proving the assertion.</p> </li> </ol> <p>Proposition/Definition: Stopped Process</p> <p>Let \\(X\\) be an adapted process and \\(\\tau\\) a stopping time.</p> <ul> <li> <p>If \\(\\tau\\) is finite, that is \\(\\tau&lt;\\infty\\), then \\(X_\\tau(\\omega):=X_{\\tau(\\omega)}(\\omega)\\) is an \\(\\mathcal{F}_{\\tau}\\)-measurable random variable.</p> </li> <li> <p>The process \\(X^\\tau:=(X_{t\\wedge \\tau})\\) is an adapted process called the stopped process.</p> </li> </ul> <p>Proof</p> <p>Let \\(B\\) be a Borel subset of \\(\\mathbb{R}\\) and \\(\\tau\\) be a finite stopping time. It holds</p> \\[   \\left\\{ X_{\\tau}\\in B \\right\\}=\\cup_t (\\left\\{ X_t\\in B \\right\\}\\cap \\{\\tau=t\\}) \\] <p>the right hand side being a countable union of events in \\(\\mathcal{F}\\) showing that \\(X_{\\tau}\\) is a random variable. Let us show that this random variable is \\(\\mathcal{F}_\\tau\\)-measurable. Let \\(A=\\{ X_{\\tau}\\in B\\}\\) and fix \\(t\\). It holds</p> \\[   A\\cap \\{\\tau \\leq t\\}=\\cup_{s\\leq t}\\left(\\left\\{ X_s\\in B \\right\\}\\cap \\{\\tau=s\\}\\right). \\] <p>However, \\(\\{X_s\\in B\\}\\cap \\{\\tau=s\\}=\\{X_s\\in B\\}\\cap \\{\\tau\\leq s\\}\\cap \\{\\tau\\leq s-1\\}^c\\) is an event in \\(\\mathcal{F}_s\\subseteq \\mathcal{F}_t\\) for every \\(s\\leq t\\). Hence, \\(A\\cap \\{\\tau \\leq t\\}\\) is in \\(\\mathcal{F}_t\\) for every \\(t\\), showing that \\(A\\) is an event in \\(\\mathcal{F}_{\\tau}\\) by definition. Thus, \\(X_{\\tau}\\) is \\(\\mathcal{F}_{\\tau}\\)-measurable.</p> <p>Let now \\(\\tau\\) be any stopping time. It follows that \\(t\\wedge \\tau\\) is a finite stopping time smaller than \\(t\\), and therefore \\(\\mathcal{F}_{t\\wedge \\tau}\\subseteq \\mathcal{F}_t\\). Since \\(X^\\tau_t=X_{t\\wedge \\tau}\\) is \\(\\mathcal{F}_{t\\wedge \\tau}\\)-measurable, it is in particular \\(\\mathcal{F}_t\\)-measurable so that \\(X^\\tau\\) is an adapted process too.</p>"},{"location":"lecture/04-Martingales/041-discrete-time-processes/#stochastic-integral","title":"Stochastic Integral","text":"<p>Let us now define one of the most important objects in stochastic analysis, namely, the stochastic integral.</p> <p>Definition: Stochastic Integral</p> <p>Let \\(X = (X_t)\\) and \\(H=(H_t)\\) be two stochastic process whereby </p> <ul> <li>\\(X\\) is adapted;</li> <li>\\(H\\) is predictable, that is \\(H_0\\) is in \\(\\mathbb{R}\\) and \\(H_t\\) is \\(\\mathcal{F}_{t-1}\\)-measurable for every \\(t=1, \\ldots\\);</li> </ul> <p>The stochastic integral \\(H\\bullet X\\) of \\(H\\) with respect to \\(X\\) is defined as the process</p> \\[   H\\bullet X_t=H_0X_0+\\sum_{s=1}^t H_s \\left( X_s-X_{s-1} \\right)=H_0X_0+\\sum_{s=1}^t H_s \\Delta X_s. \\] <p>In other terms the stochastic integral is the integration of \\(H\\) against the increments \\(\\Delta X\\) of \\(X\\). In continuous terms it would formally look like this</p> \\[ H\\bullet X_t = H_0 X_0 + \\int_0^t H_s dX_s \\] <p>Lemma</p> <p>Clearly the collection of adapted and predictable processes are vector spaces.</p> <ul> <li>The operator \\(\\bullet\\) is bilinear;</li> <li>\\(H\\bullet X\\) is an adapted process itself;</li> <li> <p>For every stopping time \\(\\tau\\), the stochastic process \\(1_{\\{\\cdot \\leq \\tau\\}} = (1_{\\{t\\leq \\tau\\}})\\), is predictable</p> </li> <li> <p>Stopping the stochastic integral: For any stopping time \\(\\tau\\) it holds that</p> \\[   \\left( H1_{\\{\\cdot \\leq \\tau\\}}\\right) \\bullet X = \\left(H\\bullet X\\right)^\\tau = H\\bullet X^\\tau \\] <p>In particular \\(1_{\\{\\cdot \\leq \\tau\\}}\\bullet X = X^\\tau\\) since \\(1\\bullet X = X\\).</p> </li> </ul> <p>The last equality might be better understood in classical integral terms (ignoring the first constant term):</p> \\[ \\int_0^t H_s 1_{\\{s\\leq \\tau\\}} dX_s = \\int_0^{t\\wedge \\tau} H_s dX_s = \\int_0^t H_s dX^\\tau_s \\] <p>since \\(H1_{\\{\\cdot \\leq \\tau\\}}\\) is equal to \\(0\\) after \\(\\tau\\) and \\(X^\\tau\\) is constant after \\(\\tau\\) (hence null increments after \\(\\tau\\)).</p> <p>Proof</p> <p>The proof is mechanical and left as an exercise. Only for \\(1_{\\{\\cdot \\leq \\tau\\}}\\) being predictable it comes from the fact that \\(\\{t\\leq \\tau\\} = \\{\\tau &lt; t\\}^c = \\{\\tau \\leq t-1\\}^c\\) which is an event in \\(\\mathcal{F}_{t-1}\\).</p>"},{"location":"lecture/04-Martingales/042-martingale-doob/","title":"Martingales and Doob's Optional Sampling","text":""},{"location":"lecture/04-Martingales/042-martingale-doob/#martingales","title":"Martingales","text":"<p>Definition: Martingale (Sub/Super)</p> <p>A stochastic process \\(X\\) is called a martingale if:</p> <ol> <li>\\(X\\) is adapted;</li> <li>\\(X\\) is integrable, that is, \\(X_t\\) is integrable for every \\(t\\);</li> <li>\\(X_s=E[X_t\\,|\\, \\mathcal{F}_s]\\) whenever \\(s\\leq t\\).</li> </ol> <p>A process \\(X\\) is called a super-martingale if instead of (3) we require:</p> <p>3'. \\(X_s\\geq E[X_t\\,|\\, \\mathcal{F}_s]\\) whenever \\(s\\leq t\\).</p> <p>A process \\(X\\) is called a sub-martingale if instead of (3) we require:</p> <p>3''. \\(X_s\\leq E[X_t\\,|\\, \\mathcal{F}_s]\\) whenever \\(s\\leq t\\).</p> <p>Remark</p> <p>Note that a martingale is, in particular, both a super-martingale and a sub-martingale at the same time.</p> <p>Note that since we are working in discrete time, the martingal (sub/super) property can be checked only on each increment, that is \\(E[\\Delta X_t |\\mathcal{F}_{t-1}]=E[X_t - X_{t-1}|\\mathcal{F}_{t-1}] =0\\).</p> <p>Example</p> <ul> <li> <p>Given and integrable random variable \\(\\xi\\), the process \\(X = (E[\\xi|\\mathcal{F}_t])\\) defines a martingale.</p> </li> <li> <p>Consider the random walk \\(S\\) from the example in the previous section.     show that </p> <ul> <li>\\(p=1/2\\), then \\(S\\) is a martingale;</li> <li>\\(p\\geq 1/2\\), then \\(S\\) is a sub-martingale;</li> <li>\\(p\\leq 1/2\\), then \\(S\\) is a super-martingale.</li> </ul> </li> </ul> <p>Proposition</p> <p>Let \\(X\\) be an adapted process and \\(\\varphi:\\mathbb{R}\\to \\mathbb{R}\\) be a measurable function such that \\(\\varphi(X_t)\\) is integrable for every \\(t\\).</p> <ul> <li>If \\(X\\) is a martingale and \\(\\varphi\\) is convex, then \\(Y=(\\varphi(X_t))\\) is a sub-martingale.</li> <li>If \\(X\\) is a martingale and \\(\\varphi\\) is concave, then \\(Y=(\\varphi(X_t))\\) is a super-martingale.</li> <li>If \\(X\\) is a sub-martingale and \\(\\varphi\\) is convex and increasing, then \\(Y=(\\varphi(X_t))\\) is a sub-martingale.</li> </ul> <p>Proof</p> <p>Since a process \\(Y\\) is a sub-martingale if and only if \\(-Y\\) is a super-martingale, and \\(\\varphi\\) is convex if and only if \\(-\\varphi\\) is concave, we only need to prove the first point to get the second. Clearly, \\(Y\\) is adapted. By assumption, \\(Y_t\\) is integrable for every \\(t\\). Finally, using Jensen's inequality for conditional expectation and the martingale property \\(X_s=E[X_t|\\mathcal{F}_s]\\), it follows that:</p> \\[   E[Y_t|\\mathcal{F}_s]=E[\\varphi(X_t)|\\mathcal{F}_s]\\geq \\varphi(E[X_t|\\mathcal{F}_s])=\\varphi(X_s)=Y_s. \\] <p>If \\(X\\) is a sub-martingale and \\(\\varphi\\) is convex and increasing, then:</p> \\[ E[Y_t|\\mathcal{F}_s]=E[\\varphi(X_t)|\\mathcal{F}_s]\\geq \\varphi(E[X_t|\\mathcal{F}_s])\\geq \\varphi(X_s)=Y_s, \\] <p>showing the sub-martingale property and therefore proving the third point.</p> <p>Clearly the notion of martingale is very minimal. A martingale can be seen as a noise process (in a vague sense) in so far that it moves in any possible direction but in average like now. Sup-martingale are trending downwards while sub-martingales are trending upwards. This intuitive notion and the centrality of this fact can be inspected in the following Doob Meyer Theorem.</p> <p>Theorem: Doob Meyer Decomposition</p> <p>Let \\(X\\) be an adapted and integrable process. Then there exists a unique decomposition:</p> \\[   X=M+A, \\] <p>where \\(M\\) is a martingale and \\(A\\) is a predictable process with \\(A_0=0\\). This decomposition is called the Doob decomposition.</p> <p>Furthermore, \\(X\\) is a sub-martingale or super-martingale if and only if \\(A\\) is increasing or decreasing respectively.</p> <p>Proof</p> <p>Assume that we had such a decomposition, then it follows that \\(M = X - A\\) is a martingale. By the martingale property and predictability of \\(A\\) we get</p> \\[   0= E[\\Delta M_{t+1}|\\mathcal{F}_t] = E[\\Delta X_{t+1}|\\mathcal{F}_t] - E[\\Delta A_{t+1}|\\mathcal{F}_t] =  E[\\Delta X_{t+1}|\\mathcal{F}_t] -(A_{t+1} - A_t) \\] <p>This provides us a recursive way to define \\(A\\) as follows</p> \\[   \\begin{equation*}     \\begin{cases}         A_0 &amp;= 0\\\\         A_t &amp;=A_{t-1}+ E[X_t-X_{t-1}|\\mathcal{F}_{t-1}] \\quad \\text{for}\\quad t\\geq 1     \\end{cases}   \\end{equation*} \\] <p>It is immediate to check by induction that \\(A\\) is predictable and by definition \\(M:=X - A\\) is a martingale providing the decomposition.</p> <p>As for the uniqueness, let \\(X = M+A = \\tilde{M}+\\tilde{A}\\) where \\(M\\) and \\(\\tilde{M}\\) are martingales and \\(A\\) and \\(\\tilde{A}\\) are predictable processes starting at \\(0\\). It follows that \\(M - \\tilde{M} = \\tilde{A}-A\\) is a predictable martingale. Hence by martingale property and then predictability it holds that \\(M_{t_1}-\\tilde{M}_{t-1} = E[M_t - \\tilde{M}_{t} |\\mathcal{F}_{t-1}] = M_t - \\tilde{M}_{t}\\) showing that </p> \\[   M_t - \\tilde{M}_{t} = M_{t-1} - \\tilde{M}_{t-1} = \\cdots = M_0 - \\tilde{M}_0 = \\tilde{A}_0 - A_0 = 0 \\] <p>We deduce that \\(M=\\tilde{M}\\) and \\(A = \\tilde{A}\\).</p> <p>The assertions about super and sub martingales are immediate to get.</p>"},{"location":"lecture/04-Martingales/042-martingale-doob/#stochastic-integration-with-respect-to-a-martingale","title":"Stochastic integration with respect to a martingale","text":"<p>Doob's Optional Sampling Theorem, Modern Version</p> <p>Let \\(H\\) be a predictable process. The following holds true:</p> <ol> <li>If \\(X\\) is a martingale and \\(H\\bullet X_t\\) is integrable for every \\(t\\), then \\(H\\bullet X\\) is a martingale.</li> <li>If \\(X\\) is a super-martingale or sub-martingale, \\(H\\geq 0\\), and \\(H\\bullet X_t\\) is integrable for every \\(t\\), then \\(H\\bullet X\\) is a super-martingale or sub-martingale.</li> </ol> <p>Proof</p> <p>Suppose that \\(X\\) is a martingale and \\(H\\) is such that \\(H\\bullet X\\) is integrable. Adaptiveness is immediate. From \\(H\\) being predictable, that is, \\(H_{t+1}\\) is \\(\\mathcal{F}_t\\)-measurable, and \\(X\\) being a martingale, that is, \\(E[X_{t+1}-X_t|\\mathcal{F}_t]=E[X_{t+1}|\\mathcal{F}_t]-X_t=0\\), it follows that:</p> \\[   E\\left[ \\Delta H\\bullet X_{t+1}|\\mathcal{F}_t \\right]=E\\left[ H_{t+1} \\Delta X_{t+1}|\\mathcal{F}_t \\right]= H_{t+1}E\\left[ \\Delta X_{t+1}|\\mathcal{F}_t \\right]= 0. \\] <p>The argument in the sub-martingale case is similar, using the fact that \\(H_{t+1}\\geq 0\\) and \\(E[X_{t+1}-X_t|\\mathcal{F}_t]=E[X_{t+1}|\\mathcal{F}_t]-X_t\\geq 0\\) and similarly for the super-martingale case.</p> <p>Remark</p> <p>Note that in this theorem, if there exists a constant \\(C&gt;0\\) such that \\(|H_t|&lt;C\\) for every \\(t\\), then \\(H\\bullet X_t\\) is integrable for every \\(t\\) as soon as \\(X\\) is integrable. Indeed,</p> \\[   E\\left[ |H\\bullet X_t| \\right]\\leq E\\left[ |H_0 X_0| \\right]+\\sum_{s=1}^tE\\left[ |H_t||X_{t}-X_{t-1}| \\right]\\leq 2C\\sum_{s=0}^t E[|X_t|]&lt;\\infty. \\] <p>So the assumption that \\(|H\\bullet X_t|\\) is integrable for every \\(t\\) can be replaced by \\(H\\) being uniformly bounded.</p> <p>This remark allows us to formulate the original Doob's sampling theorem.</p> <p>Doob's Optional Sampling Theorem</p> <p>Let \\(X\\) be a (super/sub-)martingale and \\(\\tau\\) a stopping time. Then \\(X^\\tau\\) is a (super/sub-)martingale.</p> <p>Proof</p> <p>Let \\(\\tau\\) be a stopping time. It holds that \\(X^\\tau=H\\bullet X\\) for the process \\(H=1_{\\{\\cdot \\leq \\tau\\}}\\). However, \\(H\\) is predictable, uniformly bounded since \\(|H_t|\\leq 1\\), and positive. By the property of the stochastic integral \\(1_{\\{\\cdot \\leq \\tau\\}}\\bullet X = X^\\tau\\). Hence, according to Doob's optional sampling theorem (modern version), it follows that \\(X^\\tau\\) is a (super/sub-)martingale.</p> <p>Proposition</p> <p>If \\(X\\) is a martingale or sub-martingale, then:</p> \\[   E[X_\\tau \\,|\\, \\mathcal{F}_\\sigma]=X_{\\sigma} \\quad \\text{or} \\quad E[X_\\tau \\,|\\, \\mathcal{F}_\\sigma]\\geq X_{\\sigma}, \\] <p>respectively, for every pair of bounded stopping times \\(\\sigma\\leq \\tau \\leq T\\) for some \\(T\\).</p> <p>Proof</p> <p>Since \\(\\tau \\leq T\\) for some \\(T\\), it follows that:</p> \\[ \\left\\vert X_\\tau \\right\\vert\\leq \\left\\vert X_0\\right\\vert+\\cdots +\\left\\vert X_t\\right\\vert. \\] <p>Thus, \\(X_\\tau\\) is integrable. Furthermore, \\(X^\\tau\\) is a martingale from Doob's optional sampling theorem and \\(X^\\tau_T = X_\\tau\\). For \\(A \\in \\mathcal{F}_{\\sigma}\\), it holds that \\(A\\cap \\{\\sigma=s\\}\\) is an event in \\(\\mathcal{F}_s\\). Hence,</p> \\[   E\\left[ (X_{t}-X_{\\sigma})1_{A} \\right] =\\sum_{s\\leq k}E\\left[ (X_{t}-X_{s})1_{A\\cap \\{\\sigma =s\\}} \\right]=\\sum_{s\\leq k}E\\left[ E\\left[X_{t}-X_{s}\\,|\\, \\mathcal{F}_{s}\\right]1_{A\\cap \\{\\sigma =s\\}} \\right]=0, \\] <p>showing that \\(E[X_t\\,|\\, \\mathcal{F}_{\\sigma}]=X_{\\sigma}\\). Applying this to the stopped process \\(X^\\tau\\) yields the result. The proof in the sub-martingale case follows the same argumentation.</p>"},{"location":"lecture/04-Martingales/043-martingale-as-convergence/","title":"Martingale: Almost Sure Convergence","text":"<p>Given a martingale \\(X\\), this section treats the questions whether there exists \\(X_\\infty\\) such that \\(X_t\\to X_\\infty\\) in the almost sure sense. In other terms we want to study the asymptotic behavior of a stochastic process \\(X\\).</p> <p>Given a stochastic process \\(X\\), we can classify the different behaviors of the paths \\(t \\mapsto X_t(\\omega)\\) as follows</p> <ul> <li> <p>Convergence to \\(\\pm \\infty\\): the path converges to either \\(\\infty\\) or \\(-\\infty\\).     The corresponding event of those states where it happens is given by</p> \\[C = \\{\\limsup X_t = -\\infty \\text{ or }\\liminf X_t = \\infty\\}\\] </li> <li> <p>Convergence in \\(\\mathbb{R}\\): the path converges to a real limit, that is, \\(\\lim X_t(\\omega)\\) exists in \\(\\mathbb{R}\\).     The corresponding event of those states where it happens is given by</p> \\[B = \\{-\\infty &lt; \\liminf X_t = \\limsup X_t&lt;\\infty\\}\\] </li> <li> <p>Oscillatory behavior: In the case of non convergence, the path will oscillate infinitely.     The corresponding event of those states where it happens is given by</p> \\[A = \\{\\liminf X_t &lt; \\limsup X_t\\}\\] </li> </ul> <p>Clearly each of these sets are events and build a partition of \\(\\Omega\\). The seminal idea of Doob was to recognize that sub-martingales have properties helping to estimate the probability of the latter set. The building bloc for which is the Doob's upcrossing lemma.</p>"},{"location":"lecture/04-Martingales/043-martingale-as-convergence/#doobs-upcrossing-lemma-and-martingale-convergence","title":"Doob's Upcrossing Lemma and Martingale Convergence","text":"<p>Let \\(X\\) be a process, \\(x&lt;y\\) be real numbers and \\(F\\) be a finite subset of \\(\\mathbb{N}_0\\). Usually we take \\(F = [\\![0, T ]\\!] :=\\{0, 1, \\cdots, T\\}\\). We wish to count the number of upcrossings of the path \\(t \\mapsto X_t(\\omega)\\) on the set \\(F\\). We proceed as follows by defining the stopping times</p> \\[ \\begin{equation*}     \\tau_0=0 \\end{equation*} \\] <p>and recursively</p> \\[ \\begin{align*}     \\tau_1 &amp; = \\inf\\left\\{t \\in F: t\\geq \\tau_0 \\text{ and } X_t \\leq x\\right\\}\\\\     \\tau_2 &amp; = \\inf\\left\\{t \\in F: t\\geq \\tau_1 \\text{ and } X_t \\geq y\\right\\}\\\\            &amp; \\vdots\\\\     \\tau_{2k-1} &amp; = \\inf\\left\\{t \\in F: t\\geq \\tau_{2k-2}, X_t \\leq x\\right\\}\\\\     \\tau_{2k} &amp; = \\inf\\left\\{t \\in F: t\\geq \\tau_{2k-1}, X_t \\geq y\\right\\} \\end{align*} \\] <p>with the convention that the infimum over the empty set is infinite.</p> <p> </p> <p>We define the random quantity</p> \\[ \\begin{equation*}     U_F\\left( x,y,X(\\omega) \\right)=\\sup\\left\\{k:\\tau_{2k}(\\omega)&lt;\\infty\\right\\}. \\end{equation*} \\] <p>This corresponds to the strict positive number of up-crossing of \\([x,y]\\) by \\(t\\mapsto X_t(\\omega)\\) on \\(F\\).</p> <p>Finally, we adopt the notation \\([\\![s, t ]\\!]:=\\{s,s+1,\\ldots,t\\}\\) for every integers \\(s\\leq t\\).</p> <p>Doob's Upcrossing Lemma</p> <p>Let \\(X\\) be a sub-martingale. Then for every two reals \\(x&lt;y\\), the number \\(U_{[\\![0, T ]\\!]}(x,y,X)\\) of up-crossing of \\([x,y]\\) by \\(t\\mapsto X_t\\) up to time \\(T\\), is a positive random variable and it holds</p> \\[ \\begin{equation}     (y-x)E\\left[ U_{[\\![0, T ]\\!] }\\left( x,y,X \\right) \\right]\\leq E\\left[ \\left(X_T-x\\right)^+ \\right]-E\\left[ \\left( X_0-x \\right)^+ \\right]. \\end{equation} \\] <p>Proof</p> <p>First of all, the random times \\(\\tau_k\\), \\(k=0,1,\\ldots\\) defining the up-crossing function are all stopping times. Since \\([\\![0, T ]\\!]\\) is a discrete interval here, it follows that \\(U:=U_{[\\![0, T ]\\!]}(x,y,X)\\) is a positive random variable. Define now the predictable gamble strategy, that is, the predictable process</p> \\[ \\begin{equation*}     H_t=\\sum_{k\\geq 1} 1_{]\\tau_{2k-1},\\tau_{2k}]}(t) =      \\begin{cases}       1 &amp; \\text{if } \\tau_{2k-1}&lt; t\\leq \\tau_{2k} \\text{ for some }k\\\\       0 &amp; \\text{otherwize}     \\end{cases} \\end{equation*} \\] <p>for which holds \\(H_0=0\\). It is predictable since it takes only values \\(0\\) and \\(1\\) and it holds</p> \\[ \\begin{equation*}     \\{H_t=1\\}=\\cup \\left\\{ \\tau_{2k-1}&lt;t \\right\\}\\cap\\left\\{ \\tau_{2k}&lt;t \\right\\}^c \\in \\mathcal{F}_{t-1} \\end{equation*} \\] <p>This gamble strategy \\(H\\) is a bet on upcrossings. Note that by the definition of \\(\\tau_{2k}\\) it follows that for every \\(\\omega \\in \\Omega\\), either \\(\\tau_{2k}(\\omega)\\leq t\\) or \\(\\tau_{2k}(\\omega)=\\infty\\). Further, by the definition of \\(U\\) it holds that \\(U(\\omega)\\leq t\\), and therefore \\(\\tau_{2U(\\omega)}\\leq t\\) as well as \\(\\tau_{2U(\\omega)+2}=\\infty\\) for every \\(\\omega\\). Finally, since \\(U\\) is a random variable, it follows that \\(\\tau_{2U}\\) is a random time.</p> <p>We translate our problem at \\(0\\) by defining the process \\(Y=(X-x)^+\\). Since \\(\\varphi(z)= (z-x)^+\\) is increasing and convex function, it follows that \\(Y\\) is a sub-martingale too. It clearly holds that \\(U\\) also counts the number of up-crossings of \\([0,y-x]\\) up to time \\(T\\) by \\(t\\mapsto Y_t\\) and therefore since \\(\\tau_{2U}\\leq T\\) and \\(\\tau_{2U+2} = \\infty\\), it holds</p> \\[ \\begin{align*}     H\\bullet Y_T &amp;=\\sum_{t=1}^T H_t\\left( Y_{t}-Y_{t-1} \\right)\\\\     &amp;=\\sum_{t=1}^T\\sum_{k\\geq 1} 1_{]\\tau_{2k-1},\\tau_{2k}]}(t)\\left( Y_{t}-Y_{t-1} \\right)\\\\     &amp;=\\sum_{k\\geq 1}\\sum_{t=(\\tau_{2k-1}+1)\\wedge T}^{\\tau_{2k}\\wedge T}\\left( Y_t-Y_{t-1} \\right)\\\\     &amp; = \\sum_{k=1}^{U}\\left( Y_{\\tau_2k} - Y_{\\tau_{2k-1}}\\right) + (Y_T - Y_{\\tau_{2U+1}\\wedge T})\\\\     &amp; = \\sum_{k=1}^{U}\\left( Y_{\\tau_2k} - Y_{\\tau_{2k-1}}\\right) + (Y_T - Y_{\\tau_{2U+1}})1_{\\{\\tau_{2U+1}&lt;T\\}}\\\\ \\end{align*} \\] <p>On the one hand, we know that if \\(k\\leq U\\), then \\(Y_{\\tau_{2k}}-Y_{\\tau_{2k-1}}\\geq y-x\\). On the other hand, since \\(Y_{\\tau_{2U+1}}\\) is equal to \\(0\\) on \\(\\{\\tau_{2U+1}&lt;T\\}\\), it follows that  \\((Y_T - Y_{\\tau_{2U+1}})1_{\\{\\tau_{2U+1}&lt;T\\}}\\geq 0\\). Hence it holds</p> \\[ \\begin{align*}     E[H\\bullet Y_T] &amp; =E\\left[\\sum_{k=1}^U (Y_{\\tau_{2k}}-Y_{\\tau_{2k-1}})\\right]+E\\left[(Y_{T}-Y_{\\tau_{2U+1}})1_{\\{T&gt; \\tau_{2U+1}\\}}\\right]\\\\      &amp; \\geq E\\left[\\sum_{k=1}^U (y-x)\\right]=(y-x)E[U] \\end{align*} \\] <p>Defining \\(K_t=1-H_t\\) for every \\(t\\geq 1\\) and \\(K_0=0\\) which is a positive predictable process, hence by means of Doob's optional sampling theorem, it follows that \\(K\\bullet Y\\) is a sub-martingale and therefore \\(E[K\\bullet Y_T]\\geq E[K\\bullet Y_0]= 0\\). Since \\(K+H=1_{\\{1\\leq \\cdot\\} }\\), it follows that</p> \\[ \\begin{align*}     (y-x)E\\left[ U \\right]  &amp; \\leq E\\left[ H\\bullet Y_T \\right]\\\\                             &amp; \\leq E\\left[ H\\bullet Y_T \\right]+E[K\\bullet Y_T] \\\\                             &amp; = E\\left[ \\sum_{t=1}^T Y_{t}-Y_{t-1} \\right]\\\\                             &amp; = E\\left[ Y_T-Y_0 \\right]\\\\                             &amp; =E\\left[ \\left( X_T-x \\right)^+ \\right]-E\\left[ \\left( X_0-x \\right)^+ \\right] \\end{align*} \\] <p>which ends the proof.</p> <p>Theorem: Martingale Convergence \\(P\\)-Almost Sure</p> <p>Let \\(X\\) be a sub-martingale such that \\(\\sup E[X_t^+]&lt;\\infty\\). Then \\(X_t \\to X_\\infty\\) almost surely for some integrable random variable \\(X_\\infty\\).</p> <p>Proof</p> <p>Note that if \\(X\\) is a sub-martingale, then \\(\\sup E[\\left\\vert X\\right\\vert_t]&lt;\\infty\\) is equivalent to \\(\\sup E[X^+_t]&lt;\\infty\\). Indeed, it follows from \\(\\left\\vert X\\right\\vert_t= 2X_t^+-X_t\\) and the sub-martingale property, that \\(E[X_t]\\geq E[X_0]&gt;-\\infty\\).</p> <p>Let</p> <ul> <li> <p>\\(A\\) be the event of those states \\(\\omega\\) such that \\(t\\mapsto X_t(\\omega)\\) is oscillatory discontinuous.     In other terms, the path will cross infinitely many times some interval \\([q, r]\\) for \\(q&lt;r\\) rationals.     According to the definition in Doob's Upcrossing lemma, it follows that \\(U_{\\mathbb{N}_0}(q, r, X)(\\omega) = \\lim_{T\\to \\infty} U_{[\\![0, T ]\\!]} (q, r, X)(\\omega) = \\infty\\).     Hence we can write</p> \\[ \\begin{equation*}     A= \\bigcup_{q&lt;r \\text{ and }q,r \\in \\mathbb{Q}}\\left\\{ U_{\\mathbb{N}_0}\\left( q,r,X\\right)=\\infty\\right\\}=\\bigcup_{q&lt;r\\text{ and } q,r \\in \\mathbb{Q}}\\left\\{ \\sup_{T \\in \\mathbb{N}_0}U_{[\\![0, T ]\\!]}(q,r,X)=\\infty\\right\\} \\end{equation*} \\] </li> <li> <p>\\(B\\) be the event of those states \\(\\omega\\) such that \\(t \\mapsto X_t(\\omega)\\) has a real valued limit, that is</p> \\[ \\begin{equation*}   B=\\left\\{ \\infty &lt;\\liminf X_t=\\limsup X_t &lt;\\infty \\right\\} \\end{equation*} \\] </li> <li> <p>\\(C\\) be the event of those states \\(\\omega\\) such that \\(t \\mapsto X_t(\\omega)\\) diverges to either \\(\\infty\\) or \\(-\\infty\\), that is</p> \\[   C = \\left\\{ \\limsup X_t = -\\infty \\text{ or }\\liminf X_t = \\infty \\right\\} \\] </li> </ul> <p>In other terms \\(t\\mapsto X_t\\) converges to some extended random variable \\(X_\\infty\\) on \\(B\\cup C\\). As for \\(A\\), it is a measurable set as a countable union of measurable sets. Furthermore, by means of Doob's up-crossing's Lemma, as well as monotone convergence, the assumptions of the theorem yield</p> \\[ \\begin{equation*}    E\\left[ \\sup_{t \\in \\mathbb{N}_0}U_{[\\![0, T ]\\!]}(q,r,X) \\right]=\\sup_{t \\in \\mathbb{N}_0}E\\left[ U_{[\\![0, T ]\\!] }(q,r,X) \\right]\\leq \\frac{1}{q-r}\\sup_{t}\\left\\{ E\\left[ \\left( X_t-q \\right)^+ \\right] -E\\left[ \\left( X_0-q \\right)^+ \\right]\\right\\}&lt;\\infty \\end{equation*} \\] <p>It follows that \\(P[\\sup_{t \\in \\mathbb{N}_0}U_{[\\![0, T ]\\!] }(q,r,X)=\\infty]=0\\) from which follows</p> \\[ \\begin{equation*}     P[A]\\leq \\sum_{q&lt;r\\text{ and }q,r \\in \\mathbb{Q}}P\\left[ \\sup_{t \\in \\mathbb{N}_0}U_{[\\![0, T ]\\!]}(q,r,X)=\\infty \\right]=0. \\end{equation*} \\] <p>Hence, \\(P[B\\cup C]=1\\), showing that \\(t\\mapsto X_t\\) converges almost surely to the extended real valued random variable \\(X_\\infty\\). Finally, by Fatou's Lemma,</p> \\[ \\begin{equation*}     E[|X_\\infty|]\\leq \\liminf E[|X_t|]\\leq \\sup E[|X|_t]&lt;\\infty \\end{equation*} \\] <p>showing integrability of \\(X_\\infty\\) and also that \\(P[X_\\infty=\\infty\\text{ or }X_\\infty=-\\infty]=P[C]=0\\).</p> <p>Corollary</p> <p>Let \\(X\\) be a super-martingale such that \\(\\sup_t E[X_t^-]&lt;\\infty\\). Then \\(X_t\\to X_\\infty\\) almost surely for some integrable random variable \\(X_\\infty\\).</p>"},{"location":"lecture/04-Martingales/043-martingale-as-convergence/#applications-of-p-almost-sure-convergence","title":"Applications of \\(P\\)-almost Sure Convergence","text":"<p>This almost sure convergence results has numerous applications. We present in the following several of them that as a consequence recovers the Borel-Cantelli lemma.</p> <p>Theorem</p> <p>Let \\(X\\) be a martingale with \\(X_0=0\\). Suppose that \\(|X_{t+1}-X_t|\\leq c\\) for every \\(t\\) and some constant \\(c&gt;0\\). Then it holds</p> \\[ \\begin{equation*}     P\\left[ B\\cup D \\right]=1, \\end{equation*} \\] <p>where</p> \\[ \\begin{equation*}     B =\\left\\{ -\\infty&lt;\\liminf X_t=\\limsup X_t&lt;\\infty\\right\\} \\text{ and } D =\\left\\{ \\liminf X_t=-\\infty \\text{ and } \\limsup X_t=\\infty \\right\\}. \\end{equation*} \\] <p>This theorem states that martingales with uniformly bounded increments either converge to a real value or oscilate infinitely between \\(-\\infty\\) and \\(\\infty\\).</p> <p>Proof</p> <p>Define the stopping time \\(\\tau_k=\\inf\\{t\\colon X_t &gt; k\\}\\). According to Doob's sampling theorem, it follows that \\(X^{\\tau_k}\\) is a martingale such that \\(\\sup_tE[(X^{\\tau_k}_t)^+]\\leq k+c&lt;\\infty\\). Indeed, on \\(\\{t &lt; \\tau_k\\}\\), it holds \\(X_t^{\\tau_k}\\leq k\\) and on \\(\\{\\tau_k\\leq t\\}\\), it holds \\(X_t^{\\tau_{k}}=X_{\\tau_k}\\leq X_{\\tau_k-1}+(X_{\\tau_k}-X_{\\tau_k-1})\\leq k+c\\). By the martingale convergence theorem, \\(\\lim_{t\\to \\infty} X_t^{\\tau_k}\\) exists almost surely. On \\(\\{\\tau_k=\\infty\\}\\) the processes \\(X\\) and \\(X^{\\tau_k}\\) coincide, so that \\(\\lim  X_t\\) exists almost surely on \\(\\{\\tau_k=\\infty\\}\\). In particular \\(\\lim X_t\\) exists almost surely on</p> \\[ \\begin{equation*}     \\bigcup\\{\\tau_k=\\infty\\}=\\left\\{\\limsup X_t&lt;\\infty\\right\\}. \\end{equation*} \\] <p>A similar argumentation for \\(-X\\) shows that \\(\\lim X_t\\) exists almost surely on \\(\\{\\liminf X_t&gt;-\\infty\\}\\). That is \\(\\lim X_t\\) exists almost surely on \\(\\{\\liminf X_t&gt;-\\infty \\}\\cup\\{\\limsup X_t&lt;\\infty\\}=D^c\\). It means that \\(P[D^c\\setminus B]=P[D^c\\cap B^c]=0\\). Hence, taking complementation, it follows that \\(P[B\\cup D]=P[(D^c\\cap B^c)]=1\\) which ends the proof.</p> <p>Corollary: Pre Borel-Cantelli</p> <p>We suppose that \\(\\mathcal{F}_0=\\{\\emptyset,\\Omega\\}\\). Let \\((A_t)\\) be a sequence of events in \\(\\mathcal{F}\\) such that \\(A_t\\) is in \\(\\mathcal{F}_t\\) for every \\(t\\). Then</p> \\[ \\begin{align*}     \\limsup A_t&amp;=\\bigcap_{t}\\bigcup_{s\\geq t}A_s=\\left\\{\\omega:\\omega\\in A_t\\text{ for infinitely many }t\\right\\}=\\left\\{\\sum P(A_t|\\mathcal{F}_{t-1})         =\\infty\\right\\} \\end{align*} \\] <p>holds almost surely, whereby \\(P[A_t|\\mathcal{F}_{t-1}]=E[1_{A_t}|\\mathcal{F}_{t-1}]\\).</p> <p>Proof</p> <p>We define the process \\(X\\) as follows</p> \\[ \\begin{equation*}     X_0=0\\quad \\text{ and }\\quad X_t=\\sum_{s=1}^t1_{A_s}-P\\left[ A_s|\\mathcal{F}_{s-1} \\right], \\quad \\text{ for }t\\geq 1 \\end{equation*} \\] <p>Since \\(\\mathcal{F}_0=\\{\\emptyset,\\Omega\\}\\), it follows that \\(X\\) is a martingale. Indeed, \\(X\\) is clearly adapted by definition, and \\(|X_t|\\leq 2t\\) so that \\(X\\) is integrable. Furthermore, \\(E[X_1-X_{0}|\\mathcal{F}_{0}]=E[X_1-X_0]=P[A_1]-P[A_1]=0\\) and</p> \\[ \\begin{equation*}     E[X_t-X_{t-1}|\\mathcal{F}_{t-1}]=E[1_{A_t}-E[1_{A_t}|\\mathcal{F}_{t-1}]|\\mathcal{F}_{t-1}]=E[E[1_{A_t}-1_{A_t}|\\mathcal{F}_{t-1}|\\mathcal{F}_{t-1}]=0 \\end{equation*} \\] <p>for every \\(t\\geq 2\\). Since \\(|X_{t+1}-X_t|\\leq 2\\) holds for every \\(t\\), we may apply the previous theorem of convergence for martingales with bounded bounded increments. On \\(B=\\{\\liminf X_t=\\limsup X_t \\in\\mathbb{R}\\}\\), it holds</p> \\[ \\begin{equation*}    \\sum 1_{A_t}=\\infty\\quad \\text{if, and only if,}\\quad\\sum P\\left[A_n | \\mathcal{F}_{t-1}\\right]=\\infty.  \\end{equation*} \\] <p>On \\(D=\\{\\liminf X_t=-\\infty\\text{ and }\\limsup X_t=\\infty\\}\\) it holds</p> \\[ \\begin{equation*}    \\sum 1_{A_t}=\\infty\\quad \\text{and}\\quad \\sum P\\left[A_t| \\mathcal{F}_{t-1}\\right]=\\infty.  \\end{equation*} \\] <p>Since \\(P[B\\cup D]=1\\) we deduce</p> \\[ \\begin{equation*}     \\sum 1_{A_t}=\\infty\\quad \\text{if, and only if,}\\quad \\sum P[A_t|\\mathcal{F}_{t-1}]=\\infty \\end{equation*} \\] <p>almost surely. Moreover, \\(\\limsup A_t=\\{\\sum 1_{A_t}=\\infty\\}\\), hence the claim follows.</p> <p>We close these application with Borel-Cantelli's lemma.</p> <p>Borel-Cantelli's Lemma</p> <ul> <li>If \\((A_t)\\) is a sequence of events in \\(\\mathcal{F}\\) and \\(\\sum P[A_t]&lt;\\infty\\), then it holds \\(P[\\limsup A_t]=0\\).</li> <li>If \\((A_t)\\) is an independent sequence of events in \\(\\mathcal{F}\\) and \\(\\sum P(A_t)=\\infty\\), then it holds \\(P[\\limsup A_t]=1\\).</li> </ul> <p>Proof</p> <p>We consider the filtration \\(\\mathbb{F}=(\\mathcal{F}_t)_{t \\in \\mathbb{N}_0}\\) given by \\(\\mathcal{F}_0=\\{\\emptyset, \\Omega\\}\\) and \\(\\mathcal{F}_t:=\\sigma(A_s\\colon s\\leq t)\\) for \\(t\\geq 1\\). Define \\(\\xi:=\\sum P[A_t|\\mathcal{F}_{t-1}]\\). The monotone convergence theorem as well as the tower property shows that</p> \\[ \\begin{equation*}     E[\\xi]=E\\left[\\sum E[1_{A_t}|\\mathcal{F}_{t-1}]\\right]=\\sum E[E[1_{A_t}|\\mathcal{F}_{t-1}]]=\\sum P[A_t]. \\end{equation*} \\] <ol> <li> <p>If \\(\\sum P[A_t]&lt;\\infty\\), then it holds \\(P[\\xi=\\infty]=0\\).     The previous corollary yields \\(P[\\limsup A_t]=0\\).</p> </li> <li> <p>Suppose that \\((A_t)\\) is an independent sequence of events, therefore \\(A_t\\) is independent of \\(\\mathcal{F}_{t-1}\\) which implies \\(P[A_t| \\mathcal{F}_{t-1}]=P[A_t]\\) for all \\(t\\).    Hence \\(\\sum P[A_t|\\mathcal{F}_{t-1}]=\\sum P[A_t]=\\infty\\) almost surely and by the previous corollary it follows that \\(P[\\limsup A_t]=1\\).</p> </li> </ol>"},{"location":"lecture/04-Martingales/044-martingale-lp-convergence/","title":"Martingales \\(L^p\\)-Convergence","text":"<p>As astonishing and useful the martingales convergence in the \\(P\\)-almost sure case can be due to Doob's optional sampling and upcrossing lemma it is often limiting from a topological viewpoint. The \\(P\\)-almost sure convergence does not provides a satisfactory topology on spaces of random variable (in particular it is not a locally convex topology). We would prefer in most case to get stronger convergence in terms of norms.</p> <p>It turns out that convergence in \\(L^p\\) for \\(p&gt;1\\) can be derived as shown in the subsequent section due to Doob's maximal inequalities. The case of \\(L^1\\) due to its topological particularity (is not a reflexive space) is not available without additional uniform integrability conditions.</p>"},{"location":"lecture/04-Martingales/044-martingale-lp-convergence/#doobs-maximal-inequalities-and-lp-convergence","title":"Doob's Maximal Inequalities and \\(L^p\\) Convergence","text":"<p>The building block for \\(L^p\\) convergence are the so-called Doob's maximal inequalities. In the following, given a process \\(X\\) we define the</p> <ul> <li>Running supremum process \\(\\overline{X}\\) by \\(\\overline{X}_t=\\sup_{s\\leq t}X_s\\).</li> <li>Running infimum process \\(\\underline{X}\\) by \\(\\underline{X}_t=\\inf_{s\\leq t}X_s\\).</li> <li>Running absolute supremum process \\(X^\\ast\\) by \\(X^\\ast_t=\\sup_{s\\leq t} |X_s|\\).</li> </ul> <p>Proposition: Doob's Maximal Inequalities</p> <p>The following assertions hold true.</p> <ol> <li> <p>Let \\(X\\) be a sub-martingale and \\(\\lambda&gt;0\\).     Then it holds</p> \\[ \\begin{align*}    \\lambda P\\left[ \\overline{X}_t\\geq \\lambda \\right]&amp;\\leq E\\left[ 1_{\\{\\overline{X}_t \\geq \\lambda\\}}X_t \\right]\\leq E\\left[ X_t^+ \\right];\\\\    \\lambda P\\left[ \\underline{X}_t\\leq -\\lambda \\right]&amp;\\leq E\\left[ 1_{\\{\\underline{X}_t &gt;- \\lambda\\}} X_t \\right]-E[X_0]\\leq E\\left[ X_t^+ \\right]-E\\left[ X_0 \\right]. \\end{align*} \\] </li> <li> <p>For \\(X\\) a positive sub-martingale and \\(p&gt;1\\), it holds</p> \\[ \\begin{equation*}    \\left\\Vert\\sup_{s \\leq t}X_s\\right\\Vert_p\\leq \\frac{p}{p-1}\\left\\Vert X_t\\right\\Vert_p. \\end{equation*} \\] </li> </ol> <p>Remark</p> <p>Note that Doob's maximal inequalities are similar to Markov inequality. The fundamental difference though and powerfull fact is that the probability of the behavior of the whole path between \\(0\\) and \\(t\\) is controled by the expectation of the sub martingale at the begining and end.</p> <p>Note also that the second statement shows that the norm of the running maximum of the path between \\(0\\) and \\(t\\), which can be arbitrarily large, is controled by the norm at time \\(t\\). This however only holds for \\(p&gt;1\\).</p> <p>Those statements about the path being controled by the values at its boundary is certainly not trivial.</p> <p>Proof</p> <ol> <li> <p>For the stopping time \\(\\tau=\\inf\\{s:X_s\\geq \\lambda \\}\\), observe that \\(\\{\\tau\\leq t\\}=\\{\\overline{X}_t\\geq \\lambda\\}\\).     Also, on \\(\\{\\tau\\leq t\\}\\), it holds \\(X^\\tau_{t}=X_{\\tau\\wedge t}\\geq \\lambda\\).     Hence,</p> \\[ \\begin{equation*}    X_{\\tau\\wedge t}=X_{\\tau}1_{\\{\\overline{X}_t\\geq \\lambda\\}}+X_t1_{\\{\\tau&gt;t\\}}\\geq \\lambda 1_{\\{\\overline{X}_t\\geq \\lambda\\}}+X_t1_{\\{\\tau&gt;t\\}}. \\end{equation*} \\] <p>It also holds, \\(X_t1_{\\{\\tau&gt;t\\}}\\geq -X_t^-\\). Altogether, with Doob's optional sampling theorem and \\(X\\) being a sub-martingale, we get</p> \\[ \\begin{align*}    E\\left[ X_t \\right]  &amp; = E\\left[ E\\left[X_t |\\mathcal{F}_{t\\wedge \\tau} \\right] \\right]\\\\                         &amp; \\geq E\\left[ X_{\\tau\\wedge t} \\right]\\\\                         &amp; \\geq \\lambda P\\left[ \\overline{X}_t\\geq \\lambda \\right]+E\\left[ 1_{\\{\\tau&gt;t\\}} X_t\\right]\\\\                         &amp; \\geq \\lambda P\\left[ \\overline{X}_t\\geq \\lambda \\right]-E\\left[ X_t^- \\right], \\end{align*} \\] <p>and conclude the first inequality by observing that, on the one hand, \\(E[X_t^+]=E[X_t]+E[X_t^-]\\), and on the other hand,</p> \\[ \\begin{equation*}    E[X_t]-E\\left[ 1_{\\{\\tau&gt;t\\}} X_t\\right]=E[(1- 1_{\\{\\overline{X}_t&lt;\\lambda\\}}) X_t]=E[1_{\\{\\overline{X}_t\\geq \\lambda \\}}X_t]. \\end{equation*} \\] <p>As for the second inequality, for the stopping time \\(\\sigma=\\inf\\{s: X_s\\leq -\\lambda\\}\\), observe that \\(\\{\\sigma\\leq t\\}=\\{\\underline{X}_t\\leq -\\lambda\\}\\). Also, on \\(\\{\\sigma\\leq t\\}\\), it holds \\(X^\\sigma_{t}=X_{\\sigma\\wedge t}\\leq -\\lambda\\). Hence,</p> \\[ \\begin{equation*}    X_{\\sigma\\wedge t}=X_{\\sigma}1_{\\{\\underline{X}_t\\leq -\\lambda\\}}+X_t1_{\\{\\sigma&gt;t\\}}\\leq -\\lambda 1_{\\{\\underline{X}_t\\leq -\\lambda\\}}+X_t1_{\\{\\sigma&gt;t\\}}. \\end{equation*} \\] <p>Altogether, with Doob's optional sampling theorem and \\(X\\) being a sub-martingale, we get</p> \\[ \\begin{equation*}    E\\left[ X_0 \\right]\\leq E\\left[ X_{\\sigma\\wedge t} \\right]\\leq -\\lambda P\\left[ \\underline{X}_t \\leq -\\lambda\\right]+E\\left[ 1_{\\{\\sigma&gt;t\\}} X_t \\right]\\leq -\\lambda P\\left[ \\underline{X}_t \\leq -\\lambda\\right]+E\\left[ X_t^+ \\right] \\end{equation*} \\] <p>showing the second inequality by observing that \\(E[1_{\\{\\sigma&gt;t\\}}X_t]=E[1_{\\{\\underline{X}_t&gt;-\\lambda\\}}X_t]\\).</p> </li> <li> <p>Define the random variables \\(Y=\\sup_{s\\leq t}X_s\\) and \\(Z=X_t=X_t^+\\) since \\(X\\) is positive.     For \\(\\varphi\\) an increasing, right-continuous function with \\(\\varphi(0)=0\\), by Fubini's theorem and the previous inequalities, it holds</p> \\[ \\begin{align*}    E\\left[ \\varphi(Y) \\right] &amp; = E\\left[ \\int_{0}^\\infty 1_{\\{\\lambda \\leq Y\\}}d\\varphi(\\lambda) \\right]\\\\                               &amp; = \\int_{0}^\\infty P\\left[ Y\\geq \\lambda \\right]d\\varphi(\\lambda)\\\\                               &amp; \\leq \\int_0^\\infty E\\left[1_{\\{Y\\geq \\lambda\\}}Z\\right]\\frac{d\\varphi(\\lambda)}{\\lambda}\\\\                               &amp; = E\\left[ Z \\int_0^\\infty 1_{\\{Y\\geq \\lambda\\}}\\frac{d\\varphi(\\lambda)}{\\lambda} \\right]. \\end{align*} \\] <p>If we consider \\(\\varphi(\\lambda)=\\lambda^p\\), \\(p&gt;1\\), and define \\(q=p/(p-1)\\) for which holds \\(1/p+1/q=1\\), it follows from H\u00f6lder's inequality that</p> \\[ \\begin{equation*}    \\left\\Vert Y\\right\\Vert_p^p\\leq pE\\left[ Z \\int_0^\\infty 1_{\\{Y\\geq \\lambda\\}}\\lambda^{p-2}d\\lambda \\right]=\\frac{p}{p-1}E\\left[ Z Y^{p-1} \\right]\\leq q \\left\\Vert Z\\right\\Vert_p \\left\\Vert Y^{p-1}\\right\\Vert_q=q \\left\\Vert Z\\right\\Vert_p \\left\\Vert Y\\right\\Vert_p^{p/q}. \\end{equation*} \\] <p>If \\(0&lt;\\left\\Vert Y\\right\\Vert^{p/q}_p&lt;\\infty\\), dividing the inequality by \\(\\left\\Vert Y\\right\\Vert^{p/q}_p\\), noting that \\(p-p/q =1\\), yields</p> \\[ \\begin{equation*}    \\left\\Vert\\sup_{s\\leq t}X_s\\right\\Vert_p=\\left\\Vert Y\\right\\Vert_p\\leq q \\left\\Vert Z\\right\\Vert_p=q \\left\\Vert X_t\\right\\Vert_p, \\end{equation*} \\] <p>as desired.</p> </li> </ol> <p>Corollary</p> <p>If \\(X\\) is a martingale, and \\(p&gt;1\\), it holds</p> \\[ \\begin{equation}         \\left\\Vert X^\\ast_t\\right\\Vert_p=E\\left[ \\left( \\sup_{s\\leq t}\\left\\vert X_s\\right\\vert \\right)^p \\right]^{1/p}\\leq \\left(\\frac{p}{p-1}\\right) \\left\\Vert X_t\\right\\Vert \\end{equation} \\] <p>Proof</p> <p>Follows immediately that \\(|X|\\) is a sub-martingale and the doob's maximal inequalities.</p> <p>Martingale Convergence Theorem</p> <p>Let \\(X\\) be a martingale such that \\(\\sup_{t}E[|X_t|^p]&lt;\\infty\\) for some \\(p&gt;1\\). Then, there exists a random variable \\(X_{\\infty}\\) in \\(L^p\\) such that \\(X_t \\to X_{\\infty}\\) almost surely and in \\(L^p\\).</p> <p>Proof</p> <p>Since Jensen's inequality yields \\(E[X_t^+]\\leq E[|X_t|]\\leq E[|X_t|^p]^{\\frac{1}{p}}\\), it follows that \\(\\sup E[X_t^+]&lt;\\infty\\). By the \\(P\\)-almost sure martingale convergence Theorem, there exists an integrable random variable \\(X_{\\infty}\\) for which \\(X_t\\to X_{\\infty}\\) almost surely.</p> <p>We are left to show that the sequence \\(|X_t-X_\\infty|^p\\) satisfies the assumptions of Lebesgue's dominated convergence. It holds</p> \\[ \\begin{equation*}     |X_t -X_\\infty|^p\\leq c\\left(| X_t|^p + |X_\\infty|^p \\right)\\leq c\\left(\\sup |X_t|^p+|X_\\infty|^p\\right). \\end{equation*} \\] <p>On the one hand, by Fatou's lemma we have \\(E[|X_\\infty|^p]\\leq\\liminf E [|X_t|^p]&lt;\\infty\\). On the other hand, by means of the previous corollary, it holds</p> \\[ \\begin{equation*}     E[\\sup_{s\\leq t}|X_s|^p]\\leq (p/(p-1))^p E[|X_t|^p] \\end{equation*} \\] <p>showing that</p> \\[ \\begin{equation*}     E[\\sup|X_t|^p]=\\sup_tE[\\sup_{s\\leq t}|X_s|^p]\\leq (p/(p-1))^p\\sup E[|X_t|^p]&lt;\\infty.  \\end{equation*} \\] <p>Thus, the dominated convergence theorem yields \\(X_t\\to X_\\infty\\) in \\(L^p\\).</p>"},{"location":"lecture/04-Martingales/044-martingale-lp-convergence/#applications-of-lp-convergence-law-of-large-numbers","title":"Applications of \\(L^p\\) Convergence, Law of Large Numbers","text":"<p>We apply the \\(L^p\\)-convergence of martingales to show the law of large numbers that states that the sample average of independently distributed random variables with finite mean converges almost surely to its mean.</p> <p>Theorem</p> <p>Let \\(X\\) be a square integrable martingale for which holds</p> \\[ \\begin{equation*}     \\sum E\\left[ \\left( X_t-X_{t-1} \\right)^2 \\right]&lt;\\infty. \\end{equation*} \\] <p>Then, the sequence \\((X_t)\\) converges almost surely and in \\(L^2\\).</p> <p>Proof</p> <p>Beforehand, let us show the following lemma.</p> <p>Lemma</p> <p>Let \\(X\\) be a martingale such that \\(X_t\\) is square integrable for every \\(t\\). It follows that</p> \\[ \\begin{align*}     E\\left[ \\left( X_u-X_t \\right)X_s \\right] &amp; =0,\\\\     E\\left[ \\left( X_t-X_s \\right)^2|\\mathcal{F}_s \\right]&amp;=E\\left[ X_t^2|\\mathcal{F}_s \\right]-X_s^2, \\end{align*} \\] <p>for every \\(s\\leq t\\leq u\\).</p> <p>Proof</p> <p>Since \\(s\\leq t\\leq u\\) and \\(X\\) is a square integrable martingale, it follows from the properties of the conditional expectation</p> \\[ \\begin{equation*}     E\\left[ \\left( X_u-X_t \\right)X_s \\right]=E\\left[ E\\left[\\left( X_u-X_t \\right)X_s |\\mathcal{F}_t\\right]\\right]=E\\left[ E\\left[\\left( X_u-X_t \\right) |\\mathcal{F}_t\\right]X_s\\right]=0 \\end{equation*} \\] <p>showing the first equality. The same reasoning yields</p> \\[ \\begin{align*}     E\\left[ \\left( X_t-X_s \\right)^2 |\\mathcal{F}_s\\right] &amp; = E\\left[ X_t^2 |\\mathcal{F}_s\\right]-E\\left[ X_tX_s|\\mathcal{F}_s \\right]-E\\left[ (X_t-X_s)X_s|\\mathcal{F}_s \\right]\\\\     &amp; = E\\left[ X_t^2 |\\mathcal{F}_s\\right]- X_sE\\left[ X_t|\\mathcal{F}_s \\right]-X_sE\\left[ X_t-X_s|\\mathcal{F}_s \\right]\\\\     &amp; = E\\left[ X_t^2 |\\mathcal{F}_s\\right]- X_s^2, \\end{align*} \\] <p>showing the second equality.</p> <p>For every \\(t\\), by means of this lemma, it follows that</p> \\[ \\begin{align*}     E\\left[ X_t^2 \\right] &amp; = E\\left[X_0^2\\right]+\\sum_{s=1}^tE\\left[X_{s}^2-X_{s-1}^2\\right]\\\\                           &amp; = E\\left[X_0^2\\right]+\\sum_{s=1}^tE\\left[E\\left[X_{s}^2-X_{s-1}^2|\\mathcal{F}_{s-1}\\right]\\right]\\\\                           &amp; = E\\left[X_0^2\\right]+\\sum_{s=1}^tE\\left[E\\left[\\left(X_{s}-X_{s-1}\\right)^2|\\mathcal{F}_{s-1}\\right]\\right]\\\\                           &amp; = E\\left[X_0^2\\right]+\\sum_{s=1}^tE\\left[\\left(X_{s}-X_{s-1}\\right)^2\\right]\\\\                           &amp; \\leq E\\left[ X_0^2 \\right]+\\sum E\\left[ \\left( X_s-X_{s-1} \\right)^2 \\right]. \\end{align*} \\] <p>It follows that \\(\\sup_{t}E\\left[ X_t^2 \\right]&lt;\\infty\\) and therefore, by means of martingale convergence theorem, it follows that \\(X_t\\to X_\\infty\\) almost surely and in \\(L^2\\).</p> <p>Theorem</p> <p>Let \\(X\\) be a martingale and \\(a=(a_t)\\) be an increasing sequence such that \\(a_t\\to \\infty\\). If</p> \\[ \\begin{equation*}     \\sum E[(X_t-X_{t-1})^2/a_t^2]&lt;\\infty, \\end{equation*} \\] <p>then it follows that</p> \\[ \\begin{equation*}     \\frac{X_t}{a_t}\\longrightarrow 0 \\quad \\text{almost surely} \\end{equation*} \\] <p>In particular, if \\(\\sup E[(X_t-X_{t-1})^2]&lt;\\infty\\), then it holds</p> \\[ \\begin{equation*}     \\frac{X_t}{t}\\longrightarrow 0 \\quad \\text{almost surely} \\end{equation*} \\] <p>Proof</p> <p>Define the process \\(Y\\) by \\(Y_0=0\\) and \\(Y_t=\\sum_{s=1}^t (X_s-X_{s-1})/a_s\\) for \\(t\\geq 1\\). It follows that \\(Y\\) is a martingale. Indeed, adaptiveness and integrability are immediate since \\(X\\) is a martingale. As for the martingale property, it holds</p> \\[ \\begin{equation*}     E\\left[ Y_{t}-Y_{t-1} |\\mathcal{F}_t\\right]=\\frac{1}{a_t}E\\left[ X_t-X_{t-1}|\\mathcal{F}_t \\right]=0. \\end{equation*} \\] <p>Furthermore, it holds</p> \\[ \\begin{equation*}     \\sum E\\left[ \\left( Y_t-Y_{t-1} \\right)^2 \\right]=\\sum \\frac{1}{a_t^2}E\\left[ \\left( X_t-X_{t-1} \\right)^2 \\right]&lt;\\infty \\end{equation*} \\] <p>which by means of the previous Theorem implies that </p> \\[ \\begin{equation*}     Y_t=\\sum_{s=1}^t\\frac{X_s-X_{s-1}}{a_s}\\longrightarrow Y_T=\\sum \\frac{X_t-X_{t-1}}{a_t} \\end{equation*} \\] <p>almost surely and in \\(L^2\\). The Kronecker's lemma states that if \\(\\sum b_t/a_t&lt;\\infty\\) for two sequences \\((a_t)\\) and \\((b_t)\\) whereby \\((a_t)\\) is an increasing sequence of strictly positive numbers, it follows that \\((\\sum b_t)/a_t=0\\). Hence, applying Kronecker's lemma, it follows that</p> \\[ \\begin{equation*}     \\frac{X_t}{a_t}=\\frac{1}{a_t}\\sum_{s=1}^t X_s-X_{s-1}\\to 0 \\end{equation*} \\] <p>almost surely. In particular, if \\(\\sup E[(X_t-X_{t-1})^2]&lt;\\infty\\) it follows that </p> \\[   \\sum E[(X_t-X_{t-1})^2/t^2]\\leq \\sup E[(X_t-X_{t-1})^2]\\sum \\frac{1}{t^2}&lt;\\infty \\] <p>and the second assertion of the theorem follows.</p> <p>Corollary</p> <p>Let \\((X_t)\\) be a sequence of integrable independent random variables such that \\(E[X_t]=0\\) for every \\(t\\) and such that \\(\\sum E[X_t^2]/a_t^2&lt;\\infty\\) for some increasing sequence \\((a_t)\\) of strictly positive real numbers such that \\(a_t\\to \\infty\\). Then it holds</p> \\[ \\begin{equation*}     \\frac{1}{a_t}\\sum_{s=1}^t X_s\\longrightarrow 0 \\quad \\text{almost surely} \\end{equation*} \\] <p>Proof</p> <p>Define \\(\\mathcal{F}_0=\\{\\emptyset,\\Omega\\}\\) and \\(\\mathcal{F}_t=\\sigma(X_s\\colon s\\leq t)\\) and the process \\(S\\) by \\(S_0=0\\) and \\(S_t=\\sum_{s=1}^t X_s\\). It follows that \\(S\\) is a martingale. Indeed, it is integrable by assumption. It is furthermore adapted since \\(\\mathbb{F}\\) is the filtration generated by \\(X\\). Finally due to the independence, it follows that</p> \\[ \\begin{equation*}     E\\left[ S_t-S_{t-1} |\\mathcal{F}_{t-1}\\right]=E\\left[ X_t|\\mathcal{F}_{t-1} \\right]=E\\left[ X_t \\right]=0. \\end{equation*} \\] <p>Furthermore, since</p> \\[ \\begin{equation*}     \\sum \\frac{1}{a_t^2}E\\left[ \\left( S_t-S_{t-1} \\right)^2 \\right]=\\sum \\frac{1}{a_t^2}E\\left[ X_t^2 \\right]&lt;\\infty, \\end{equation*} \\] <p>Applying the previous theorem yields</p> \\[ \\begin{equation*}     \\frac{S_t}{a_t}=\\frac{1}{a_t}\\sum_{s=1}^t X_s\\longrightarrow 0 \\quad \\text{almost surely} \\end{equation*} \\] <p>Theorem: Strong Law of Large Numbers</p> <p>Let \\((X_t)\\) be a sequence of integrable, independent, and identically distributed random variables. Then it holds</p> \\[ \\begin{equation*}     \\frac{1}{t}\\sum_{s=1}^t X_s\\xrightarrow[t \\to \\infty]{\\text{almost surely}}E\\left[ X_1 \\right]. \\end{equation*} \\] <p>Note</p> <p>Note that we do not make here the traditional assumption that the sequence shall be square integrable.</p> <p>Proof</p> <p>Step 1: Define first the countable family \\((A_t)\\) as \\(A_t=\\{ |X_t|&gt;t\\}\\) of events in \\(\\mathcal{F}\\). Using the fact that \\(X_t\\sim X_1\\) for every \\(t\\) and Fubini's Theorem, it holds</p> \\[ \\begin{equation*}     \\sum P\\left[ A_t \\right]=\\sum P\\left[ |X_t|&gt;t \\right]=\\sum P\\left[ |X_1|&gt;t \\right]\\leq \\int_{0}^\\infty P\\left[ |X_1|&gt;\\lambda \\right]d\\lambda=E\\left[ |X_1| \\right]&lt;\\infty. \\end{equation*} \\] <p>By Borel-Cantelli, it follows that \\(P[\\limsup A_t]=0\\) and therefore, for almost all \\(\\omega\\) in \\(\\Omega\\), there exists \\(t_0(\\omega)\\) such that \\(\\omega\\) does not belong to \\(A_t\\) for every \\(t\\geq t_0\\). Hence, defining \\(Y_t=X_t1_{A_t^c}\\), it follows that </p> \\[ \\begin{equation*}     \\liminf \\frac{1}{t}\\sum_{s\\leq t} X_s=\\liminf \\frac{1}{t}\\sum_{s\\leq t}  Y_s\\quad \\text{as well as}\\quad \\limsup \\frac{1}{t} \\sum_{s\\leq t}X_s=\\limsup \\frac{1}{t}\\sum_{s\\leq t} Y_s, \\end{equation*} \\] <p>and so we just have to show that</p> \\[ \\begin{equation*}     \\frac{1}{t}\\sum_{s\\leq t} Y_s\\xrightarrow[t \\to \\infty]{\\text{almost surely}} E\\left[ X_1 \\right]. \\end{equation*} \\] <p>Step 2: Let \\(Z_t=Y_t-E[Y_t]\\) for every \\(t\\) which is an independent sequence of random variables. Furthermore, note that</p> \\[ \\begin{equation*}     \\sum \\frac{E[Z_t^2]}{t^2}=\\sum \\frac{E\\left[ (Y_t-E[Y_t])^2 \\right]}{t^2}=\\sum \\frac{E\\left[ Y_t^2 \\right]-E\\left[ Y_t \\right]^2}{t^2}\\leq \\sum \\frac{E[Y_t^2]}{t^2}. \\end{equation*} \\] <p>By Fubini's theorem, and the fact that \\(P[|Y_t|&gt;s]=P[|Y_t|&gt;t]=0\\) for every \\(s\\geq t\\) as well as \\(P[Y_t&gt;\\lambda ]\\leq P[X_t&gt;\\lambda]=P[X_1&gt;\\lambda]\\) for every \\(t\\), it holds</p> \\[ \\begin{equation*}     E\\left[ Y_t^2 \\right]=E\\left[ \\int_{0}^\\infty 1_{\\{|Y_t|&gt;\\lambda\\}}2\\lambda d\\lambda \\right]=\\int_{0}^\\infty P\\left[ |Y_t|&gt;\\lambda \\right]2\\lambda d\\lambda \\leq\\int_{0}^t P\\left[ |X_1|&gt;\\lambda \\right]2\\lambda d\\lambda. \\end{equation*} \\] <p>The monotone convergence of Lebesgue yields</p> \\[ \\begin{equation*}     \\sum \\frac{1}{t^2}\\int_{0}^t P\\left[ |X_1|&gt;\\lambda \\right]2\\lambda d\\lambda=\\int_{0}^\\infty \\sum \\frac{1_{\\{t\\geq \\lambda\\}}}{t^2}P\\left[ |X_1|&gt;\\lambda \\right]2\\lambda d\\lambda. \\end{equation*} \\] <ul> <li> <p>For \\(\\lambda &lt;1\\), it holds</p> \\[ \\begin{equation*}   2 \\lambda \\sum \\frac{1}{t^2}=2\\lambda\\frac{\\pi^2}{6}\\leq 4\\lambda\\leq 4. \\end{equation*} \\] </li> <li> <p>For \\(\\lambda\\geq 1\\), it holds</p> \\[ \\begin{equation*}   2\\lambda \\sum_{t\\geq \\lambda}\\frac{1}{t^2}\\leq \\frac{2}{\\lambda}+2\\lambda\\int_{\\lambda}^\\infty \\frac{1}{x^2}dx\\leq 2+2\\lambda \\frac{1}{\\lambda}=4. \\end{equation*} \\] </li> </ul> <p>Hence,</p> \\[ \\begin{equation*}     \\sum \\frac{E\\left[ Z_t^2 \\right]}{t^2}\\leq 4 \\int_0^\\infty P\\left[ |X_1|&gt;\\lambda \\right]d\\lambda=4E\\left[ |X_1| \\right]&lt;\\infty. \\end{equation*} \\] <p>According to the previous corollary, it follows that \\((\\sum_{s\\leq t} Z_s)/t\\to 0\\) almost surely.</p> <p>Step 3: We finally show that \\((\\sum_{s\\leq t} Y_s)/t\\to E[X_1]\\) almost surely. It holds</p> \\[ \\begin{align*}     \\left| \\frac{1}{t}\\sum_{s\\leq t}Y_s-E[X_1]\\right|         &amp; \\leq \\left| \\frac{1}{t} \\sum_{s\\leq t}Z_s\\right|+\\frac{1}{t}\\sum_{s\\leq t}\\left|E\\left[Y_s  \\right]-E\\left[ X_s \\right]\\right|\\\\         &amp; = \\left| \\frac{1}{t} \\sum_{s\\leq t}Z_s\\right|+\\frac{1}{t}\\sum_{s\\leq t}\\left|E\\left[X_s1_{\\{|X_s|\\leq s\\}}  \\right]-E\\left[ X_s \\right]\\right|\\\\         &amp; \\leq \\left| \\frac{1}{t} \\sum_{s\\leq t}Z_s\\right|+\\frac{1}{t}\\sum_{s\\leq t}E\\left[|X_s|1_{\\{|X_s|&gt; s\\}}  \\right]\\\\         &amp; = \\left| \\frac{1}{t} \\sum_{s\\leq t}Z_s\\right|+\\frac{1}{t}\\sum_{s\\leq t}E\\left[ |X_1|1_{|X_1|&gt;s} \\right]\\\\         &amp; =\\left| \\frac{1}{t} \\sum_{s\\leq t}Z_s\\right|+E\\left[|X_1|\\frac{1}{t}\\sum_{s\\leq t} 1_{\\{|X_1|&gt;s\\}}\\right]\\\\         &amp; =I_t+E[J_t]. \\end{align*} \\] <p>We already shown in the previous step that \\(I_t\\to 0\\) almost surely. On the other hand, it holds \\(J_t\\leq |X_1|\\) with \\(E[|X_1|]&lt;\\infty\\) and since \\((\\sum_{s\\leq t} 1_{\\{|X_1|&gt;s\\}})/t\\to 0\\) almost surely, it follows that \\(J_t\\to 0\\) almost surely. Hence, by Lebesgue's dominated convergence theorem, it follows that \\(E[J_t]\\to 0\\) which ends the proof.</p>"},{"location":"lecture/04-Martingales/044-martingale-lp-convergence/#l1-convergence","title":"\\(L^1\\) Convergence","text":"<p>The \\(L^1\\)-case is more delicate. There we have to make use of uniform integrability in order to show similar results.</p> <p>Theorem: \\(L^1\\)-Martingale Convergence</p> <p>Let \\(X\\) be a sub-martingale bounded in \\(L^1\\), that is, \\(\\sup E[|X_t|]&lt;\\infty\\) or equivalently \\(\\lim E[X_t]&gt;-\\infty\\). In particular, by almost sure martingale convergence Theorem, there exists \\(X_\\infty \\in L^1\\) such that \\(X_t\\to X_\\infty\\) almost surely. Then the following two assertions are equivalent:</p> <ol> <li>\\(X\\) is uniformly integrable;</li> <li>\\(X_t\\to X_{\\infty}\\) in \\(L^1\\) and \\(E[ X_{\\infty}|\\mathcal{F}_t ]\\geq X_t\\) for every \\(t\\).</li> </ol> <p>Proof</p> <p>If \\(X_t\\to X_\\infty\\) almost surely, uniform integrability of \\(X\\) and \\(L^1\\) convergence are equivalent by means of Uniform Integrability Theorem. In particular, by the sub-martingale property, for every event \\(A\\) in \\(\\mathcal{F}_t\\), it holds that</p> \\[ \\begin{equation*}     E[X_{\\infty}1_A]=\\lim_{s\\geq t}E\\left[ X_{s}1_A \\right]\\geq E[X_t1_A], \\end{equation*} \\] <p>showing that (i) is equivalent to (ii).</p> <p>The following corollaries are consequences of this theorem as well as uniform integrability properties.</p> <p>Corollary</p> <p>Let \\(X\\) be a martingale. Then the following assertions are equivalent:</p> <ul> <li>\\(X_t=E[\\xi|\\mathcal{F}_t]\\) for some \\(\\xi\\in L^1\\);</li> <li>\\(X\\) is uniformly integrable;</li> <li>\\(X_{t}\\to X_{\\infty}\\) in \\(L^1\\).</li> </ul> <p>Let \\(\\xi\\) be an integrable random variable and \\(\\mathcal{F}_\\infty=\\sigma(\\cup \\mathcal{F}_t)\\). Then it follows that </p> \\[ \\begin{equation*}     X_t:=E[\\xi|\\mathcal{F}_t]\\to X_{\\infty}:=E[\\xi|\\mathcal{F}_{\\infty}] \\end{equation*} \\] <p>almost surely and in \\(L^1\\).</p> <p>Proof</p> <p>The proof is left as an exercise for the first part of the corollary.</p> <p>We show the second part. Clearly, \\(X\\) is a martingale which is uniformly integrable. Hence, from the previous theorem, it converges to \\(X_\\infty\\) almost surely and in \\(L^1\\). We are left to show that \\(X_{\\infty}=E\\left[ \\xi|\\mathcal{F}_{\\infty} \\right]\\). Let </p> \\[ \\mathcal{C}=\\{A \\in \\mathcal{F}_{\\infty}\\colon E[X_{\\infty}1_A]=E[\\xi1_A]\\}. \\] <p>For every \\(A \\in\\mathcal{F}_t\\), it holds</p> \\[ \\begin{equation*}     E[X_{\\infty}1_A]=\\lim E[X_t1_A]=\\lim E\\left[ E[\\xi|\\mathcal{F}_t]1_A \\right]=E[\\xi1_A], \\end{equation*} \\] <p>showing that \\(\\cup \\mathcal{F}_t\\) is in \\(\\mathcal{C}\\). Since \\(\\mathcal{C}\\) is clearly a \\(\\lambda\\)-system, by Dynkin's Lemma, it follows that \\(\\mathcal{C}\\) contains \\(\\mathcal{F}_{\\infty}\\), ending the proof.</p>"},{"location":"lecture/05-Markov/050-introduction/","title":"Markov Processes Browninan Motion","text":"<p>This Chapter serves as a bridge in our study of stochastic processes towards the continuous time and the stochastic integral. The goal is to introduce the concepts of Markov processes\u2014that is, memoryless processes. We will start with the definition and key properties of general markov processes and how to construct them. We turn to specific applications in discrete time and then turn to the construction of a central Markov process, and martingale, namely the Brownian motion.</p> <ul> <li>Markov Processes</li> <li>Markov Chains</li> <li>Brownian Motion</li> </ul>"},{"location":"lecture/05-Markov/051-markov-extension/","title":"Markov Chain and Extension","text":"<p>In this section we will study a special class of stochastic processes namely those which immediate next evolution only depends on the current state. In other terms they are memory less. We will first introduce them in general framework and dive down into the more intuitive markov chain framework.</p> <p>In this section we consider a time index \\(\\mathbf{T}\\) which can be either \\(\\mathbb{N}_0\\) or \\([0,\\infty)\\). The Markov process will take value in a measurable state space \\((S, \\mathcal{S})\\) where \\(S\\) is a closed or open subset of \\(\\mathbb{R}^d\\) and \\(\\mathcal{S}\\) is the Borel \\(\\sigma\\)-Algebra\u2014in particular \\(S\\) is a Polish space. Though we can always consider processes from any abstract probability space, it is always possible to map it on the canonical space of paths with the product \\(\\sigma\\)-algebra.</p> <p>Definition: Path Space (or Canonical Space)</p> <p>The canonical space with values in \\((S, \\mathcal{S})\\) is given by the triplet</p> \\[   (\\Omega, \\mathcal{F}, \\mathbb{F}) \\] <p>together with the canonical process \\(X = (X_t)_{t \\in \\mathbf{T}}\\) where</p> <ul> <li> <p>State Space: </p> \\[   \\Omega = \\left\\{ \\omega = (\\omega_t)_{t \\in \\mathbf{T}}\\colon \\omega_t \\in S \\right\\} = S^{\\mathbf{T}} \\] </li> <li> <p>\\(\\sigma\\)-Algebra: is the resulting product \\(\\sigma\\)-algebra</p> \\[   \\mathcal{F} = \\otimes_{t \\in \\mathbf{T}} \\mathcal{S} \\] </li> <li> <p>Canonical Process: \\(X = (X_t)_{t \\in \\mathbf{T}}\\) where</p> \\[   \\begin{equation*}     \\begin{split}       X_t \\colon \\Omega &amp;\\longrightarrow S \\\\                 \\omega = (\\omega_s)_{s \\in \\mathbf{T}} &amp; \\longmapsto X_t(\\omega) = \\omega_t     \\end{split}   \\end{equation*} \\] <p>which is basically the projection process. By definition of the product \\(\\sigma\\)-algebra \\(X\\) is a stochastic process.</p> </li> <li> <p>Filtration: \\(\\mathbb{F}=(\\mathcal{F}_t)_{t \\in \\mathbf{T}}\\) where</p> \\[   \\mathcal{F}_t = \\sigma\\left( X_s \\colon s\\leq t \\right) \\] <p>turning \\(X\\) into an adapted process, its own filtration.</p> </li> </ul> <p>Definition: Markov Process on Canonical Space</p> <p>The canonical process \\(X\\) under a given probability measure \\(P\\) is called a Markov process if it satisfies the Markov property:</p> \\[ \\begin{equation}     P\\left[ X_{t} \\in B |\\mathcal{F}_s \\right]=P\\left[ X_{t} \\in B |X_s \\right] \\end{equation} \\] <p>for every \\(s\\leq t\\) and Borel set \\(B \\in \\mathcal{S}\\).</p> <p>The probability distribution \\(B\\mapsto \\mu[B]:=P[X_0 \\in B]\\) is called the start distribution of the Markov process.</p> <p>Note that the Markov property is equivalent to \\(E[ f(X_t)|\\mathcal{F}_s ]=E[ f(X_t)| X_s ]\\) for every bounded measurable function \\(f:S \\to \\mathbb{R}\\).</p> <p>Remark</p> <p>In this definition, a Markov process is in fact the specification of a probability measure on the path space such that the canonical process satisfies the Markov property.</p> <p>Note that we can alternatively give ourselves any abstract filtrated probability space \\((\\tilde{\\Omega}, \\tilde{\\mathcal{F}}, \\tilde{\\mathbb{F}},\\tilde{P})\\) and define Markov processes as adapted processes \\(\\tilde{X}\\) satisfying the markov property.</p> <p>However the mapping \\(\\omega \\mapsto (t\\mapsto \\tilde{X}_t(\\omega))\\) from \\(\\tilde{\\Omega}\\) to \\(\\Omega\\) with the pullback measure \\(P:=\\tilde{P}\\circ\\tilde{X}^{-1}\\) specifies the probability measure \\(P\\) under which the canonical process \\(X\\) is a Markov process with the same start distribution and same law.</p> <p>From this remark, we see that defining a Markov process corresponds precisely to specifying the probability on the canonical space \\(\\Omega = S^{\\mathbf{T}}\\). In other terms, providing the structure of the mappings</p> \\[ \\begin{equation*}     P_{s,t}(B):=P\\left[ X_t \\in B |X_s \\right] \\quad \\text{and}\\quad \\mu(B)=P[X_0 \\in B] \\end{equation*} \\] <p>for every \\(B \\in \\mathcal{S}\\) and \\(s\\leq t\\).  </p> <p>Example</p> <p>A typical way to see a discrete time finite state Markov process is as follows. We set \\(S=\\{1,2,3\\}\\) and \\(\\mu:=\\delta_1\\). We further assume that the Markov process \\(X\\) is time homogeneous, that is \\(P[X_{t+1}\\in B|X_s]=P[X_1 \\in B|X_0]\\) providing the following evolution starting from \\(1\\).</p> \\[ \\begin{equation*}     p=\\begin{pmatrix}         0 &amp; 1/2 &amp; 1/2 \\\\ 1/2 &amp;         1/4 &amp; 1/4\\\\ 2/3 &amp; 1/3 &amp; 0     \\end{pmatrix}.      \\end{equation*} \\] <pre><code>flowchart LR\n  s2((State 2)) --&gt;|1/4| s2\n  s2 --&gt;|1/2| s1((State 1))\n  s1 --&gt;|1/2| s2\n  s1 --&gt;|1/2| s3\n  s3 --&gt;|2/3| s1\n  s3 --&gt;|1/3| s2\n  s2 --&gt;|1/4| s3((State 3))</code></pre> <p>Random walk</p> <p>Let \\(Y\\) be a discrete stochastic process of independent random variables with values in \\(S=\\mathbb{Z}^d\\). Define \\(X_t:=\\sum_{s=0}^{t} Y_s\\) and \\(\\mathcal{F}_t:=\\sigma(X_s\\colon s\\leq t)\\). For \\(y\\in\\mathbb{Z}^d\\), it holds</p> \\[ \\begin{align*}     P[X_{t+1}=y | \\mathcal{F}_t]     &amp; =P[Y_{t+1} =y-X_t | \\mathcal{F}_t]     \\\\     &amp;=\\sum_{x\\in\\mathbb{Z}^d} P[Y_{t+1}=y-x | \\mathcal{F}_t] 1_{\\{X_t=x\\}}      \\\\     &amp; = \\sum_{x\\in\\mathbb{Z}^d} P[Y_{t+1}=y-x ] 1_{\\{X_t=x\\}}      \\\\     &amp; = \\sum_{x\\in\\mathbb{Z}^d} P[Y_{t+1}=y-x | X_t] 1_{\\{X_t=x\\}}     \\\\     &amp; = P[Y_{t+1}=y-X_t | X_t]     \\\\     &amp; = P[X_{t+1}=y | X_t]. \\end{align*} \\] <p>In both examples, we are either providing the transition probabilities or assuming a probability measure on the full space without checking whether such a probability measure can be constructed.</p> <p>Hence</p> <ul> <li>A Markov process defines a start measure \\(\\mu_0\\) and family of transition probabilities \\(P_{st}(\\cdot, \\cdot)\\). What are these transition probabilities? What are their properties?</li> <li>Is it possible to construct a markov process (or in other terms a probability measure \\(P\\) on the path space) from families of transition probabilities? If so, under which conditions?</li> </ul> <p>This is the content of the following section</p>"},{"location":"lecture/05-Markov/051-markov-extension/#from-markov-process-to-transition-probability","title":"From Markov Process to Transition probability","text":"<p>Every \\(\\sigma(X_s)\\)-measurable random variable \\(Y\\) can be written as \\(Y = f(X_s)\\) for some measurable function \\(f:S\\to \\mathbb{R}\\). Hence, there exist measurable functions \\(x\\mapsto P_{st}(x,B)\\) such that</p> \\[ \\begin{equation*}     P_{st}(X_s,B)=P\\left[ X_t\\in B|X_s \\right] \\end{equation*} \\] <p>for every \\(s&lt;t\\) and \\(B\\in \\mathcal{S}\\). Furthermore, it seems very natural that \\(B\\mapsto P_{st}(x,B)\\) should be a probability measure. This leads us to the notion of stochastic kernel and transition probability which is an alternative way to see Markov processes.</p> <p>Definition: Stochastic Kernel (see Fubini-Tonelli in Chapter 3)</p> <p>A stochastic kernel on \\((S, \\mathcal{S})\\) is a function \\(K:S\\times \\mathcal{S}\\to [0,\\infty)\\) such that</p> <ul> <li>\\(x \\mapsto K(x,B)\\) is measurable for every event \\(B\\) in \\(\\mathcal{S}\\).</li> <li>\\(B \\mapsto K(x,B)\\) is a measure for every \\(x\\) in \\(S\\).</li> </ul> <p>If \\(K(x,\\cdot)\\) is a probability measure, then we call it sometimes refered to as a transition probability.</p> <p>For a measurable function \\(f:S\\to \\mathbb{R}\\) and two kernels \\(K\\) and \\(L\\), we define</p> \\[ \\begin{equation*}     Kf(x)=\\int_{}^{} f(y)K(x,dy) \\quad \\text{and}\\quad KL(x,A)=\\int_{}^{}L(y,A) K(x,dy) \\end{equation*} \\] <p>An easy exercise shows that \\(Kf\\) is a measurable function and that \\(KL\\) is once again a stochastic kernel. The question of whether the mapping \\(B\\mapsto P_{st}(x,B)\\) is a probability measure for every \\(x\\) is in general not true. However, it holds on Borel spaces as the following proposition shows.</p> <p>Regular conditional distribution</p> <p>Let \\(X\\) and \\(Y\\) be two \\(S\\) valued random variables. Then, there exists a stochastic kernel \\(K:S\\times \\mathcal{S}\\to [0,1]\\) such that</p> \\[ K\\left( X,B \\right)= P\\left[ Y \\in B | X \\right] \\] <p>almost surely for every Borel set \\(B\\) and this stochastic kernel is unique almost surely.</p> <p>Proof</p> <p>Without loss of generality, we may assume that \\(S=\\mathbb{R}\\). For every rational \\(r\\), there exists a measurable function \\(f(\\cdot,r): S\\to [0,1]\\) such that \\(f(X,r)=P[ Y\\leq r |X ]\\) almost surely. Since \\(f(X,r)\\leq f(X,q)\\) almost surely for every \\(r\\leq q\\) and \\(\\lim_{r \\to  \\infty} f(X,r) =1\\) and \\(\\lim_{r\\to -\\infty}f(X,r)=0\\) almost surely, and these conditions are countable and only depending on \\(X\\), there exists a set \\(A\\in \\sigma(X)\\) of measure one such that \\(f(x,r)\\) is increasing with limit at \\(\\pm \\infty\\) being \\(0\\) or \\(1\\).</p> <p>Hence, defining</p> \\[ F(x,t)=1_A(x)\\inf_{r&gt;t, r\\in \\mathbb{Q}}f(x,r)+1_{A^c}(x)1_{[0,\\infty)}(t) \\] <p>we get that \\(F(x,\\cdot)\\) is a cumulative distribution function for every \\(x\\in \\mathbb{R}\\). In particular, there exists probability measures \\(K(x, \\cdot)\\) such that</p> \\[ K(x,B)=\\int_{B}^{} F(x,dt) \\] <p>and by construction \\(x\\mapsto K(x,B)\\) is measurable for every \\(x\\). A monotone class argument together with monotone convergence for conditional expectation shows that</p> \\[ K(X,B)=P\\left[ Y \\in B|X \\right] \\] <p>and uniqueness almost surely follows from the uniqueness almost surely of the conditional expectation.</p> <p>Remark</p> <p>In particular for any bounded measurable function \\(f:\\mathbb{R}^2\\to \\mathbb{R}\\), it holds</p> \\[ E\\left[ f(X,Y)| X \\right]=\\int_{}^{} f(X,y)K(X,dy) = g(X) \\] <p>where</p> \\[ g(x) = \\int_{}^{} f(x,y)K(x,dy) \\] <p>This statement leads to the following proposition.</p> <p>Markov process transition probabilities</p> <p>If \\(X\\) is a Markov process under \\(P\\) with start distribution \\(\\mu\\), there exists a family \\((P_{st})_{s&lt;t}\\) of transition probabilities such that</p> \\[ P\\left[ X_t \\in B |\\mathcal{F}_s \\right]=P_{st}(X_s,B) \\] <p>for every \\(s&lt;t\\). Furthermore, \\((P_{st})_{s&lt;t}\\) satisfies the semi-group property</p> \\[ P_{st}P_{tu}=P_{su} \\] <p>for every \\(s&lt;t&lt;u\\).</p> <p>Proof</p> <p>Suppose that \\(X\\) is a Markov process. According to Proposition \"Regular conditional distribution\", it follows that there exists a family of stochastic kernels \\(P_{st}\\) such that \\(P[ X_t \\in B|X_s ]=P_{st}(X_s, B)\\), hence Property.</p> <p>As for the semi-group property, it follows from the tower property of conditional expectation. Indeed, it holds \\(P_{st}(x,B)=P[X_t\\in B|X_s=x]\\) almost surely for every \\(x\\), \\(B\\in \\mathcal{S}\\) and \\(s&lt;t\\) as well as \\(E[f(X_t)|\\mathcal{F}_s]=E[f(X_t)|X_s]=\\int_{}^{} f(y)P_{st}(X_s,dy)\\). Hence, using the Markov property,</p> \\[ P_{st}P_{tu}(X_s,B)=\\int_{S}^{} P_{tu}(y,B)P_{st}(X_s,dy)=E\\left[ P_{tu}(X_t,B)|\\mathcal{F}_s \\right] = E\\left[ E\\left[ 1_{\\{X_u \\in B\\}}|X_t \\right]|\\mathcal{F}_s \\right] \\] \\[ E\\left[ E\\left[ 1_{\\{X_u \\in B\\}} |\\mathcal{F}_t\\right] |\\mathcal{F}_s\\right]=E\\left[ 1_{\\{X_u \\in B\\}} |\\mathcal{F}_s\\right]=E\\left[ 1_{\\{X_u \\in B\\}} | X_s\\right]=P_{su}(X_s,B) \\] <p>By the uniqueness of the stochastic kernel, we deduce that \\(P_{st}P_{tu}=P_{su}\\).</p>"},{"location":"lecture/05-Markov/051-markov-extension/#from-transition-probabilities-to-markov","title":"From Transition Probabilities to Markov","text":"<p>The most interesting, and involving question though is the reciprocal. In other terms, given a start distribution \\(\\mu\\) and a family of transition probabilities, does there exists a probability measure \\(P\\) on the path space such that the canonical process is a Markov process with the given transition probabilities? Is this process unique? It is indeed true and based on the fondamental Kolmogorov extension Theorem that we will treat in a separate subsection during the construction of the Brownian motion.</p> <p>Existence of Markov process</p> <p>Given a probability distribution \\(\\mu\\) and a family of transition probabilities \\((P_{st})_{s&lt;t}\\) satisfying the semi-group property, then there exists a probability measure \\(P^\\mu\\) such that \\(X\\) is a Markov process with start distribution \\(\\mu\\) and such that the transition probability holds.</p> <p>Proof</p> <p>We define the family of probability measures \\((P^\\mu_I)\\) for every finite family \\(I=\\{0&lt;t_1&lt;\\ldots&lt;t_n\\}\\subseteq \\mathbf{T}\\) by setting for every \\(n+1\\)-dimensional Borel set \\(A_0\\times A_1\\times \\cdots A_n\\)</p> \\[ P^\\mu_I(A_0\\times \\ldots \\times A_n )=\\int_{A_0}^{}\\mu(dx_0)\\int_{A_1}^{}P_{0t_1}(x_0,dx_1)\\int_{A_2}^{}P_{t_1t_2}(x_1,dx_2)\\cdots \\int_{A_n}^{} P_{t_{n-1}t_n}(x_{n-1},dx_n) \\] <p>Due to the semi-group property, it defines a consistent family of probability measures. Hence, by means of the Kolmogorov extension theorem, we can extend this projective family to a unique probability measure \\(P^\\mu\\) such that \\(X\\) by definition fulfills the transition probability property. Hence, \\(X\\) is a Markov process under \\(P^\\mu\\) with start distribution \\(\\mu\\) and transition probability \\((P_{st})_{s&lt;t}\\).</p> <p>Remark</p> <p>Note that given a family of transition probabilities \\((P_{st})\\) we can define a probability measure \\(P^\\mu\\) on the path space such that \\(X\\) is a Markov process with start distribution \\(\\mu\\). We denote in that case \\(E^\\mu\\) the expectation under this probability measure. This is in particular the case for all the Dirac measures \\(\\delta_{x}\\) for \\(x\\) in \\(S\\), that is, for Markov processes starting at \\(x\\). We denote \\(P^x\\) instead of \\(P^{\\delta_x}\\) and \\(E^x\\) instead of \\(E^{\\delta_x}\\). Given \\(P^x\\) for every \\(x\\) and a distribution \\(\\mu\\), we can recover any \\(P^\\mu\\) as follows.</p> \\[ P^{\\mu}[A]=\\int_{}^{} P^{x}[A] \\mu(dx) \\] <p>In fact, \\((x,A)\\mapsto P^{x}[A]\\) is a stochastic kernel on \\(S\\times \\mathcal{F}\\) and therefore the relation</p> \\[ P^{\\mu}[A]=\\int_{}^{} P^{x}[A] \\mu(dx) \\]"},{"location":"lecture/05-Markov/051-markov-extension/#markov-property","title":"Markov Property","text":"<p>From now on, we will only consider time homogeneous Markov processes:</p> <p>Time homogeneous Markov process</p> <p>A Markov process is called time homogeneous if and only if \\(P_{st}=P_{0t-s}\\), or in other terms, \\(P[X_t\\in B|X_s]=P[X_{t-s}\\in B|X_0]\\).</p> <p>In that case, we only have to specify the start distribution \\(\\mu\\) and a family of transition probabilities \\(P_t\\).</p> <p>Let \\(Z\\) be a random variable on \\(\\Omega\\), that is, \\(\\mathcal{F}=\\mathcal{F}_{\\infty}=\\sigma(X_t\\colon t \\in \\mathbf{T})\\)-measurable. It is, in particular, a function \\(\\omega=(\\omega_t)\\mapsto Z(X(\\omega))=Z((\\omega)_{t \\in \\mathbf{T}})\\).</p> <p>However:</p> <ul> <li>If \\(Z\\) is \\(\\mathcal{F}_{t}=\\sigma(X_s\\colon s\\leq t)\\)-measurable, then \\(Z\\) can actually be seen as a measurable function that only depends on the paths up to time \\(t\\), that is, \\(\\omega \\mapsto Z((X_s(\\omega))_{s\\leq t})=Z((\\omega)_{s\\leq t})\\).</li> <li>If \\(Z\\) is \\(\\sigma(X_t)\\)-measurable, then it can be seen as a measurable function that only depends on the value of the path at time \\(t\\), that is, \\(\\omega \\mapsto Z(X_t(\\omega))=Z(\\omega_t)\\).</li> </ul> <p>In particular, for the shift operator of a path by \\(t\\):</p> \\[ \\begin{aligned}     \\theta_t :\\Omega &amp; \\longrightarrow \\Omega\\\\     \\omega =(\\omega_s)_{s \\in \\mathbf{T}} &amp; \\longmapsto \\theta_t(\\omega)=(\\omega_{s+t})_{s\\in \\mathbf{T}} \\end{aligned} \\] <p>we have that \\(Z\\circ \\theta_t(\\omega)=Z\\left( (\\omega_{s+t})_{s\\in \\mathbf{T}} \\right)\\) is the evaluation of the random variable \\(Z\\) on the shifted path space by \\(t\\). In particular, if \\(Z\\) is \\(\\sigma(X_s)\\)-measurable, then it holds that \\(Z\\circ \\theta_t(\\omega)=Z(\\omega_{t+s})\\) is \\(\\sigma(X_{t+s})\\)-measurable.</p> <p>Markov Property</p> <p>Let \\((P_{t})\\) be a family of transition probabilities and \\(\\mu\\) be a probability distribution. For every bounded or positive measurable random variable \\(Z\\), it holds that \\(x \\mapsto E^x[Z]\\) is measurable. In particular, for every \\(t\\), the function \\(E^{X_t}[Z]\\) defined as</p> \\[ \\omega \\mapsto E^{X_t(\\omega)}[Z] \\] <p>is \\(\\sigma(X_t)\\)-measurable, and the Markov property holds</p> \\[ E^\\mu\\left[ Z\\circ \\theta_t |\\mathcal{F}_t  \\right]=E^{X_t}\\left[ Z \\right] \\] <p>Proof</p> <p>By monotony and approximation arguments, it is enough to show the proposition for the function \\(Z = 1_{A_0\\times A_1\\times \\ldots \\times A_n}(X_0,X_{t_{1}},\\ldots, X_{t_n})\\) where \\(A_k\\) are Borel sets. By definition of \\(P^x\\) and the previous remarks, it follows that</p> \\[   \\begin{align*}      E^x[Z] &amp; = \\int_{A_0}^{}\\delta_x(dx_0)\\int_{A_1}^{}P_{t_1}(x_0,dx_1)\\ldots \\int_{A_n}^{}P_{t_n-t_{n-1}}(x_{n-1},dx_n)\\\\             &amp; = 1_{A_0}(x)\\int_{A_1}^{}P_{t_1}(x,dx_1)\\ldots \\int_{A_n}^{}P_{t_n - t_{n-1}}(x_{n-1},dx_n)   \\end{align*} \\] <p>Since \\(x \\mapsto 1_{A_0}(x)\\) is measurable, and the \\((P_{st})\\) are stochastic kernels, the first assertion follows. In particular, for this specific form of \\(Z\\), it holds  </p> \\[ E^{X_t}[Z]=1_{A_0}(X_t)\\int_{A_1}^{}P_{t_1}(X_t,dx_1)\\ldots \\int_{A_n}^{}P_{t_n-t_{n-1}}(x_{n-1},dx_n) \\] <p>As for the second assertion, once again with a monotone class argument, it is enough to show that</p> \\[   E^\\mu[ Z\\circ \\theta_t Y ]=E^\\mu[ E^{X_t}[ Z ]Y] \\] <p>for \\(Y = 1_{B_0\\times B_1\\times \\ldots \\times B_m}(X_0,X_{s_{1}},\\ldots, X_{s_m})\\) where \\(A_k\\) are Borel sets and \\(s_m= t\\). By definition of \\(P^\\mu\\), the shift operator, and the expression of \\(E^{X_t}[Z]\\) above we get</p> \\[   \\begin{align*}      E^\\mu[ Z\\circ \\theta_t Y ] &amp; = E^\\mu\\left[ 1_{A}(X_{t}, X_{t+t_1}, \\ldots, X_{t+t_n}) 1_B(X_{0}, \\ldots, X_{s_m}) \\right]\\\\                                 &amp; = \\int_{B_0}^{}\\mu(dx_0)\\int_{B_1}^{}P_{s_1}(x_0,dx_1)\\ldots\\\\                                 &amp; \\qquad \\qquad \\qquad\\ldots \\int_{B_m\\cap A_0}^{}P_{t-s_{m-1}}(x_{m-1},dx_m)\\int_{A_1}^{} P_{t+t_1-t}(x_{m},dy_1)\\cdots \\int_{A_n}^{} P_{t+t_{n} -t-t_{n-1}}(y_{n-1},dy_n)\\\\                                 &amp; = \\int_{B_0}^{}\\mu(dx_0)\\int_{B_1}^{}P_{s_1}(x_0,dx_1)\\ldots \\int_{B_m\\cap A_0}^{}P_{t-s_{m-1}}(x_{m-1},dx_m)\\int_{A_1}^{} P_{t_1}(x_{m},dy_1)\\cdots\\\\                                 &amp; \\qquad \\qquad \\qquad \\cdots \\int_{A_n}^{} P_{t_{n}-t_{n-1}}(y_{n-1},dy_n)\\\\                                 &amp; = E^\\mu[ E^{X_t}[ Z ]Y]   \\end{align*} \\]"},{"location":"lecture/05-Markov/052-markov-discrete/","title":"Markov Chains","text":"<p>In this subsection we treat discrete time Markov processes chains with a finite or eventually countable state space \\(S\\), also called Markov Chains. Recall that we only consider time homogenous Markov processes. Defining</p> \\[ \\begin{align*}     \\mu_x:=P[X_0=x] \\quad p_{xy}:=P\\left[X_{t+1}=y|X_t=x\\right]=P[X_1=y|X_0=x] \\end{align*} \\] <p>it follows that \\(0\\leq \\mu_x, p_{xy}\\leq 1\\) and \\(\\sum \\mu_x=1\\), as well as \\(\\sum_y p_{xy}=1\\) for every \\(x\\). In other terms, the initial distribution \\(\\mu:=(\\mu_x)\\) is a random vector and the one step transition probability can be represented by the stochastic matrix \\(P=(p_{xy})\\). For \\(B\\subseteq S\\), it holds</p> \\[ \\begin{equation*}     P_1(x,B)=\\sum_{y \\in B}p_{xy} \\end{equation*} \\] <p>By Chapman Kolmogorov relation, we have \\(P_t=P_{t-1}P_1\\), hence, defining recursively</p> \\[ \\begin{equation}\\label{eq:repetition_markov}     p^t_{xy}=\\sum_{z}p^{t-1}_{xz}p_{zy} \\end{equation} \\] <p>we have</p> \\[ \\begin{equation*}     P_t(x,B)=\\sum_{y \\in B}p^t(x,y) \\end{equation*} \\] <p>In the discrete case the following strong Markov property holds.</p> <p>Strong Markov Property</p> <p>Let \\(Z\\) be a bounded random variable and \\(\\tau\\) a stopping time. Then it holds</p> \\[ \\begin{equation*}     1_{\\{\\tau&lt;\\infty\\}}E^{\\mu}\\left[ Z\\circ\\theta_{\\tau}|\\mathcal{F}_\\tau \\right]=1_{\\{\\tau&lt;\\infty\\}} E^{X_{\\tau}}\\left[ Z \\right]. \\end{equation*} \\] <p>Proof</p> <p>For every \\(A \\in \\mathcal{F}_\\tau\\) we get by Theorem \\ref{thm:markov property} and the fact that \\(A\\cap \\{\\tau=t\\}\\in \\mathcal{F}_t\\) for every \\(t\\),</p> \\[ \\begin{align*}     E^{\\mu}\\left[1_A1_{\\{\\tau&lt;\\infty\\}} Z\\circ\\theta_\\tau\\right]     &amp;=\\sum_{t} E^\\mu \\left[1_A1_{\\{\\tau=t\\}} Z\\circ\\theta_t\\right]\\\\     &amp;= \\sum_{t} E^{\\mu}\\left[1_A1_{\\{\\tau=t\\}} E^{X_t}\\left[Z\\right]\\right]\\\\      &amp;=E^\\mu\\left[1_A1_{\\{\\tau&lt;\\infty\\}} E^{X_\\tau}\\left[Z\\right]\\right], \\end{align*} \\] <p>from which the claim follows.</p> <p>Markov chains are defined locally: The next step is entirely defined by the place where you are now and the transition probability. The natural question therefore is whether you will come back or not. Given a state \\(y\\) in \\(S\\), define recursively </p> \\[ \\begin{align*}     \\tau^0_y  &amp; :=0\\\\     \\tau^1_y &amp; := \\inf\\left\\{ t&gt; \\tau^0_y\\colon X_t=y \\right\\}\\\\     \\vdots\\\\     \\tau^k_y &amp; := \\inf\\left\\{ t&gt;\\tau^{k-1}_y\\colon X_t=y \\right\\}\\\\     \\vdots \\end{align*} \\] <p>Here \\(\\tau^k_y\\) denotes the \\(k\\)-th return time to the state \\(y\\). Let further </p> \\[ \\begin{equation*}     \\rho_{xy}:=P^{x}\\left[ \\tau_y&lt;\\infty \\right] \\end{equation*} \\] <p>be the probability that starting from \\(x\\), the Markov chain visits the state \\(y\\) at least once,  where we denote the first return time as \\(\\tau_y = \\tau^1_y\\).</p> <p>Definition</p> <p>We say that a time homogeneous Markov chain is </p> <ul> <li>recurrent: if \\(\\rho_{xx}=1\\);</li> <li>transient: if \\(\\rho_{xx}&lt;1\\).</li> </ul> <p>Theorem</p> <p>For any two states \\(x\\) and \\(y\\) in \\(S\\), it holds</p> \\[ \\begin{equation*}     P^x[\\tau_y^k &lt; \\infty] = \\rho_{xy}\\rho_{yy}^{k-1}. \\end{equation*} \\] <p>Proof</p> <p>We show it per induction. Per definition, it holds \\(P^x[\\tau_y^1 &lt; \\infty]= \\rho_{xy}\\). Suppose therefore that the claim holds for every \\(l=1,\\ldots,k-1\\) and we show it for \\(k\\).</p> <p>Define \\(\\tau=\\tau_y^{k-1}\\) and \\(Z:=1_{\\{\\tau_y &lt; \\infty \\}}\\). It follows that \\(\\{ \\tau_y^k &lt; \\infty \\} = \\{ \\tau_y \\circ \\theta_\\tau &lt; \\infty \\}\\). Furthermore, from \\(1_{\\{\\tau&lt;\\infty\\}}\\) bounded and \\(\\mathcal{F}_{\\tau}\\)-measurable and \\(X_{\\tau}=y\\) on \\(\\{\\tau&lt;\\infty\\}\\), using the strong Markov property it follows that</p> \\[ \\begin{align*}     P^{x}[\\tau_y^k &lt; \\infty ] &amp;= P^{x}[\\tau_y \\circ \\theta_\\tau &lt; \\infty ]\\\\                               &amp;= E^x\\left[1_{\\{\\tau &lt; \\infty\\}}  (Z \\circ \\theta_\\tau) \\right]\\\\                               &amp;= E^x\\left[1_{\\{\\tau &lt; \\infty\\}}  E^x\\left[Z \\circ \\theta_\\tau| \\mathcal{F}_\\tau\\right]\\right]\\\\                               &amp;= E^x\\left[1_{\\{\\tau &lt; \\infty\\}}  E^{X_\\tau}\\left[Z\\right] \\right]\\\\                               &amp;= E^x\\left[1_{\\{\\tau &lt; \\infty\\}}  P^y[\\tau_y&lt;\\infty]\\right]\\\\                               &amp;= \\rho_{yy} P^x[\\tau_y^{k-1} &lt; \\infty]\\\\                               &amp;= \\rho_{yy} \\rho_{xy} \\rho_{yy}^{k-2}\\\\                               &amp;= \\rho_{xy} \\rho_{yy}^{k-1}. \\end{align*} \\] <p>Theorem</p> <p>Let \\(x\\) and \\(y\\) be two states in \\(S\\), where \\(x\\) is recurrent and \\(\\rho_{xy}&gt;0\\). Then \\(y\\) is recurrent and \\(\\rho_{yx}=1\\).</p> <p>Proof</p> <p>Let us first show that \\(\\rho_{yx}=1\\). Since \\(x\\) is recurrent, it follows that \\(\\tau_x(\\omega)&lt;\\infty\\) for almost all \\(\\omega \\in \\Omega\\). Hence, for almost all \\(\\omega \\in \\Omega\\) such that \\(\\tau_y(\\omega)&lt;\\infty\\) we get \\(\\tau_x \\circ \\theta_{\\tau_y}(\\omega) &lt;\\infty\\).</p> <p>Thus with \\(H:=1_{\\{\\tau_x=\\infty\\}}\\), the strong markov property, and the fact that \\(X_{\\tau_y}=y\\), we get</p> \\[ \\begin{align*}     0 &amp; =P^x[\\tau_y &lt; \\infty, \\tau_x \\circ \\theta_{\\tau_y} = \\infty]\\\\       &amp; =E^x\\left[1_{\\{\\tau_y&lt;\\infty\\}} 1_{\\{\\tau_x \\circ \\theta_{\\tau_y} = \\infty\\}} \\right]\\\\       &amp; =E^x\\left[1_{\\{\\tau_y&lt;\\infty\\}} E^{X_{\\tau_y}}\\left[H\\right] \\right]\\\\       &amp; =E^x\\left[1_{\\{\\tau_y&lt;\\infty\\}} P^y[\\tau_x=\\infty]\\right] \\\\       &amp; =\\rho_{xy}(1-\\rho_{yx}). \\end{align*} \\] <p>Since \\(\\rho_{xy} &gt; 0\\), it must be that \\(\\rho_{yx}=1\\).</p> <p>Let us finally show that \\(y\\) is recurrent. Let \\(i\\) and \\(j\\) be two states in \\(S\\) and \\(k\\) in\\(\\mathbb{N}\\). Then by Chapman-Kolmogorov relation and an induction we get \\(P_i[X_k=j]=p^k_{ij}\\). Since \\(\\rho_{xy}&gt;0\\) and \\(\\rho_{yx}&gt;0\\), there exist \\(k_1\\) and \\(k_2\\) in \\(\\mathbb{N}\\) with \\(p_{xy}^{k_1}&gt;0\\) and \\(p_{yx}^{k_2}&gt;0\\). By the Chapman-Kolmogorov relation we get</p> \\[ p_{yy}^{k_1+t+k_2} \\geq p_{yx}^{k_2} p_{xx}^t p_{xy}^{k_1} \\] <p>so that</p> \\[ E^y\\left[N_y\\right] =p_{yx}^{k_2} E^x\\left[N_x\\right]p_{xy}^{k_1} =\\infty. \\] <p>Recurrence/Transience Theorem implies that \\(y\\) is recurrent.</p> <p>Definition</p> <p>A set \\(C \\subseteq S\\) is called</p> <ul> <li>closed, if for \\(x\\in C\\), \\(y\\in S\\) and \\(\\rho_{xy}&gt;0\\) it holds \\(y \\in C\\),</li> <li>irreducible, if \\(\\rho_{xy}&gt;0\\) for all \\(x,y\\in C\\).</li> </ul> <p>Theorem</p> <p>Suppose \\(C \\subset S\\) is finite and closed.</p> <ul> <li>There exists \\(x\\in C\\) such that \\(x\\) is recurrent.</li> <li>If \\(C\\) is irreducible, then all its states are recurrent.</li> </ul> <p>Proof</p> <ul> <li> <p>By contradiction, assume that all states are transient, that is \\(E^x[N_y] &lt; \\infty\\) for all \\(x\\) and \\(y\\) in \\(C\\) by the recurrent/transient Theorem.     But then, since \\(C\\) is finite we get with Tonelli's theorem</p> \\[ \\sum_{y\\in C} E^x[N_y] =\\sum_{y\\in C} \\sum_{t} P^x [X_t=y] =\\sum_{t}\\sum_{y\\in C} P^x[X_t=y] =\\sum_{t} P^x [ X_t\\in C] =\\sum_{t} 1=\\infty. \\] <p>Indeed, if \\(P^x [X_t\\in C] &lt; 1\\), then there is \\(y\\) in \\(C^c\\) with \\(P^x[X_t=y] &gt;0\\), that is \\(\\rho_{xy} &gt;0\\). Since \\(C\\) is closed, it follows \\(y \\in C\\), a contradiction.</p> </li> <li> <p>If \\(x \\in C\\) is recurrent and \\(\\rho_{xy}&gt;0\\), then \\(y\\) is recurrent by Theorem the previous theorem.</p> </li> </ul> <p>Theorem</p> <p>Let \\(R:=\\{ x \\in S \\colon \\rho_{xx} =1  \\}\\) be the set of recurrent states. Then \\(R\\) is a disjoint union of closed and irreducible sets.</p> <p>Proof</p> <p>Fix \\(x\\) in$ R$ and let $C_x :={ y\\in R \\colon \\rho_{xy} &gt;0 } $.</p> <ul> <li> <p>For \\(x\\), \\(y\\) and \\(z\\) in \\(R\\) it holds \\(\\rho_{xy} \\geq \\rho_{xz} \\rho_{zy}\\).     Indeed, with \\(H:=1_{\\{\\tau_y &lt; \\infty\\}}\\) and the strong Markov property using the same argument as in recurrence Theorem we obtain</p> \\[ \\begin{align*}    \\rho_{xy}  &amp; =P^x[\\tau_y&lt;\\infty]\\\\               &amp; \\geq P^x[\\tau_z&lt;\\infty, \\tau_y \\circ \\theta_{\\tau_z} &lt; \\infty]\\\\               &amp; =E^x[1_{\\{\\tau_z &lt; \\infty\\}} E^x[H \\circ \\theta_{\\tau_z} | \\mathcal{F}_{\\tau_z}]]\\\\               &amp; =E^x[1_{\\{\\tau_z &lt; \\infty\\}}] E^z[1_{\\{\\tau_y &lt; \\infty\\}}]]\\\\               &amp; =\\rho_{xz}\\rho_{zy}. \\end{align*} \\] </li> <li> <p>\\(C_x\\) is irreducible and closed.     Indeed, for \\(y\\) in \\(C_x\\) and \\(\\rho_{yz} &gt;0\\), since \\(y\\) is in \\(C_x\\) we have \\(\\rho_{xy}&gt;0\\) and therefore by the previous step \\(\\rho_{xz} &gt;0\\), that is \\(z\\) belongs to \\(C_x\\).     Furthermore, for \\(y\\) and \\(z\\) in \\(C_x\\), it implies that \\(\\rho_{xy} &gt;0\\), \\(\\rho_{xz}&gt;0\\).     Recurrence Theorem yields \\(\\rho_{yx}&gt;0\\) and therefore \\(\\rho_{yz}&gt;0\\).</p> </li> <li> <p>We now show that \\(C_x \\cap C_y \\neq \\emptyset\\) implies \\(C_x=C_y\\).     Let \\(z\\) be in \\(C_x \\cap C_y\\) and \\(y^\\prime\\) in \\(C_y\\).     Therefore \\(\\rho_{xz}&gt;0\\), \\(\\rho_{yz}&gt;0\\), \\(\\rho_{yy^\\prime}&gt;0\\) and by recurrence Theorem \\(\\rho_{zy}&gt;0\\).     This means \\(\\rho_{xy^\\prime} &gt;0\\) which yields \\(y^\\prime\\in C_x\\), hence \\(C_y \\subset C_x\\).     Analogously, \\(C_x \\subset C_y\\).</p> </li> </ul> <p>Definition</p> <p>A measure \\(\\mu\\) on is called stationary\u2014or invariant\u2014if</p> <ul> <li>\\(\\mu(y)&lt; \\infty\\) for all \\(y \\in S\\),</li> <li>\\(\\mu(y)=\\sum_{x\\in S} \\mu(x)p_{xy}\\).</li> </ul> <p>If \\(\\mu\\) is a probability measure, then \\(\\mu\\) is called a stationary distribution.</p> <p>Remark</p> <p>Suppose that \\(\\mu\\) is a stationary distribution, and let \\(P^\\mu\\) the measure such that \\(X\\) is Markov with start distribution \\(\\mu\\). Then</p> \\[   \\begin{align*}      P^\\mu[X_1=y] &amp; = \\sum_{x\\in S}P^\\mu[X_1=y | X_0=x] P^\\mu[X_0=x]\\\\                   &amp; =\\sum_{x\\in S} \\mu(x) p_{xy}\\\\                   &amp; =\\mu(y)   \\end{align*} \\] <p>By induction, we assume that \\(P^\\mu[X_t=y]=\\mu(y)\\). Then</p> \\[   \\begin{align*}      P^\\mu[X_{t+1}=y] &amp; =\\sum_{z\\in S} P^\\mu[X_{t+1}=y|X_t=z]P^\\mu[X_t=z]\\\\                       &amp; =\\sum_{z\\in S} \\mu(z) p_{zy}\\\\                       &amp; =\\mu(y)   \\end{align*} \\] <p>This shows \\(P^\\mu(X_t=y) = \\mu(y)\\) for every \\(t\\).</p> <p>Example: Randomw Walk</p> <p>Let \\(X_t:=X_0+\\sum_{s=1}^{t} Y_s\\) and \\(\\mathcal{F}_t:=\\sigma(X_0,\\dots,X_t)\\). Then</p> \\[   \\begin{align*}      p_{xy} &amp; = P[X_{t+1}=y | X_t=x]=P[\\xi_{t+1}=y-X_t | X_t=x]\\\\             &amp; =P[\\xi_1=y-x]\\\\             &amp; =f(y-x)   \\end{align*} \\] <p>where \\(f \\colon S \\to [0,1]\\) is such that \\(\\sum_{y\\in S}f(y)=1\\), that is \\(f(y):=P[\\xi_1=y]\\). In this case \\(\\mu \\equiv 1\\) is a stationary measure. Indeed,</p> \\[   \\begin{align*}      \\sum_{x\\in S} \\mu(x)p_{xy}   &amp; = \\sum_{x\\in S} p_{xy}\\\\                                   &amp; = \\sum_{x\\in S} f(y-x) \\\\                                   &amp; =\\sum_{x^\\prime\\in S} f(x^\\prime) \\\\                                   &amp; =1\\\\                                   &amp; =\\mu(y)   \\end{align*} \\] <p>Remark</p> <p>Let \\(x\\in S\\) be transient and \\(\\pi\\) a stationary distribution. Then \\(\\pi(x)=0\\).</p> <p>Proof</p> <p>Exercise.</p> <p>Theorem</p> <p>Suppose \\(x\\) is recurrent and \\(\\tau:=\\inf\\{ t\\colon X_t = x \\}\\). Define</p> \\[ \\mu(y)=E^x\\left[\\sum_{t=0}^{\\tau-1}1_{\\{X_t=y\\}}\\right]=\\sum_{t} P^x[X_t=y, t&lt;\\tau] \\] <p>for all \\(y\\in S\\). Then \\(\\mu\\) is a stationary measure.</p> <p>Proof</p> <p>For \\(z\\) in \\(S\\) and \\(t\\) let \\(\\bar{p}_t(x,z):=P^x[X_t=z,\\tau&gt;t]\\). We claim that \\(\\sum_{t} \\bar{p}_t(x,\\cdot)\\) is a stationary measure.</p> <ul> <li> <p>For \\(z\\neq x\\) we have</p> \\[   \\begin{align*}      \\sum_{y\\in S} \\bar{p}_t(x,y) p_{yz}        &amp; = \\sum_{y\\in S} P^x[X_t=y, \\tau&gt;t] p_{yz} \\\\       &amp; = \\sum_{y\\in S} P^x(X_t=y,\\tau&gt;t,X_{t+1}=z]\\\\       &amp; = P^x[\\tau&gt;t+1,X_{t+1}=z]\\\\       &amp; =\\bar{p}_{t+1}(x,z)   \\end{align*} \\] <p>Hence,</p> \\[   \\begin{align*}      \\sum_{y\\in S}\\sum_{t} \\bar{p}_t(x,y)p_{yz}          &amp; = \\sum_{t}\\sum_{y\\in S} \\bar{p}_t(x,y)p_{yz}\\\\         &amp; = \\sum_{t} \\bar{p}_{t+1}(x,z)\\\\         &amp; = \\mu(z)   \\end{align*} \\] <p>since \\(\\bar{p}_0(x,z)=0\\).</p> </li> <li> <p>For \\(z=x\\) we have</p> \\[ \\sum_{y\\in S} \\bar{p}_t(x,y) p_{yx} = \\sum_{y\\in S} P^x[X_t=y,\\tau&gt;t,X_{t+1}=x] = P^x[\\tau=t+1]. \\] <p>Hence,</p> \\[ \\sum_{t}\\sum_{y\\in S} \\bar{p}_t(x,y)p_{yz} = \\sum_{t} P^x[\\tau=t+1] = 1 = \\mu(x). \\] </li> <li> <p>Finally we show that \\(\\mu(y)&lt;\\infty\\) for any \\(y\\) in \\(S\\).     We have \\(\\mu(x)=1\\), and \\(\\mu p^t=\\mu\\), showing that \\(\\mu(y)&lt;\\infty\\) if \\(p^t_{xy}&gt;0\\) for some \\(t\\).</p> <ul> <li>If \\(P^x[\\tau_y&lt;\\infty]=0\\), then \\(\\mu(y)=0\\).</li> <li>If \\(P^x[\\tau_y&lt;\\infty]&gt;0\\), then by recurrence Theorem we have \\(P^y[\\tau_x&lt;\\infty]&gt;0\\) so that \\(p_{yx}^t&gt;0\\) for some \\(t\\), hence \\(\\mu(y)&lt;\\infty\\).</li> </ul> </li> </ul>"},{"location":"lecture/05-Markov/053-brownian/","title":"Brownian Motion","text":"Note: Browninan Motion and Wiener Measure <p>The Brownian motion, named after the botanist Robert Brown, was first observed in 1827 when Brown noticed the erratic motion of pollen particles suspended in water. While Brown initially attributed this movement to some \"life force,\" it was later understood as a physical phenomenon resulting from molecular collisions.</p> <p>At the end of the 19th and the beginning of the 20th century, physicists such as Albert Einstein and Marian Smoluchowski provided theoretical models that linked Brownian motion to the kinetic theory of gases, demonstrating the random behavior of particles in a fluid. This work provided critical evidence for the atomic theory of matter.</p> <p>In spite of its success and applications, it tooks a century until a rigorous mathematical formulation and proof of the existence of Brownian motion as a stochastic process was achieved by Norbert Wiener in the 1930 ies. This layed the foundation for modern probability theory and the study of continuous-time stochastic processes. The resulting process, is now often called the Wiener process.</p> <p>The Brownian motion is one of the central objects of continuous time stochastic analysis. Though being classical and intuitive, it is not an easy object with fascinating mathematical properties.</p> <p>Definition: Brownian Motion</p> <p>Let \\((\\Omega,\\mathcal{F},P)\\) be a probability space. A stochastic process \\(B\\) is called a Brownian Motion if</p> <ul> <li>Independence of Increments: The increments \\(B_{t_n}-B_{t_{n-1}}\\), \\(B_{t_{n-1}}-B_{t_{n-2}}\\), \\(\\ldots\\), \\(B_{t_1}-B_{t_0}\\) are independent for every finite family \\(0\\leq t_0&lt;t_1&lt;\\ldots&lt;t_n\\).</li> <li>Normal Behavior of Increments: Increments are normally distributed \\(B_{t}-B_s\\sim \\mathcal{N}(0,t-s)\\).</li> <li> <p>Continuity of paths: (almost surely)</p> \\[ P\\left[ \\left\\{ \\omega \\colon t\\mapsto B_t(\\omega) \\text{ is continuous} \\right\\} \\right]=1 \\] </li> </ul> <p>Note that we do not require any filtration in the definition of the Brownian motion. As we will see later, we will often consider the filtration \\(\\mathcal{F}_t=\\sigma(B_s\\colon s\\leq t)\\) up to completion, and this filtration has particular properties.</p> <p>It is intuitive to see the Brownian motion as a scaling limit of a symmetric random wall\u2014and it actually is. However, one of the first questions to ask is whether such an object exists. Precisely, one asks if, for an adequate measurable space \\((\\Omega,\\mathcal{F})\\) and stochastic process \\(B\\), there exists a probability measure \\(P\\colon\\mathcal{F}\\to [0,1]\\) such that under \\(P\\), the stochastic process \\(B\\) is a Brownian motion. This measure is called the Wiener measure.</p> <p>There are several ways to construct such a measure, including a wavelet construction, a Hilbert space approach, or an appropriate scaling of the symmetric random walk together with some weak convergence. Hereafter, we will present a pure stochastic construction based on the Kolmogorov-Carath\u00e9odory extension theorem. It may be a little technical, but it has the advantage of presenting several important aspects of measure theory without relying on any advanced functional analysis assumptions.</p> <p>The construction will follow two important steps:</p> <ul> <li>Construction of a measure \\(P\\) on the path space such hat the canonical process \\(X\\) satisfies the two first properties. \\(\\leadsto\\) Kolmogorov extension Theorem.</li> <li>Modification of the Canonical process \\(X\\) to \\(B\\) such that \\(B\\) additionally satisfies the continuity property. \\(\\leadsto\\) Kolmogorov-Centov Theorem.</li> </ul>"},{"location":"lecture/05-Markov/053-brownian/#pre-brownian-motion-kolmogorov-caratheodory-extension-theorem","title":"Pre-Brownian Motion: Kolmogorov-Carath\u00e9odory extension Theorem","text":"<p>For a given index set \\(\\mathbf{T}\\), we consider \\((S,\\mathcal{S})\\) where \\(S\\) is a Polish space<sup>1</sup> with Borel \\(\\sigma\\)-algebra \\(\\mathcal{S}\\). For ease, you may assume that \\(S \\subseteq \\mathbb{R}^d\\) is a closed or open subset. The product of countable Polish spaces is Polish, on which according to Ulam, probability measures are regular.</p> <p>We recall the Ulam Theorem, see the section on measures.</p> <p>Ulam</p> <p>Let \\(P\\) be a probability measure on \\((S,\\mathcal{S})\\), then \\(P\\) is regular, that is</p> \\[   P\\left[ A \\right]=\\sup\\left\\{ P[K]\\colon K\\subseteq A, K\\text{ compact} \\right\\} \\] <p>for every Borel set \\(A\\subseteq S\\).</p> <p>Recall standard notations for the path space:</p> <ul> <li>Sample space given by \\(\\Omega :=\\{\\omega=(\\omega_t) :\\omega_t \\in  S \\text{ for all } t\\}=S^{\\mathbf{T}}\\).</li> <li>Coordinate process \\(X\\) given by \\(X_t(\\omega)=\\omega_t\\) for every \\(t\\) and \\(\\omega\\).</li> <li> <p>Projection For \\(F\\) and \\(G\\) subsets of \\(\\mathbf{T}\\) with \\(F\\subseteq G\\), define the projections:</p> \\[ \\begin{equation*}   \\begin{split}     \\pi_F \\colon \\Omega &amp; \\longrightarrow S^{F}\\\\                   \\omega &amp; \\longmapsto  \\pi_F(\\omega) = (\\omega_t)_{t\\in F}   \\end{split} \\end{equation*} \\] <p>and</p> \\[ \\begin{equation*}   \\begin{split}     \\pi_{GF} \\colon S^{G} &amp; \\longrightarrow S^{F}\\\\                   (\\omega_t)_{t \\in G} &amp; \\longmapsto  \\pi_{GF}\\left((\\omega_t)_{t \\in G}\\right) = (\\omega_t)_{t\\in F}   \\end{split} \\end{equation*} \\] <p>Note that for \\(F\\subseteq G\\), it holds that \\(\\pi_{GF}(\\pi_G) = \\pi_F\\) from which follows that the preimage satisfies \\(\\pi^{-1}_G(\\pi^{-1}_{GF}) = \\pi^{-1}_F\\).</p> </li> <li> <p>Algebra \\(\\mathcal{C}\\) of those sets \\(C=\\pi^{-1}_F(A)=\\{ \\omega \\in \\Omega\\colon (\\omega_{t_1},\\ldots,\\omega_{t_n})\\in A \\}=\\{(X_{t_1},\\ldots X_{t_n})\\in A\\}\\) where \\(A\\) is in the Borel \\(\\sigma\\)-algebra \\(\\mathcal{F}^F:=\\mathcal{B}(S^F)\\) and \\(F\\subseteq\\mathbf{T}\\) is finite.</p> </li> <li>Product \\(\\sigma\\)-Algebra \\(\\mathcal{F}=\\sigma(\\mathcal{C}) =\\otimes_{t \\in \\mathbf{T}}\\mathcal{S}\\)</li> </ul> <p>Consistent family</p> <p>A family \\((P_{F})\\) of probability measures \\(P_F:\\mathcal{F}^F\\to [0,1]\\) for every finite subset \\(F\\) of \\(\\mathbf{T}\\) is called consistent if</p> \\[   P_{F}(A)=P_{G}\\left( B \\right) \\] <p>for every \\(F\\subseteq G\\) and \\(A\\in \\mathcal{F}^F\\) where \\(B=\\pi_{GF}^{-1}(A)\\).</p> <p>We can now formulate the Kolmogorov extension theorem, a consequence of Carath\u00e9odory's Theorem.</p> <p>Kolmogorov Extension Theorem</p> <p>Let \\((P_F)\\) be a consistent family of Borel probability measures. Then, there exists a unique probability measure \\(P\\) on \\(\\mathcal{F}\\) such that</p> \\[ \\begin{equation*}     P(C)=P_F(A)     \\end{equation*} \\] <p>for every \\(A \\in \\mathcal{F}^F\\) where \\(C=\\pi^{-1}_F(A)\\).</p> <p>In other words, it is possible to construct a unique probability measure whose finite-dimensional restriction coincides exactly with each given finite-dimensional distribution \\(P_F\\), provided they are consistent with each other.</p> <p>Proof</p> <p>Note that for every finite family \\((C_k)_{k\\leq n}=(\\pi^{-1}_{F_k}(A_k))_{1\\leq k\\leq n}\\), if we define \\(F=\\cup_{k\\leq n}F_k\\) and \\(B_k=\\pi^{-1}_{FF_k}(A_k) \\in \\mathcal{F}^F\\), it follows that \\(C_k=\\pi^{-1}_{F}(B_k)\\). In particular, up to enlargement, we can always assume that we take a common finite family to represent the \\((C_k)\\). Furthermore, if the \\((C_k)\\) are disjoint, then so are the \\((B_k)\\).</p> <p>Step 1: Definition of \\(P\\) as a set function Define \\(P:\\mathcal{C}\\to [0,1]\\) by setting \\(P[C]=P_F(A)\\) where \\(C=\\pi^{-1}_F(A)\\) for \\(A\\in \\mathcal{F}^F\\). This function is well-defined due to consistency. Suppose \\(C=\\pi^{-1}_F(A)=\\pi^{-1}_{G}(B)\\) for \\(A\\) in \\(\\mathcal{F}^F\\) and \\(B\\) in \\(\\mathcal{F}^G\\). Then \\(D := \\pi^{-1}_{F\\cup G F}(A) = \\pi^{-1}_{F\\cup G G}(B)\\) and \\(\\pi^{-1}_{F\\cup G}(D)=C\\). By the consistency of the family, it follows that \\(P_F(A)=P_{F\\cup G}(D)=P_{G}(B)\\), confirming that \\(P\\) is well-defined.</p> <p>Step 2: \\(P\\) as an additive measure Clearly, \\(P[\\emptyset]=0\\) and \\(P[\\Omega]=1\\). As mentioned above, let \\((C_k)_{k\\leq n}=(\\pi^{-1}_{F}(A_k))_{k\\leq n}\\) be a finite disjoint family of elements in the algebra \\(\\mathcal{C}\\) with common finite set \\(F\\). Since \\(P_F\\) is a probability measure, it follows that</p> \\[ P\\left[\\cup_{k\\leq n} C_k\\right] = P_F\\left[\\cup_{k\\leq n} A_k\\right] = \\sum_{k\\leq n} P_F[A_k] = \\sum_{k\\leq n} P[C_k]. \\] <p>Therefore, \\(P\\) is an additive probability measure on the algebra \\(\\mathcal{C}\\).</p> <p>Step 3: \\(P\\) is \\(\\sigma\\)-additive Using continuity at \\(\\emptyset\\), let \\((C_n) = (\\pi^{-1}_{F_n}(A_n))\\) be a decreasing sequence of elements in \\(\\mathcal{C}\\) such that \\(\\cap C_n = \\emptyset\\) and suppose that \\(P[C_n] \\geq \\varepsilon &gt; 0\\) for some \\(\\varepsilon &gt; 0\\). Up to redefining \\(\\tilde{F}_n = \\cup_{k\\leq n}F_k\\) and \\(\\tilde{A}_n = \\pi^{-1}_{\\cup_{k\\leq n}F_k F_n}(A_n)\\), where \\(C_n = \\pi_{\\tilde{F}_n}(\\tilde{A}_n)\\) with \\(\\tilde{A}_n\\) in \\(\\mathcal{F}^{\\tilde{F}_n}\\), we may assume that \\((F_n)\\) is an increasing sequence of finite subsets of \\(\\mathbf{T}\\). Since \\((F_n)\\) is increasing and \\((C_n)\\) decreasing, it follows that \\(A_{n+1}\\subseteq \\pi_{F_{n+1}F_n}^{-1}(A_n)\\). By inner regularity of Borel probability measures on \\(\\mathbb{R}\\), we can find a sequence of compacts \\((\\tilde{K}_n)\\) such that \\(\\tilde{K}_n\\subseteq A_n\\) and \\(P_{F_n}[A_n\\setminus \\tilde{K}_n]\\leq \\varepsilon/2^{n+1}\\). However, we do not know whether this sequence of compacts fulfills the same monotonicity condition as \\((A_n)\\). We therefore shrink the compacts to </p> \\[ K_n=\\cap_{k\\leq n}\\pi^{-1}_{F_nF_k}(\\tilde{K}_k)\\subseteq \\tilde{K}_n \\] <p>ensuring \\(K_{n+1} \\subseteq \\pi^{-1}_{F_{n+1}F_n}(K_n)\\) for every \\(n\\). By construction,</p> \\[   \\begin{align*}      P_{F_n}\\left[ K_n \\right]        &amp; = P_{F_n}[A_n]-P_{F_n}[A_n\\setminus K_n]\\\\       &amp; \\geq \\varepsilon -P_{F_n}[A_n\\setminus \\cap_{k\\leq n}\\pi^{-1}_{F_nF_k}(\\tilde{K}_k)]\\\\       &amp; =\\varepsilon -P_{F_n}[\\cup_{k\\leq n} A_n\\setminus \\pi^{-1}_{F_nF_k}(\\tilde{K}_k)]\\\\       &amp; \\geq \\varepsilon -P_{F_n}[\\cup_{k\\leq n} \\pi^{-1}_{F_nF_k}(A_k\\setminus \\tilde{K}_k)]\\\\       &amp; \\geq \\varepsilon -\\sum_{k\\leq n}P_{F_n}[\\pi^{-1}_{F_nF_k}(A_k\\setminus \\tilde{K}_k)]\\\\       &amp; =\\varepsilon -\\sum_{k\\leq n}P_{F_k}[A_k\\setminus \\tilde{K}_k]\\\\       &amp; \\geq \\varepsilon -\\sum_{k=1}^{n}\\frac{\\varepsilon}{2^{k+1}}\\\\       &amp; \\geq \\frac{\\varepsilon}{2}   \\end{align*} \\] <p>In particular, each compact is non empty, so let \\(\\omega_n\\) be in \\(\\pi^{-1}_{F_n}(K_n)\\), that is \\(\\pi_{F_n}(\\omega_n)\\) is in \\(K_n\\). It holds from \\(K_n \\subseteq \\pi_{F_1}^{-1}(K_1)\\) that \\(\\pi_{F_1}(\\omega_n)\\in K_1\\) for every \\(n\\). By compactness of \\(K_1\\), we have for a subsequence, again denoted by \\((\\omega_n)\\), that \\(\\pi_{F_1}(\\omega_{n})\\to \\pi_{F_1}(\\bar{\\omega}_1)\\) some \\(\\bar{\\omega}_1\\) in \\(\\Omega\\). Further, from \\(K_n\\subseteq \\pi_{F_2}^{-1}(K_2)\\) we have for the same reason as before for a sub-subsequence also denoted by \\((\\omega_n)\\), that \\(\\pi_{F_2}(\\omega_n)\\to \\pi_{F_2}(\\bar{\\omega}_2)\\). Since \\(\\pi_{F_1}(\\bar{\\omega}_1)=\\pi_{F_1}(\\bar{\\omega}_2)\\), we deduce that the coordinates of \\(\\bar{\\omega}_2\\) and \\(\\bar{\\omega}_1\\) coincide on \\(F_1\\). Doing so forth, we can construct a point \\(\\bar{\\omega}\\) by setting arbitrarily points on \\((\\cup F_n)^c\\) such that \\(\\pi_{F_n}(\\bar{\\omega})=\\pi_{F_n}(\\bar{\\omega}_n)\\) for every \\(n\\). It follows in particular that \\(\\bar{\\omega}\\in \\pi^{-1}_{F_n}(K_n)\\subseteq C_n\\) for every \\(n\\) showing that \\(\\cap C_n\\neq \\emptyset\\), contradicting our initial assumption that \\(\\cap C_n = \\emptyset\\).</p> <p>Step 4: Carath\u00e9odory's Extension Theorem Since \\(P\\) is a \\(\\sigma\\)-additive probability measure on the algebra \\(\\mathcal{C}\\), by Carath\u00e9odory's Theorem, it can be uniquely extended to \\(\\mathcal{F}=\\sigma(\\mathcal{C})\\), hence the theorem.</p> <p>Example: Existence of iid Sequences and Henceforth a Random Walk</p> <p>We can apply Kolmogorov's extension theorem to show the existence of iid desquences and henceforth a Random Walk. Let \\(S = \\{-1, 1\\}\\), which is a closed subset of \\(\\mathbb{R}\\) with the Borel \\(\\sigma\\)-algebra \\(\\mathcal{S}\\), which reduces to \\(2^S\\). Let \\(\\mathbb{T} = \\mathbb{N}_0\\) and \\(0&lt;p&lt;1\\). For every finite subset \\(F = \\{t_0 &lt; t_1 \\ldots &lt; t_n\\} \\subset \\mathbb{N}_0\\), define</p> \\[   P_F\\left[ (\\omega_{t_1},\\ldots, \\omega_{t_n})=(e_1,\\ldots, e_n) \\right] = p^l(1-p)^{n-l}, \\] <p>where \\(e_i \\in \\{-1, 1\\}\\) for every \\(i\\), and \\(l = \\#\\{ i \\colon e_i = 1, i = 1, \\ldots, n \\}\\), which defines a probability measure on \\(\\mathcal{F}^F = \\otimes_F \\mathcal{S}\\).</p> <p>It is straightforward to check that the family \\((P_F)\\) is a consistent family of probability measures. By Kolmogorov's extension theorem, there exists a unique probability measure on \\(S^{\\mathbf{T}} = \\{-1, 1\\}^{\\mathbb{N}_0}\\) with the product \\(\\sigma\\)-algebra such that</p> \\[   P[B] = P_F[A]  \\] <p>where \\(B = \\pi^{-1}_F(A)\\) for any \\(F \\subseteq \\mathbb{N}_0\\) finite and \\(A\\) in \\(\\mathcal{F}^F\\). In particular,</p> \\[   P[X_t = 1] = P_{\\{t\\}}[\\omega_t = 1] = p \\quad \\text{and} \\quad P\\left[ X_t = -1 \\right] = 1 - p. \\] <p>A straightforward computation shows that the canonical process \\(X\\) is a sequence of i.i.d. random variables. As seen before, it is also a Markov process.</p> <p>Doing so, the random walk \\(S_0 =0\\) and \\(S_t = \\sum_{s=1}^t X_s\\) is well defined.</p> <p>With this extension theorem at hand, we can therefore construct a pre-Brownian motion.</p> <p>Proposition: Existence of a Pre-Brownian Motion</p> <p>Taking \\(S = \\mathbb{R}\\) and \\(\\mathbf{T} = [0, \\infty)\\), with the notations of the sample space here above, there exists a probability measure on \\(\\mathcal{F}\\) such that \\(X\\) is, up to continuity of paths, a Brownian motion.</p> <p>Proof</p> <p>For the sample space \\(\\Omega =\\mathbb{R}^{[0,\\infty)}\\) with the \\(\\sigma\\)-algebra \\(\\mathcal{F}=\\sigma(\\mathcal{C})\\) where \\(\\mathcal{C}\\) is the collection of those \\(C=\\pi_{F}^{-1}(A)\\) for \\(A\\) in \\(\\mathcal{B}(\\mathbb{R}^F)\\), \\(F=\\{t_0, t_1,\\ldots,t_n\\}\\) for \\(0&lt; t_0&lt;t_1&lt; \\ldots&lt;t_n\\), we define the conditional probability distribution</p> \\[   p(t,x,y)=\\frac{1}{\\sqrt{t2\\pi}}\\exp\\left( -\\frac{(x-y)^2}{2t} \\right) \\] <p>for \\(t&gt;0\\) and \\(x\\), \\(y\\) in \\(\\mathbb{R}\\). For \\(x=(x_1,\\ldots,x_n)\\) we set the cumulative distribution </p> \\[ P_F\\left[ X_{t_0}\\leq x_0, \\ldots, X_{t_n}\\leq x_n \\right] =\\int_{-\\infty}^{x_0}\\int_{-\\infty}^{x_1}\\ldots \\int_{-\\infty}^{x_n}p(t_0,0,y_0)p(t_1-t_0,y_0,y_1)\\ldots p(t_n-t_{n-1},y_{n-1},y_n)dy_0\\ldots dy_{n}    \\] <p>For \\(F\\subseteq G\\subseteq \\mathbf{T}\\) both finite set and \\(A \\in \\mathcal{B}(\\mathbb{R}^F)\\), it holds \\(D=\\pi_{GF}^{-1}(A)\\approx \\mathbb{R}^{G\\setminus F}\\times A\\) where \\(\\approx\\) stands for reordering of the coordinates of \\(G\\) along those who belong to \\(F\\). It follows that</p> \\[ P_{F}\\left[ A \\right]=\\int_{A}^{}dP_{F}=\\int_{A}^{}\\int_{\\mathbb{R}^{G\\setminus F}}^{}dP_{F}dP_{G\\setminus F}=\\int_{D}^{}dP_{G}=P_{G}[D]  \\] <p>showing that \\((P_{F})\\) is a consistent family of probability measures. Hence, by Kolmogorov extension's theorem, it follows that it can uniquely be extended to \\(\\Omega\\) and it holds</p> \\[ P\\left[ X \\in \\pi_{F}^{-1}(A) \\right]=P_{F}\\left[ A \\right] \\] <p>for any \\(A\\) in \\(\\mathcal{F}^{F}\\) where $F={t_0,t_1,\\ldots, t_n} with \\(0&lt; t_0&lt; t_1&lt;\\ldots&lt;t_n\\).</p> <p>Let us show that \\(X\\) under \\(P\\) fulfills the first two properties of a Brownian motion. As for the first property, it holds that</p> \\[   \\begin{align*}      P\\left[ X_t-X_s \\leq x \\right]   &amp; =P_{\\{s,t\\}}\\left[ \\{(x_1,x_2)\\in \\mathbb{R}^2 \\colon x_2\\leq x+x_1\\} \\right]\\\\                                       &amp; =\\int_{\\mathbb{R}}^{}\\int_{-\\infty}^{x+y_1}p(s,0,y_1)p(t-s,y_1,y_2)dy_1dy_2\\\\                                        &amp; =\\int_{\\mathbb{R}}^{}\\int_{-\\infty}^{x}p(s,0,y_1)p(t-s,y_1,y_2-y_1)dy_1dy_2\\\\                                       &amp; =\\int_{-\\infty}^{x}p(t-s,0,y_2)dy_2   \\end{align*} \\] <p>showing that \\(X_t-X_s\\sim \\mathcal{N}(0,t-s)\\).</p> <p>As for the independence, \\((X_{t_n}-X_{t_{n-1}}, \\ldots, X_{t_1}-X_{t_0})\\) is a Gaussian vector for every finite \\(0\\leq t_0&lt;\\ldots&lt; t_n\\). Indeed, by the definition of \\(P\\), every linear combination of them yields a normal distribution -- check it as an exercise. Hence, being a Gaussian vector, it is enough to check that their covariance is equal to \\(0\\).</p> <p>We check it for \\(n=2\\), and the general case being left to you. By obvious variable change we have</p> \\[   \\begin{align*}      E\\left[ (X_{t_{2}}-X_{t_1})(X_{t_1}-X_{t_0}) \\right]         &amp; = \\int_{\\mathbb{R}^4} \\left( x_3-x_2 \\right)\\left( x_1-x_0 \\right)p(t_0,0,x_0)p(t_0-t_1,x_0,x_1)p(t_1-t_2,x_1,x_2)p(t_3-t_2,x_2,x_3)dx_0dx_1dx_2dx_3\\\\         &amp; =\\int_{\\mathbb{R}^2} y_1 y_2 p(t_1-t_0,0,y_1)p(t_3-t_2,0,y_2)dy_1dy_2\\\\         &amp; =0   \\end{align*} \\] <p>finishing the proof.</p>"},{"location":"lecture/05-Markov/053-brownian/#continuity-of-paths-kolmogorov-centov-theorem","title":"Continuity of Paths: Kolmogorov-\u010centov Theorem","text":"<p>As for the continuity, we should prove that</p> \\[   P[\\{\\omega \\colon t\\mapsto X_t(\\omega)\\text{ is continuous}\\}]=1 \\] <p>to ensure that we have a Brownian motion. Since \\(X\\) is the canonical process, it follows that \\(\\{\\omega \\colon t\\mapsto X_t(\\omega)\\text{ is continuous}\\}\\) is exactly the set \\(C[0,t)\\subseteq \\mathbb{R}^{[0,\\infty)}\\) of continuous functions. A naive way to show this would be to show that \\(P\\) assigns probability one to the subset \\(C[0,t)\\subseteq \\mathbb{R}^{[0,\\infty)}\\) of continuous functions. In that case, it would follow that almost all the paths of \\(X\\) are concentrated under \\(P\\) in the space of continuous functions. This strategy is hopeless as the following proposition shows.</p> <p>Proposition</p> <p>The set of continuous functions is not a measurable set for the product \\(\\sigma\\)-algebra of \\(\\mathbb{R}^{[0,\\infty)}\\).</p> Proof <p>Intuitively, it follows from the fact that measurable sets of \\(\\mathbb{R}^{[0,\\infty)}\\) for the product \\(\\sigma\\)-algebra are generated by finite-dimensional ones of the form</p> \\[   C=\\{\\omega \\colon \\omega_{t_0}\\in A_0, \\ldots, \\omega_{t_n}\\in A_n\\}, \\quad A_k \\in \\mathcal{B}(\\mathbb{R}) \\] <p>As an exercise, try to show why this proposition holds.</p> <p>To overcome this difficulty, we will modify the canonical process \\(X\\) to another process \\(B\\) which has continuous paths with probability \\(1\\), that is construct a version of the Brownian motion that has continuous paths.</p> <p>Definition: Modification vs Indistinguishable</p> <p>Let \\((\\Omega, \\mathcal{F}, P)\\) be a probability space and \\(X\\) and \\(Y\\) be two stochastic processes. We say that</p> <ul> <li> <p>\\(X\\) is a modification of \\(Y\\) if</p> \\[   P\\left[ X_t = Y_t \\right] = 1 \\text{ for any }t \\text{ in }\\mathbf{T} \\] </li> <li> <p>\\(X\\) is indistinguishable from \\(Y\\) if</p> \\[   P\\left[ \\{ \\omega\\colon X_t(\\omega) = Y_t(\\omega) \\text{ for all }t \\text{ in }\\mathbf{T}\\}\\right] = 1 \\] </li> </ul> <p>Remark</p> <p>Clearly, indistinguishable implies modification. If \\(\\mathbf{T}\\) is countable, then the reciprocal is true as</p> \\[     P[\\{ \\omega\\colon X_t(\\omega) \\neq Y_t(\\omega) \\text{ for some }t \\text{ in }\\mathbf{T}\\}] = P\\left[ \\cup_{t \\in \\mathbf{T}} \\{X_t \\neq Y_t\\} \\right] \\leq \\sum_{t \\in \\mathbf{T}} P[X_t \\neq Y_t] = 0 \\] <p>If \\(\\mathbf{T}\\) is not countable, then \\(\\cup_{t \\in \\mathbf{T}}\\{X_t\\}\\) is not a countable union of measurable sets and we can not apply subadditivity. The following counter example illustrate this fact.</p> <p>Let \\(\\Omega = [0,1]^{\\mathbf{T}}\\) and \\(\\mathcal{F} = \\otimes_{t \\in \\mathbf{T}} \\mathcal{B}([0,1])\\) for \\(\\mathbf{T} = [0,1]\\). As for the measure we consider the product measure such that each marginal is equal to lebesgue. Define the two processes</p> \\[     X_t \\equiv 0 \\quad \\text{and}\\quad Y_t (\\omega) =        \\begin{cases}       0 &amp; \\text{if }\\omega \\neq t\\\\       \\omega &amp; \\text{if }\\omega = t       \\end{cases} \\] <p>This defines two stochastic processes. Clearly, for every \\(t\\), the two processes differes only on one point which is of lebesgue measure \\(0\\). Hence they are modifications of each others. However \\(\\{\\omega\\colon X_t(\\omega) = Y_t(\\omega)\\text{ for all }0\\leq t\\leq 1\\} = \\emptyset\\). </p> <p>If \\(P\\) is a probability measure on the path space such that \\(X\\) is a pre-Brownian motion and \\(B\\) is a modification of \\(X\\), then \\(B\\) is a pre Brownian motion as well as it only involves finitely many marginals. The goal is therefore to find a modification \\(B\\) of \\(X\\) such that \\(P[\\{\\omega\\colon t \\mapsto B_t(\\omega) \\text{ is continuous }\\}] = 1\\) which is a consequence of the following theorem</p> <p>Kolmogorov-\u010centov</p> <p>Let \\((\\Omega,\\mathcal{F},P)\\) be a probability space and \\(\\tilde{X}=(\\tilde{X}_{t})_{0\\leq t\\leq T}\\) be a stochastic process. Suppose that</p> \\[   E\\left[ |\\tilde{X}_t-\\tilde{X}_s|^{\\alpha} \\right]\\leq C|t-s|^{1+\\beta} \\] <p>for every \\(s&lt;t\\leq T\\) and some strictly positive constants \\(\\alpha,\\beta\\), and \\(C\\). Then \\(\\tilde{X}\\) admits a continuous modification \\(X\\) which is locally H\u00f6lder continuous for every exponent \\(0&lt;\\gamma&lt;\\beta/\\alpha\\), that is</p> \\[   P\\left[ \\left\\{ \\omega \\colon \\sup_{0&lt;t-s&lt;h(\\omega), t,s\\leq T}\\frac{|X_t(\\omega)-X_s(\\omega)|}{|t-s|^\\gamma}\\leq \\delta \\right\\} \\right]=1 \\] <p>where \\(h\\) is an almost surely strictly positive random variable and \\(\\delta&gt;0\\).</p> <p>Proof</p> <p>We show it for \\(T=1\\) and define \\(\\Pi^n=\\{k/2^n\\colon k=0,\\ldots,2^n\\}\\) as well as \\(\\Pi=\\cup \\Pi^n\\), the sequence of dyadic numbers in \\([0,1]\\).</p> <ul> <li> <p>Step 1: H\u00f6lder continuity restricted to \\(\\Pi^n\\)     Denote by</p> \\[   A_n = \\max_{\\substack{s,t \\in \\Pi^n\\\\ |t-s|\\leq 2^{-n}}}|\\tilde{X}_t-\\tilde{X}_s|\\geq 2^{-n\\gamma} \\] <p>By Markov's inequality,</p> \\[   P[|\\tilde{X}_t-\\tilde{X}_s|\\geq \\varepsilon] \\leq \\frac{1}{\\varepsilon^\\alpha} E[|\\tilde{X}_t-\\tilde{X}_s|^\\alpha] \\leq C \\varepsilon^{-\\alpha}|t-s|^{1+\\beta}. \\] <p>Hence for \\(0&lt;\\gamma &lt; \\beta/\\alpha\\) and \\(\\varepsilon=2^{-\\gamma n}\\), it holds</p> \\[ \\begin{align*}    P\\left[ A_n \\right]      &amp; = P\\left[ \\bigcup_{k=1}^{2^n}\\left\\{ |\\tilde{X}_{k/2^n}-\\tilde{X}_{(k-1)/2^n}|\\geq 2^{-n\\gamma} \\right\\} \\right]\\\\     &amp; \\leq \\sum_{k=1}^{2^n}P\\left[ |\\tilde{X}_{k/2^n}-\\tilde{X}_{(k-1)/2^n}|\\geq 2^{-n\\gamma} \\right]\\\\     &amp; \\leq C\\sum_{k=1}^{2^n} 2^{-n(1+\\beta-\\alpha\\gamma)}\\\\     &amp; =C2^{-n(\\beta-\\alpha \\gamma)} \\end{align*} \\] <p>Since \\(\\beta-\\alpha \\gamma &gt;0\\) by the very choice of \\(\\gamma\\), it follows from Borel-Cantelli that</p> \\[ P\\left[\\limsup A_n \\right] = P\\left[ \\bigcap_n \\bigcup_{k\\geq n} A_k \\right]=0 \\] <p>In other terms, for each \\(\\omega\\) out of a set \\(\\mathcal{N}\\) of zero measure, it holds that \\(1_{\\cap_{k \\geq n} }A_k^c (\\omega) \\rightarrow 1\\). Denote by  </p> \\[ n_0\\left( \\omega \\right) = \\inf\\left\\{ n \\in \\mathbb{N}\\colon 1_{ \\cap_{k\\geq n}A_k^c}(\\omega)\\geq \\frac{1}{2}\\right\\} \\] <p>it follows that \\(n_0\\) is a random variable finite on \\(\\Omega \\setminus \\mathcal{N}\\). Hence  </p> \\[ \\max_{\\substack{s,t \\in \\Pi^n\\\\ |t-s|\\leq 2^{-n}}}|\\tilde{X}_t(\\omega)-\\tilde{X}_s(\\omega)|&lt; 2^{-n\\gamma} \\] <p>for all \\(n\\) greater than \\(n_0(\\omega)\\).</p> </li> <li> <p>Step 2: H\u00f6lder continuity restricted to \\(\\Pi\\).  </p> <p>Fixing \\(\\omega\\) outside of \\(\\mathcal{N}\\), some integer \\(n\\), we first show per induction that for every \\(m\\) greater than \\(n+1\\) it holds  </p> \\[ |\\tilde{X}_t(\\omega)-\\tilde{X}_s(\\omega)|\\leq 2 \\sum_{k=n+1}^{m} 2^{-\\gamma k} \\] <p>for every two \\(s\\) and \\(t\\) in \\(\\Pi^m\\) with \\(|t-s| &lt;2^{-n}\\).</p> <ul> <li> <p>For \\(m=n+1\\), from \\(|t-s|&lt;2^n\\), we can only have \\(s=(k-1)/2^{n+1}\\) and \\(t=k/2^{n+1}\\) for some \\(k\\in \\{1,\\ldots, 2^{n+1}\\}\\).   Applying the relations from the previous steps the recursion hypothesis follows immediately for \\(m=n+1\\).</p> </li> <li> <p>Suppose that the recursion assumption holds up to \\(m-1\\) for \\(m\\geq n+1\\), and let us show that it follows for \\(m\\).   For \\(s&lt;t\\) with \\(s,t\\) in \\(\\Pi^m\\) and \\(|t-s|&lt;2^n\\), we define \\(s_1=\\min\\{\\tilde{s}\\in \\Pi^{m-1}\\colon \\tilde{s}\\geq s\\}\\) and \\(t_1=\\max\\{\\tilde{t}\\in \\Pi^{m-1}\\colon \\tilde{t}\\leq t\\}\\).   It follows that \\(s\\leq s_1\\leq t_1\\leq t\\), \\(s_1,t_1\\) are in \\(\\Pi^{m-1}\\) with \\(|t_1-s_1|\\leq 2^n\\) and \\(|t-t_1|\\leq 2^{m}\\) and \\(|s_1-s|\\leq 2^{m}\\).   From the previous step, it follows that \\(|\\tilde{X}_t(\\omega)-\\tilde{X}_{t_1}(\\omega)| \\leq 2^{-\\gamma m}\\) and \\(|\\tilde{X}_{s_1}(\\omega)-\\tilde{X}_s(\\omega)|\\leq 2^m\\).   From the recursion hypothesis it also holds \\(|\\tilde{X}_{t_1}(\\omega)-\\tilde{X}_{s_1}(\\omega)|\\leq 2\\sum_{k=n+1}^{m-1} 2^{-\\gamma k}\\).   These three inequalities together with the triangular inequality yields </p> \\[ \\begin{align*} |\\tilde{X}_t(\\omega)-\\tilde{X}_s(\\omega)|    &amp; \\leq |\\tilde{X}_t(\\omega)-\\tilde{X}_{t_1}(\\omega)|+|\\tilde{X}_{t_1}(\\omega)-\\tilde{X}_{s_1}(\\omega)|+|\\tilde{X}_{s_1}(\\omega)-\\tilde{X}_s(\\omega)|\\\\   &amp; \\leq 2^{-\\gamma m}+2\\sum_{k=n+1}^{m-1} 2^{-\\gamma k}+2^{-\\gamma m}\\\\   &amp; =2\\sum_{k=n+1}^{m} 2^{-\\gamma k} \\end{align*} \\] <p>ending the proof of the recursion.</p> </li> </ul> <p>Now for every \\(t\\) and \\(s\\) in \\(\\Pi\\) with \\(0&lt;|t-s|&lt; h(\\omega)\\) where \\(h(\\omega)=2^{-n_0(\\omega)}\\), we pick \\(n\\geq n_0(\\omega)\\) such that \\(2^{-(n+1)}\\leq |t-s|&lt; 2^{n}\\). From the result of the recursion, and \\(\\gamma&gt;0\\), we get</p> \\[   \\begin{align*}      |\\tilde{X}_t(\\omega)-\\tilde{X}_s(\\omega)|         &amp; \\leq 2\\sum_{k=n+1}^{\\infty} 2^{-\\gamma k}\\\\         &amp; =\\frac{2}{1-2^{-\\gamma}}2^{-\\gamma (n+1)}\\\\         &amp; \\leq \\delta |t-s|^{\\gamma}   \\end{align*} \\] <p>for every \\(t\\) and \\(s\\) in $\\Pi with \\(0&lt;|t-s|&lt;h(\\omega)\\) where \\(\\delta = 2/(1-2^{-\\gamma})\\), showing that \\(t \\mapsto \\tilde{X}_t(\\omega)\\) is uniformly H\u00f6lder continuous of order \\(\\gamma\\) on \\(\\Pi\\).</p> </li> <li> <p>Step3: Definition of the continuous version \\(X\\).  </p> <p>For \\(\\omega\\) in \\(\\mathcal{N}\\) we set \\(X(\\omega)=0\\). For \\(\\omega\\) outside of \\(\\mathcal{N}\\), and \\(t\\) we pick a sequence \\((s_n)\\) of elements in \\(\\Pi\\) converging to \\(t\\) which by the uniform continuity of \\(\\tilde{X}(\\omega)\\) on \\(\\Pi\\) yields a limit \\(X_t(\\omega)=\\lim \\tilde{X}_{s_n}(\\omega)\\) independent of the choice of the sequence \\((s_n)\\) in \\(\\Pi\\) converging to \\(t\\). It follows that \\(X\\) has continuous paths. Defined as a limit of sequence of random variables, it follows also that \\(X\\) is a process. Given \\(\\delta&gt;0\\) and \\(t\\), for \\(|t-s|\\leq \\gamma\\) from triangular as well as Markov inequality, it holds</p> \\[   \\begin{align*}     P\\left[ |X_t - \\tilde{X}_t|&gt;\\delta \\right] &amp; \\leq P\\left[ |X_t - X_s|geq \\delta \\right] + P\\left[ |X_s - \\tilde{X}_s|\\geq \\delta \\right]    \\end{align*} \\] <p>Finally, \\(\\{X_t=\\tilde{X}_t\\}\\) is contained in the set of those \\(\\omega\\) such that \\(\\tilde{X}_{s_n}(\\omega)\\) has a limit for some sequence \\((s_n)\\) in \\(\\Pi\\) converging to \\(t\\), it follows that \\(\\{X_t = \\tilde{X}_t\\}\\supseteq \\mathcal{N}^c\\). Hence \\(P[X_t=\\tilde{X}_t]\\geq P[\\mathcal{N}^c]=1\\) showing that \\(X\\) is a version of \\(\\tilde{X}\\) which ends the proof of the Theorem.</p> </li> </ul> <p>Proposition</p> <p>There exists a probability space \\((\\Omega,\\mathcal{F},P)\\) and a stochastic process \\(B\\) such that \\(B\\) is a Brownian motion.</p> <p>Proof</p> <p>As seen is a proposition above consequence of Kolomogorov extension theorem, we can construct a probability measure \\(P\\) on the canonical space \\((\\Omega,\\mathcal{F})\\) such that the canonical process \\(X\\) is a pre-brownian motion. To verify the conditions of Kolmogorov- \u010centov's Theorem, recall that if a random variable \\(Y \\sim \\mathcal{N}(0,\\sigma^2)\\), then it holds that \\(E[Y^{2n}] = \\sigma^n(2n-1)(2n-3)\\ldots\\). Since \\(X_t-X_s \\sim \\mathcal{N}(0,t-s)\\), it follows that</p> \\[ E\\left[ \\left| X_t-X_s \\right|^{2n} \\right]=C_n|t-s|^{n} \\] <p>where \\(C_n = (2n-1)(2n-3)\\ldots\\). Hence, for \\(\\beta_n = n-1\\) and \\(\\alpha_n = 2n\\), it follows that we can find a continuous version \\(B\\) of \\(X\\) locally H\u00f6lder continuous of order \\(0&lt;\\gamma &lt; \\beta_n/\\alpha_n=1/2-1/(2n)\\) for every \\(n\\). The continuous version \\(B\\) having the same finite dimensional distribution properties as \\(X\\) we deduce that \\(B\\) is a Brownian motion.</p> <p>Proposition</p> <p>Almost all paths of the Brownian motion are nowhere locally H\u00f6lder continuous of order \\(\\gamma&gt;1/2\\). In particular, they are nowhere differentiable.</p> <p>Proof</p> <p>Homework sheet.</p> <p>Some properties of the Brownian motion.</p> <p>Proposition</p> <p>Let \\(B\\) be a Brownian motion. Then the following processes:</p> <ol> <li>\\(B_{s+\\cdot}-B_s\\) is a Brownian motion independent of \\(\\sigma(B_u\\colon u\\leq s)\\);  </li> <li>\\(-B\\) is a Brownian motion;  </li> <li>\\(\\sigma B_{\\cdot / \\sigma^2}\\) is a Brownian motion for every \\(\\sigma &gt; 0\\);  </li> <li>\\(X_0 = 0\\) and \\(X_t = t B_{1/t}\\) for \\(t &gt; 0\\) is a Brownian motion.  </li> </ol> <p>Proof</p> <p>Is left as an exercise of the homework sheet.</p> <ol> <li> <p>A complete metric space which is separable.\u00a0\u21a9</p> </li> </ol>"},{"location":"lecture/06-Continuous-Time/060-introduction/","title":"Continuous Time Processes: Lebesgue-Stieljes Integral, Martingales","text":"<p>In this Chapter we will extend the notion of stochastic processes to the continuous time setting, that is, processes where time takes positive real values. Throughout, \\((\\Omega, \\mathcal F, P)\\) denotes a probability space. Unless otherwise specified, stochastic processes are always implicitly considered as indexed by time \\(0\\leq t &lt; \\infty\\).</p> <p>Warning</p> <p>Unless otherwize specified, the letters \\(q\\) and \\(r\\) used for time means that they are rational.</p> <ul> <li>Continuous Time Processes</li> <li>Lebesgue-Stieljes Integral</li> <li>Martingales</li> </ul>"},{"location":"lecture/06-Continuous-Time/061-continuous-time-processes/","title":"Continuous Time Processes: Regularity, Filtration, Stopping Times","text":"<p>Warning</p> <p>Unless otherwize specified, the letters \\(q\\) and \\(r\\) used for time means that they are rational.</p> <p>Definition</p> <p>Let \\(X\\) and \\(Y\\) be two processes. We say that</p> <ul> <li>\\(X\\) is a modification of \\(Y\\) if \\(X_t=Y_t\\) \\(P\\)-almost surely for every \\(t\\), that is</li> </ul> \\[ P[X_t=Y_t]=1,\\quad \\text{for every }t. \\] <ul> <li>\\(X\\) is indistinguishable from \\(Y\\) if \\(X_t=Y_t\\) for all \\(t\\), \\(P\\)-almost surely, that is</li> </ul> \\[ P[X_t=Y_t; \\text{ for every }t]=1. \\] <p>In the case where the stochastic process is indexed by a countable set, these two notions are equivalent. However, if it is indexed by \\(t\\) in \\([0, \\infty)\\) of any uncountable directed set, modification and indistinguishability are different in that we may have to take into account uncountably many null sets as the following example shows.</p> <p>Example</p> <p>Set \\((\\Omega, \\mathcal{F},P):=([0,1], \\mathcal{B}([0,1]),dt)\\), where \\(dt\\) is the Lebesgue measure and \\(\\mathcal{B}([0,1])\\) is the Borel \\(\\sigma\\)-algebra. Define the processes \\(X\\) and \\(Y\\) by</p> \\[ X_t=0\\quad\\text{and}\\quad Y_t= \\begin{cases}     Y_t(\\omega)=1&amp; \\text{if }\\omega = t\\\\     Y_t(\\omega)=0 &amp; \\text{otherwise} \\end{cases} \\] <p>for every \\(0\\leq t\\leq 1\\). It follows that </p> \\[   P[X_t=Y_t]=P[ \\{\\omega\\in [0,1]\\colon \\omega\\neq t\\}]=1 \\] <p>whereas </p> \\[   P[X_t=Y_t\\colon\\text{ for every }t]=P[\\{\\omega \\in [0,1]\\colon \\omega\\neq t\\text{ for every }t\\}]=P[\\emptyset]=0 \\] <p>We see that uncountably many sets of measure zero can add up to something that may no longer have measure zero. However, if we can infer from the structure of the trajectories that it is sufficient to consider countably many times, then these two conditions will coincide again.</p> <p>We say that a process \\(X\\) has</p> <ul> <li> <p>des limites \u00e0 gauche(1) (l\u00e0g) if </p> \\[ P\\left[\\liminf_{s\\nearrow t}X_s=\\limsup_{s\\nearrow t}X_s: \\text{ for every }t&gt;0\\right]=1, \\] </li> <li> <p>des limites \u00e0 droite (l\u00e0d) if</p> \\[ P\\left[\\liminf_{s\\searrow t}X_s=\\limsup_{s\\searrow t}X_s:\\text{ for every }t\\right]=1, \\] </li> <li> <p>continue \u00e0 gauche (c\u00e0g) if</p> \\[ P\\left[\\lim_{s\\nearrow t}X_s=X_t: \\text{ for every }t&gt;0, t\\in \\mathbf{T}\\right]=1, \\] </li> <li> <p>continue \u00e0 droide (c\u00e0d) if</p> \\[ P\\left[\\lim_{s\\searrow t}X_s=X_t:\\text{ for every }t&lt;T, t \\in \\mathbf{T}\\right]=1, \\] </li> </ul> <p>Note</p> <p>The notations l\u00e0g, l\u00e0d, c\u00e0d, or c\u00e0g comes from french where \"gauche\" stands for \"left\", \"droite\" stands for \"right\", \"limites\" stands for \"limits\" and \"continue\" stands for \"continuous\". In some Americanized textbooks, \"ll\" stands for \"l\u00e0g\", \"lr\" stands for \"l\u00e0d\", \"rc\" stands for \"c\u00e0d\", or \"lc\" stands for \"c\u00e0g\".</p> <p>A process \\(X\\) is said to be c\u00e0dl\u00e0g, c\u00e0gl\u00e0d, or l\u00e0dl\u00e0g, if it is \u201ccontinue \u00e0 droite avec des limites \u00e0 gauche\u201d, \u201ccontinue \u00e0 gauche avec des limites \u00e0 droite\u201d or \u201climites \u00e0 gauche et limites \u00e0 droite\u201d, respectively.</p> <p>Lemma</p> <p>Suppose that \\(X\\) and \\(Y\\) are modifications of each other and both are either c\u00e0d or c\u00e0g. Then \\(X\\) and \\(Y\\) are indistinguishable.</p> <p>Proof</p> <p>Let \\(X\\) and \\(Y\\) both be c\u00e0d and modifications of each other. Since \\(X\\) and \\(Y\\) are c\u00e0d, it follows that</p> \\[ \\begin{align*}   P\\left[ X_t\\neq Y_t:\\text{for some }t\\right]      &amp; = P\\left[ \\lim_{ q\\searrow t}X_q\\neq \\lim_{ q\\searrow t}Y_q: \\text{ for some }t \\right]\\\\     &amp; = P\\left[X_q \\neq Y_q: \\text{for some }q \\in \\mathbb{Q} \\right]\\\\     &amp; = P\\left[ \\cup_{q \\in \\mathbb{Q}}\\{X_q\\neq Y_q\\} \\right]\\\\     &amp; \\leq \\sum P[X_q\\neq Y_q]=0 \\end{align*} \\] <p>Hence, \\(P\\left[ X_t=Y_t\\colon \\text{for every }t \\right]=1\\) showing that \\(X\\) and \\(Y\\) are indistinguishable.</p> <p>Note</p> <p>The assumption of left- or right-continuity is central. The counter example provided for distinction between version and indistinguishable are two l\u00e0dl\u00e0g processes modification of each others while not indistinguishable.</p> <p>The definition of a filtration \\(\\mathbb{F}=(\\mathcal{F}_t)\\) does not change as an increasing family of \\(\\sigma\\)-algebra indexed by time. However, in continuous time, we can also define the right and left filtration \\(\\mathbb{F}^+=(\\mathcal{F}_t^+)\\) and \\(\\mathbb{F}^-=(\\mathcal{F}^-_t)\\) as follows(1)</p> <ol> <li>Clearly for the left continuous version we have to assume \\(t&gt;0\\) and set as convention \\(\\mathcal{F}_0^- = \\mathcal{F}_0\\). If the time index is \\([0, T]\\), then also for the right continuous version we set \\(\\mathcal{F}_T^+ = \\\\mathcal{F}_T\\).</li> </ol> \\[   \\mathcal{F}_t^+=\\bigcap_{s&gt;t}\\mathcal{F}_s\\quad \\text{and}\\quad \\mathcal{F}_{t}^-=\\bigvee_{s&lt;t}\\mathcal{F}_s:=\\sigma\\left( \\mathcal{F}_s: s&lt;t \\right) \\] <p>We say that the filtration is left- or right-continuous if \\(\\mathbb{F}=\\mathbb{F}^-\\) or \\(\\mathbb{F}=\\mathbb{F}^+\\), and continuous if it is both.</p> <p>Remark</p> <p>From the definition, \\(\\mathbb{F}^\\pm\\) are themselves filtrations and it holds \\(\\mathcal{F}_t^-\\subseteq \\mathcal{F}_t\\subseteq \\mathcal{F}_t^+\\) as well as \\(\\mathcal{F}^+_s\\subseteq \\mathcal{F}_t^-\\) whenever \\(s&lt;t\\). Hence \\((\\mathbb{F}^-)^+=(\\mathbb{F})^+=(\\mathbb{F}^+)^+\\) as well as \\((\\mathbb{F}^+)^-=(\\mathbb{F})^-=(\\mathbb{F}^-)^-\\).</p> <p>As such, a process is nothing else than an arbitrary family of random variables indexed by the time. It can also be seen as a mapping \\(X:\\Omega \\times [0, \\infty)\\to \\mathbb{R}\\).</p> <p>Definition</p> <p>Given a filtration \\(\\mathbb{F} = (\\mathcal{F}_t)\\), we say that a process \\(X\\) is</p> <ul> <li> <p>measurable if \\(X\\colon \\Omega\\times [0, \\infty) \\to \\mathbb{R}\\) is measurable with respect to the product \\(\\sigma\\)-algebra \\(\\mathcal{F}\\otimes \\mathcal{B}([0, \\infty))\\).</p> </li> <li> <p>adapted if \\(X_t\\) is \\(\\mathcal{F}_t\\)-measurable for every \\(t\\).</p> </li> <li> <p>progressively measurable if for every \\(t\\), the function \\(X\\colon \\Omega \\times [0, t]\\to \\mathbb{R}\\), \\((\\omega, s) \\mapsto X_s(\\omega)\\) is measurable with respect to the product \\(\\sigma\\)-algebra \\(\\mathcal{F}\\otimes \\mathcal{B}([0, t])\\)</p> </li> </ul> <p>In particular, progressively measurable processes are automatically adapted. The reciprocal is true if the paths of the process are regular enough.</p> <p>Proposition</p> <p>Let \\(X\\) be a c\u00e0d or c\u00e0g \\(\\mathbb{F}\\)-adapted process. Then \\(X\\) is progressively measurable.</p> <p>Proof</p> <p>Suppose that \\(X\\) is c\u00e0d and fix \\(t\\). Define</p> \\[     X^n_s=X_{\\frac{k+1}{2^n}t}, \\quad \\text{for} \\quad \\frac{k}{2^n}t \\leq  s &lt; \\frac{k+1}{2^n}t \\] <p>It follows that \\(X^n\\) is also c\u00e0d as \\(X\\), hence \\(\\lim X^n =X\\) on \\(\\Omega \\times [0,t]\\) up to the null set of those \\(\\omega\\) on which \\(X\\) does not have right-continuous paths. Furthermore, since \\(X\\) is adapted, it follows that the piecewise constant process \\(X^n\\) is \\(\\mathcal{F}_t\\otimes \\mathcal{B}([0,t])\\)-measurable. Hence \\(X\\) is progressively measurable.</p> <p>The previous result makes use of the regularity of paths to derive progressive measurability from adaptiveness. The following result goes a step further by showing that measurability together with adaptiveness yields progressive measurability, up to a modification though.</p> <p>Theorem</p> <p>Any measurable and adapted process admits a progressive modification.</p> <p>The proof of this theorem is clearly not trivial, somewhat lengthy and often just mentioned like here without proof. If you are interested you can see Delacherie and Meyer<sup>1</sup><sup>2</sup>.</p> <p>The notion of stopping times also has to be slightly modified in the continuous time.</p> <p>Definition</p> <p>On a probability space, a random time is a measurable mapping \\(\\tau :\\Omega \\to [0, \\infty)\\cup \\{\\infty\\}\\). Given a filtration, a random time is</p> <ul> <li>an optional time if \\(\\{\\tau &lt;t\\}\\) is in \\(\\mathcal{F}_t\\) for every \\(t\\).</li> <li>a stopping time if \\(\\{\\tau \\leq t\\}\\) is in \\(\\mathcal{F}_t\\) for every \\(t\\).</li> </ul> <p>Proposition</p> <p>Every stopping time is an optional time, and every optional time is a stopping time for the right-filtration. In particular, the two notions coincide if the filtration is right-continuous.</p> <p>Proof</p> <p>The first assertion is trivial. As for the second, let \\(\\tau\\) be an optional time and fix \\(t\\). It follows that \\(\\{\\tau \\leq t\\}=\\cap_n\\{\\tau &lt; t+ 1/n\\}\\) which is an event in \\(\\mathcal{F}_{t}^+\\).</p> <p>For a process \\(X\\) and a subset \\(V\\) of the state space we define the hitting time of \\(X\\) in \\(V\\) as</p> \\[ \\tau_V(\\omega)=\\inf\\{t\\colon X_t(\\omega)\\in V\\}. \\] <p>This function is not necessarily measurable even if \\(X\\) is adapted, however we have the following.</p> <p>Proposition</p> <p>If \\(X\\) adapted and c\u00e0d and \\(V\\) is open, then \\(\\tau_{V}\\) is an optional time. If \\(X\\) is adapted and continuous and \\(V\\) is closed, then \\(\\tau_{V}\\) is a stopping time.</p> <p>Proof</p> <p>It holds \\(\\{\\tau_V &lt;t\\}=\\{\\omega \\in \\Omega: X_s(\\omega)\\in V, s&lt;t\\}\\). Since \\(X\\) is c\u00e0d and \\(V\\) is open, \\(X_s(\\omega)\\) being in \\(V\\) implies the existence of a rational \\(q&lt;t\\) such that \\(X_q(\\omega)\\) is already in \\(V\\). Hence </p> \\[   \\{\\tau_V&lt;t\\}=\\{X_q \\in V:  q&lt;t\\}=\\cup_{ q&lt;t}\\{X_q \\in V\\}\\in \\mathcal{F}_t \\] <p>For the case of \\(X\\) being continuous and \\(V\\) closed, define the open sets \\(V_n=\\{x: d(x,V)&lt;1/n\\}\\supseteq V\\). Then by continuity of \\(X\\) we obtain</p> \\[   \\{\\tau_V \\leq t\\}=\\{X_t \\in V\\}\\cup \\left( \\cap_n \\cup_{ q&lt;t}\\{X_q \\in V_n\\} \\right) \\in \\mathcal{F}_t. \\] <p>Let us collect some standard properties of optional and stopping times.</p> <p>Proposition</p> <p>The following assertions hold:</p> <ul> <li>Every constant \\(t\\) is a stopping time;</li> <li>\\(\\tau+\\sigma\\), \\(\\tau \\vee \\sigma\\) and \\(\\tau\\wedge \\sigma\\) are stopping/optional times as soon as \\(\\tau,\\sigma\\) are stopping/optional times;</li> <li>\\(\\lim \\tau^n\\) is a stopping time as soon as \\((\\tau^n)\\) is an increasing sequence of stopping times;</li> <li>\\(\\lim \\tau^n\\) is an optional time as soon as \\((\\tau^n)\\) is a decreasing sequence of optional times;   It is a stopping time if \\((\\tau^n)\\) are stationary stopping times, that is, \\(\\tau^m(\\omega)=\\tau^n(\\omega)\\) for all \\(m\\) greater than a given \\(n\\), for \\(P\\)-almost all \\(\\omega \\in \\Omega\\);</li> <li>If \\(\\tau\\) is a stopping time, then the collection \\(\\mathcal{F}_\\tau=\\{A \\in \\mathcal{F}: A\\cap \\{\\tau\\leq t\\}\\in \\mathcal{F}_t\\}\\) is a \\(\\sigma\\)-algebra and \\(\\tau\\) is \\(\\mathcal{F}_{\\tau}\\)-measurable;</li> <li>For any two stopping times, it holds \\(\\mathcal{F}_{\\sigma}\\cap \\mathcal{F}_{\\tau}=\\mathcal{F}_{\\sigma \\wedge \\tau}\\).   In particular, \\(\\mathcal{F}_{\\sigma}\\subseteq \\mathcal{F}_{\\tau}\\), if \\(\\sigma \\leq \\tau\\).   For every integrable random variable \\(\\xi\\), it holds \\(E[E[\\xi|\\mathcal{F}_{\\sigma}]| \\mathcal{F}_{\\tau}]=E[\\xi| \\mathcal{F}_{\\sigma \\wedge \\tau}]\\).</li> </ul> <p>Proof</p> <p>The proof follows the same argumentation as in the discrete time since \\(\\mathbb{Q}\\) is a countable dense subset of \\([0, \\infty)\\). Only the following two points need a certain care.</p> <ul> <li> <p>Let \\(\\tau\\) and \\(\\sigma\\) be two stopping times, let us show that the sum is still a stopping time.     Noting that \\(\\tau\\) is a stopping time if and only if \\(\\{\\tau &gt;t \\}=\\{\\tau\\leq t\\}^c\\) is in \\(\\mathcal{F}_t\\) for every \\(t\\), the following decomposition holds</p> \\[ \\{\\tau+\\sigma &gt;t\\}=\\{\\tau=0, \\sigma &gt; t\\}\\cup \\{\\sigma=0,\\tau &gt; t\\}\\cup \\{\\tau \\geq t, \\sigma&gt;0 \\}\\cup\\{\\sigma+\\tau&gt;t,0&lt;\\tau&lt;t\\} \\] <p>Noting that \\(\\{\\tau=0\\}=\\{\\tau\\leq 0\\}\\) is in \\(\\mathcal{F}_0\\subseteq \\mathcal{F}_t\\), the same for \\(\\{\\sigma=0\\}\\) being in \\(\\mathcal{F}_t\\), it follows immediately that the first two sets are in \\(\\mathcal{F}_t\\). Further, \\(\\{\\tau \\geq t\\}=\\cap_{n}\\{\\tau&gt;t-1/n\\}\\) is in \\(\\mathcal{F}_{t-}\\subseteq \\mathcal{F}_t\\) and \\(\\{\\sigma&gt;0\\}\\) is in \\(\\mathcal{F}_0\\) showing that the third set in this decomposition is in \\(\\mathcal{F}_t\\). As for the last one, note that</p> \\[   \\{\\sigma+\\tau&gt;t,0&lt;\\tau&lt;t\\}=\\cup_{0&lt;q&lt;t}\\{\\sigma&gt;t-q\\}\\cap\\{t&gt;\\tau&gt;q\\}=\\cup_{0&lt;q&lt;t}\\{\\sigma&gt;t-q\\}\\cap \\{\\tau&gt;q\\}\\cap \\{\\tau&lt;t\\} \\] <p>which is for the same reason as before in \\(\\mathcal{F}_t\\) since \\(0&lt;q&lt;t\\).</p> </li> <li> <p>Suppose that \\(\\tau^n\\) is a decreasing sequence of optional times.   It follows from \\(\\{\\lim \\tau^n &lt;t\\}=\\{\\tau^n &lt;t: \\text{ for some }n\\}=\\cup_n\\{\\tau^n &lt;t\\}\\) is in \\(\\mathcal{F}_t\\) that \\(\\lim \\tau^n\\) is an optional time.   If \\(\\tau^n\\) are stopping times, it only holds \\(\\{\\lim \\tau^n \\leq t\\}=\\cap_{q&gt;0}\\{\\tau^n \\leq t+q: \\text{for some }n\\}\\) is in \\(\\mathcal{F}^+_t\\) and therefore \\(\\lim \\tau^n\\) is optional.   However, defining \\(A_n=\\{\\tau^n=\\tau^m: \\text{for all }m\\geq n\\}\\), it follows from stationarity that \\(A_n\\) is increasing to \\(\\Omega\\).   Furthermore, \\(A_n\\) is an event in \\(\\mathcal F_{\\tau^n}\\) and hence \\(\\{\\lim \\tau^n \\leq t\\}=\\cup_n \\{\\tau^n\\leq t\\}\\cap A_n\\) is in \\(\\mathcal{F}_t\\).</p> </li> </ul> <p>Proposition</p> <p>Let \\(X\\) be a progressively measurable process and \\(\\tau\\) a stopping time with \\(\\tau &lt;\\infty\\). Then \\(X_\\tau(\\omega):=X_{\\tau(\\omega)}(\\omega)\\) is an \\(\\mathcal{F}_{\\tau}\\)-measurable random variable. Furthermore, \\(X^\\tau:=(X_{\\cdot\\wedge \\tau})\\) is a progressive process.</p> <p>Proof</p> <p>First, \\(\\tau\\) being a stopping time implies that \\((\\omega,s)\\mapsto h(\\omega,s):= (\\omega, \\tau(\\omega)\\wedge s)\\) from \\(\\Omega \\times [0,t]\\) onto itself is \\(\\mathcal{F}_t\\otimes \\mathcal{B}([0,t])\\)-measurable for every \\(t\\). Since \\(X\\) is progressive and \\(X^\\tau_s(\\omega)=X\\circ h(\\omega, s)\\) for every \\(s\\leq t\\), it follows that \\((s,\\omega)\\mapsto X^\\tau_s(\\omega)\\) is also \\(\\mathcal{F}_t\\otimes \\mathcal{B}([0,t])\\)-measurable. Thus \\(X^\\tau\\) is progressive and, in particular, \\(X_{\\tau}\\) is \\(\\mathcal{F}_{\\tau}\\)-measurable.</p> <p>The null sets on a probability space play a central role. They allow to identify random variables in the almost sure sense. With regard to a filtration indexed by an uncountable time set, this may yield some tricky problems \u2014 this is mainly due to the problem of right-continuous version of processes not further discussed here, see Theorem III-44 p.~64, Theorems IV-32-33 pp.~102--103 From Delacherie-Meyer<sup>1</sup>. In order to get rid of these problems and the identification between optional and stopping times we will work with the following assumption.</p> <p>Definition</p> <p>A filtration \\(\\mathbb{F}\\) is said to </p> <ul> <li> <p>be complete if \\(\\mathcal{F}_0\\) contains all the \\(P\\)-negligible sets of \\(\\mathcal{F}\\);</p> </li> <li> <p>satisfy the usual conditions if it is complete and right-continuous, that is \\(\\mathbb{F}^+=\\mathbb{F}\\).</p> </li> </ul> <p>From now on, unless otherwise specified:</p> \\[ \\mathbb{F}=\\mathbb{F}^+\\quad \\text{and}\\quad \\mathcal{F}_0\\text{ contains all the }P\\text{ null sets of }\\mathcal{F} \\] <p>For a stopping/optional time \\(\\tau\\), we denote by \\([\\tau]=\\{(\\omega,t) \\in \\Omega \\times \\mathbf{T}: \\tau(\\omega)=t\\}\\) its graph.</p> <p>Proposition</p> <p>Let \\(X\\) be a c\u00e0dl\u00e0g, adapted process on a filtration satisfying the usual conditions. Then there exists a sequence of stopping times \\((\\tau^n)\\) which exhausts the jumps\\footnote{For \\(X\\) c\u00e0dl\u00e0g, the jump process \\(\\Delta X\\) is the difference of \\(X\\) with the c\u00e0gl\u00e0d version \\(X_{-}\\) of \\(X\\)} \\(\\Delta X=X-X_{-}\\) of \\(X\\), that is</p> \\[ \\left\\{\\Delta X\\neq 0\\right\\}\\subseteq\\bigcup_{n}\\left[ \\tau^n \\right]. \\] <p>This proposition is also particularly difficult to prove buy it basically shows that the jumps can be described by stopping times.</p> <ol> <li> <p>Claude Dellacherie and Paul-Andr\u00e9 Meyer. Probabilities and Potential. A. Volume 29 of North-Holland Mathematics Studies. North-Holland Publishing Co., Amsterdam, 1978. ISBN 0-7204-0701-X.\u00a0\u21a9\u21a9</p> </li> <li> <p>Claude Dellacherie and Paul Andr\u00e9 Meyer. Probabilities and Potential. B. Volume 72 of North-Holland Mathematics Studies. North-Holland Publishing Co., Amsterdam, 1982.\u00a0\u21a9</p> </li> </ol>"},{"location":"lecture/06-Continuous-Time/062-lebesgue/","title":"Lebesgue-Stieljes Integral","text":""},{"location":"lecture/06-Continuous-Time/062-lebesgue/#deterministic-definition","title":"Deterministic Definition","text":"<p>Theorem: Lebesgue-Stieljes measure</p> <p>Let \\(F:\\mathbb{R}\\to \\mathbb{R}\\) be a c\u00e0d increasing function function (in particular c\u00e0dl\u00e0g). There exists a unique measure \\(dF\\) on the Borel \\(\\sigma\\)-algebra of the real line such that  </p> \\[   dF((a,b]) = F(b) - F(a) \\] <p>for any real \\(a\\leq b\\). This measure is called the Lebesgue-Stieljes measure.</p> Proof <p>Let \\(\\Omega = \\mathbb{R}\\) and \\(\\mathcal{B}\\) be the Borel \\(\\sigma\\)-algebra which is generated by the semi-ring \\(\\mathcal{R} = \\{(a,b] \\colon a \\leq b\\}\\) with the convention that \\((a,a] = \\emptyset\\). Define  </p> \\[ P((a,b]) = F(a) - F(b) \\] <p>for any \\((a, b]\\) in \\(\\mathcal{R}\\). Straightforward inspection shows that \\(P\\) is additive, such that \\(P[\\emptyset] = 0\\) and \\(P\\) is sub-additive. To show that \\(P\\) extends uniquely to a \\(\\sigma\\)-finite measure on \\(\\mathcal{B}\\), we just have to check that \\(P\\) is \\(\\sigma\\)-subadditive on \\(\\mathcal{R}\\). Let \\(A = (a,b]\\) be in \\(\\mathcal{R}\\) and \\((A_n) = (]a_n,b_n])\\) a countable family in \\(\\mathcal{R}\\) such that \\(A \\subseteq \\cup A_n\\). Taking \\(\\varepsilon &gt; 0\\), by right-continuity of \\(F\\), choose some \\(a^\\varepsilon \\in (a,b[\\) such that \\(F(a^\\varepsilon) - F(a) &lt; \\varepsilon/2\\). Also using the right-continuity of \\(F\\), choose \\(b_n^\\varepsilon &gt; b_n\\) for every \\(n\\) such that \\(F(b_n^\\varepsilon) - F(b_n) \\leq \\varepsilon 2^{-n-1}\\). It follows that</p> \\[   [a^\\varepsilon, b] \\subseteq (a,b] \\subseteq \\cup (a_n, b_n] \\subseteq \\cup (a_n, b_n^\\varepsilon). \\] <p>However, \\([a^\\varepsilon, b]\\) is a compact set, therefore, the open covering \\(\\cup (a_n, b_n^\\varepsilon)\\) of \\([a^\\varepsilon, b]\\) can be chosen finite. Hence, there exists \\(n_0\\) such that</p> \\[   [a^\\varepsilon, b] \\subseteq (a^\\varepsilon, b] \\subseteq \\cup_{k \\leq n_0} (a_k, b_k^\\varepsilon) \\subseteq \\cup_{k \\leq n_0} (a_k, b_k^\\varepsilon]. \\] <p>and therefore</p> \\[   \\begin{align*}     P((a,b])        &amp; = F(b) - F(a)\\\\       &amp; \\leq \\varepsilon/2 + F(b) - F(a^\\varepsilon)\\\\       &amp; \\leq \\varepsilon/2 + \\sum_{k=1}^{n_0} (F(b_k^\\varepsilon) - F(a_k)) \\\\       &amp; \\leq \\varepsilon + \\sum (F(b_n) - F(a_n))\\\\       &amp; = \\varepsilon + \\sum P((a_n, b_n]).   \\end{align*} \\] <p>showing that \\(P\\) extends to a measure on the real line. This measure is also \\(\\sigma\\)-finite in the sense that there exists an increasing sequence of sets \\((]a_n,b_n])\\) such that \\(\\mathbb{R} = \\cup ]a_n, b_n]\\) and \\(P(]a_n, b_n]) &lt; \\infty\\) for every \\(n\\). Hence, this extension is unique and we denote it \\(dF\\).</p> <p>Example</p> <ol> <li> <p>The classical Lebesgue measure \\(dx\\) on the real line is derived from the continuous increasing function \\(F(x) = x\\), for which it holds  </p> \\[ dx((a,b]) = b - a \\] </li> <li> <p>If we consider the increasing right continuous function \\(F(x) = 1_{[y,\\infty)}(x)\\) for a given real \\(y\\) we get the Dirac measure  </p> \\[   dF[A] = \\delta_y[A] =     \\begin{cases}       1 &amp; \\text{if } y \\in A \\\\       0 &amp; \\text{otherwise}     \\end{cases} \\] </li> </ol> <p>Clearly, given two c\u00e0d increasing function, their difference defines a signed measure. The set of those functions are better described as the set of bounded variation functions.</p> <p>Definition</p> <p>We say that a function \\(F:[0,\\infty) \\to \\mathbb{R}\\), \\(t \\mapsto F(t) := F_t\\) is of bounded variation if  </p> \\[   S_t = \\sup_{\\Pi \\text{ subdivision of } [0,t]} S_t^{\\Pi} &lt; \\infty \\] <p>for every \\(t\\) where for \\(\\Pi = \\{0=t_0&lt;t_1&lt;\\ldots&lt;t_n = t\\}\\)</p> \\[   S_t^{\\Pi} = \\sum_{1 \\leq k \\leq n} |F_{t_{k+1}} - F_{t_k}| \\] <p>Functions of bounded variations are those that can be defined as a difference of two increasing functions.</p> <p>Proposition</p> <p>A function is of bounded variations if and only if it can be written as the difference between two increasing functions.</p> <p>Proof</p> <p>Let \\(F\\) be a function of bounded variations. Inspection shows that \\(F^+ = (S + F)/2\\) and \\(F^- = (S - F)/2\\) are two increasing functions whose difference is equal to \\(F\\). This decomposition is actually the minimal one, in the sense that if \\(F = A - B\\) for two increasing functions \\(A\\) and \\(B\\), then it follows that \\(F^+ \\leq A\\) and \\(F^- \\leq B\\). The reciprocal is easy.</p> <p>Given a right continuous function \\(F\\) of bounded variations, we can therefore define a so-called signed measure and the absolute value of this measure </p> \\[   dF = dF^+ - dF^- \\quad \\text{and} \\quad |dF| = dF^+ + dF^- \\] <p>If \\(H:[0,\\infty) \\to \\mathbb{R}\\) is a locally bounded, that is, bounded on any compact interval \\([0,t]\\), and \\(\\mathcal{B}([0,\\infty))\\)-measurable, we can define the integral</p> \\[   \\int_{0}^{t} H_s dF_s = \\int_{(0,t]} H_s dF_s := \\int_{0}^{t} H_s dF^+_s - \\int_{0}^{t} H_s dF^-_s \\] <p>which is called the Lebegues-Stieljes integral of \\(H\\) with respect to \\(F\\). The integral is understood over the interval \\(]0,t]\\) so that \\(\\int_0^t dF_s = F_t - F_0\\).</p> <p>Proposition: Chain Rule or Integration by Parts</p> <p>Let \\(F\\) and \\(G\\) be two right continuous functions of finite variations, then it holds</p> \\[   \\begin{align*}      F_t G_t  &amp; = F_0 G_0 + \\int_{0}^{t} F_s dG_s + \\int_{0}^{t} G_{s-} dF_s\\\\               &amp; = F_0 G_0 + \\int_{0}^{t} F_{s-} dG_s + \\int_{0}^{t} G_{s} dF_s\\\\               &amp; = F_0 G_0 + \\int_{0}^{t} F_{s-} dG_s + \\int_{0}^{t} G_{s-} dF_s + \\sum_{0&lt;s \\leq t} \\Delta F_s \\Delta G_s   \\end{align*} \\] <p>where \\(F_{s-} = \\lim_{u \\nearrow s} F_u\\) and \\(\\Delta F_s = F_s - F_{s-} = dF[\\{s\\}]\\).</p> <p>Remark</p> <p>This proposition is often stated in differential form, that is</p> \\[\\begin{equation*}   dFG = F_{\\cdot -}dG + G_{\\cdot -}dF + \\Delta F \\Delta G \\end{equation*}\\] <p>Note that if \\(F\\) and \\(G\\) are continuous, the more classical chain rule formula reads as follows</p> \\[\\begin{equation*}   dFG = FdG + G dF \\end{equation*}\\] <p>Proof</p> <p>Considering the product measure \\(dF \\otimes dG\\) on \\([0,\\infty) \\times [0,\\infty)\\), using the triangular equality</p> \\[ 1_{]0,t]}(s_1) 1_{]0,t]}(s_2) = 1_{]0,t]}(s_1) 1_{]0,s_1]}(s_2) + 1_{]0,s_2[}(s_1) 1_{]0,t]}(s_2) \\] <p>using Fubini-Tonelli, we obtain</p> \\[ \\begin{align*}   dF \\otimes dG \\left[ (0,t] \\times (0,t] \\right]      &amp; = (F_t - F_0)(G_t - G_0) \\\\     &amp; = \\int \\int 1_{]0,t]}(s_1) 1_{]0,t]}(s_2) \\, dF_{s_1} dG_{s_2} \\\\     &amp; = \\int_{(0,t]} \\left( \\int_{(0,s_1]} dG_{s_2} \\right) dF_{s_1} + \\int_{(0,t]} \\left( \\int_{(0,s_2)} dF_{s_1} \\right) dG_{s_2} \\\\     &amp; = \\int_{(0,t]} \\left(G_s - G_0\\right) \\, dF_s + \\int_{(0,t]} \\left(F_{s-} - F_0\\right) \\, dG_s \\\\     &amp; = \\int_{(0,t]} G_s \\, dF_s + \\int_{(0,t]} F_{s-} \\, dG_s - G_0 (F_t - F_0) - F_0 (G_t - G_0) \\end{align*} \\] <p>showing the first equality. The second follows exactly the same argumentation by swapping \\(F\\) and \\(G\\). As for the last one, note that \\(F = F_{-} + \\Delta F\\), and since \\(F\\) can only have countably many discontinuity points, the last equality follows.</p> <p>This basic form of the classical chain rule formula leads to the general one</p> <p>Theorem: Chain Rule Formula</p> <p>Let \\(f:\\mathbb{R} \\to \\mathbb{R}\\) be a continuously differentiable function and \\(F\\colon [0, \\infty)\\to \\mathbb{R}\\) be a c\u00e0d bounded variation function. It follows that</p> \\[   f(F_t) = f(F_0) + \\int_{0}^{t} f^\\prime(F_{s-}) \\, dF_s + \\sum_{s \\leq t} \\left( f(F_s) - f(F_{s-}) - f^\\prime(F_{s-}) \\Delta F_s \\right) \\] <p>In particular, if \\(F\\) is continuous, it holds</p> \\[   f(F_t) = f(F_0) + \\int_{0}^{t} f^\\prime(F_s) \\, dF_s \\] <p>Remark</p> <p>The differential form of this chain rule formula reads as follows</p> \\[ \\begin{equation*}       df(F) = f^\\prime(F_{\\cdot -}) dF + \\Delta f(F) - f^\\prime(F_{\\cdot -})\\Delta F  \\end{equation*} \\] <p>and if \\(F\\) is continuous we obtain the classical chain rule formula</p> \\[   df(F) = f(F)dF \\] <p>which is the building block for differential equations.</p> <p>Proof</p> <p>We here just sketch the idea of the proof, as a more general one will be shown for the Ito-Formula later in the lecture.</p> <ul> <li> <p>Step 1: Any differentiable function $ f \\colon \\mathbb{R} \\to \\mathbb{R}$ can be approximated on any compact uniformly by interpolation by a polynomial \\(f(x) = \\sum_{k\\leq n} \\alpha_k x^k\\).   Hence, it would be enough to show it for polynomial of arbitrary degree.</p> </li> <li> <p>Step 2: Since the integral is a linear operator, showing the formula for any polynomial is equivalent to show it for any monomial \\(x^n\\).     We show by induction that the chain rule formula holds for any monomial \\(x^n\\), that is</p> \\[ \\begin{equation*}   d F^n  = n F^{n-1}_{\\cdot -} dF + \\Delta F^n - n F^{n-1}_{\\cdot -}\\Delta F \\end{equation*} \\] <p>For \\(n=1\\), this is immediate. Suppose that it holds for any \\(m \\leq n-1\\) and we show if for \\(n\\geq 2\\). Defining \\(G = F^{n-1}\\), from the product chain rule formula and the recursion hypothesis for \\(G\\) it holds that</p> \\[ \\begin{align*}   dF^n        &amp; = d FG \\\\       &amp; = F_{\\cdot -} dG + G_{\\cdot -} dF + \\Delta F \\Delta G\\\\       &amp; = F_{\\cdot -}\\left( (n-1) F^{n-2}_{\\cdot -} dF + \\Delta F^{n-1} - (n-1)F^{n-2}_{\\cdot -}\\Delta F \\right) + F^{n-1}_{\\cdot -}dF + \\Delta F \\Delta F^{n-1}\\\\       &amp; = n F^{n-1}dF + F_{\\cdot -}F^{n-1} - F_{\\cdot - }^n -(n-1)F^{n-1}_{\\cdot -}F + (n-1)F^n_{\\cdot -}\\\\       &amp; \\quad \\quad \\quad \\quad + F^n + F^n_{\\cdot -} - F_{\\cdot -}F^{n-1} - F F^{n-1}_{\\cdot -}\\\\       &amp; = n F^{n-1}dF + \\Delta F^n - n F^{n-1}_{\\cdot -} \\Delta F \\end{align*} \\] </li> </ul> <p>Remark</p> <p>Note that according to the proof, we can show the chain rule formula for any monomial of the type \\(x^n y^m\\). Hence the chain rule formula extends for multifariate functions \\(f\\) which in the case of continuous bounded c\u00e0d functions \\(F\\) and \\(G\\) yields</p> \\[\\begin{equation*}   df(F, G) = \\partial_x f(F, G)dF +\\partial_y f(F, G) \\end{equation*}\\]"},{"location":"lecture/06-Continuous-Time/062-lebesgue/#stochastic-lebesgue-stieljes-integral","title":"Stochastic Lebesgue-Stieljes Integral","text":"<p>We can extend this integration procedure for every \\(\\omega\\)-dependent paths as follows.</p> <p>Definition</p> <p>A process \\(A\\) is called increasing if - \\(A\\) is adapted with \\(A_0 = 0\\) - \\(A\\) is c\u00e0dl\u00e0g, and almost all sample paths are increasing  </p> <p>An increasing process \\(A\\) is called integrable if \\(E[A_t] &lt; \\infty\\).  </p> <p>A process \\(A\\) is called of bounded variations if \\(A\\) is the difference between two increasing processes.</p> <p>We denote by \\(dA\\) the \\(\\omega\\)-wise \\(\\sigma\\)-finite signed measure \\(dA_t(\\omega)\\) induced by \\(A\\). For every locally measurable process(1) process \\(H\\) which is locally bounded, that is \\((\\omega,s) \\mapsto H_s(\\omega)\\) is uniformly bounded for almost all \\(\\omega\\) and all \\(s \\in [0,t]\\), we can define the \\(\\omega\\)-wise Lebesgue-Stieljes Integral</p> <ol> <li>Recall that a measurable process is a process such that \\((\\omega,t) \\mapsto H_t(\\omega)\\) is \\(\\mathcal{F} \\otimes \\mathcal{B}([0,\\infty))\\)-measurable; in particular \\(t \\mapsto H_t(\\omega)\\) is \\(\\mathcal{B}([0,\\infty[)\\)-measurable for every \\(\\omega\\).</li> </ol> \\[   \\int_0^t H_s(\\omega) \\, dA_s(\\omega) \\] <p>for any \\(\\omega\\) and \\(0\\leq t&lt;\\infty\\). We usually do not mention the time and omega index and simplify the notation to \\(\\int_{0}^{t} H \\, dA\\).</p> <p>Proposition</p> <p>If \\(H\\) is a locally bounded measurable process and \\(A\\) is a process of bounded variations, then</p> \\[ \\int H \\, dA = \\left( \\int_{0}^{t} H \\, dA \\right) \\] <p>defines a c\u00e0dl\u00e0g right continuous measurable process. If furthermore \\(H\\) is progressive, then \\(\\int H \\, dA\\) is progressive, c\u00e0dl\u00e0g, and of bounded variations.</p> <p>Proof</p> <p>The proof is quite easy, as one approximates \\(H\\) by sequences of simple step processes with the right measureability. Let us however check that if \\(H\\) is progressive, then \\(\\int H \\, dA\\) is of bounded variations. Since it is c\u00e0dl\u00e0g and adapted with \\(A_0 = 0\\), we just have to check that it is of bounded variations. The process \\(H\\) being locally bounded, let \\(K\\) be such that \\(|H_s(\\omega)| \\leq K\\) for every \\(0\\leq s\\leq t\\). For any partition \\(\\Pi\\) of \\([0,t]\\), it holds  </p> \\[ \\begin{align*}     \\sum_{\\Pi} \\left| \\int_{t_{k-1}}^{t_k} H_s(\\omega) \\, dA_s(\\omega) \\right|          &amp; \\leq \\sum_{\\Pi} \\int_{t_{k-1}}^{t_k} |H_s(\\omega)| \\, d|A_s(\\omega)|\\\\         &amp; \\leq K \\sum_{\\Pi} \\int_{t_{k-1}}^{t_k} d|A_s(\\omega)| \\\\         &amp; = K |A_t(\\omega)|&lt; \\infty \\end{align*} \\] <p>showing that \\(\\int X \\, dA\\) is of bounded variations.</p> <p>Exercice</p> <p>Using Radon-Nikodym, show that for any two increasing processes \\(A\\) and \\(B\\) such that \\(A - B\\) is still increasing, then there exists an adapted measurable process \\(H\\) such that </p> \\[   B = \\int H dA \\] <p>In particular, if \\(A\\) is of bounded variations, there exists \\(H\\) adapted and measurable such that  </p> \\[   A = \\int H \\left| dA \\right| \\]"},{"location":"lecture/06-Continuous-Time/063-martingales/","title":"Martingales","text":"<p>The definition of (Super-/Sub-)Martingales does not change in the continuous time. The martingale properties and theorems extend to the continuous time. However, some restrictions have to be made in terms of path regularity. Indeed, as mentioned earlier, the infinite amount of null sets that may add up has to be countably controlled.</p> <p>Definition: Simple Processes</p> <p>We denote by \\(\\mathcal{S}\\) the set of simple predictable processes \\(H\\) of the form  </p> \\[   H = H_0 1_{\\{0\\}} + \\sum_{k=1}^n H_k 1_{(\\tau_{k-1}, \\tau_k]} \\] <p>for a finite sequence \\(0 = \\tau_0 \\leq \\tau_1 \\leq \\ldots \\leq \\tau_n\\) of stopping times where \\(\\tau_n&lt;\\infty\\), and \\(H_k\\) is bounded and \\(\\mathcal{F}_{\\tau_{k-1}}\\) measurable for \\(k = 0, \\dots, n\\).</p> <p>For a progressive process \\(X\\) and \\(H \\in \\mathcal{S}\\), we denote by \\(\\int H d X\\) the process</p> \\[ \\int H dX := H_0 X_0 + \\sum_{k=1}^n H_k \\left( X^{\\tau_k} - X^{\\tau_{k-1}} \\right) \\] <p>which is the simple definition of a stochastic integral of \\(H\\) with respect to \\(X\\).</p> <p>Theorem</p> <p>Let \\(X\\) be a c\u00e0d stochastic process and \\(H\\) be a simple process. The following assertions hold true.</p> <ol> <li> <p>If \\(X\\) is a martingale and then \\(\\int H d X\\) is a martingale.     If \\(X\\) is a super/sub-martingale, and \\(H\\) is positive then \\(\\int Hd X\\) is a super/sub-martingale.</p> <p>In particular, if \\(\\tau\\) is a bounded stopping time then \\(X^\\tau\\) is a martingale or super/sub-martingale, respectively.</p> </li> <li> <p>Let \\(X\\) be a submartingale.     For any \\(\\lambda &gt; 0\\) it holds</p> \\[ \\begin{align*}   \\lambda P\\left[ \\overline{X}_t \\geq \\lambda \\right] &amp; \\leq E\\left[ 1_{\\{\\overline{X}_t &lt; \\lambda\\}} X_t \\right] \\leq E\\left[ X_t^+ \\right]\\\\   \\lambda P\\left[ \\underline{X}_t \\leq -\\lambda \\right] &amp; \\leq E\\left[ 1_{\\{\\underline{X}_t &gt; -\\lambda\\}} X_t \\right] - E\\left[ X_0 \\right] \\leq E\\left[ X_t^+ \\right] - E\\left[ X_0 \\right] \\end{align*} \\] </li> <li> <p>Let \\(X\\) be a positive submartingale and \\(p &gt; 1\\), it holds</p> \\[   \\left\\Vert \\sup_{s \\leq t} X_s \\right\\Vert_p \\leq \\frac{p}{p-1} \\left\\Vert X_t \\right\\Vert_p \\] </li> <li> <p>Let \\(X\\) be a submartingale.     Then for every two reals \\(x &lt; y\\), the number of up-crossings of \\((x,y)\\) by \\(X\\) up to time \\(t\\), \\(U_{[0,t]}(x,y,X)\\) is a random variable and it holds  </p> \\[   (y - x) E\\left[ U_{[0,t]}(x,y,X) \\right] \\leq E\\left[ \\left( X_t - x \\right)^+ \\right] - E\\left[ \\left( X_0 - x \\right)^+ \\right] \\] </li> </ol> <p>In particular, if \\(X\\) is a c\u00e0d martingale, and \\(p &gt; 1\\), then \\(|X|^p\\) is a positive c\u00e0d submartingale and therefore</p> \\[   \\left\\Vert X^\\ast_t \\right\\Vert_p \\leq \\left( \\frac{p}{p - 1} \\right) \\left\\Vert X_t \\right\\Vert_p \\] <p>for every \\(p &gt; 1\\).</p> <p>Proof</p> <p>The inequalities hold true if the process \\(X\\) is sampled on any finite discretization of \\([0,t]\\) containing \\(0\\) and \\(t\\). Hence, passing to the limit, these inequalities hold for \\(([0,t] \\cap \\mathbb{Q}) \\cup \\{0,t\\}\\) and since the paths of \\(X\\) are c\u00e0d, the inequalities follow.</p> <p>The single thing to check is whether \\(U_{[0,t]}(x,y,X)\\) is a well-defined random variable. However, for any finite \\(F \\subseteq [0,t]\\), since \\(X\\) is right-continuous, the \\(\\tau^k\\) and \\(\\sigma^k\\) in the construction of \\(U_F(x,y,X)\\) are stopping times according to the hitting times propositions for continuous processes. Therefore \\(U_F(x,y,X)\\) is a random variable. It follows that \\(U_{([0,t] \\cap \\mathbb{Q}) \\cup \\{0,t\\}}(x,y,X)\\) is a random variable. Since \\(X\\) is c\u00e0d, this set takes into account all the up-crossings on \\([0,t]\\).</p> <p>Theorem</p> <p>Any c\u00e0d sub-martingale is c\u00e0dl\u00e0g, and every sample path is almost surely bounded on any compact interval.</p> <p>Furthermore, \\(X\\) is a submartingale with respect to \\(\\mathbb{F}^+\\) as well as with respect to the augmentation of \\(\\mathbb{F}\\).</p> <p>Proof</p> <p>Let \\(X\\) be a c\u00e0d sub-martingale. The boundedness of the sample paths on any compact interval almost surely follows from the previous inequalities. As for the c\u00e0dl\u00e0g property, define</p> \\[   A = \\bigcup_{n \\in \\mathbb{N}} \\bigcup_{p,q \\in \\mathbb{Q}, p &lt; q} \\left\\{U_{[0,n]}(p,q,X) = \\infty \\right\\} \\] <p>By means of the up-crossing inequality, it follows that this countable union is of measure \\(0\\). However, \\(A\\) contains the set</p> \\[ \\left\\{ \\liminf_{s \\nearrow t} X_s &lt; \\limsup_{s \\nearrow t} X_s, \\, \\text{for some } \\right\\} \\] <p>Hence \\(X\\) is c\u00e0dl\u00e0g. The fact that \\(X\\) is a supermartingale with respect to \\(\\mathbb{F}^+\\) is immediate. As for the augmentation, observe that null sets do not modify the supermartingale inequalities.</p> <p>As noticed, the up-crossing inequality shows that sub-martingales have some nice regularity of paths. However, we assumed from the beginning that these sub-martingales were right-continuous, central to derive Doob's maximal inequalities. Let us show that up to modification, any sub-martingale has nice properties, however in the right-continuous filtration or in a filtration satisfying the usual conditions.</p> <p>Theorem</p> <p>Let \\(X\\) be a sub-martingale, then the following holds true.</p> <ol> <li> <p>Almost surely, the limits  </p> \\[ X_{t+} = \\lim_{q \\searrow t} X_q \\quad \\text{and} \\quad X_{t-} = \\lim_{q \\nearrow t} X_q \\] <p>exist for every \\(t\\) and thereby define two processes \\(X_{+}\\) and \\(X_{-}\\), respectively.</p> </li> <li> <p>The process \\(X_{+}\\) is a \\(\\mathbb{F}^+\\) sub-martingale and is a martingale if \\(X\\) is.     Analogously, the process \\(X_{-}\\) is a \\(\\mathbb{F}^-\\) submartingale and is a martingale if \\(X\\) is.     Furthermore  </p> \\[ \\begin{align*}     X_t     &amp; \\leq E\\left[ X_{t+} \\,\\big|\\, \\mathcal{F}_{t} \\right]\\\\     X_{t-}  &amp; \\leq E\\left[ X_t \\,\\big|\\, \\mathcal{F}_{t-} \\right] \\end{align*} \\] <p>with equality in the first if \\(t \\mapsto E[X_t]\\) is right-continuous, and equality in the second if \\(t \\mapsto E[X_t]\\) is left-continuous. In particular, equality holds in both if \\(X\\) is a martingale.</p> </li> </ol> <p>Proof</p> <ol> <li> <p>Unlike in the previous proof we can only estimate the up-crossing of \\(X\\) over a countable bounded interval.     Define  </p> \\[ A = \\bigcup_{n \\in \\mathbb{N}} \\bigcup_{p &lt; q,\\, p,q \\in \\mathbb{Q}} \\left\\{ \\omega \\in \\Omega : U_{[0,n] \\cap \\mathbb{Q}}(p,q,X(\\omega)) = \\infty \\right\\} \\] <p>This set is of measure \\(0\\). Hence, with the same argumentation as in the previous proof, it follows that</p> \\[ \\begin{align*}    P\\left[ \\liminf_{q \\nearrow t, q \\in \\mathbb{Q}} X_q &lt; \\limsup_{q \\nearrow t, q \\in \\mathbb{Q}} X_q  \\text{ for some } t \\right] &amp; = 0\\\\   P\\left[ \\liminf_{q \\searrow t, q \\in \\mathbb{Q}} X_q &lt; \\limsup_{q \\searrow t, q \\in \\mathbb{Q}} X_q  \\text{ for some } t \\right] &amp; = 0 \\end{align*} \\] <p>We can then define the processes \\(X_{-}\\) and \\(X_{+}\\) by</p> \\[   X_{t+} = \\lim_{q \\searrow t} X_q, \\quad \\text{ and } \\quad X_{t-} = \\lim_{q \\nearrow t} X_q \\] <p>with the conventions that \\(X_{0-} = X_0\\).</p> </li> <li> <p>Clearly \\(X_{+}\\) and \\(X_{-}\\) are \\(\\mathbb{F}^+\\)- and \\(\\mathbb{F}^-\\)-adapted processes, respectively.     Let us show that they are integrable and satisfy the sub-martingale property.     Let \\((q_n) \\subseteq \\mathbb{Q}\\) be a sequence decreasing to \\(t\\).     From the previous step, \\(X_{q_n}\\) converges \\(P\\)-almost surely to \\(X_{t+}\\).     Further, \\(E[X_t] \\leq E[X_{q_n}] \\leq E[X_{q_0}]\\) for every \\(n\\), so \\((X_{q_n})\\) is uniformly bounded in \\(L^1\\), and \\(E[X_{q_n}]\\) is a decreasing sequence converging to \\(\\lim E[X_{q_n}] &gt; E[X_t] &gt; -\\infty\\).     Hence, for \\(\\lambda &gt; 0\\) and \\(\\varepsilon &gt; 0\\), let \\(n_0\\) be such that \\(E[X_{q_n}] \\geq E[X_{q_{n_0}}] - \\varepsilon\\) for every \\(n \\geq n_0\\).     As \\(X\\) is a submartingale, it follows that  </p> \\[ \\begin{align} E\\left[ |X_{q_n}| 1_{\\{ |X_{q_n}| &gt; \\lambda \\}} \\right]    &amp;= E\\left[ X_{q_n} 1_{\\{ X_{q_n} &gt; \\lambda \\}} \\right] - E\\left[ X_{q_n} 1_{\\{ X_{q_n} &lt; -\\lambda \\}} \\right] \\\\   &amp;= E\\left[ X_{q_n} 1_{\\{ X_{q_n} &gt; \\lambda \\}} \\right] - E[X_{q_n}] + E\\left[ X_{q_n} 1_{\\{ X_{q_n} \\geq -\\lambda \\}} \\right] \\\\   &amp;\\leq E\\left[ X_{q_{n_0}} 1_{\\{ X_{q_n} &gt; \\lambda \\}} \\right] + \\varepsilon - E[X_{q_{n_0}}] + E\\left[ X_{q_{n_0}} 1_{\\{ X_{q_n} \\geq -\\lambda \\}} \\right] \\\\   &amp;= E\\left[ X_{q_{n_0}} 1_{\\{ X_{q_n} &gt; \\lambda \\}} \\right] - E\\left[ X_{q_{n_0}} 1_{\\{ X_{q_n} &lt; -\\lambda \\}} \\right] + \\varepsilon \\\\   &amp;\\leq E\\left[ |X_{q_{n_0}}| 1_{\\{ |X_{q_n}| &gt; \\lambda \\}} \\right] + \\varepsilon \\end{align} \\] <p>By Markov's inequality, \\(P[|X_{q_n}| &gt; \\lambda] \\leq \\sup_n E[|X_{q_n}|]/\\lambda = C/\\lambda\\) for some \\(C &lt; \\infty\\), showing that \\((X_{q_n})\\) is uniformly integrable. Together with \\(P\\)-almost sure convergence, it follows that \\(X_{q_n} \\to X_{t+}\\) in \\(L^1\\). Thus \\(X_{t+}\\) is integrable and it holds</p> \\[   X_t \\leq \\lim E\\left[ X_{q_n} \\,\\big|\\, \\mathcal{F}_t \\right] = E\\left[ X_{t+} \\,\\big|\\, \\mathcal{F}_t \\right] \\] <p>Further, for \\(s &lt; t\\) and \\(q_n \\searrow s\\) with \\(q_n &lt; t\\), it holds  </p> \\[   X_{q_n} \\leq E\\left[ X_t \\,\\big|\\, \\mathcal{F}_{q_n} \\right] \\leq E\\left[ E\\left[ X_{t+} \\,\\big|\\, \\mathcal{F}_t \\right] \\,\\big|\\, \\mathcal{F}_{q_n} \\right] = E\\left[ X_{t+} \\,\\big|\\, \\mathcal{F}_{q_n} \\right] \\] <p>for every \\(n\\). The same arguments as above show that \\(E\\left[ X_{t+} \\,\\big|\\, \\mathcal{F}_{q_n} \\right]\\) is uniformly integrable and converges \\(P\\)-almost surely and in \\(L^1\\), and that the limit is \\(E\\left[ X_{t+} \\,\\big|\\, \\mathcal{F}_{s+} \\right]\\). Thus \\(X_{+}\\) is a \\(\\mathbb{F}^+\\)-submartingale. Finally, if \\(t \\mapsto E[X_t]\\) is right-continuous, it follows that \\(E[X_{t+}] = \\lim E[X_{q_n}] = E[X_t]\\). Hence, the positive random variable \\(X_t - E[X_{t+} \\,|\\, \\mathcal{F}_t]\\) has zero expectation and therefore is zero.</p> <p>As for the case of \\(X_{-}\\), a similar argumentation holds using the submartingale convergence theorem for the existence and integrability of \\(X_{t-}\\) and inequality  </p> \\[   X_{t-} \\leq E[X_t \\,|\\, \\mathcal{F}_{t-}] \\] <p>Furthermore, by \\(X_{s-} \\leq E[X_s \\,|\\, \\mathcal{F}_{s-}] \\leq E[E[X_{t-} \\,|\\, \\mathcal{F}_s] \\,|\\, \\mathcal{F}_{s-}] = E[X_{t-} \\,|\\, \\mathcal{F}_{s-}]\\) it follows that \\(X\\) is a \\(\\mathbb{F}^-\\) submartingale.</p> <p>The equality if \\(t \\mapsto E[X_t]\\) is left-continuous follows by an analogous argumentation.</p> </li> </ol> <p>Theorem</p> <p>Let \\(X\\) be a supermartingale with respect to a filtration satisfying the usual assumptions. Suppose further that \\(t \\mapsto E[X_t]\\) is c\u00e0d. Then \\(X\\) has a c\u00e0dl\u00e0g modification.</p> <p>Proof</p> <p>According to the previous theorem, set \\(Y = X_{+}\\) outside the negligible set \\(A\\) up to which \\(X_{+}\\) and \\(X_{-}\\) are defined, and \\(Y = 0\\) on \\(A\\). Since \\(A \\in \\mathcal{F}_0\\), it follows that \\(Y\\) is c\u00e0dl\u00e0g. Furthermore, from \\(t \\mapsto E[X_t]\\) right-continuous, by the previous theorem it holds that</p> \\[ X_t = E[X_{t+} \\,|\\, \\mathcal{F}_t] = E[Y_t \\,|\\, \\mathcal{F}_t] \\] <p>However, since \\(\\mathbb{F}\\) is right-continuous, it follows that \\(Y_t\\) is \\(\\mathcal{F}_t\\)-measurable and so \\(X_t = Y_t\\) almost surely for every \\(t\\).</p>"},{"location":"lecture/07-Stochastic-Integral/070-introduction/","title":"Stochastic Integral","text":"<p>In this Chapter we construct the stochastic integral and show the seminal It-Formula.</p> <p>Throughout, \\((\\Omega, \\mathcal F, P)\\) denotes a probability space with a filtration \\(\\mathbb{F}\\) satisfying the usual conditions. Furthermore, unless otherwise specified, the processes are continuous.</p> <ul> <li>Doob-Meyer Decomposition</li> <li>Stochastic Integral</li> <li>Quadratic Variations - Semi-Martingales</li> <li>It\u00f4's Formula</li> </ul>"},{"location":"lecture/07-Stochastic-Integral/071-doob-meyer/","title":"Doob-Meyer Decomposition","text":"<p>We already saw in discrete time that any process can be decomposed into the sum of a martingale and a predictable process. In particular if \\(X\\) is a sub-martingale, the predictable process is increasing. The proof is relatively straightforward, and one wonders whether it still holds in continuous time. It turns out that this is way more involved. In this section, we do not assume continuity of processes.</p> <p>Definition: Natural Processes</p> <p>An increasing process \\(A\\) is called natural if for every bounded right-continuous martingale \\(M\\) and any \\(t\\) it holds</p> \\[   E\\left[\\int_0^t M_s \\, dA_s\\right] = E\\left[ \\int_0^t M_{s-} \\, dA_s \\right] \\] <p>Remark</p> <p>Note that every increasing and continuous process is automatically natural. Indeed  </p> \\[   \\int_0^t (M_s - M_{s-}) \\, dA_s = 0 \\] <p>almost surely, since every path \\(s \\mapsto M_s\\) has only countably many discontinuities and therefore is a set of \\(dA\\)-zero measure.</p> <p>Lemma</p> <p>The condition for an increasing process to be natural is equivalent to  </p> \\[ E\\left[ M_t A_t \\right] = E\\left[ \\int_0^t M_{s-} \\, dA_s \\right] \\] <p>Proof</p> <p>It suffices to show that</p> \\[ E[M_t A_t] = \\int_0^t M_s \\, dA_s. \\] <p>Let \\(0 = t_0 &lt; t_1 &lt; \\cdots &lt; t_n = t\\) and define  </p> \\[   M^n = \\sum_{k=1}^n M_{t_k} 1_{(t_{k-1}, t_k]}. \\] <p>By the martingale property, it follows that  </p> \\[ \\begin{align} E\\left[ \\int_0^t M^n_s \\, dA_s \\right]    &amp; = \\sum_{k=1}^n E\\left[ M_{t_k} (A_{t_k} - A_{t_{k-1}}) \\right] \\\\   &amp; = E[M_t A_t] - \\sum_{k=1}^{n-1} E\\left[ A_{t_k} (M_{t_{k+1}} - M_{t_k}) \\right]\\\\   &amp; = E[M_t A_t]. \\end{align} \\] <p>letting the mesh of the subdivision to \\(0\\), yields \\(M^n \\to M\\) \\(P\\)-almost surely, and by dominated convergence, the claim follows.</p> <p>Natural processes are the natural pendant to predictable processes in discrete time.</p> <p>Lemma</p> <p>In the discrete time context, an increasing process is natural if and only if it is predictable and integrable.</p> <p>Proof</p> <p>If an increasing process is predictable and integrable, then clearly it is natural. Reciprocally, define the bounded positive martingale \\(M_s = E[1_B \\,|\\, \\mathcal{F}_s]\\) where  </p> \\[   B = \\{ A_t - E[A_t \\,|\\, \\mathcal{F}_{t-1}] &gt; \\varepsilon \\}. \\] <p>From \\(A\\) being natural, it holds  </p> \\[   E[M_t A_t] = E\\left[ \\int_0^t M_{s-} \\, dA_s \\right] = \\sum_{1 \\leq s \\leq t} E\\left[ M_{s-1} (A_s - A_{s-1}) \\right] \\] <p>for every \\(t = 1, \\ldots\\). Hence, per induction, it holds  </p> \\[ \\begin{align}   0 &amp; = E[(M_t - M_{t-1}) A_t] \\\\     &amp; = E[1_B A_t] - E[E[1_B \\,|\\, \\mathcal{F}_{t-1}] A_t] \\\\     &amp; \\geq \\varepsilon P[B] + E[1_B E[A_t \\,|\\, \\mathcal{F}_{t-1}]] - E[1_B E[A_t \\,|\\, \\mathcal{F}_{t-1}]] \\\\     &amp; = \\varepsilon P[B]. \\end{align} \\] <p>showing that \\(P[B] = 0\\). The same holds for \\(B = \\{ A_t - E[A_t \\,|\\, \\mathcal{F}_{t-1}] &lt; -\\varepsilon \\}\\), showing that  </p> \\[   A_t = E[A_t \\,|\\, \\mathcal{F}_{t-1}]. \\] <p>As in the discrete time where a predictable martingale is uniformly constant, the same holds for natural martingales.</p> <p>Proposition</p> <p>Let \\(M\\) be a c\u00e0d martingale which can be written as the difference between two natural increasing processes. Then \\(M\\) is indistinguishable from \\(0\\).</p> <p>Proof</p> <p>By the identity</p> \\[   E[X_t M_t] = E\\left[ \\int_0^t X_{s-} \\, dM_s \\right] \\] <p>for every c\u00e0dl\u00e0g bounded martingale \\(X\\), consider the approximation</p> \\[ X^n = \\sum_{k=1}^n X_{t_{k-1}} 1_{[t_{k-1}, t_k)} + X_t 1_{\\{t\\}} \\] <p>over a subdivision \\(0 = t_0 &lt; t_1 &lt; \\cdots &lt; t_n = t\\), which satisfies  </p> \\[   X^n_{-} = X_0 1_{\\{0\\}} + \\sum_{k=1}^n X_{t_{k-1}} 1_{(t_{k-1}, t_k]}. \\] <p>Hence, by the martingale property of \\(M\\) it holds  </p> \\[   E\\left[ \\int_0^t X^n_{s-} \\, dM_s \\right] = E\\left[ \\sum_{k=1}^n X_{t_{k-1}} (M_{t_k} - M_{t_{k-1}}) \\right] = 0. \\] <p>Letting the mesh of the subdivision to \\(0\\), dominated convergence yields</p> \\[   E[X_t M_t] = E\\left[ \\int_0^t X_{s-} \\, dA_s \\right] = 0. \\] <p>Let \\(X = E[1_A \\,|\\, \\mathcal{F}_\\cdot]\\) where \\(A = \\{M_t &gt; \\varepsilon\\}\\). Then \\(X\\) is a bounded martingale, and up to a modification, it is c\u00e0dl\u00e0g. It follows that</p> \\[   0 = E[X_t M_t] = E[1_A M_t] \\geq \\varepsilon P[A] \\] <p>so \\(P[A] = 0\\). The same holds for \\(A = \\{M_t &lt; -\\varepsilon\\}\\), showing that \\(M_t = 0\\). Since both \\(M\\) and \\(0\\) are c\u00e0dl\u00e0g, this implies indistinguishability.</p> <p>We can now address the Doob-Meyer decomposition.</p> <p>Definition</p> <p>A c\u00e0d process \\(X\\) is said to belong to class:</p> <ul> <li>(D) if the collection \\(\\{X_\\tau : \\tau \\text{ stopping time}, \\tau &lt; \\infty\\}\\) is uniformly integrable</li> <li>(DL) if the collections \\(\\{X_\\tau : \\tau \\text{ stopping time}, \\tau &lt; t\\}\\) are uniformly integrable for every \\(t\\)</li> </ul> <p>Doob-Meyer Decomposition</p> <p>Let \\(X\\) be a c\u00e0dl\u00e0g sub-martingale of class (DL). Then \\(X\\) can be decomposed uniquely \u2014 up to indistinguishability \u2014 into</p> \\[   X = M + A \\] <p>where \\(M\\) is a c\u00e0dl\u00e0g martingale and \\(A\\) is a natural increasing process. If furthermore, \\(X\\) is of class (D), then \\(M\\) is uniformly integrable and \\(A\\) is integrable.</p> <p>The proof relies on a deep functional analysis result describing the relatively compacts subsets of \\(L^1\\).</p> <p>Dunford-Pettis's Theorem</p> <p>A subset of \\(L^1\\) is \\(\\sigma(L^1, L^\\infty)\\)-relatively compact if and only if it is uniformly integrable.</p> <p>We do not address the proof of this theorem which involves functional analysis arguments.</p> <p>Remember that we use the notation \\(E[\\xi \\colon A] := E[X 1_A]\\).</p> <p>Proof of Doob-Meyer Decomposition</p> <ol> <li> <p>Uniqueness: Set \\(X = M + A = M' + A'\\).    It follows that \\(A - A' = M - M'\\) is a c\u00e0dl\u00e0g martingale which is the difference of two increasing natural processes.    From the previous proposition, \\(A - A' = M - M'\\) is indistinguishable from \\(0\\), hence the uniqueness.</p> </li> <li> <p>Decomposition along a discrete partition:     Fix \\(T\\) and consider the process on \\([0,T]\\).     Assume without loss of generality that \\(X_0 = 0\\) and use the dyadic partitions \\(\\Pi^n = \\{t_k^n = kT / 2^n : k = 0, \\ldots, 2^n\\}\\), and \\(\\Pi = \\cup \\Pi^n\\).     Define</p> \\[ A_t^n =   \\begin{cases}     0 &amp; \\text{if } t =0 \\\\     \\sum_{j=0}^{k-1} E[\\Delta_j^n X \\,|\\, \\mathcal{F}_{t_j^n}] &amp; \\text{if } t_k^n &lt; t \\leq t_{k+1}^n,\\; k=1,\\ldots,2^n-1   \\end{cases} \\] <p>where we use the notation \\(\\Delta_k^n Y = Y_{t_{k+1}^n} - Y_{t_k^n}\\). In other terms</p> \\[   A^n = \\sum_{k=0}^{2^n-2} E[\\Delta_k^n X \\,|\\, \\mathcal{F}_{t_k^n}] 1_{[t_k^n, t_{k+1}^n)} +  E[\\Delta_{2^{n-1}}^n X \\,|\\, \\mathcal{F}_{t_{2^n-1}^n}] 1_{\\{T\\}} \\] <p>This defines a c\u00e0g, piecewise constant, increasing process \\(A^n\\). Define \\(M^n = X - A^n\\), so that \\(X = M^n + A^n\\). Since \\(X\\) is a sub-martingale, \\(M^n\\) is a martingale on \\(\\Pi^n\\).</p> </li> <li> <p>Convergence of \\((A_T^n)\\):     For \\(\\lambda &gt; 0\\), define the stopping time \\(\\tau_\\lambda^n = \\inf\\{t \\colon A_t^n &gt; \\lambda\\} \\wedge T\\).     Since \\(A^n\\) is increasing, c\u00e0g and piecewise constant over \\(\\Pi^n\\), it follows that \\(\\tau_\\lambda^n\\) takes values in \\(\\Pi^n\\) and on \\(\\{\\tau^n_{\\lambda}&lt;T\\}\\) it holds that \\(A_{\\tau^n_\\lambda}^n \\leq \\lambda\\).     From optional sampling we have</p> \\[ \\begin{align}     E[A_T^n \\, \\colon \\, A_T^n &gt; \\lambda]       &amp; = E[A_T^n - A_{\\tau_\\lambda^n} \\, \\colon \\, \\tau^n_\\lambda &lt;T] + E[A_{\\tau_\\lambda^n}^n \\, \\colon \\, A_T^n &gt;\\lambda ]\\\\       &amp; = E[X_T - X_{\\tau_\\lambda^n} \\, \\colon \\, \\tau^n_\\lambda &lt;T] - \\underbrace{E[M^n_T - M^n_{\\tau^n_\\lambda} \\, \\colon \\, \\tau^n_\\lambda&lt;T]}_{=0 \\text{ Doob optional sampling}} + E[A_{\\tau_\\lambda^n}^n \\, \\colon \\, A_T^n &gt;\\lambda]\\\\     &amp;\\leq E[X_T^n - X_{\\tau_\\lambda^n }^n \\, \\colon\\, \\tau_\\lambda^n &lt; T] + \\lambda P[A_T^n&gt;\\lambda] \\end{align} \\] <p>On the other hand, for \\(\\tau^n_{\\lambda/2}\\) with the same doob's optional sampling arguments we get</p> \\[   \\begin{align*}      2E[X_T^n - X_{\\tau_{\\lambda/2}^n \\wedge T}^n \\, \\colon \\tau_{\\lambda/2}^n &lt; T]          &amp; = 2 E[A_T^n -A_{\\tau^n_{\\lambda/2}} \\colon A_T^n\\geq \\lambda/2]\\\\         &amp; \\geq 2 E[A_T^n -A_{\\tau^n_{\\lambda/2}} \\colon A_T^n\\geq \\lambda ]\\\\         &amp; \\geq \\lambda P[A_T^n &gt; \\lambda]\\\\   \\end{align*} \\] <p>Combining both, we get:</p> \\[   E[A_T^n \\, \\colon \\, A_T^n &gt; \\lambda] \\leq E[X_T - X_{\\tau_\\lambda^n} \\, \\colon\\, \\tau_\\lambda^n &lt; T] + 2 E[X_T - X_{\\tau_{\\lambda/2}^n} \\, \\colon\\, \\tau_{\\lambda/2}^n &lt; T] \\] <p>Since \\(X\\) is of class (DL), the families \\((X_T - X_{\\tau^n_\\lambda})\\) and \\((X_T - X_{\\tau^n_\\lambda})\\) are uniformly integrable. We therefore just need to show that \\(\\{\\tau_{\\lambda/2}^n&lt;T\\}\\supseteq \\{\\tau_\\lambda^n\\}\\) can be made arbitrarily small in \\(\\lambda\\) uniformly in \\(n\\) to show that \\((A_T^n)\\) is uniformly integrable. However, by Markov inequality, it holds that</p> \\[   P[\\tau_{\\lambda/2}^n&lt;T] = P[A_T^n &gt; \\lambda/2] \\leq \\frac{2}{\\lambda}E[A_T^n]= \\frac{2}{\\lambda} E[X_T] \\] <p>Thus, \\((A_T^n)\\) is uniformly integrable. By Dunford-Pettis, up to a subsequence, \\(A_T^n\\) converges weakly in \\(L^1\\) to some \\(A_T\\) in \\(L^1\\), that is \\(E[\\xi A_T^n] \\to E[\\xi A_T]\\) for all \\(\\xi\\) in \\(L^\\infty\\).</p> </li> <li> <p>Definition of the limit decomposition:     Define \\(M = E[X_T - A_T \\,|\\, \\mathcal{F}_\\cdot]\\), a c\u00e0dl\u00e0g martingale, and \\(A = X^T - M\\).     So \\(X = M + A\\) on \\([0,T]\\).     We just remained to show that \\(A\\) is natural.     Fix \\(t \\in \\Pi\\), for \\(n\\) large enough such that \\(t\\) is in \\(\\Pi^n\\), it holds that for every \\(\\xi\\) in \\(L^\\infty\\):</p> \\[   E[\\xi(A_t^n - A_t)] = E[E[\\xi \\,|\\, \\mathcal{F}_t](M_t - M_t^n)] = E[E[\\xi \\,|\\, \\mathcal{F}_t](A_T^n - A_T)] \\to 0 \\] <p>Hence \\(A_t^n \\to A_t\\) in \\(\\sigma(L^1, L^\\infty)\\). For any \\(s&lt;t\\) with \\(s\\) and \\(t\\) in \\(\\Pi^n\\), since \\(1_{\\{A_t&lt;A_s\\}}\\) is bounded, it holds</p> \\[     0\\geq E[(A_t-A_s)1_{\\{A_t&lt;A_s\\}}] = \\lim E[(A_t^n - A_s^n)1_{\\{A_t&lt;A_s\\}}] \\geq 0 \\] <p>showing that \\(P[A_t\\geq A_s] = 1\\). Since \\(A\\) is c\u00e0dl\u00e0g, we deduce that \\(A\\) is increasing.</p> <p>We are left to show that \\(A\\) is natural. For a bounded c\u00e0dl\u00e0g martingale \\(N\\)</p> \\[   \\begin{align}     E[N_T A_T^n] &amp;= E\\left[ \\int_0^T N_{s-} \\, dA_s^n \\right] \\\\     &amp;= \\sum E[N_{t_k^n} \\Delta_k^n A] + \\sum E[N_{t_k^n} \\Delta_k^n(M - M^n)] \\\\     &amp;\\to E\\left[ \\int_0^T N_{s-} \\, dA_s \\right]   \\end{align} \\] <p>so \\(E[N_T A_T] = E\\left[ \\int_0^T N_{s-} \\, dA_s \\right]\\), hence \\(A\\) is natural on \\([0,T]\\).</p> </li> <li> <p>Extension to \\([0,\\infty)\\) and case (D):     By uniqueness, decompositions on \\([0, T+n]\\) for each \\(n\\) are consistent, extending the result to \\([0,\\infty)\\).     If \\(X\\) is of class (D), then \\(A_T^n\\) are uniformly integrable, hence \\(A_T \\in L^1\\).     Also, \\(\\sup_t E[|X_t|] &lt; \\infty\\) implies:</p> \\[ E[M_t 1_{\\{M_t &gt; \\lambda\\}}] \\leq E[(X_t - A_T) 1_{\\{X_t - A_T &gt; \\lambda\\}}] \\] <p>By Markov\u2019s inequality and uniform integrability of \\(X_t - A_T\\), \\(M\\) is uniformly integrable.</p> </li> </ol> <p>In the following we will define the stochastic integral with respect to continuous martingale using the Doob-Meyer decomposition. So one may think that if \\(X\\) is continuous, then the Doob-Meyer decomposition is also continuous. This is not straightforward a-priori, and is the subject of the following theorem.</p> <p>Theorem</p> <p>Let \\(X\\) be a c\u00e0dl\u00e0g sub-martingale such that \\(E[X_{\\tau^n}]\\to E[X_\\tau]\\) for every increasing sequence of stopping times \\((\\tau^n)\\) with \\(\\sup \\tau^n=\\tau&lt;T\\) for some \\(T&gt;0\\). Then, the natural increasing process in the Doob-Meyer decomposition of \\(X\\) is continuous.</p> Proof <p>To be updated</p>"},{"location":"lecture/07-Stochastic-Integral/072-stochastic-integral/","title":"Stochastic Integral","text":"<p>Remark</p> <p>Note that if \\(X\\) is a c\u00e0dl\u00e0g sub-martingale such that \\(\\sup_{s\\leq t} X_s\\) is integrable for each \\(t\\), then \\(X\\) is of class (DL). Indeed, for any stopping time it holds</p> \\[     |X_{\\tau \\wedge t}|\\leq \\sup_{s \\leq t}|X_s| \\] <p>showing that the family is uniformly bounded by an integrable random variable, hence, is uniformly integrable.</p> <p>In particular, if \\(M\\) is a c\u00e0dl\u00e0g martingale which is \\(p\\)-integrable for \\(p&gt;1\\), then \\(|M|^p\\) is a positive sub-martingale and from from Doob's maximal inequality it follows that</p> \\[     E\\left[ \\sup_{s\\leq t} |M_s|^p \\right]^{1/p} \\leq \\frac{p}{p-1}\\left\\| M_t \\right\\|_{p} &lt;\\infty \\] <p>For \\(p=2\\), it follows that \\(M^2\\) is a sub-martingale of class (DL), hence, admits a Doob-Meyer decomposition. In particular, if \\(M\\) is continuous, it follows that the natural process in the decomposition is continuous too.</p> <p>Let us fix some notations.</p> <ul> <li> <p>By \\(\\mathcal{M}^2_c\\) we denote the space of square integrable continuous martingales \\(M\\) such that \\(M_0=0\\).</p> </li> <li> <p>For \\(M\\) in \\(\\mathcal{M}_c^2\\), we denote by \\(\\langle M\\rangle\\) the continuous natural process of bounded variation in the Doob-Meyer decomposition of the sub-martingale \\(M^2\\).      That is, \\(M^2=\\text{martingale}+\\langle M\\rangle\\).     We call \\(\\langle M\\rangle\\) the quadratic variations of \\(M\\).</p> </li> <li> <p>Such a continuous quadratic variation process \\(\\langle M\\rangle\\) defines a product measure \\(P\\otimes d\\langle M\\rangle\\) on \\(\\Omega\\otimes [0,\\infty)\\) with \\(\\sigma\\)-algebra \\(\\mathcal{F}\\otimes \\mathcal{B}([0, \\infty))\\).</p> </li> <li> <p>For every locally bounded and progressive measurable process \\(H\\) we can define the continuous and adapted process \\(\\int H d\\langle M\\rangle\\), and we denote by \\(\\mathcal{L}^2(M)\\) the space of progressively measurable processes \\(H\\) such that</p> \\[ E\\left[ \\int_{0}^{t}H^2 d\\langle M\\rangle  \\right]&lt;\\infty \\] <p>for every \\(t\\). If there is no risk of confusion, we often drop the reference to \\(M\\) and use the notation \\(\\mathcal{L}^2:=\\mathcal{L}^2(M)\\).</p> </li> <li> <p>We generically denote by \\(\\Pi=\\{0=\\tau_0&lt;\\tau_1&lt;\\ldots&lt;\\tau_n&lt;T\\}\\) a stochastic partition where \\(\\tau_k\\) are stopping times and \\(T&gt;0\\).     We call it a deterministic partition if each \\(\\tau_k=t_k \\in [0,\\infty)\\).     Further, we adopt the handy notation \\(\\Delta_k Y=Y^{\\tau_k}-Y^{\\tau_{k-1}}\\) for an increment of a progressive stochastic process \\(Y\\).     That is, \\(\\Delta_kY_t=Y_t^{\\tau_k}-Y_{t}^{\\tau_{k-1}}=Y_{t\\wedge \\tau_k}-Y_{t\\wedge \\tau_{k-1}}\\) for every \\(t\\).</p> </li> <li> <p>We denote by \\(\\mathcal{S}\\) the set of simple predictable integrands</p> \\[     H=H_0+\\sum_{k=1}^n H_k 1_{(\\tau_{k-1},\\tau_k]} \\] <p>where along a stochastic partition \\(\\Pi\\), \\(H_k\\) is \\(\\mathcal{F}_{\\tau_{k-1}}\\)-measurable and \\(|H_k|\\leq C\\) for every \\(k\\) and some constant \\(C\\).</p> </li> <li> <p>Finally for \\(H\\) in \\(\\mathcal{S}\\) and \\(M\\) in \\(\\mathcal{M}_c^2\\), we define the discrete stochastic integral</p> \\[ \\int H dM:=M_0H_0+\\sum_{k=1}^nH_k(M^{\\tau_k}-M^{\\tau_{k-1}})=\\sum_{k=1}^nH_k\\Delta_k M \\] </li> </ul> <p>Remark</p> <p>The stochastic integral \\(\\int H dM\\) for simple \\(H\\) follows the same definition as for the integral in the Lebesgue-Stieljes integral if we replace \\(M\\) by some BV process \\(A\\). Both are clearly linear operators, however, a fundamental difference between both, is the lack of monotonicity for the \\(\\int \\cdot dM\\), which is a corner stone of the definition of the Lebesgue-Stieljes integral that yields monotone convergence and then dominated convergence.</p> <p>In other terms, defining the stochastic integral \\(\\int \\cdot dM\\) beyond the class of simple processes can not involve the same arguments as the classical Lebesgue-Stieljes approach. The key answer to this problem is the so called Ito-Isometry.</p> <p>According to what has been done so far, we have from Doob's optional sampling theorem and the fact that \\(M\\) is a square integrable the following proposition easily follows</p> <p>Proposition</p> <p>Let \\(M\\) in \\(\\mathcal{M}_c^2\\). It follows that \\(\\int \\cdot\\, dM\\) is an operator from \\(\\mathcal{S}\\) to \\(\\mathcal{M}_c^2\\). It satisfies the following properties:</p> <ol> <li> <p>Linearity: \\(\\int (\\alpha H+\\beta G) dM=\\alpha\\int HdM+\\beta \\int GdM\\) for \\(\\alpha\\) and \\(\\beta\\) constants.</p> </li> <li> <p>Stopping property: \\(\\int 1_{\\{\\cdot \\leq \\tau\\}} H dM=\\int H dM^\\tau=\\int_0^{\\cdot \\wedge\\tau} H dM\\).</p> </li> <li> <p>Ito-Isometry: for every \\(t\\)</p> \\[   E\\left[ \\left( \\int_{0}^{t}H dM  \\right)^2 \\right]= E\\left[ \\int_{0}^{t} H^2 d\\langle M \\rangle   \\right] \\] </li> </ol> <p>Proof</p> <p>Since \\(H\\) is uniformly bounded, we know from Doob's optional sampling theorem that \\(\\int HdM\\) is a martingale which is continuous since \\(M\\) is continuous. Linearity is immediate and the stopping property is a simple adaptation of the discrete time version.</p> <p>We show the Ito-Isometry which as a consequence will show that \\(\\int HdM\\) is square integrable since \\(H\\) is bounded and \\(\\langle M\\rangle\\) is integrable, hence an element of \\(\\mathcal{M}_c^2\\). We denote by \\(N\\) the martingale in the Doob-Meyer decomposition \\(M^2=N+\\langle M\\rangle\\). Since \\(H\\) is uniformly bounded and \\(M\\) is square integrable, the following expectations and conditional expectations are well defined.</p> \\[ E\\left[ \\left( \\int_{0}^{t}H dM  \\right)^2 \\right]=\\sum_{k=1}^n E\\left[H_k^2\\left(\\Delta_kM_t\\right)^2  \\right] +2\\sum_{k&lt;j} E\\left[ H_kH_j\\Delta_k M_t \\Delta_j M_t \\right] \\] <p>Note that for every martingale, \\(E[M_{t\\wedge \\tau_j}|\\mathcal{F}_{\\tau_{j-1}}]=M_{t\\wedge \\tau_{j-1}}\\), and therefore \\(E[\\Delta_kM_t|\\mathcal{F}_{\\tau_{k-1}}]=0\\). Since \\(j&gt;k\\) and \\(H\\) is predictable, for the second term it holds</p> \\[ E\\left[ H_kH_j\\Delta_kM_t \\Delta_j M_t \\right] =E\\left[ H_kH_j\\Delta_k M_tE\\left[\\Delta_j M_t|\\mathcal{F}_{\\tau_{j-1}}\\right]\\right]=0 \\] <p>As for the first term, for the same reasons, one has</p> \\[ \\begin{align*}   E\\left[ H_k^2\\left(\\Delta_k M_{t} \\right)^2\\right]     &amp; = E\\left[ H_k^2\\left(\\left(M_{t\\wedge \\tau_k}^2 - M_{t\\wedge \\tau_{k-1}}^2\\right) -2 M_{t\\wedge \\tau_{k-1}}\\left(M_{t\\wedge \\tau_k} - M_{t\\wedge \\tau_{k-1}}\\right)\\right) \\right]\\\\     &amp; = E\\left[ H_k^2 \\Delta_k M^2_t \\right] -2 E\\left[ H_k^2 M_{t\\wedge \\tau_{k-1}}\\underbrace{E\\left[\\Delta_k M_t | \\mathcal{F}_{\\tau_{k-1}}\\right]}_{=0} \\right]\\\\     &amp; = E\\left[ H_k^2 \\left( \\Delta_k N_t + \\Delta_k \\langle M\\rangle_t \\right) \\right]\\\\     &amp; = E\\left[ H_k^2 \\underbrace{E\\left[ \\Delta_k N_t|\\mathcal{F}_{\\tau_{k-1}} \\right]}_{=0}\\right] + E\\left[H_k^2\\Delta_k \\langle M\\rangle_{t} \\right]\\\\     &amp; =E\\left[H_k^2\\Delta_k \\langle M\\rangle_{t} \\right]  \\end{align*} \\] <p>Summing up yields</p> \\[ E\\left[ \\left(\\int_{0}^{t}H dM\\right)^2  \\right]=E\\left[\\sum_{k=1}^n H_k^2 \\Delta_k\\langle M\\rangle_t\\right] =E\\left[ \\int_{0}^{t}H^2 d\\langle M\\rangle  \\right] \\] <p>Showing the Ito-Isometry and finishes the proof.</p> <p>So far we constructed a stochastic integral operator from \\(\\mathcal{S}\\) to \\(\\mathcal{M}_{c}^2\\). The question is whether we can extend it to some closure to \\(\\mathcal{S}\\subseteq \\mathcal{L}^2(M)\\) and in which form.</p> <p>Let us state first a classical topological result.</p> <p>Definition</p> <p>A metric vector space \\((E,d)\\) is called a Fr\u00e9chet space if</p> <ul> <li>Addition and multiplication by a scalar are continuous operations with respect to \\(d\\).</li> <li>\\(d\\) is translation invariant, that is, \\(d(x,y)=d(x+z,y+z)\\).</li> <li>\\((E,d)\\) is complete.</li> </ul> <p>Proposition</p> <p>Let \\((E,d)\\) and \\((E^\\prime,d^\\prime)\\) be two Fr\u00e9chet spaces and \\(F\\subseteq E\\) a linear subspace. Any linear function \\(f:F\\to E^\\prime\\) which is an isometry, that is, \\(d\\left( f(x),f(y) \\right)=d(x,y)\\), can be extended uniquely to a linear function \\(f:\\bar{F}\\to E^\\prime\\) which is also an isometry where \\(\\bar{F}\\) is the closure of \\(F\\) in \\(E\\). In particular, the extension is continuous.</p> <p>Proof</p> <p>For \\(x \\in \\bar{F}\\), let \\((x_n)\\) be a sequence of elements in \\(F\\) converging to \\(x\\). It follows that \\((x_n)\\) is in particular Cauchy. By the isometric property, so is the sequence \\((f(x_n))\\), which, by completeness of \\(E^\\prime\\), converges to some \\(y \\in E^\\prime\\). For another sequence \\((\\tilde{x}_n)\\) converging to \\(x\\), it also follows that \\((f(\\tilde{x}_n))\\) converges to some \\(\\tilde{y} \\in E^\\prime\\). By isometry and triangular inequality</p> \\[ \\begin{align*} d^\\prime(y,\\tilde{y})      &amp; \\leq d^\\prime(y,f(x_n))+d^\\prime(f(x_n),f(\\tilde{x}_n))+d^\\prime(f(\\tilde{x}_n),\\tilde{y})     \\\\     &amp; = d^\\prime(y,f(x_n))+d(x_n,\\tilde{x}_n)+d^\\prime(f(\\tilde{x}_n),\\tilde{y})     \\\\     &amp; \\leq d^\\prime(y,f(x_n))+d^\\prime(f(\\tilde{x}_n),\\tilde{y})+d(x_n,x)+d(x,\\tilde{x}_n) \\xrightarrow[n\\to \\infty]{} 0 \\end{align*} \\] <p>showing that \\(y = \\tilde{y}\\). Hence, the limit does not depend on the choice of the sequence \\((x_n)\\) converging to \\(x\\), so that we can extend \\(f\\) to \\(\\bar{F}\\). It is straightforward to check that the extension is once again an isometry and also linear since both metrics are translation invariant distances and addition as well as multiplication are continuous. As for the uniqueness of this isometric extension, it is also straightforward.</p> <p>Since \\(\\int \\cdot \\, dM\\) is a linear operator which is an isometry, we will apply this classical result of functional analysis to define the stochastic integral on the closure of \\(\\mathcal{S}\\). Two main questions now:</p> <ul> <li> <p>Question 1: What are the metrics \\(d\\) and \\(d^\\prime\\) we consider on \\(\\mathcal{L}^2(M)\\) and \\(\\mathcal{M}_c^2\\) making them into Fr\u00e9chet spaces?</p> </li> <li> <p>Question 2: What is the closure of \\(\\mathcal{S}\\)?</p> </li> </ul> <p>As for the first question, the answer comes from a general fact that Fr\u00e9chet distances are generated by countable families of semi-norms. For every \\(n\\), with some abuse of notations, let</p> \\[   \\begin{align*}     \\left\\Vert H1_{[0,n]}\\right\\Vert_{2}       &amp; : =E\\left[ \\int H^21_{[0,n]} d\\langle M\\rangle \\right]^{1/2}\\\\       &amp; =E\\left[ \\int_{0}^{n}H^2 d\\langle M\\rangle \\right]^{1/2} \\\\     \\left\\Vert N_n\\right\\Vert_{2}       &amp; :=E\\left[ N_n^2 \\right]^{1/2}   \\end{align*} \\] <p>for \\(H\\) in \\(\\mathcal{L}^2(M)\\) and \\(N \\in \\mathcal{M}_c^2\\). On the one hand \\(\\left\\Vert\\cdot 1_{[0,n]}\\right\\Vert_{2}\\) is the standard \\(L^2\\) norm on the product space of \\(\\Omega\\times [0,n]\\) with the measure \\(P\\otimes d\\langle M\\rangle\\), and therefore a semi-norm on \\(\\mathcal{L}^2(M)\\). On the other hand, by Doob's maximal inequality \\(E[\\sup_{s\\leq n}N_s^2]\\leq C E[N_n^2]\\), and therefore \\(\\left\\Vert\\cdot_n\\right\\Vert_{2}\\) is a norm on the space of continuous square integrable martingales restricted to \\([0,n]\\), hence a semi-norm on \\(\\mathcal{M}^2_c\\).</p> <p>We can define</p> \\[ \\begin{align*} d(H,H^\\prime) &amp;= \\sum \\frac{1}{2^n}\\frac{\\left\\Vert(H-H^\\prime)1_{[0,n]}\\right\\Vert_{2}}{1+\\left\\Vert(H-H^\\prime)1_{[0,n]}\\right\\Vert_{2}}, \\\\ d^\\prime(N,N^\\prime) &amp;= \\sum \\frac{1}{2^n}\\frac{\\left\\Vert N_n-N^\\prime_n\\right\\Vert_{2}}{1+\\left\\Vert N^\\prime_n-N^\\prime_n\\right\\Vert_{2}} \\end{align*} \\] <p>for \\(H,H^\\prime\\) in \\(\\mathcal{L}^2(M)\\) and \\(N,N^\\prime\\) in \\(\\mathcal{M}^2_c\\).</p> <p>Lemma</p> <p>Both \\((\\mathcal{L}^2(M),d)\\) and \\((\\mathcal{M}_c^2,d^\\prime)\\) are Fr\u00e9chet spaces.</p> <p>Proof</p> <p>It is quite standard to check that both functions define distances which are translation invariant and for which addition and multiplication by scalar in both vector spaces are continuous. Furthermore, it is also clear that \\(\\mathcal{L}^2(M)\\) is complete since the \\(\\left\\Vert\\cdot\\right\\Vert_2\\) norm on any compact \\([0,n]\\) makes \\(L^2(P\\otimes d\\langle M\\rangle)\\) into a complete normed space. We just check that \\(\\mathcal{M}_c^2\\) is complete for the distance \\(d^\\prime\\).</p> <p>Let \\((M^n)\\) be a Cauchy sequence in \\(\\mathcal{M}^2_c\\). It follows that \\((M_t^n)\\) is Cauchy in \\(L^2_t\\) for any \\(t\\), hence converges in \\(L^2\\) to \\(M_t\\). Let further \\(A\\) be an event in \\(\\mathcal{F}_s\\). It follows from the martingale property of \\(M^n\\) that \\(E[M_t1_{A}]=\\lim_n E[M_t^n1_{A}]=\\lim_n E[M_s^n 1_{A}]=E[M_s1_{A}]\\). Choosing the c\u00e0dl\u00e0g version of \\(M\\) shows that \\(M\\) is a c\u00e0dl\u00e0g martingale with \\(M_t\\) in \\(L^2_t\\) for every \\(t\\). Let us prove that \\(M\\) is actually continuous. By Doob's maximal inequality one has</p> \\[ P\\left[ \\sup_{s\\leq t} \\left\\vert M_s^n-M_s\\right\\vert&gt;\\lambda \\right]\\leq \\frac{1}{\\lambda} \\left\\Vert M_t^n-M_t\\right\\Vert_2^2 \\xrightarrow[n\\to \\infty]{} 0. \\] <p>Hence \\(P[\\sup_{s\\leq t}\\left\\vert M_s^{n_k}-M_s\\right\\vert&gt;\\lambda]\\leq 1/2^{k}\\) for some \\(n_k\\) and every \\(k\\). Applying Borel-Cantelli, it follows that \\(P[\\liminf \\{\\sup_{s\\leq t}\\left\\vert M_s^n-M_s\\right\\vert\\leq \\lambda\\}]=1\\) for every \\(\\lambda\\), showing that for \\(P\\)-almost all \\(\\omega\\in \\Omega\\) the continuous path \\(M^n(\\omega)\\) converges uniformly on \\([0,t]\\) to \\(M(\\omega)\\), that is \\(M\\) is continuous.</p> <p>As for the second question about the closure of \\(\\mathcal{S}\\), we have</p> <p>Lemma</p> <p>The space \\(\\mathcal{S}\\) is dense in \\(\\mathcal{L}^2(M)\\). In particular, for each \\(H\\in\\mathcal{L}^2(M)\\) there exists a sequence \\((H^n)\\subseteq\\mathcal{S}\\) satisfying \\(\\left\\Vert(H-H^n)1_{[0,t]}\\right\\Vert_{2}\\to 0\\) for all \\(t\\).</p> <p>Remark</p> <p>The \u201csize\u201d of the closure of \\(\\mathcal{S}\\) depends on the \u201cregularity\u201d of \\(\\langle M\\rangle\\), allowing for more or fewer integrands for the stochastic integral with respect to \\(M\\). On the one hand, if \\(\\langle M\\rangle\\) is absolutely continuous \u2014 for instance in the case of the Brownian motion \u2014 then it is even possible to define a stochastic integral with respect to integrands in \\(L^2(P\\otimes d\\langle M\\rangle)\\) which are \u201conly\u201d measurable and adapted and not necessarily progressive. On the other hand, if \\(M\\) were an element of \\(\\mathcal{M}^2\\) \u2014 those c\u00e0dl\u00e0g martingales such that \\(E[M_t^2]&lt;\\infty\\) for all \\(t\\), such as some class of L\u00e9vy Processes \u2014 then it is also possible to define a stochastic integral but with respect to a smaller set of integrands, namely those predictable processes in \\(\\mathcal{L}^2(M)\\).</p> <p>Proof</p> <p>Step 1: Assume first that the paths of \\(\\langle M\\rangle\\) are absolutely continuous almost surely. In particular, \\(P\\otimes d\\langle M\\rangle \\ll P\\otimes dt\\). Fix \\(t\\).</p> <ul> <li> <p>If \\(H\\) is continuous, adapted and bounded, hence, by a proposition in the previous chapter, progressive, it holds that \\(H^n\\) were</p> \\[   H^n_s = H_{\\frac{kt}{2^n}}, \\] <p>for \\(kt/2^n &lt; s \\leq (k+1)t/2^n\\) converges \\(P\\otimes dt\\) to \\(H\\) on \\(\\Omega \\times [0,t]\\), and by Lebesgue's dominated convergence, it follows that \\(\\left\\Vert(H^n-H)1_{[0,t]}\\right\\Vert_{2}\\to 0\\), showing that continuous adapted and bounded processes are included in \\(\\bar{\\mathcal{S}}\\).</p> </li> <li> <p>If \\(H\\) is progressively measurable and bounded.     For every \\(n\\), define</p> \\[ G_s^n(\\omega) = n \\int_{(s - 1/n) \\vee 0}^s H_u(\\omega) \\, du. \\] <p>It follows that \\(G^n\\) is a bounded, adapted and continuous process on \\([0,t]\\). By the fundamental theorem of calculus, it follows that for almost all \\(\\omega \\in \\Omega\\), \\(G_s^n(\\omega) \\to H_s(\\omega)\\) for \\(dt\\)-almost all \\(s \\in [0,t]\\). Hence, by Fubini, \\(\\{\\lim G^n \\neq H\\}\\) is a \\(P \\otimes dt\\)-null measure set. Indeed,</p> \\[ P\\otimes dt\\left[ \\lim G_n \\neq H \\right] = \\int_{\\Omega}\\left( \\int_{0}^{t} 1_{\\left\\{ (\\omega,u): \\lim G_u^n(\\omega) \\neq H_u(\\omega) \\right\\}}(s) \\, ds \\right) P(d\\omega) = 0. \\] <p>And since \\(P \\otimes d\\langle M\\rangle \\ll P \\otimes dt\\), it follows that \\(\\{\\lim G^n \\neq H\\}\\) is a \\(P \\otimes d\\langle M\\rangle\\)-null set. In other terms, \\(G^n \\to H\\) \\(P \\otimes d\\langle M\\rangle\\)-almost surely. By Lebesgue's dominated convergence, it follows that \\(\\left\\Vert(G^n - H)1_{[0,t]}\\right\\Vert_{2} \\to 0\\).</p> <p>Hence, bounded progressively measurable processes are included in the closure of continuous adapted and bounded processes, themselves included in \\(\\bar{\\mathcal{S}}\\).</p> </li> <li> <p>If \\(H\\) is a progressive process, define \\(G^n_t = H_t 1_{\\{|H_t| \\leq n\\}}\\), which is progressive and bounded.     It follows that \\(G^n \\to H\\) \\(P \\otimes d\\langle M\\rangle\\)-almost surely and is dominated by \\(H\\), which is integrable.     Hence, by dominated convergence we have \\(\\left\\Vert(H^n - H)1_{[0,t]}\\right\\Vert_{2} \\to 0\\), showing that \\(\\mathcal{L}^2(M)\\) is included in the closure of bounded progressively measurable processes, themselves included in \\(\\bar{\\mathcal{S}}\\).</p> </li> </ul> <p>Step 2: Let us now address the case where \\(d\\langle M\\rangle\\) is not absolutely continuous with respect to \\(dt\\). Just as previously, it is enough to show that every \\(H\\) progressive, uniformly bounded by a constant \\(C\\), and nonzero only on \\([0,m]\\) can be approximated by elements of \\(\\mathcal{S}\\) in the \\(\\left\\Vert\\cdot\\right\\Vert_{2}\\)-norm. The idea is to \u201ctweak\u201d \\(d\\langle M\\rangle\\) into a measure absolutely continuous with respect to \\(dt\\) by means of a time change. Since \\(\\langle M \\rangle_s + s\\) is strictly increasing and continuous, there exists a strictly increasing and continuous inverse \\(T:\\Omega \\times \\mathbf{T} \\to \\mathbf{T}\\) such that \\(\\langle M\\rangle_{T_s(\\omega)}(\\omega) + T_s(\\omega) = s\\) for all \\(s \\in \\mathbf{T}\\). In particular,(1) \\(T_s \\leq s\\) since \\(A_t + t \\geq t\\) and \\(\\{T_s \\leq t\\} = \\{A_t + t \\geq s\\} \\in \\mathcal{F}_t\\) for all \\(t\\). It follows that \\(T_s\\) is a bounded stopping time for every \\(s\\).</p> <ol> <li>Recall that the general right-continuous inverse of an increasing function \\(f\\) is given by \\(f^{-1}(s)=\\sup\\{t: f(t)\\leq s\\}\\). However, if \\(f\\) is strictly increasing and continuous, it follows that \\(f^{-1}(s)=\\inf\\{t: s\\leq f(t)\\}\\). Furthermore, if \\(f(t)\\geq t\\), then \\(f^{-1}(s)\\leq s\\).</li> </ol> <p>We then define the new filtration \\(\\mathcal{G}_s := \\mathcal{F}_{T_s}\\) for \\(s \\in \\mathbf{T}\\) and the process \\(G_s = H_{T_s}\\), which is \\(\\mathbb{G}\\)-adapted and measurable since \\(H\\) is \\(\\mathbb{F}\\)-progressive. However, we do not know whether \\(G\\) is progressive. We can however modify it and assume that it is progressive and adapted. From the previous argumentation, there exists a simple process \\(G^\\varepsilon\\) of the form</p> \\[ H^n_s = H_{\\frac{kt}{2^n}}, \\quad \\text{for } \\frac{kt}{2^n} &lt; s \\leq \\frac{(k+1)t}{2^n} \\] <p>such that \\(E[\\int_0^\\lambda |G - G^\\varepsilon|^2 ds] \\leq \\varepsilon/2\\) for a given \\(\\lambda\\). However, since</p> \\[ E\\left[\\int G_s^2 \\, ds\\right] \\leq E\\left[\\int 1_{\\{T_s \\leq m\\}} H_{T_s}^2 \\, ds\\right] \\leq C E[\\langle M\\rangle_m + m] &lt; \\infty, \\] <p>we may choose \\(\\lambda\\) large enough and \\(G^\\varepsilon\\) zero outside \\([0,\\lambda]\\) to get</p> \\[ E\\left[\\int |G^\\varepsilon_s - G_s|^2 \\, ds\\right] &lt; \\varepsilon. \\] <p>Reversing the time clock, it follows that</p> \\[ H^\\varepsilon_t = H_0 1_{\\{0\\}}(t) + \\sum G^\\varepsilon_{s_k} 1_{]T_{s_k}, T_{s_{k+1}}]}(t) \\] <p>which is a simple process since \\(T_{s_k}\\) is a bounded stopping time and \\(G^\\varepsilon_{s_k}\\) is \\(\\mathcal{F}_{T_{s_k}}\\)-measurable. Hence, by definition</p> \\[ E\\left[ \\int_0^m |H_t^\\varepsilon - H_t|^2 d\\langle M\\rangle_t \\right] \\leq E\\left[ \\int_0^m |H_t^\\varepsilon - H_t|^2 (d\\langle M\\rangle_t + dt) \\right] \\leq E\\left[ \\int |G^\\varepsilon_s - G_s|^2 ds \\right] \\leq \\varepsilon, \\] <p>which ends the proof.</p> <p>We have now all the ingredients to define the stochastic integral.</p> <p>Theorem</p> <p>Let \\(M \\in \\mathcal{M}_c^2\\). There exists a unique continuous linear functional </p> \\[ \\begin{equation*}   \\begin{split}     \\int \\cdot \\, dM  \\colon \\mathcal{L}^2(M) &amp; \\longrightarrow \\mathcal{M}_2^c\\\\                               H &amp; \\longmapsto \\int H dM   \\end{split} \\end{equation*} \\] <p>coinciding with the elementary stochastic integral on \\(\\mathcal{S}\\). Furthermore, the following properties hold:</p> <ol> <li> <p>Linearity: \\(\\int (\\alpha H + \\beta G) \\, dM = \\alpha \\int H \\, dM + \\beta \\int G \\, dM\\) for constants \\(\\alpha\\) and \\(\\beta\\).</p> </li> <li> <p>Stopping property: \\(\\int 1_{\\{\\cdot \\leq \\tau\\}} H \\, dM = \\int H \\, dM^\\tau = \\int_0^{\\cdot \\wedge \\tau} H \\, dM\\).</p> </li> <li> <p>It\u00f4-Isometry: For every \\(t\\)</p> \\[ E\\left[ \\left( \\int_{0}^{t}H \\, dM  \\right)^2 \\right] = E\\left[ \\int_{0}^{t} H^2 \\, d\\langle M \\rangle \\right] \\] </li> </ol> <p>And the quadratic variations of the square integrable continuous martingale \\(\\int H \\, dM\\) are given by</p> \\[       \\left\\langle \\int H \\, dM \\right\\rangle = \\int H^2 \\, d\\langle M \\rangle \\] <p>Proof</p> <p>We already handled here all the elements of the proof which are consequences of the previous results, up to the stopping property and the quadratic variations of \\(\\int H \\, dM\\). As for the stopping property, it follows directly by approximating \\(H \\in \\mathcal{L}^2\\) by elements in \\(\\mathcal{S}\\).</p> <p>As for the quadratic variations of \\(\\int H \\, dM\\), note that \\(\\int H_s^2 \\, d\\langle M\\rangle\\) is a continuous process of bounded variation, hence normal. From the uniqueness of the Doob-Meyer decomposition, we just have to show that</p> \\[ \\left( \\int H \\, dM \\right)^2 - \\int H^2 \\, d\\langle M\\rangle \\] <p>is a martingale. Clearly it is integrable and adapted. For \\(s \\leq t\\) and any event \\(A\\) in %\\mathcal{F}_s$, by It\u00f4-isometry and \\(\\int H \\, dM\\) being a square integrable martingale, it holds</p> \\[ \\begin{multline*} E\\left[ 1_A \\left( \\left( \\int_{0}^{t} H \\, dM \\right)^2 - \\int_{0}^{t} H^2 \\, d\\langle M\\rangle - \\left( \\int_{0}^{s} H \\, dM \\right)^2 + \\int_{0}^{s} H^2 \\, d\\langle M\\rangle \\right) \\right] \\\\ = E\\left[ 1_A \\left( \\int_{s}^{t} H \\, dM \\right)^2 \\right] - E\\left[ 1_A \\int_{s}^{t} H^2 \\, d\\langle M\\rangle \\right] + E\\left[ 1_A \\left( \\int_{0}^{s} H \\, dM \\right) \\left( \\int_{s}^{t} H \\, dM \\right) \\right] \\\\ = E\\left[ 1_A E\\left[ \\left( \\int_{s}^{t} H \\, dM \\right)^2 \\big| \\mathcal{F}_s \\right] \\right] - E\\left[ 1_A \\int_{s}^{t} H^2 \\, d\\langle M\\rangle \\right] + E\\left[ 1_A \\left( \\int_{0}^{s} H \\, dM \\right) E\\left[ \\int_{s}^{t} H \\, dM \\big| \\mathcal{F}_s \\right] \\right] \\\\ = E\\left[ 1_A \\int_{s}^{t} H^2 \\, d\\langle M\\rangle \\right] - E\\left[ 1_A \\int_{s}^{t} H^2 \\, d\\langle M\\rangle \\right] = 0 \\end{multline*} \\] <p>finishing the proof.</p> <p>We call this operator the stochastic integral of \\(H\\) with respect to \\(M\\). For square integrable continuous martingales \\(M\\) and \\(N\\), the covariation of \\(M,N\\) is given by the polar formula</p> \\[   \\langle M, N\\rangle = \\frac{1}{4} \\left( \\langle M + N \\rangle - \\langle M - N \\rangle \\right) \\] <p>The following relation holds</p> <p>Proposition</p> <p>Let \\(M, N \\in \\mathcal{M}_c^2\\) and \\(G \\in \\mathcal{L}^2(M)\\), \\(H \\in \\mathcal{L}^2(N)\\). Then it holds</p> \\[ \\langle \\int G \\, dM, \\int H \\, dN \\rangle = \\int G \\, d\\langle M, \\int H \\, dN \\rangle = \\int GH \\, d\\langle M, N \\rangle \\] <p>In particular, for \\(G \\in \\mathcal{L}^2(M)\\) and \\(H \\in \\mathcal{L}^2\\left( \\int G \\, dM \\right)\\), it holds that \\(GH \\in \\mathcal{L}^2(M)\\) and the chain rule</p> \\[ \\int H \\, d \\int G \\, dM = \\int GH \\, dM \\] <p>This relation is straightforward for \\(G, H \\in \\mathcal{S}\\). The passage to the limit is left as an exercise by using the following proposition known as the Kunita-Watanabe inequality, a stochastic version of H\u00f6lder.</p> <p>Proposition</p> <p>Let \\(M, N \\in \\mathcal{M}_{c}^2\\) and \\(G \\in \\mathcal{L}^2(M)\\), \\(H \\in \\mathcal{L}^2(N)\\). Then it holds</p> \\[   \\begin{align*}      \\left\\vert\\int GH \\, d\\langle M,N\\rangle \\right\\vert          &amp; \\leq \\int \\left\\vert GH \\right\\vert \\, d\\left\\vert \\langle M,N \\rangle \\right\\vert         \\\\         &amp; \\leq \\left( \\int \\left\\vert G \\right\\vert^2 \\, d\\langle M \\rangle \\right)^{1/2} \\left( \\int \\left\\vert H \\right\\vert^2 \\, d\\langle N \\rangle \\right)^{1/2}   \\end{align*} \\] <p>Proof</p> <p>Recall that</p> \\[ \\langle M, N \\rangle = \\frac{1}{4}(\\langle M + N \\rangle - \\langle M - N \\rangle) \\] <p>and therefore</p> \\[ |\\langle M, N \\rangle| = \\frac{1}{4}(\\langle M + N \\rangle + \\langle M - N \\rangle). \\] <p>Furthermore, for two simple processes \\(G, H \\in \\mathcal{S}\\), a painful but easy inspection shows that \\(GH \\in \\mathcal{S}\\). Hence,</p> \\[ \\begin{align*}   \\left\\vert \\int GH \\, d\\langle M,N\\rangle \\right\\vert      &amp; = \\left\\vert \\sum G_k H_k \\Delta_k \\langle M, N \\rangle \\right\\vert     \\\\     &amp; \\leq \\sum \\left\\vert G_k H_k \\right\\vert \\left\\vert \\Delta_k \\langle M, N \\rangle \\right\\vert\\\\     &amp; = \\int \\left\\vert GH \\right\\vert \\, d|\\langle M, N \\rangle| \\end{align*} \\] <p>showing, by passing to the limit on the simple processes, the first inequality. Furthermore, by the Cauchy-Schwarz inequality, it holds</p> \\[ |\\Delta_k \\langle M, N \\rangle| \\leq (\\Delta_k \\langle M \\rangle)^{1/2} (\\Delta_k \\langle N \\rangle)^{1/2}. \\] <p>Hence, for simple integrands, using H\u00f6lder's inequality, it holds</p> \\[ \\begin{align*}   \\int \\left\\vert GH \\right\\vert \\, d|\\langle M,N \\rangle|     &amp; = \\sum \\left\\vert G_k H_k \\right\\vert \\left\\vert \\Delta_k \\langle M, N \\rangle \\right\\vert     \\\\     &amp; \\leq \\sum \\left\\vert G_k \\right\\vert \\left\\vert H_k \\right\\vert (\\Delta_k \\langle M \\rangle )^{1/2} (\\Delta_k \\langle N \\rangle )^{1/2}     \\\\     &amp; \\leq \\left( \\sum \\left\\vert H_k \\right\\vert^2 \\Delta_k \\langle M \\rangle \\right)^{1/2} \\left( \\sum \\left\\vert G_k \\right\\vert^2 \\Delta_k \\langle N \\rangle \\right)^{1/2}     \\\\     &amp; = \\left( \\int \\left\\vert G \\right\\vert^2 \\, d\\langle M \\rangle \\right)^{1/2} \\left( \\int \\left\\vert H \\right\\vert^2 \\, d\\langle N \\rangle \\right)^{1/2} \\end{align*} \\] <p>The case of general integrands follows by passing to the limit with simple integrands in this inequality.</p>"},{"location":"lecture/07-Stochastic-Integral/073-quadratic-variations/","title":"Semi-Martingales - Quadratic Variations","text":""},{"location":"lecture/07-Stochastic-Integral/073-quadratic-variations/#localization-semi-martingales-quadratic-and-co-variations","title":"Localization, Semi-Martingales, Quadratic and Co-Variations","text":"<p>Up to now we defined the stochastic integral with respect to continuous square integrable martingale. However, we saw that we may localise the construction by stopping the processes, so that we can define a stochastic integral by localizing. We call an increasing sequence of stopping times \\((\\tau^n)\\) such that \\(\\tau^n \\nearrow \\infty\\) a localizing sequence of stopping times. Let \\(\\mathcal{M}^{loc}_c\\) be the set of adapted continuous processes such that there exists a localizing sequence of stopping times \\((\\tau^n)\\) with \\(M^{\\tau^n}\\in \\mathcal{M}_c^2\\) for every \\(n\\). Given such a process \\(M\\in \\mathcal{M}^{loc}_c\\), with corresponding localizing sequence of stopping times, we can define \\(\\langle M^{\\tau^n}\\rangle\\) for every \\(n\\) and it holds \\(\\langle M^{\\tau^{n}}\\rangle =\\langle M^{\\tau^{n+1}}\\rangle\\) on \\([0,\\tau^n]\\). Hence we can define \\(\\langle M\\rangle\\). Following the same idea, we define \\(\\mathcal{L}^{loc}(M)\\) for \\(M \\in \\mathcal{L}^{loc}\\) as the set of progressive measurable processes such that \\(\\int_0^t Hd \\langle M\\rangle &lt;\\infty\\) \\(P\\)-almost surely for every \\(t\\) that allows to define locally the stochastic integral.</p> <p>Proposition</p> <p>Let \\(M \\in \\mathcal{M}^{loc}_c\\) and \\(H \\in \\mathcal{L}^{loc}(M)\\), then there exists a unique continuous local martingale \\(\\int_{}^{} H d M\\) in \\(\\mathcal{M}_c^{loc}\\) such that \\(\\int_{}^{} H d M=\\int_{}^{} Hd M^{\\tau^n}\\) on \\([0,\\tau^n]\\) for every \\(n\\).</p> <p>Proof</p> <p>We define \\(\\tau^n=\\inf\\{t\\colon |M_t|&gt;n \\text{ or }\\int_{0}^{t}|H|^2d\\langle M\\rangle &gt;n\\}\\). It follows that \\((\\tau^n)\\) is a localizing sequence of stopping time and \\(H^n=H1_{\\cdot \\leq \\tau^n}\\) is in \\(\\mathcal{L}^2(M^{\\tau^n})\\). Therefore \\(\\int_{}^{} H^n dM^{\\tau^n}\\) is well defined in \\(\\mathcal{M}_2^c\\). Furthermore \\(\\int_{}^{} H^n dM^{\\tau^n}=\\int_{}^{} H^{n+1} dM^{\\tau^{n+1}}\\) on the stochastic interval \\([0, \\tau^n]\\). Since \\(\\tau^n \\nearrow \\infty\\), the assertion follows by defining \\(\\int_{0}^{t} H dM(\\omega)=\\int_{0}^{t}H^n dM^{\\tau^n}(\\omega)\\) for \\(n\\) such that \\(\\tau^n(\\omega)&gt;t\\).</p> <p>All the properties of the stochastic integral also holds by localising. We can therefore define a stochastic integral with respect to continuous local martingales as well as a Lebesgue-Stieljes integral with respect to processes of bounded variations. This motivates the following definition:</p> <p>Definition</p> <p>A semi-martingale is a process \\(X\\) with decomposition \\(X=X_0+M+A\\) where \\(A\\) is the difference of two increasing continuous processes and \\(M\\) is a continuous local martingale.</p> <p>For two semi-martingales<sup>1</sup> \\(X=X_0+M+A\\) and \\(Y=Y_0+N+B\\), we define </p> <ul> <li>the quadratic variations: \\(\\langle X\\rangle:=\\langle M\\rangle\\);</li> <li>the co-variations: \\(\\langle X,Y\\rangle:=(\\langle X+Y\\rangle -\\langle X-Y\\rangle)/4=(\\langle M+N\\rangle-\\langle M-N\\rangle)/4=\\langle M,N\\rangle\\).</li> </ul> <p>For every progressive process \\(H\\) such that \\(\\int_{0}^{t}|H|d|A|&lt;\\infty\\) and \\(\\int_{0}^{t} |H|^2d\\langle M\\rangle&lt;\\infty\\) almost surely for every \\(t\\), we can therefore define</p> \\[ \\int_{}^{} H dX:= \\int_{}^{} H dM+\\int_{}^{} HdA \\] <p>We denote by \\(\\mathcal{L}^{loc}(X)\\) the set of these processes. The definition of quadratic and co-variations of a semi-martingale may seem a little bit arbitrary, all derived from the increasing process in the Doob-Meyer decomposition. However, we have an alternative way \u2014 in the pathwise sense \u2014 to interpret the quadratic and co-variations. In order to do so, let us first provide a new notion of convergence.</p> <p>Definition</p> <p>We say that a sequence of c\u00e0dl\u00e0g processes \\((X^n)\\) converges uniformly on compacts in probability to a c\u00e0dl\u00e0g process \\(X\\) if it holds</p> \\[ P\\left[ \\sup_{s\\leq t}\\left| X^n_s-X_s \\right|&gt;\\varepsilon \\right]\\xrightarrow[n\\to \\infty]{}0 \\] <p>for every \\(t\\). In that case we use the shorthand notation \\(X^n \\rightarrow X\\) in ucp.</p> <p>The following lemma will be quite useful in the following propositions.</p> <p>Lemma</p> <p>Let \\((\\tau^m)\\) be a localizing sequence of stopping times and \\((X^n)\\) a sequence of c\u00e0dl\u00e0g adapted processes. It follows that \\(X^n \\to X\\) ucp if and only if \\(X^{n, \\tau^m}\\to X^{\\tau^m}\\) ucp for every \\(m\\).</p> <p>Proof</p> <p>The implication is obvious. As for the reciprocal, it holds</p> \\[ \\left\\{ \\sup_{s\\leq t}|X^n_s - X_s|\\geq \\varepsilon \\right\\}\\subseteq \\left\\{ \\tau^m \\leq t \\right\\}\\cup \\left\\{ \\sup_{s\\leq t}\\left| X_s^{n,\\tau^m}-X^{\\tau_m}_s \\right|&gt;\\varepsilon \\right\\} \\] <p>Let \\(\\delta &gt;0\\), there exists \\(m\\) such that \\(P[\\tau^m\\leq t]&lt;\\delta /2\\). By ucp convergence of \\((X^{n,\\tau^m})\\) to \\(X^{\\tau^m}\\), it follows that for any \\(n\\) large enough, \\(P[\\sup_{s\\leq t}|X_s^{n,\\tau^m}-X_s^{\\tau^m}|&gt;\\varepsilon]\\leq \\delta /2\\). All together it follows that for all \\(n\\) large enough, we have</p> \\[ P\\left[ \\sup_{s\\leq t}\\left| X^n_s-X_s \\right|&gt;\\varepsilon \\right]\\leq P\\left[\\tau^m\\leq t  \\right]+P\\left[\\sup_{s\\leq t}|X_s^{n,\\tau^m}-X_s^{\\tau^m}|&gt;\\varepsilon\\right]\\leq \\delta \\] <p>ending the proof.</p> <p>This lemma shows that ucp convergence is a very local property, so that we just have to check it for every stopping time of a localizing sequence of stopping times.</p> <p>Given stochastic processes \\(X\\) and \\(Y\\) and a partition \\(\\Pi=\\{0=t_0&lt;t_1&lt;\\cdots&lt;t_n \\ldots \\nearrow \\infty\\}\\), we define</p> \\[ \\begin{split}     [X,Y]_t^{\\Pi}&amp; =\\sum \\left( X_{t_{k}\\wedge t}-X_{t_{k-1}\\wedge t} \\right)\\left( Y_{t_k\\wedge t}-Y_{t_{k-1}\\wedge t} \\right)\\\\                  &amp; =\\sum_{k=1}^n \\left( X_{t_k}-X_{t_{k-1}} \\right)\\left( Y_{t_k}-Y_{t_{k-1}} \\right)+(X_{t}-X_{t_n})(Y_t-Y_{t_{n}})\\\\     [X]_t^{\\Pi} :=[X,X]_t^{\\Pi} &amp; =\\sum \\left( X_{t_{k}\\wedge t}-X_{t_{k-1}\\wedge t} \\right)^2=\\sum_{k=1}^n \\left( X_{t_k}-X_{t_{k-1}} \\right)^2+(X_{t}-X_{t_n})^2 \\end{split} \\] <p>where \\(n\\) is such that \\(t_n \\leq t&lt;t_{n+1}\\), the quadratic variations process of \\(X\\) along \\(\\Pi\\). Note that \\([X,Y]^{\\Pi}=([X+Y]^{\\Pi}-[X-Y]^\\Pi)/4\\), so that we can as well define the co-variations from the quadratic variations. By \\(|\\Pi|=\\sup |t_k-t_{k-1}|\\) we denote the mesh of the subdivision.</p> <p>Definition</p> <p>Let \\(X\\) and \\(Y\\) be two c\u00e0dl\u00e0g processes. We say that</p> <ul> <li> <p>\\(X\\) has quadratic variations if there exists a c\u00e0dl\u00e0g process \\([X]\\) such that</p> \\[   [X]^{\\Pi^n}\\xrightarrow[n\\to \\infty]{ucp} [X] \\] <p>for every sequence of partitions \\((\\Pi^n)\\) with mesh converging to \\(0\\).</p> </li> <li> <p>\\(X\\) and \\(Y\\) have co-variations if there exists a c\u00e0dl\u00e0g process \\([X,Y]\\) such that</p> \\[ [X,Y]^{\\Pi^n}\\xrightarrow[n\\to \\infty]{ucp} [X,Y] \\] <p>for every sequence of partitions \\((\\Pi^n)\\) with mesh converging to \\(0\\).</p> </li> </ul> <p>This may seem to be an overload of definition, but the following proposition shows that the two concepts coincide in the case of continuous semi-martingales.</p> <p>Proposition</p> <p>Any continuous semi-martingales \\(X\\) and \\(Y\\) have quadratic variations \\([X]=\\langle X\\rangle=\\langle M\\rangle\\) and co-variations \\([X,Y]=\\langle X,Y\\rangle=\\langle M,N\\rangle\\).</p> <p>Proof</p> <p>Without loss of generality, \\(X_0=0\\). Since \\(\\tau^m =\\sup\\left\\{ t\\colon |M_t|&gt;m \\text{ or }\\langle M\\rangle_t&gt;m \\right\\}\\) defines a localizing sequence of stopping times, according to localizing lemma, we just have to show the theorem with the assumption that \\(M\\) as well as \\(\\langle M\\rangle\\) are uniformly bounded by some constant \\(K\\). Fix a generic partition \\(\\Pi\\). Note that we have</p> \\[ [X]^{\\Pi}=[M]^{\\Pi}+[A, X+M]^{\\Pi} \\] <p>Let us first show that \\([M]^{\\Pi^n}\\to \\langle M\\rangle\\) in ucp for every sequence \\((\\Pi^n)\\) of subdivision of \\([0,t]\\) converging to \\(0\\). For generic partition \\(\\Pi\\) of \\([0,t]\\), we denote by \\(\\sum \\Delta_k Y=\\sum_{k=1}^n (Y_{t_k}-Y_{t_{k-1}})\\) for a process \\(Y\\). For a function \\(f\\), we denote by \\(m(f,\\Pi)=\\sup\\{\\left\\vert f(s)-f(u)\\right\\vert: \\left\\vert s-u\\right\\vert&lt;\\left\\vert\\Pi\\right\\vert, s,u \\in [0,t]\\}\\). By uniform continuity of continuous functions on compact intervals, if \\(f\\) is continuous then \\(m(f,\\Pi)\\to 0\\) as \\(|\\Pi|\\to 0\\). Also, if \\(f\\) is bounded by \\(K\\), it follows that \\(m(f,\\Pi)\\leq 2K\\). Straightforward inspection with \\(M\\) martingale and the Doob-Meyer decomposition shows</p> \\[ E\\left[ \\left( M_t-M_s \\right)^2\\,|\\, \\mathcal{F}_s \\right]=E\\left[ M_t^2-M_s^2 \\,|\\, \\mathcal{F}_s \\right]=E\\left[ \\langle M\\rangle_t-\\langle M\\rangle_s \\,|\\, \\mathcal{F}_s \\right] \\] <p>where \\(s\\leq t\\). In particular</p> \\[ E\\left[ \\sum \\left( \\Delta_k M \\right)^2 \\right]=E\\left[ \\sum \\Delta_k \\langle M \\rangle \\right]=E\\left[ \\langle M \\rangle_t \\right]\\leq K \\] <p>Using the inequalities \\(2a^2+2b^2-(a-b)^2=(a+b)^2\\geq 0\\), and the fact that \\(M^2-\\langle M\\rangle\\) is a martingale, it holds</p> \\[ \\begin{aligned}     E\\left[ \\left( [M]^{\\Pi}_t-\\langle M\\rangle_t \\right)^2 \\right]     &amp; =E\\left[ \\left( \\sum \\left(\\Delta_k M \\right)^2-\\Delta_k \\langle M\\rangle \\right)^2 \\right]\\\\     &amp; \\leq E\\left[ \\sum \\left(\\left( \\Delta_k M \\right)^2 - \\Delta_k \\langle M\\rangle \\right)^2\\right]\\\\     &amp; \\leq 2\\sum E\\left[ \\left( \\Delta_k M \\right)^4 \\right]+2\\sum E\\left[ \\left(\\Delta_k \\langle M\\rangle \\right)^2 \\right]\\\\     &amp; \\leq 2\\sum E\\left[m\\left( M,\\Pi \\right)^2 \\left( \\Delta_k M \\right)^2  \\right]+2\\sum E\\left[ m\\left( \\langle M\\rangle,\\Pi \\right)\\Delta_k \\langle M\\rangle \\right]\\\\     &amp; \\leq 2\\sum E\\left[m\\left( M,\\Pi \\right)^2 \\left( \\Delta_k M \\right)^2  \\right]+2 K E\\left[ m\\left( \\langle M\\rangle,\\Pi \\right) \\right] \\end{aligned} \\] <p>Since \\(m(\\langle M\\rangle ,\\Pi^n)\\to 0\\) almost surely as \\(|\\Pi^n|\\to 0\\), the uniform boundedness of \\(m(\\langle M\\rangle, \\Pi^n)\\leq 2K\\) in combination with dominated convergence yields that the second term on the right-hand side converges to \\(0\\) as \\(|\\Pi^n|\\to 0\\). As for the first term, applying Cauchy-Schwartz yields</p> \\[  E\\left[ m\\left( M,\\Pi \\right)^2\\sum \\left( \\Delta_k M \\right)^2 \\right]\\leq E\\left[ m\\left( M,\\Pi \\right)^4 \\right]^{1/2} E\\left[ \\left(\\sum \\left(\\Delta_k M \\right)^2 \\right)^2\\right]^{1/2}. \\] <p>On one hand, dominated convergence yields that \\(E[m(M,\\Pi^n)^4]\\) converges to \\(0\\) as \\(|\\Pi^n|\\to 0\\). On the other hand, the fact that \\(|\\Delta_k M| \\leq 2K\\) yields</p> \\[ \\begin{aligned}     &amp; E\\left[ \\left(\\sum \\left( \\Delta_kM \\right)^2 \\right)^2\\right]\\\\     &amp; =E\\left[ \\sum \\left( \\Delta_k M \\right)^4 \\right]+2E\\left[ \\sum_k (\\Delta_k M)^2\\sum_{l&gt;k}E\\left[\\left( \\Delta_l M \\right)^2 \\:\\big | \\: \\mathcal{F}_{t_{l-1}}\\right]\\right]\\\\     &amp; \\leq 4K^2 E\\left[ \\sum \\left( \\Delta_k M \\right)^2 \\right]+2E\\left[ \\sum_k (\\Delta_k M)^2\\left(\\langle M \\rangle_t - \\langle M \\rangle_{t_{k-1}}\\right)\\right]\\\\     &amp; \\leq 4K^2 E\\left[ \\langle M \\rangle_t \\right]+4KE\\left[ \\sum \\left( \\Delta_k M  \\right)^2 \\right]\\\\     &amp; \\leq 4K^3+4KE\\left[ \\langle M \\rangle_t \\right]\\\\     &amp; \\leq 4K^2(K+1), \\end{aligned} \\] <p>We deduce that</p> \\[ E\\left[ \\left( [M]^{\\Pi^n}_t-\\langle M\\rangle_t \\right)^2 \\right]\\leq 2 KE\\left[ m\\left( \\langle M\\rangle,\\Pi^n \\right) \\right] + 4K^2(K+1)E\\left[ m\\left( M,\\Pi^n \\right)^4 \\right]^{1/2}\\xrightarrow[|\\Pi^n|\\to 0]{} 0 \\] <p>showing convergence in \\(L^2\\). Using Doob's maximal inequality for square integrable martingales shows that \\(\\sup_{s\\leq t}|[M]^{\\Pi^n}_s-\\langle M\\rangle_s| \\to 0\\) in \\(L^2\\), in particular in probability. Hence, according to the localization lemma, \\([M]^{\\Pi^n}\\to \\langle M\\rangle\\) in ucp for every sequence \\((\\Pi^n)\\) of partitions whose mesh converges to \\(0\\).</p> <p>We are left to show that \\([X+M,A]^{\\Pi^n}\\to 0\\) in ucp for every sequence of partitions whose mesh converges to \\(0\\). Again, we fix \\(t\\) and without loss of generality, we may assume that \\(\\Pi\\) is a partition of \\([0,t]\\). Since \\(A\\) is of bounded variations, it follows that \\(\\sum |\\Delta_k A|\\leq K_t&lt;\\infty\\). It follows that \\(| [X+M,A]^{\\Pi} |\\leq m( M+A, \\Pi )K_t\\). Since \\(X+M\\) is a continuous process, it follows that \\(m(X+M, \\Pi^n)\\to 0\\) on every finite interval \\([0,t]\\) as \\(|\\Pi^n|\\to 0\\). Hence \\([X+M,A]^{\\Pi^n}_t\\to 0\\) almost surely for every \\(t\\) as \\(|\\Pi^n|\\to 0\\).</p> <ol> <li> <p>Note that the space of semi-martingales is clearly a vector space.\u00a0\u21a9</p> </li> </ol>"},{"location":"lecture/07-Stochastic-Integral/074-ito-formula/","title":"It\u00f4's Formula","text":"<p>This Section is dedicated to the celebrated It\u00f4's Formula. To begin with, let us state a result about an analogue to Lebesgue's dominated convergence for stochastic integral.</p> <p>Proposition: Lebegue's Stochastic Dominated Convergence</p> <p>Let \\(X\\) be a semi-martingale. For \\((H^n)\\) sequence in \\(\\mathcal{L}^{loc}(X)\\) converging point-wise to \\(0\\), if \\(\\left\\vert H^n\\right\\vert\\leq H\\) for \\(H \\in \\mathcal{L}^{loc}(X)\\), then it follows that \\(\\int_{}^{} H^n d X \\to 0\\) in ucp.</p> <p>In particular, if \\(H\\) is a continuous adapted process, then, \\(\\int_{}^{} H^n d X\\) converges uniformly in probability on \\([0,t]\\) to \\(\\int_{}^{} HdX\\) for \\(H^n=H_0+\\sum H_{t^n_{k-1}}1_{(t_{k-1}^n,t^n_{k}]}\\) and for a subdivision \\(\\Pi^n=\\{0=t_0^n&lt; \\cdots&lt; t_{k_n}^n\\nearrow \\infty\\}\\) whose mesh is converging to \\(0\\).</p> <p>Proof</p> <p>Let \\(X=M+A\\). It is enough to show the convergence to zero uniformly on compact in probability for both \\(\\int_{}^{} H^n dM\\) and \\(\\int_{}^{} H^ndA\\). Defining \\(\\tau^m = \\inf\\{t \\colon |M_t|&gt;m \\text{ or }\\int_{0}^{t} |H| d|A| &gt;m \\text{ or } \\int_{0}^{t} H^2 d\\langle M\\rangle &gt;m\\}\\) provides a localizing sequence of stopping times. Hence according to the localization's Lemma, we may show the theorem by assuming that \\(M\\), \\(\\int |H| d|A|\\) and \\(\\int H^2 d\\langle M\\rangle\\) are all uniformly bounded. By the fact that \\(|H^n|\\leq H\\), the same holds uniformly for \\(\\int_{}^{} |H^n| d|A|\\) and \\(\\int_{}^{} (H^n)^2 d\\langle M\\rangle\\). By Lebesgue's dominated convergence and It\u00f4's isometry, it follows that</p> \\[  \\begin{equation*}     \\int_{0}^{t}H^n dM \\xrightarrow[ n\\to \\infty]{L^2}0 \\quad \\text{and} \\quad \\int_{0}^{t}H^n dA \\xrightarrow[ \\to \\infty]{L^1} 0  \\end{equation*} \\] <p>From Doob's maximal inequalities, follows that \\(\\sup_{s\\leq t}(\\int_{0}^{s}H^n dM)^2 \\to 0\\) in \\(L^1\\) and therefore \\(P\\)-almost surely. Since \\(|\\int_{0}^{s}H^n dA|\\leq \\int_{0}^{s}|H^n|d|A|\\leq \\int_{0}^{t}|H^n|d|A|\\to 0\\) in \\(L^1\\), it follows that \\(\\sup_{s\\leq t}\\int_{0}^{s}H^n dA\\to 0\\) \\(P\\)-almost surely, hence in probability for every \\(t\\), ending the proof.</p> <p>Theorem: Product Rule</p> <p>Let \\(X\\) and \\(Y\\) be semi-martingales, then it holds</p> \\[  \\begin{equation}\\label{eq:itomonome}     \\begin{split}         XY&amp;=X_0Y_0+\\int XdY+\\int YdX+\\int d\\langle X,Y\\rangle\\\\           &amp;=X_0Y_0+\\int XdY+\\int YdX+\\langle X,Y\\rangle     \\end{split} \\end{equation} \\] <p>In particular</p> \\[  \\begin{equation}\\label{eq:itoquadrat}     \\begin{split}         X^2&amp;=X_0+2\\int X dX+\\int d\\langle X\\rangle=X_0+2\\int X dX+\\langle X\\rangle     \\end{split} \\end{equation} \\] <p>Furthermore, for any \\(n\\geq 2\\) it holds</p> \\[   X^n = X_0^n + \\int n X^{n-1}dX + \\frac{1}{2}\\int n(n-1)X^{n-2}d\\langle X \\rangle \\] <p>Proof</p> <p>Note that from the polar relation \\(XY=((X+Y)^2-(X-Y)^2)/4\\) and the linearity of the relation \\eqref{eq:itoquadrat}, it is enough to show \\eqref{eq:itoquadrat}. Let \\((\\Pi^n)\\) be a sequence of subdivisions whose mesh is converging to \\(0\\). It follows that</p> \\[  \\begin{equation*}     \\begin{split}         X^2-X_0^2 &amp; = 2\\sum X_{t_{k-1}}\\left( X_{t_k\\wedge t}-X_{t_{k-1}\\wedge t} \\right)+ \\sum \\left( X_{t_{k}\\wedge t}-X_{t_{k-1}\\wedge t} \\right)^2\\\\                   &amp; = 2\\int_{}^{} X^n dX+\\left[ X \\right]^{\\Pi^n}     \\end{split} \\end{equation*} \\] <p>where \\(X^n=X_0+\\sum X_{t_{k-1}}1_{(t_{k-1},t_k]}\\). Since \\(X\\) is continuous, according to Lebesgue's stochastic dominated convergence, it follows that \\(2\\int X^n dX\\to 2\\int_{}^{}X dX\\) in ucp. On the other hand, according to the quadratic variation proposition, it holds that \\([X]^{\\Pi^n}\\to \\langle X\\rangle\\) in ucp. Hence, up to a rapid subsequence, we get the result point-wise.</p> <p>We show per induction on \\(n\\geq 2\\) the product formula. For \\(n=2\\), this is the previous result. Assume that it holds for any \\(m \\leq n\\) and we show it for \\(n\\geq 3\\). Define \\(Y = X^{n-1}\\). According to the product rule it holds </p> \\[   X^n = XY = X_0^n + \\int X dX^{n-1} + \\int X^{n-1}dX + \\langle X, Y\\rangle \\] <p>However by induction assumption it holds </p> \\[  \\begin{align*}     \\int XdX^{n-1} &amp; = \\int Xd\\left( X_0+(n-1)\\int X^{n-2}dX+\\frac{(n-1)(n-2)}{2}\\int X^{n-3}d\\langle X\\rangle \\right)\\\\                    &amp; = (n-1)\\int X^{n-1}dX+\\frac{(n-1)(n-2)}{2}\\int X^{n-2}d\\langle X\\rangle \\end{align*} \\] <p>and since the covariation where one of the process is of bounded variation is \\(0\\), for the covariation we get</p> \\[  \\begin{align*}     \\langle X,X^{n-1}\\rangle&amp;=\\left\\langle X,X_0+(n-1)\\int X^{n-2}dX+\\frac{(n-1)(n-2)}{2}\\int X^{n-3}d\\langle X\\rangle\\right\\rangle\\\\     &amp; = (n-1)\\langle \\int dX, \\int X^{n-2}dX \\rangle\\\\     &amp;=(n-1)\\int_{}^{}X^{n-2}d\\langle X\\rangle. \\end{align*} \\] <p>Substituting these two relations in the product formula yields the result.</p> <p>Remark</p> <p>Note that a similar proof also shows </p> \\[    \\begin{align}     X^nY^m &amp; = X_0^nY_0^m+n\\int_{}^{}X^{n-1}Y^m dX+m\\int X^nY^{m-1}dY\\\\       &amp; \\quad \\quad \\quad +\\frac{n(n-1)}{2}\\int_{}^{} X^{n-2}Y^m d\\langle X\\rangle+nm\\int_{}^{} X^{n-1}Y^{m-1}d\\langle X,Y\\rangle+\\frac{m(m-1)}{2}\\int_{}^{} X^{n}Y^{m-2}d\\langle Y\\rangle   \\end{align} \\] <p>The product rule formula can immediately be reformulated into Ito's formula.</p> <p>Theorem</p> <p>Let \\(X\\) and \\(Y\\) be semi-martingale, and \\(f:\\mathbb{R}^2\\to \\mathbb{R}\\) be a twice continuously differentiable function.</p> <p>Then it holds</p> \\[  \\begin{align}     f(X,Y) &amp; = f(X_0,Y_0)+\\int_{}^{}\\partial_x f(X,Y)dX+\\int_{}^{} \\partial_y f(X,Y) dY \\\\       &amp; \\quad \\quad \\quad +\\frac{1}{2}\\int_{}^{} \\partial_{xx} f(X,Y)d\\langle X\\rangle +\\int_{}^{} \\partial_{xy}f(X,Y)\\langle X,Y\\rangle+\\frac{1}{2}\\int_{}^{} \\partial_{yy}f(X,Y) d\\langle Y\\rangle \\end{align} \\] <p>In particular, if \\(f\\) only depends on \\(x\\), we get the more classical version</p> \\[  \\begin{equation}\\label{eq:ito}     f(X)=f(X_0)+\\int_{}^{} f^\\prime (X)dX+\\frac{1}{2}\\int_{}^{} f^{\\prime\\prime}(X)d\\langle X\\rangle \\end{equation} \\] <p>Proof</p> <p>Obviously, It\u00f4's formula holds in the case where \\(f(x,y) = x^n y^m\\) and by linearity for any multivariate polynomials \\(f(x,y) = \\sum_{0\\leq n\\leq N, 0\\leq m\\leq M} a_{n,m} x^n y^m\\). We will show the unidimensional case, the argumentation for the two or \\(n\\)-dimensional case is just a simple adaptation of the argumentation. Note that by localization, we can show the statement for \\(X\\) uniformly bounded by \\(K\\). We denote by \\(\\|\\cdot \\|_{K}\\) the supremum norm on \\([-K, K]\\). By density of polynomials in the set of \\(C^2\\) functions on compact, for any \\(n\\) we can find a polynomial \\(P_n\\) such that</p> \\[   \\left\\Vert P_n-f\\right\\Vert_K+\\left\\Vert P^\\prime -f^\\prime\\right\\Vert_K+\\left\\Vert P^{\\prime\\prime}-f^{\\prime \\prime}\\right\\Vert_K&lt;1/n \\] <p>It follows that</p> \\[   \\begin{multline*}     \\left|f(X) - f(X_0) - \\int f^\\prime(X)dx - \\frac{1}{2}\\int f^{\\prime\\prime}(X) d\\langle X\\rangle\\right| \\\\     \\leq \\left| f(X) - P_n(X)\\right| + \\left|f(X_0) - P_n(X_0)\\right| + \\left|\\int \\left( f^\\prime(X) - P_n^\\prime(X) \\right)dX\\right| + \\int \\left| f^{\\prime\\prime}(X) - P_n^{\\prime\\prime}(X)\\right| d\\langle X\\rangle   \\end{multline*} \\] <p>The first two differences can be made arbitrarily small. As for the stochastic integral difference, the uniform convergence on compact in probability follows from Lebesgue's stochastic dominated convergence. Hence, up to a rapid subsequence, we have almost sure convergence. Finally the Lebesgues-Stieltjes integral converges to \\(0\\) due to Lebesgues' dominated convergence.</p> <p>Ito's formula as we will see later is the door to stochastic differential equations as well as the link between stochastic analysis and partial differential equations. Note that we often use the differential notation</p> \\[   \\begin{align*}     df(X) &amp; = f^\\prime(X) dX + \\frac{1}{2}f^\\prime\\prime(X) d \\langle X \\rangle\\\\           &amp; = f^\\prime dX + \\frac{1}{2}f^{\\prime\\prime}d\\langle X\\rangle\\\\     df(X,Y) &amp; = \\partial_x f(X,Y)dX + \\partial_y f(X,Y) dY \\\\             &amp; \\quad \\quad \\quad + \\frac{1}{2}\\partial_{xx}f(X,Y)d \\langle X \\rangle + \\partial_{xy}f(X,Y)d \\langle X,Y \\rangle + \\frac{1}{2}\\partial_{yy}f(X,Y)d \\langle Y\\rangle\\\\             &amp; = \\partial_x f dX + \\partial_y fdY + \\frac{1}{2}\\partial_{xx} f d\\langle X\\rangle +\\partial_{xy}f d\\langle X,Y\\rangle + \\frac{1}{2}\\partial_{yy}f d\\langle Y \\rangle   \\end{align*} \\] <p>Note also that by taking \\(Y_t = t\\) which is a semi-martingale without local martingale term where \\(dY = dt\\) and \\(d\\langle Y\\rangle = d\\langle X, Y\\rangle =0\\) we obtain a very common version of It\u00f4's formula for \\(f:[0, \\infty)\\times \\mathbb{R} \\to \\mathbb{R}\\) which is \\(C^{1,2}\\) as follows</p> \\[   df(t, X) = \\partial_t f dt + \\partial_x f dX + \\frac{1}{2}\\partial_{xx} f d\\langle X\\rangle \\] <p>Example</p> <p>Let us have a look at a classical situation that provides a hint as to the relation between PDEs and Stochastics. Let \\(\\mu, \\sigma \\colon \\mathbb{R}\\to \\mathbb{R}\\) be two smooth functions and suppose that there exists a semi martingale \\(X\\) such that</p> \\[ X = X_0 + \\int \\mu(X) dt + \\int \\sigma(X) dW \\] <p>where \\(W\\) is the Brownian motion. In other terms, \\(X\\) solves the stochastic differential equation </p> \\[  dX = \\mu(X) dt +\\sigma(X) dW \\] <p>Note that</p> \\[     d\\langle X\\rangle = \\sigma^2(X)d\\langle W\\rangle = \\sigma^2(X)dt \\] <p>Given a \\(C^{1,2}\\) function \\(u \\colon [0, \\infty) \\times \\mathbb{R}\\), using It\u00f4's formula we get</p> \\[     \\begin{align*}         du(t, X_t)              &amp; = \\partial_t u(t, X_t)dt + \\partial_x u(t, X_t)dX_t + \\frac{1}{2}\\partial_{xx}u(t, X_t)d\\langle X\\rangle_t\\\\             &amp; = \\partial_t u(t, X_t)dt +\\partial_x u(t, X_t)\\left(\\mu(X_t)dt + \\sigma(X_t)dW_t\\right) + \\frac{\\sigma^2(X_t)}{2}\\partial_{xx}u(t, X_t) dt\\\\             &amp; = \\left(\\partial_t +\\underbrace{\\mu(X_t)\\partial_x +\\frac{\\sigma^2(X_t)}{2}\\partial_{xx}}_{=: \\mathcal{L}^X(X_t)}\\right)u(t, X_t)dt + \\sigma(X_t)\\partial_x u(t, X_t)dW     \\end{align*} \\] <p>Defining the differential operator \\(\\mathcal{L}^X(x)\\) \u2014 also called infinitesimal generator of \\(X\\) \u2014 on \\(C^{1,2}\\) functions \\(f\\):</p> \\[     \\mathcal{L}^X(x) f(t, x) := \\mu(x)\\partial_x f(t,x) + \\frac{\\sigma^2(x)}{2}\\partial_{xx}f(t,x) \\] <p>We can rewrite the result of the It\u00f4's formula as follows</p> \\[     du = \\underbrace{\\left(\\partial_t + \\mathcal{L}^X\\right) u dt}_{\\text{Bounded variations}} + \\underbrace{\\sigma \\partial_x u dW}_{\\text{Local martingale}} \\] <p>Suppose that \\(u\\) is in particular a solution of the following PDE</p> \\[     \\begin{equation*}         \\begin{cases}             \\begin{aligned}             \\partial_t u(t, x) + \\mathcal{L}^X(x) u(t, x) &amp; = 0\\\\             \\\\             u(0, x) &amp; = X_0             \\end{aligned}         \\end{cases}     \\end{equation*} \\] <p>then it follows that</p> \\[     du = \\left(\\partial_t + \\mathcal{L}^X\\right) u dt +\\sigma \\partial_x u dW = \\sigma \\partial_x dW \\] <p>and therefore \\(u(t, X_t)\\) is a local martingale.</p> <p>Geometric Brownian Motion</p> <p>In finance, the bank account \\(B\\) pays interest \\(r \\Delta\\) over the period \\(\\Delta\\). It follows that the value of the bank account at time \\(t+\\Delta\\) is given by \\(B_{t+\\Delta} = B_t (1+ r\\Delta)\\). In differential form it follows that</p> \\[     dB_t \\approx B_{t+\\Delta} - B_t = B_t r \\Delta \\approx B_t r dt \\] <p>With one RMB at time \\(0\\), that is, \\(B_0 = 1\\), this stochastic differential equation is a simple (eventually stochastic) ODE \\(dB = B r dt\\) with solution</p> \\[     B = B_0 \\exp\\left(\\int r dt\\right) = e^{\\int r dt} \\] <p>On the other hand, looking at a risky asset \\(S\\), such as a stock price,, the return between \\(t\\) and \\(t+\\Delta\\) might be subject to uncertainty. In this case, the stock price \\(S_{t+\\Delta} = S_t(1+R_{t+\\Delta})\\) where</p> \\[     R_{t+\\Delta} = \\mu \\Delta + \\sigma \\sqrt{\\Delta} \\xi_t \\] <p>where \\(\\xi_t \\sim \\mathcal{N}(0, 1)\\) is some random noise, \\(\\mu\\) is the certain return on the asset over the short period while \\(\\sigma\\) is the volatility, or amount of uncertainty. For the differential form we have a problem as how \\(\\sigma \\sqrt{\\Delta}\\xi_t\\) scales as \\(\\Delta\\) is infinitesimaly small. However, from the properties of the brownian motion, it hodls that \\(\\sqrt{\\Delta}\\xi_t \\sim \\mathcal{N}(0, \\Delta) \\sim W_{t+\\Delta} - W_t\\). We can therefore reformulate the differential evolution of the stock price as</p> \\[     dS = S\\left(\\mu dt + \\sigma dW\\right)         \\] <p>In this case we are no longer facing an ODE but a stochastic differential equation as for the \\(dW\\) term. It is not clear as if there exists a solution \\(S\\) that satisfies this stochastic differential equation. However in this case, we can guess the solution as follows. Let \\(X\\) be the semi martingale defined as</p> \\[     X = \\int \\left( \\mu -\\frac{\\sigma^2}{2}\\right)dt + \\int \\sigma dW \\] <p>Applying It\u00f4's formula to \\(f(X) = \\exp(X)\\), knowing that \\(f = f^\\prime= f^{\\prime\\prime}\\) we get</p> \\[     \\begin{align*}         df(X)              &amp; = f^\\prime(X)dX + \\frac{1}{2}f^{\\prime \\prime}(X)d\\langle X\\rangle\\\\             &amp; = f(X)\\left(\\underbrace{dX}_{=(\\mu-\\sigma^2/2) dt + \\sigma dW} + \\frac{1}{2}\\underbrace{d\\langle X\\rangle}_{= \\sigma^2 dt}\\right)\\\\             &amp; = f(X)\\left(\\left(\\mu dt - \\frac{1}{2}\\sigma^2 + \\frac{1}{2}\\sigma^2\\right)dt + \\sigma dW\\right)\\\\             &amp; = f(X)(\\mu dt + \\sigma dW)     \\end{align*} \\] <p>We deduce that </p> \\[     S_t = S_0 \\exp \\left( \\int \\left(\\mu - \\frac{\\sigma^2}{2}\\right)dt + \\int \\sigma dW\\right) \\] <p>satisifies the stochastic differential equation of the stock price evolution.</p>"}]}