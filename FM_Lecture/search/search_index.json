{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Financial Mathematics: Lecture Notes","text":"<p>These lecture notes, still a work in progress, are for a course taught at Shanghai Advanced Institute for Finance, Shanghai Jiao Tong University, for graduate students.</p>"},{"location":"#course-objective","title":"Course Objective","text":"<p>Stochastics as a mathematical field evolved in parallel with the development of the finance industry, starting with insurance, followed by stock markets, derivatives, and more. This lecture serves as an introduction to the mathematical theory underpinning modern finance. The course aims to introduce mathematical concepts in finance through the following topics:</p> <ul> <li> <p>One-period financial markets: Financial assets, self-financing strategies, arbitrage, the fundamental theorem of asset pricing, and option pricing.   From a mathematical perspective, this introduces probability spaces, expectations, pricing measures, and measure changes.</p> </li> <li> <p>Modern risk management and quantification: Value at Risk (V@R), Expected Shortfall (ES), and systemic risk.   From a mathematical perspective, this introduces the concept of probability distribution (CDF, PDF, quantile), joint distributions and tail risk.</p> </li> <li> <p>Multi-period financial markets: Concepts of information, the CRR model, pricing and hedging, exotic options, stopping times, and American options.   This includes mathematical concepts such as filtrations, conditional expectations, martingales, and stopping times.</p> </li> <li> <p>Basics of ruin theory and default pricing.</p> </li> <li> <p>Continuous-time financial markets: Introduction to the Black-Scholes framework.</p> </li> </ul>"},{"location":"#concrete-approach","title":"Concrete Approach","text":"<p>The course combines blackboard lectures with practical applications in Python. Lecture notes will be provided and updated during the course. Simple homework exercises (not graded but corrected and discussed by the TA) will be assigned. Additionally, students will complete two group projects (5-6 members per group), alongside a midterm and final exam.</p> <p>For further reading, we recommend Shreve<sup>1</sup> for an introduction to mathematical finance in discrete time and F\u00f6llmer and Schied<sup>2</sup> for a more advanced treatment.</p>"},{"location":"#references","title":"References","text":"<ol> <li> <p>Steven E. Shreve. Stochastic Calculus for Finance. Volume I of Springer Finance. Springer-Verlag, New York, 2004. ISBN 0-387-40100-8. The binomial asset pricing model.\u00a0\u21a9</p> </li> <li> <p>Hans F\u00f6llmer and Alexander Schied. Stochastic Finance. An Introduction in Discrete Time. De Gruyter Studies in Mathematics. Walter de Gruyter, Berlin, New York, 3rd edition, 2011.\u00a0\u21a9</p> </li> </ol>"},{"location":"javascripts/node_modules/mathjax/","title":"MathJax","text":""},{"location":"javascripts/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"javascripts/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"javascripts/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"javascripts/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\n  loader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\n  const svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\n  console.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"javascripts/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"javascripts/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"},{"location":"lecture/00-Introduction/000-index/","title":"Introduction","text":""},{"location":"lecture/00-Introduction/000-index/#what-is-mathematical-finance","title":"What is Mathematical Finance?","text":"<p>Finance concerns the allocation and pricing of assets\u2014goods, stocks, etc.\u2014and liabilities\u2014debts, loans, bonds, etc.\u2014in the presence of uncertainty and risk. This definition raises several fundamental questions:</p> <ul> <li>What is trade, money, or pricing?  </li> <li>What are uncertainty and risk?  </li> <li>Which academic fields address these questions?  </li> <li>What role does mathematics\u2014particularly stochastics\u2014play in finance?  </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#a-brief-and-biased-history-of-trade-money-and-finance","title":"A Brief and Biased History of Trade, Money, and Finance","text":""},{"location":"lecture/00-Introduction/000-index/#trade-of-goods-and-the-emergence-of-money","title":"Trade of Goods and the Emergence of Money","text":"<ul> <li> <p>Exchange of goods (around 150,000 BC):</p> <ul> <li>Advantages: Better allocation of comparative advantages.  </li> <li>Question:  <ul> <li>How is exchange value determined (bilateral agreement)?  </li> <li>Need for intermediaries.  </li> </ul> </li> </ul> </li> <li> <p>Money as a medium of exchange (around 12,000 BC):  </p> <ul> <li>Advantages:  <ul> <li>Solves the double coincidence problem, enabling efficient allocation.  </li> <li>Serves as a unit of account (num\u00e9raire).  </li> <li>Stores value over time.  </li> </ul> </li> <li>Questions:  <ul> <li>How is value established (multilateral agreements between numerous goods)? Law of demand and supply.  </li> <li>How does money preserve value over time?  </li> <li>Introduces the concept of the time value of money.  </li> </ul> </li> </ul> </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#assessing-uncertainty-the-rise-of-financial-markets","title":"Assessing Uncertainty: The Rise of Financial Markets","text":"<ul> <li> <p>Commodity markets (4,000 BC):     Development of forward contracts to hedge against price fluctuations.  </p> <ul> <li>Question: How are prices determined?  </li> </ul> </li> <li> <p>Loans and banking systems (2,000 BC):     Facilitated leveraged investments.  </p> <ul> <li>Question: How to price future payments?  </li> </ul> </li> <li> <p>Insurance (1400s):     Emerged during overseas trading, with premiums exchanged for risk.  </p> <ul> <li>Sparked the beginnings of probability theory.  </li> </ul> </li> <li> <p>Stock markets (1600s):     Enabled capital raising and introduced challenges such as dividend payments and stock price modeling (e.g., Bachelier model, Brownian motion).  </p> </li> <li> <p>Options (1600s, standardized in 1973):     Put and call options provided bounded insurance against price movements.  </p> </li> <li> <p>Derivatives:     Broader contracts written on assets, indices, interest rates, etc.  </p> </li> </ul> <p>Pricing remains the central problem for all these financial instruments. While agreements between counterparties can set prices, mathematical models provide fair and robust valuations. A specialized subfield of mathematical finance also focuses on assessing financial risk.</p>"},{"location":"lecture/00-Introduction/000-index/#academic-fields-involved-in-finance","title":"Academic Fields Involved in Finance","text":"<ul> <li>Economics: Macroeconomics, microeconomics, decision theory.  </li> <li>Psychology: Behavioral finance.  </li> <li>Law.  </li> <li>Computer Science: Algorithmic trading, machine learning.  </li> <li>Mathematics:  <ul> <li>Stochastics (modeling).  </li> <li>Statistics (calibration, machine learning...).  </li> <li>Optimization.  </li> <li>Functional analysis and partial differential equations (e.g., Black-Scholes model).  </li> </ul> </li> </ul>"},{"location":"lecture/00-Introduction/001-notations/","title":"Notations","text":""},{"location":"lecture/00-Introduction/001-notations/#mathematical-notations","title":"Mathematical Notations","text":"<p>The following notations will be used throughout the course:</p> <ul> <li>Natural Numbers: \\(\\mathbb{N} = \\{1, 2, \\ldots\\}\\), \\(\\mathbb{N}_0 = \\{0, 1, 2, \\ldots\\}\\).</li> <li>Integers: \\(\\mathbb{Z} = \\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\)</li> <li>Rational Numbers: \\(\\mathbb{Q} = \\{ p/q\\colon p \\in \\mathbb{Z}, q \\in \\mathbb{N}\\}\\)</li> <li>Real Numbers: \\(\\mathbb{R}\\)</li> <li>Vectors in \\(\\mathbb{R}^d\\) are denoted in bold font, \\(\\boldsymbol{x} = (x^1, \\dots, x^d)\\), and are assumed to be column vectors.  </li> <li>Vectors with positive components \\(\\mathbb{R}^d_+ = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k \\geq 0, k=1,\\ldots,d\\}\\) and vectors with strictly positive components \\(\\mathbb{R}^d_{++} = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k &gt; 0, k=1,\\ldots,d\\}\\).  </li> <li>Scalar Product: \\(\\boldsymbol{x} \\cdot \\boldsymbol{y} := \\sum x_k y_k\\) denotes the scalar product of \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\) in \\(\\mathbb{R}^d\\).  </li> <li>\\(\\beta \\boldsymbol{x} := (\\beta x_1, \\ldots, \\beta x_d)\\) represents the multiplication of \\(\\boldsymbol{x}\\) in \\(\\mathbb{R}^d\\) by a scalar \\(\\beta \\in \\mathbb{R}\\).  </li> <li>\\(\\boldsymbol{x} + \\boldsymbol{y} := (x_1 + y_1, \\ldots, x_d + y_d)\\) represents vector addition in \\(\\mathbb{R}^d\\).  </li> <li>Component wise operations: \\(\\boldsymbol{x}\\boldsymbol{y}= (x_1 y_1, \\ldots, x_d y_d)\\), \\(\\boldsymbol{x}/ \\boldsymbol{y} = (x_1/ y_1, \\ldots, x_d/y_d)\\), \\(f(\\boldsymbol{x}) = (f(x_1), \\ldots, f(x_d))\\) for any function \\(f\\colon \\mathbb{R}\\to \\mathbb{R}\\).</li> <li> <p>For scalars \\(x, y \\in \\mathbb{R}\\), the following notations are used:  </p> \\[   x \\vee y = \\max\\{x, y\\}, \\quad x \\wedge y = \\min\\{x, y\\}, \\quad x^+ = \\max\\{x, 0\\}, \\quad x^- = \\max\\{-x, 0\\}. \\] <p>Notably, \\(x = x^+ - x^-\\) and \\(|x| = x^+ + x^-\\).  </p> </li> </ul>"},{"location":"lecture/00-Introduction/001-notations/#colorenvironment-conventions","title":"Color/Environment conventions","text":"<p>Definition</p> <p>For a ... we define</p> <p>Remark</p> <p>Note that  </p> <p>Example</p> <p>As an example we consider </p> <p>Theorem</p> <p>Let \\((\\Omega, \\mathcal{F}, P)\\) be a probability space...</p> <p>Proposition</p> <p>Assuming no-arbitrage for the financial market, the followign assertions holds...</p> <p>Corollary</p> <p>As a corrolary to the previous proposition, it holds</p> <p>Lemma</p> <p>In the case where \\(P^\\ast\\) is equivalent to \\(P\\), it holds...</p> <p>Proof</p> <p>In a first step we show that \\((i)\\) implies \\((ii)\\)...</p> <p>Exercise</p> <p>Solve in a a binomial financial market...</p>"},{"location":"lecture/01-One-Period/011-mathematical-model/","title":"Mathematical Model","text":"<p>In this section, we model a one-period financial market evolving between two points in time:</p> <ul> <li>Today: The current state of the world is known, including the prices of equities, commodities, and the overall economic condition.</li> <li>Tomorrow: Various possible states of the world may emerge, where changes in the economy or the prices of stocks and commodities occur based on these states.</li> </ul> <p>In this financial market, we have \\(d\\) risky assets available for investment and a bank account to store or borrow liquidity.</p> <ul> <li>At time \\(0\\): The prices of these \\(d\\) financial assets and the amount in the bank account are known.     Investors can decide on a strategy, specifying how much to invest in each asset by purchasing a certain number of shares. The bank account is used to finance these investments.</li> <li>At time \\(1\\): The portfolio's value is determined by:<ul> <li>The remaining balance in the bank account after buying the shares at time \\(0\\), including interest earned.</li> <li>The uncertain value of the financial assets at time \\(1\\), multiplied by the number of shares held.</li> </ul> </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#bank-account","title":"Bank Account","text":"<p>The bank account is denoted by \\(B\\), where \\(B_0 = 1\\) represents the price of one unit of currency at time \\(0\\). The bank offers an interest rate \\(r\\), announced at time \\(0\\) and applied at time \\(1\\). With one unit deposited at time \\(0\\), the amount in the account at time \\(1\\) becomes:</p> \\[ \\begin{equation*}   B_1 = B_0(1 + r) = 1 + r \\end{equation*} \\] <p>We assume \\(r &gt; -1\\), meaning the bank does not default. The bank account evolution is summarized as:</p> \\[ \\begin{equation*}   \\begin{cases}     B_0 = 1 \\\\     B_1 = 1 + r   \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#financial-assets","title":"Financial Assets","text":"<p>These assets are represented by the vector:</p> \\[ \\begin{equation*}   \\boldsymbol{S} = (S^1, \\ldots, S^d) \\end{equation*} \\] <p>Each \\(S^k\\) for \\(k = 1, \\ldots, d\\) describes the price evolution of financial asset \\(k\\) between time \\(0\\) and \\(1\\).</p> <ul> <li> <p>At time \\(0\\): The price of asset \\(k\\) is \\(S_0^k\\), which is strictly positive and known:</p> \\[ \\begin{equation*}   \\boldsymbol{S}_0 = (S_0^1, \\ldots, S_0^d) \\quad \\text{where} \\quad S_0^k &gt; 0 \\; \\text{for all }k \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The price of asset \\(k\\) is \\(S_1^k\\), which is uncertain but non-negative (if \\(S_1^k = 0\\), the asset \\(k\\) has defaulted):</p> \\[ \\begin{equation*}   \\boldsymbol{S}_1 = (S_1^1, \\ldots, S_1^d) \\quad \\text{where} \\quad S_1^k \\geq 0 \\; \\text{for all }k \\end{equation*} \\] </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#self-financing-portfolio","title":"Self-Financing Portfolio","text":"<p>A portfolio consists of holdings in each financial asset and the balance in the bank account. The portfolio's total value is denoted by \\(\\bar{V}\\).</p> <ul> <li> <p>At time \\(0\\): You observe the prices \\(S_0^k\\) for \\(k = 1, \\ldots, d\\) and decide on a strategy, holding \\(\\eta^k \\in \\mathbb{R}\\) shares of each asset. The cost of purchasing these assets is:</p> \\[ \\begin{equation*}   \\sum_{k=1}^d \\eta^k S_0^k = \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\end{equation*} \\] <p>where \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\) represents your holdings. The self-financing condition requires that this cost is fully covered by the bank account. Thus:</p> \\[ \\begin{equation*}   \\bar{V}_0 \\leadsto \\underbrace{\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Bank account value}} +  \\underbrace{\\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Asset holdings value}}= \\bar{V}_0 - \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 + \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 = \\bar{V}_0 \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The portfolio value evolves as asset prices change:</p> \\[ \\begin{align*}     \\bar{V}_1 &amp; = \\left(\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0\\right)(1+r) + \\sum_{k=1}^d \\eta^k S^k_1 \\\\               &amp; = \\left( \\bar{V}_0 - \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\right)(1+r) +\\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_1  \\\\               &amp; = \\bar{V}_0(1+r) +\\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r) \\right) \\end{align*} \\] </li> </ul> <p>Hence a portfolio over time is entirely determined by its start value \\(\\bar{V}_0\\) as well as the strategy \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\).</p> Remark: How realistic are those assumptions? <p>In this setting, we make somewhat restrictive assumptions that are disputable namely:</p> <ul> <li>No dividends.</li> <li>No transaction costs when buying assets: fixed fees, taxes, transaction fees, liquidity.</li> <li>The amount of shares in a financial asset is a real number.       Usually you are only allowed to buy/sell a round lot.       Furthermore, you are allowed to hold a negative amount of shares.       In other terms short selling is allowed and without particular transaction costs related to it.</li> <li>You can buy/sell unlimited amount of shares, in particular for very large amount you face no liquidity costs.</li> <li>The bank account provides the same rate \\(r\\) for deposit and lending which is very unlikely.     And this rate is independent of the amount.</li> <li>You can lend infinite amount of money from the bank.</li> </ul> <p>We consider the ideal scenario of a small investor operating in a frictionless financial market\u2014an assumption that closely approximates modern realities. Some aspects, such as taxes, transaction fees, dividends, and round lot restrictions, are either negligible or can be incorporated with minimal adjustments. However, factors like differing lending and deposit rates, liquidity costs, short-selling constraints, and price impacts are more complex and can significantly influence the results.    </p>"},{"location":"lecture/01-One-Period/011-mathematical-model/#discounting","title":"Discounting","text":"<p>It is often convenient to consider discounted values of financial assets and the portfolio to express their worth in terms of today's currency. Define the discounted prices \\(\\boldsymbol{X}=\\boldsymbol{S}/B\\) and portfolio value \\(V=\\bar{V}/B\\) as follows:</p> \\[ \\begin{align*}     X_0^k &amp; = \\frac{S^k_0}{B_0}=S^k_0         &amp; \\text{and} &amp;  &amp; X_1^k &amp; = \\frac{S_1^k}{B_1}=\\frac{S_1^k}{1+r}         \\\\     V_0   &amp; = \\frac{\\bar{V}_0}{B_0}=\\bar{V}_0 &amp; \\text{and} &amp;  &amp; V_1   &amp; = \\frac{\\bar{V}_1}{B_1}=\\frac{\\bar{V}_1}{1+r} \\end{align*} \\] <p>In particular, it follows that</p> \\[ \\begin{align*}     V_1     &amp; = \\frac{\\bar{V}_1}{1+r}\\\\             &amp; = \\frac{1}{1+r}\\left(\\bar{V}_0(1+r) +\\sum_{k=1}^d \\eta^k\\left( S^k_1  - (1+r)S_0^k\\right)\\right)\\\\             &amp; = \\bar{V}_0 +\\sum_{k=1}^d \\eta^k\\left( \\frac{S^k_1}{1+r}  - S_0^k\\right)\\\\                 &amp; = V_0 + \\sum_{k=1}^n \\eta^k\\left( X^k_1 - X^k_0 \\right)\\\\           &amp; = V_0 + \\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{X}_1 - \\boldsymbol{X}_0 \\right) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\end{align*} \\] <p>for which we get an interpretation of the evolution of the discounted value of the portfolio:</p> \\[ \\begin{equation*}   V_1 = \\underbrace{V_0}_{\\text{Initial Value}} + \\underbrace{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1}_{\\text{Incremental gain/loss of discounted prices}} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#uncertainty","title":"Uncertainty","text":"<p>So far, we have described a simple financial market and how investments can be made while adhering to self-financing principles. However, while we acknowledged that the prices of assets at time \\(1\\) are subject to uncertainty, we have not detailed how this uncertainty is modeled.  In other words, while we treated the financial assets at time \\(1\\) as a vector of prices, we have not specified how this vector reflects the uncertainty associated with its values.</p> <p>The price evolution depends on the \"state of the world\" that will be realized. If we denote by \\(\\omega\\) one such possible state, then \\(S_1^k(\\omega)\\) represents the price of asset \\(k\\) at time \\(1\\) in state \\(\\omega\\). If \\(\\Omega\\) denotes the collection of all possible states, the stock price \\(S_1^k\\) is a function:</p> \\[ \\begin{align*}   S_1^k\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_+\\\\   \\omega &amp; \\longmapsto \\underbrace{S_1^k(\\omega)}_{\\text{Price of financial asset $k$ at time $1$ in state $\\omega$}} \\end{align*} \\] <p>Combining all such functions, we obtain state-dependent price vectors:</p> \\[ \\begin{align*}   \\boldsymbol{S}_1\\colon \\Omega &amp; \\longrightarrow \\mathbb{R}_+^d\\\\   \\omega &amp; \\longmapsto \\boldsymbol{S}_1(\\omega) = (S_1^1(\\omega), \\ldots, S_1^d(\\omega)) \\end{align*} \\] <p>Similarly, the discounted self-financing portfolio value at time \\(1\\) and the discounted asset prices become state-dependent functions:</p> \\[ \\begin{align*}   \\boldsymbol{X}_1\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_{+}^d &amp; V_1 \\colon \\Omega &amp;\\longrightarrow \\mathbb{R} \\\\   \\omega &amp; \\longmapsto \\boldsymbol{X}_1(\\omega) = \\left( \\frac{S_1^1(\\omega)}{1+r}, \\ldots, \\frac{S_1^d(\\omega)}{1+r} \\right) &amp; \\omega &amp;\\longmapsto V_1(\\omega) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1(\\omega) \\end{align*} \\] <p>The objective of financial mathematics is to estimate or price these state-dependent portfolios. To achieve this, we need further assessments of how likely each event is to occur. This is where stochastic theory plays a crucial role.</p> <p>Definition: One Period Financial Market</p> <p>Given a probability space \\((\\Omega, \\mathcal{F}, P)\\), a financial market is defined as follows:</p> <ul> <li> <p>A bank account \\(B\\), where:</p> \\[ B_0 = 1 \\quad \\text{and} \\quad B_1 = 1 + r \\] <p>for \\(r&gt;-1\\)</p> </li> <li> <p>\\(d\\)-financial assets \\(\\boldsymbol{S} = (S^1, \\ldots, S^d)\\), where:</p> \\[   S_0^k &gt; 0 \\quad \\text{and} \\quad S_1^k : \\Omega \\to \\mathbb{R}_+ \\] <p>for \\(k = 1, \\ldots, d\\), with \\(S_1^k\\) being a measurable random variable.</p> </li> </ul> <p>A Portfolio \\(\\bar{V}\\) is given by a start value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and a holding strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). Self financing condition implies</p> \\[   \\bar{V}_1 = \\bar{V}_0(1+r) + \\sum \\eta^k \\left(S_1^k - S_0^k(1+r)\\right) = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\left(\\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r)\\right) \\] <p>The discounded portfolio \\(V = \\bar{V}/B\\) and financial assets \\(\\boldsymbol{X} = \\boldsymbol{S}/B\\) allows to write</p> \\[   V_1 = V_0 + \\sum \\eta^k \\left(X_1^k - X_0^k\\right) = V_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\] Warning: What about returns, portfolio weights? <p>Very often in finance, the exposition is done in terms of returns and portfolio weights. Talking in terms of returns and weights requires some particular care.</p> <p>It is possible to speak of returns for the financial market as the prices at time \\(0\\) are strictly positive. In other terms, if we define the interest rate \\(r\\) as:</p> \\[ r = \\frac{B_1 - B_0}{B_0}, \\quad \\text{then it holds} \\quad B_1 = B_0(1 + r) \\] <p>Similarly, for the return \\(R_1^k\\) of a financial asset \\(k\\), we define:</p> \\[ R_1^k = \\frac{S_1^k - S_0^k}{S_0^k}, \\quad \\text{then it holds} \\quad S_1^k = S_0^k(1 + R_1^k) \\] <p>Thus, the definition of a financial market as described earlier is equivalent to specifying:</p> <ul> <li>A vector \\(\\boldsymbol{S}_0\\) of strictly positive initial prices.</li> <li>An interest rate \\(r &gt; -1\\), with \\(r \\in \\mathbb{R}\\).</li> <li> <p>A vector \\(\\boldsymbol{R}_1 = (R_1^1, \\ldots, R_1^d)\\) of random returns, where:</p> \\[ R_1^k: \\Omega \\longrightarrow [-1, \\infty), \\quad \\omega \\longmapsto R_1^k(\\omega) \\] <p>for each \\(k = 1, \\ldots, d\\).</p> </li> </ul> <p>It is also possible for a portfolio to speak in terms of holding value rather than number of shares, that is \\(\\boldsymbol{h} = \\boldsymbol{\\eta}\\boldsymbol{S}_0 = (\\eta^1 S_0^1, \\ldots, \\eta^d S_0^d)\\). In this case we can write the portfolio evolution as</p> \\[ \\begin{align*}   \\bar{V_1} &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k\\left(S_1^k - S_0^k (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k S_0^k \\left(\\frac{S_1^k}{S_0^k} - (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum h^k \\left(R_1^k - r\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\boldsymbol{h}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>Now we would like to consider the returns of the portfolio \\((\\bar{V}_1 - \\bar{V}_0)/\\bar{V}_0\\) as well as the portfolio weight \\(\\boldsymbol{w} = \\boldsymbol{h}/\\bar{V_0}\\). Indeed, the portfolio weight in asset \\(k\\) is equal to the asset value holding divided by the portfolio value at time \\(0\\). Following on the previous computation we have</p> \\[ \\begin{align*}   \\frac{\\bar{V}_1 - \\bar{V}_0}{\\bar{V}_0} &amp; = r + \\sum \\frac{h^k}{\\bar{V}_0}\\left(R^k_1 - r\\right)\\\\       &amp; = r + \\boldsymbol{w}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>We get the classical interpretation that the portfolio returns is equal to the risk free rate plus the weighted excess returns in the financial assets. In particular if \\(\\sum w^k = 1\\), meaning that you hold your portfolio entirely in assets, the returns of the portfolio is equal to \\(\\boldsymbol{w}\\cdot \\boldsymbol{R}_1\\).</p> <p>This looks familar and used widely, it is however  mathematically not correct without further assumptions. Consider the following situations where \\(\\bar{V}_0 &lt;0\\) or \\(\\bar{V}_0 = 0\\), returns and weights do not make much sense isn't it?</p> <p>Furthermore, even if you assume that \\(\\bar{V}_0&gt;0\\) (usually \\(\\bar{V}_0 = 1\\)), suppose that you can short, then you may well end-up with a strictly negative or zero portfolio value at time \\(1\\). How would you then compute the portfolio returns between time \\(1\\) and time \\(2\\)?</p> <p>Such a way to look at portfolio returns are consistent mathematically if some strong assumptions are made to garantee that \\(\\bar{V}_0\\) and \\(\\bar{V}_1\\) remain strictly positive (no shorting plus budget constraint for instance). This is the reason why we do not consider during this lecture this kind of approach (portfolio returns or portfolio weights).</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/","title":"Arbitrage and Pricing","text":"<p>A fundamental concept in financial market is the notion of Arbitrage. Consider the following example</p> <p>Example: Arbitrage in a coint toss model</p> <p>Consider the example of a simple coin toss model. Formally:</p> <ul> <li>\\(\\Omega = \\{-1, 1\\}\\)</li> <li>\\(\\mathcal{F} = \\{\\emptyset, \\{1\\}, \\{-1\\}, \\{-1, 1\\}\\}\\)</li> <li> <p>Given \\(0&lt;p&lt;1\\)</p> \\[ P[\\{\\omega\\}] = \\begin{cases}     p &amp; \\text{if } \\omega = 1, \\\\     1-p &amp; \\text{if } \\omega = -1 \\end{cases} \\] </li> </ul> <p>We define for our bank account \\(B_0 = 1\\) and \\(B_1 = 1 + r\\) where \\(r &gt; -1\\). We also consider a single stock with:</p> \\[ S_0 &gt; 0, \\quad S_1(\\omega) = S_0(1 + R(\\omega)) \\] <p>where the return \\(R\\) is given by:</p> \\[ R(\\omega) = \\begin{cases}     u &amp; \\text{if } \\omega = 1, \\\\     d &amp; \\text{if } \\omega = -1 \\end{cases} \\] <p>with \\(d &lt; u\\). We assume that \\(S_1\\) is strictly positive, so \\(d &gt; -1\\).</p> <p>Suppose I enter the market with no money and observe that \\(r \\leq d\\). I borrow \\(\\eta S_0\\) from the bank to buy \\(\\eta&gt;0\\) shares of the stock. At time \\(1\\), the value of my portfolio is:</p> \\[     \\bar{V}_1(\\omega) = -\\eta S_0(1 + r) + \\eta S_1(\\omega) =     \\begin{cases}         \\eta S_0(u - r) &amp; \\text{if } \\omega = 1, \\\\         \\eta S_0(d - r) &amp; \\text{if } \\omega = -1     \\end{cases} \\] <p>Since \\(r \\leq d &lt; u\\), my strategy does not lose money in any cases and I always make a strictly positive gain with probability \\(p&gt;0\\). By scaling this strategy, I could generate unlimited wealth without risk. A similar scenario arises if \\(d &lt; u \\leq r\\), where I could short-sell the stock infinitely.</p> <p>As this example shows, such a market would be dysfunctional. Economically, arbitrageurs would exploit this situation, driving the stock price back within boundaries to eliminate these opportunities. Hence, we require the concept of an arbitrage-free market.</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#arbitrage","title":"Arbitrage","text":"<p>Definition Arbitrage and Arbitrage Free Market</p> <p>A portfolio \\(\\bar{V}\\) with initial value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) is called an arbitrage if</p> \\[ \\begin{equation*}         \\underbrace{P\\left[\\bar{V}_1(\\omega) \\geq \\bar{V}_0(1 + r)\\right] = 1}_{\\text{No downside risk}}\\quad \\text{and}\\quad \\underbrace{P\\left[\\bar{V}_1(\\omega) &gt; \\bar{V}_0(1 + r)\\right] &gt;0}_{\\text{Strict positive gains with strict positive probability}} \\end{equation*} \\] <p>A financial market is call arbitrage free, if there exists no arbitrage.</p> <p>In other words, a self-financing strategy is an arbitrage if it guarantees a net gain at time \\(1\\) in every possible state and a strictly positive gain with nonzero probability.</p> <p>There exists several equivalent way to express arbitrage as the following proposition states</p> <p>Proposition Arbitrage Equivalence</p> <p>The following statements are equivalent:</p> <ol> <li>The financial market admits an arbitrage portfolio.</li> <li> <p>There exists a discounted portfolio \\(V\\) such that:</p> \\[ P\\left[V_1 \\geq V_0\\right] = 1 \\quad \\text{and} \\quad P\\left[V_1 &gt; V_0\\right] &gt; 0 \\] </li> <li> <p>There exists a strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\right] = 1 \\quad \\text{and} \\quad P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0\\right] &gt; 0 \\] </li> </ol> Proof <ol> <li> <p>Equivalence of (i) and (ii):     For a portfolio \\(\\bar{V}\\), \\(\\bar{V}_1 \\geq (1 + r)\\bar{V}_0\\) is equivalent to \\(V_1 \\geq V_0\\) by dividing the inequality by \\(1 + r &gt; 0\\). The same holds for the strict inequality.</p> </li> <li> <p>Equivalence of (ii) and (iii):     For a discounted portfolio \\(V\\), \\(V_1 = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq V_0\\) is equivalent to \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\) by subtracting \\(V_0\\).</p> </li> </ol> Exercise <p>Recall that the returns vector \\(\\boldsymbol{R}_1\\) are defined as</p> \\[     R^k_1 = \\frac{S_1^k - S_0^k}{S_0^k}\\quad \\text{for }k=1, \\ldots, d \\] <p>Show that the following assertions are equivalent:</p> <ol> <li> <p>The financial market admits and arbitrage.</p> </li> <li> <p>There exists \\(\\boldsymbol{h} \\in \\mathbb{R}^d\\) such that:</p> \\[     P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\geq 0 \\right] = 1      \\quad \\text{and} \\quad      P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) &gt; 0 \\right] = 1  \\] </li> </ol>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#pricing-measure","title":"Pricing Measure","text":"<p>As we will consequently see in the Fundamental Theorem of Asset Pricing, another central concept in financial market are pricing measures</p> <p>Definition: Pricing Measure</p> <p>A probability measure \\(P^\\ast\\) is called a pricing measure(1) if:</p> <ol> <li> Also known as a pricing kernel in financial engineering or martingale measure in mathematics.</li> </ol> \\[     E^{P^\\ast}\\left[\\frac{S_1^k}{1 + r}\\right] = S_0^k, \\quad \\text{for } k = 1, \\ldots, d \\] <p>In other words, under a pricing measure the discounted expected value of each asset equals its present price.</p> <p>Remark: Vector notation and equivalent formulations</p> <p>For a vector of random variables \\(\\boldsymbol{Z} = (Z^1, \\ldots, Z^d)\\) and a probability measure \\(Q\\), we denote:</p> \\[ E^Q[\\boldsymbol{Z}] := \\left(E^Q[Z^1], \\ldots, E^Q[Z^d]\\right) \\] <p>In particular, \\(P^\\ast\\) is a pricing measure if:</p> \\[ E^{P^\\ast}\\left[\\frac{\\boldsymbol{S}_1}{1 + r}\\right] = \\boldsymbol{S}_0, \\quad \\text{or equivalently}\\quad E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0 \\] <p>This implies that under a pricing measure, the average return of each financial asset equals the bank's interest rate:</p> \\[ E^{P^\\ast}[R_1^k] = r, \\quad \\text{for every } k = 1, \\ldots, d \\] <p>Lemma</p> <p>Suppose that the financial market admits a pricing measure \\(P^\\ast\\). Then</p> <ol> <li> <p>for every portfolio \\(\\bar{V}\\), it holds</p> \\[     \\bar{V}_0 = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right] \\] </li> <li> <p>for every (discounted) portfolio \\(V\\), it holds</p> \\[     V_0 = E^{P^\\ast}\\left[ V_1 \\right] \\] </li> <li> <p>for every strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\), it holds</p> \\[     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0 \\] </li> </ol> Proof <p>We just show the last assertion, the other two follows directly. Let \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) and \\(P^\\ast\\) be a pricing measure. By definition of \\(P^\\ast\\) and the properties of the expectation, it follows that</p> \\[ \\begin{equation*}     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right]  = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right]= \\sum \\eta^k E^{P^\\ast}\\left[ \\Delta X_1^k  \\right] = \\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right] = 0 \\end{equation*} \\] <p>In the following, we will consider those pricing measures \\(P^\\ast\\) that are equivalent to \\(P\\)(1). By the very definition, it follows in particular that if \\(P^\\ast\\sim P\\) and \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, then </p> <ol> <li> <p>See appendix on probability theory for details and consequence in terms of Radon-Nykodym derivative.</p> <p>Just recalling the definition, a probability measure \\(Q\\) is equivalent to \\(P\\) and denoted by \\(Q\\sim P\\) if</p> \\[P[A] = 0 \\quad \\text{if and only if} \\quad Q[A]=0\\] <p>In other terms the two measures agrees on negligible events.</p> <p>This is however equivalent to</p> \\[P[A] = 1 \\quad \\text{if and only if} \\quad Q[A]=1\\] <p>or</p> \\[P[A] &gt; 0 \\quad \\text{if and only if} \\quad Q[A]&gt;0\\] </li> </ol> \\[ \\begin{equation*} \\begin{cases}   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\quad \\text{is equivalent to } \\quad \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#fundamental-theorem-of-asset-pricing","title":"Fundamental Theorem of Asset Pricing","text":"<p>Fundamental Theorem of Asset Pricing (FTAP)</p> <p>In a financial market, the following conditions are equivalent:</p> <ol> <li>The market is arbitrage-free.</li> <li>There exists at least one pricing measure \\(P^\\ast \\sim P\\) with bounded density \\(dP^\\ast/dP\\).</li> </ol> Proof: (sketch) <ol> <li> <p>Step 1 (easy direction): condition 2. implies 1..     By contradiction, assume that there exists a pricing measure \\(P^\\ast \\sim P\\) and an arbitrage strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). We show that this is not possible.</p> <p>On one hand, having a pricing measure \\(P^\\ast\\) implies that \\(E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0\\). It follows that for the arbitrage strategy \\(\\boldsymbol{\\eta}\\), we have:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right] = 0 \\] <p>On the other hand, since \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, it holds that:</p> \\[ \\begin{cases}   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>Since \\(P^\\ast \\sim P\\), this is equivalent to:</p> \\[ \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>The first line implies that the random variable \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\) is positive \\(P^\\ast\\)-almost surely. The second line indicates that this variable is strictly positive somewhere. Taking the expectation of this strictly positive random variable results in a strictly positive expectation:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 \\] <p>However, this contradicts the earlier result that \\(E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0\\). This shows that 2. implies 1..</p> </li> <li> <p>Step 2 (difficult direction): condition 1. implies 2.. </p> <p>Here, we show that if 1.$ does not hold (i.e., there exists no pricing measure \\(P^\\ast\\) with bounded density), then there exists an arbitrage. To state that there exists no pricing measure \\(P^\\ast\\) with bounded density, consider the set:</p> \\[   \\mathcal{C} = \\left\\{ E^Q[\\Delta \\boldsymbol{X}_1] : Q \\sim P \\text{ and } \\frac{dQ}{dP} \\text{ is bounded} \\right\\} \\] <p>This set includes all vectors of expectations of discounted gains under pricing measures with bounded density \\(Q\\). There exists a pricing measure \\(P^\\ast \\sim P\\) with bounded density if and only if the vector \\(0\\) is in \\(\\mathcal{C}\\). Hence, the condition that 2. does not hold is equivalent to \\(0 \\notin \\mathcal{C}\\).</p> <p>We show that the set \\(\\mathcal{C} \\subseteq \\mathbb{R}^d\\) has the following properties:</p> <ul> <li> <p>Non-emptiness: \\(\\mathcal{C} \\neq \\emptyset\\). Since \\(P \\sim P\\) and \\(\\frac{dP}{dP} = 1\\), it follows that \\(E^P[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C}\\)(1).</p> </li> <li> <p>Note: We never assumed \\(\\boldsymbol{X}_1\\) is integrable under \\(P\\). This can be addressed in the appendix.</p> </li> <li> <p>Convexity: \\(\\mathcal{C}\\) is convex(1).</p> <ol> <li>That is, for any two points \\(\\boldsymbol{x}, \\boldsymbol{y} \\in \\mathcal{C}\\) and any \\(\\lambda \\in [0, 1]\\), the interval \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y}\\) is also in \\(\\mathcal{C}\\).  </li> </ol> <p>By definition, there exist \\(Q^{\\boldsymbol{x}}\\) and \\(Q^{\\boldsymbol{y}}\\) equivalent to \\(P\\) with bounded density such that \\(E^{Q^{\\boldsymbol{x}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{x}\\) and \\(E^{Q^{\\boldsymbol{y}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{y}\\). By the Radon-Nikodym theorem, define:</p> \\[   \\frac{dQ}{dP} = \\lambda \\frac{dQ^{\\boldsymbol{x}}}{dP} + (1 - \\lambda) \\frac{dQ^{\\boldsymbol{y}}}{dP} \\] <p>This \\(dQ/dP\\) is a strictly positive bounded random variable (since \\(dQ^{\\boldsymbol{x}}/dP\\) and \\(dQ^{\\boldsymbol{y}}/dP\\) are) with expectation equal to \\(1\\):</p> \\[   E^P\\left[ \\frac{dQ}{dP} \\right] = \\lambda E^P\\left[ \\frac{dQ^{\\boldsymbol{x}}}{dP} \\right] + (1 - \\lambda) E^P\\left[ \\frac{dQ^{\\boldsymbol{y}}}{dP} \\right] = \\lambda + (1 - \\lambda) = 1 \\] <p>Hence, \\(dQ/dP\\) defines a probability measure \\(Q \\sim P\\) with bounded density, and:</p> \\[   \\boldsymbol{z} = E^Q[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C} \\] <p>Moreover:</p> \\[   \\boldsymbol{z} = \\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\] <p>showing that \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\in \\mathcal{C}\\).</p> </li> </ul> <p>The fact that \\(0 \\notin \\mathcal{C}\\), where \\(\\mathcal{C}\\) is not a convex set, the Hahn-Banach theorem allows to separate with a line (an hyperplane) the point from the convex set.</p> <p> </p> <p>It translates mathematicaly into the existence of a vector \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ \\begin{cases}    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x} \\geq 0 &amp; \\text{for all } \\boldsymbol{x} \\in \\mathcal{C}, \\\\    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x}_0 &gt; 0 &amp; \\text{for some } \\boldsymbol{x}_0 \\in \\mathcal{C}. \\end{cases} \\] <p>By definition of \\(\\mathcal{C}\\), this translates to:</p> \\[ \\begin{cases}    E^Q\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] \\geq 0 &amp; \\text{for all } Q \\sim P \\text{ with bounded } \\frac{dQ}{dP}, \\\\    E^{Q_0}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 &amp; \\text{for some } Q_0 \\sim P \\text{ with bounded } \\frac{dQ_0}{dP}. \\end{cases} \\] <p>The last condition implies that \\(Q_0[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\), and since \\(Q_0\\) is equivalent to \\(P\\), it also implies that </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\] <p>As for the first condition, we claim that it implies </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\] <p>showing then that \\(\\boldsymbol{\\eta}\\) is an arbitrage.</p> <p>To this end, define \\(A = \\{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &lt; 0\\}\\) and consider the sequence of strict positive random variables:</p> \\[   Y_n := \\left( 1 - \\frac{1}{n} \\right)1_A + \\frac{1}{n}1_{A^c} \\] <p>which is bounded by \\(1\\) and satisfies \\(Y_n \\to 1_A\\) \\(P\\)-almost surely. Since \\(Y_n &gt; 0\\), it generates a sequence of probability measures \\(Q_n\\) equivalent to \\(P\\) with bounded densities:</p> \\[   \\frac{dQ_n}{dP} = \\frac{Y_n}{E[Y_n]} \\] <p>Hence</p> \\[   0 \\leq E^{Q_n}\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\right] = \\frac{1}{E[Y_n]} E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right]. \\] <p>Taking the limit (1), it follows that:</p> <ol> <li>To be rigorous you invoke the dominated convergence theorem applied to \\(Y_n\\).</li> </ol> \\[   0 \\leq E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right] \\to E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 1_A\\right] \\] <p>which, by the definition of \\(A\\), shows that \\(P[A] = 0\\). In other words, \\(P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\). Hence, \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, contradicting the assumption of an arbitrage-free market.  </p> <p>Thus, there exists a pricing measure equivalent to \\(P\\) with bounded density, which concludes the proof.</p> </li> </ol> <p>This Theorem is called a theorem and fundamental because it states an if and only if assertion between a somehow economical concept (no arbitrage) and a mathematical concept (the existence of a pricing measure). This statement will have many consequences that will unfold while studying derivative pricing.</p> <p>However, an immediate consequence of which is the so called Law of One Price, often stated as given in finance, yet is a consequence of the FTAP.</p> <p>Theorem: Law of One Price</p> <p>If the market is arbitrage free, then for any two portfolios \\(\\bar{V}\\) and \\(\\tilde{V}\\) with exact same outcome tomorrow, that is</p> \\[   P\\left[ \\bar{V}_1 = \\tilde{V}_1\\right] = 1 \\] <p>the value of each portfolio at time \\(0\\) is the same, that is \\(\\bar{V}_0 = \\tilde{V}_0\\)</p> Proof <p>By the fundamental theorem of asset pricing, no arbitrage is equivalent to the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Let further \\(\\bar{V}\\) and \\(\\tilde{V}\\) be two portfolio such that</p> \\[   P\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>Since \\(P^\\ast \\sim P\\), it follows that</p> \\[   P^\\ast\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>showing that \\(E^{P^\\ast}\\left[ \\bar{V}_1 \\right] = E^{P^\\ast}\\left[ \\tilde{V}_1 \\right]\\).</p> <p>Furthermore, it holds that</p> \\[   \\frac{\\bar{V}_1}{1+r} = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\quad \\text{and}\\quad \\frac{\\tilde{V}_1}{1+r} = \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1 \\] <p>for some \\(\\boldsymbol{\\eta}\\) and \\(\\tilde{\\boldsymbol{\\eta}}\\) in \\(\\mathbb{R}^d\\).</p> <p>Taking expectation under the pricing measure, it follows that</p> \\[ \\begin{align*}   \\bar{V}_0 &amp; = \\bar{V}_0 + \\underbrace{\\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right]}_{=0\\text{ since }P^\\ast \\text{ is a pricing measure}}\\\\   &amp; = E^{P^\\ast}\\left[  \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\tilde{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[  \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = \\tilde{V}_0 \\end{align*} \\] <p>This statement stipulates that if a market is arbitrage free, regardless the portfolio you have in the market, if those deliver the same outcome, then their financing costs has to be the same.</p> <p>The statement of the FTAP seems to be quite abstract, but is has a very easy interpretation in terms of linear algebra when the set of possible states is finite. Indeed, consider the following financial market where </p> <ul> <li>\\(\\Omega = \\{\\omega_1, \\ldots, \\omega_N\\}\\)</li> <li>\\(\\mathcal{F} = 2^\\Omega\\).  </li> <li>\\(P\\) is a probability measure specified by the vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N)\\) where \\(p_i = P[\\{\\omega_i\\}] &gt;0\\) and \\(\\sum p_i =1\\).</li> </ul> <p>We have a bank account with:</p> \\[ B_0 = 1, \\quad B_1 = 1 + r \\] <p>for some \\(r&gt;-1\\).</p> <p>As for the finanical asset, suppose that we have a single one:</p> \\[ S_0 &gt; 0 \\quad \\text{and} \\quad S_1(\\omega_i) = s_i &gt; 0. \\] <p>Up to reordering, we assume that \\(0 &lt; s_1 &lt; s_2 &lt; \\ldots &lt; s_N\\), and denote \\(\\boldsymbol{s} = (s_1, \\ldots, s_N)\\) as the vector of payoffs for \\(S^1\\) at time \\(1\\). </p> <p>Since the state space is finite, any expectation of the asset price can be written as</p> \\[ \\begin{equation*}   E^{Q}\\left[ S_1 \\right] = \\boldsymbol{s}\\cdot \\boldsymbol{q} \\end{equation*} \\] <p>where \\(\\boldsymbol{q} = (q_1, \\ldots, q_N)\\) represent a probability equivalent to \\(P\\) if and only if \\(q_i&gt;0\\) for every \\(i\\).</p> <p>Hence the  market is arbitrage-free if and only if</p> \\[ (1 + r)S_0 \\in \\left\\{\\boldsymbol{s} \\cdot \\boldsymbol{q} \\colon \\boldsymbol{q} \\in \\mathbb{R}^d, \\sum q_i =1 , \\; q_i &gt; 0 \\text{ for every } i\\right\\} = (s_1, s_N) \\] <p>This means the market is arbitrage-free if and only if the following system of equations:</p> \\[ \\begin{cases}     q_1 s_1 + \\cdots + q_n s_n = (1 + r)S_0 \\\\     q_1 + \\cdots + q_n = 1 \\\\     q_i &gt; 0 &amp; \\text{for all } i \\end{cases} \\] <p>admits at least one solution.  </p> <p>If a solution exists, it is unique if and only if \\(N = 2\\).</p> <p>If you extend to several assets \\(d\\), then you will end up with \\(d+1\\) equations in the system.  If a solution exists then it is unique if and only if \\(N = d+1\\)</p>"},{"location":"lecture/01-One-Period/013-derivative-securities/","title":"Derivative Securities","text":"<p>A contingent claim is a contract between a seller and a buyer where the seller agrees to deliver a certain payoff at a future time. A contingent claim is called a derivative if this contract is written as a payoff depending on some underlying, such as stocks, bonds, indices, portfolios, or funds. Options are specific derivatives characterized by parameters like strike price and expiration date. While definitions may vary, the mathematical interpretation remains consistent.</p> <p>Examples of Derivatives</p> <p>In the presentation of the different derivatives we consider a financial market with a generic asset \\(S\\).</p> <ul> <li> <p>Forward/Future Contract</p> <p>A forward contract is an agreement between two parties to buy or sell an asset \\(S\\) at a future time for a price \\(K\\) fixed today. The payoff for the contract owner is determined by the difference between the asset price and the agreed price:  </p> \\[     C^{fw} = S - K \\] </li> <li> <p>Forward Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>European Put/Call Option</p> <p>A European Call or Put option grants the right, but not the obligation, to buy or sell an asset \\(S\\) at a future time for a strike price \\(K\\) fixed today.       The payoff is</p> \\[     \\begin{align*}       C^{call} &amp; = (S - K)^+                 =     \\begin{cases}       S - K &amp; \\text{if } S \\geq K, \\\\       0 &amp; \\text{otherwise}.     \\end{cases}\\\\     C^{put} &amp; = (K - S)^+              =     \\begin{cases}       K - S &amp; \\text{if } K \\geq S, \\\\       0 &amp; \\text{otherwise}.     \\end{cases}     \\end{align*} \\] <p>European call and put options are related by the formula </p> \\[   C^{call} - C^{put} = S - K \\] </li> <li> <p>European Call/Put Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>Straddle Option</p> <p>The goal of a straddle option is to profit from significant price movements of the underlying asset, regardless of the direction. It grants the right to get the price deviation (positive or negative) of the underlying asset with respect to a strike \\(K\\).</p> <p>The payoff is:</p> \\[   C^{straddle} = |S - K| =   \\begin{cases}     S-K &amp; \\text{ if } S\\geq K\\\\     K-S &amp; \\text{ if } S &lt;K   \\end{cases} \\] <p>Note that a straddle option is equivalent to holding a call and a put option with the same strike.</p> \\[   C^{straddle}(K) = C^{call}(K) + C^{put}(K) \\] </li> <li> <p>Straddle Option Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>Butterfly Option</p> <p>A butterfly option has somehow the counter effect to a straddle option in the sense that it is designed to profit from price movement around a given target \\(K\\) within an interval \\(\\underline{K} &lt; K &lt;\\overline{K}\\).</p> <p>The payoff is:</p> \\[   C^{butterfly} =    \\begin{cases}     0 &amp; \\text{if }S&lt;\\underline{K} \\text{ or }S&gt;\\overline{K}\\\\     S-\\underline{K} &amp; \\text{if } \\underline{K}\\leq S\\leq K\\\\     \\overline{K} - S &amp; \\text{if } K&lt;S \\leq \\overline{K}   \\end{cases} \\] <p>Note that such a straddle option can also be written as a combination of put and call options strikes</p> \\[   C^{butterfly}(\\underline{K}, K, \\overline{K}) = C^{call}(\\underline{K}) + C^{call}(\\overline{K}) - 2 C^{call}(K) \\] <p>Usually, the strike \\(K\\) is at the mid point between \\(\\underline{K}\\) and \\(\\overline{K}\\).</p> </li> <li> <p>Butterfly Option Payoff</p> <p> </p> </li> </ul> <p>Note that each of these options can be expressed as \\(f(S)\\), where \\(S\\) is the underlying asset, and \\(f: \\mathbb{R} \\to \\mathbb{R}\\) is some continuous function.</p> <p>Definition: Contingent Claim</p> <ul> <li> <p>A contingent claim \\(C\\) is a positive random variable.(1)</p> <ol> <li>In a strictly more general sense it does not need to be strictly positive but usually bounded from below. See for instance forward contracts.</li> </ol> </li> <li> <p>A derivative \\(C\\) is a contingent claim that depends only on the information provided by the underlying on which it is written.     In other terms, \\(C = f(\\boldsymbol{S}_1)\\) for some continuous function \\(f:\\mathbb{R}^d \\to [0, \\infty)\\).(1)</p> <ol> <li>In a more general fashion, it means that \\(C\\) is \\(\\sigma(\\boldsymbol{S}_1)\\)-measurable, which with some proof work can be shown to be equivalent to \\(C = f(\\boldsymbol{S}_1)\\) for some measurable function \\(f\\).</li> </ol> </li> </ul>"},{"location":"lecture/01-One-Period/013-derivative-securities/#pricing-a-contingent-claim","title":"Pricing a Contingent Claim","text":"<p>Given a contingent claim \\(C\\), the goal is to determine a fair price \\(\\pi(C)\\) at which it can be sold. To do this, we analyze the situation from the seller's perspective:</p> <ol> <li> <p>Time 0:      The seller receives \\(\\pi(C)\\) and deposits it into their bank account. This amount is used to invest in a strategy \\(\\boldsymbol{\\eta}\\) in \\(\\mathbb{R}^d\\).     The holdings in the bank account become \\(\\pi(C) - \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0\\) and the golding in assets becomes \\(\\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0\\).     The initial portfolio value is \\(\\bar{V}_0(\\boldsymbol{\\eta}) = \\pi(C)\\).</p> </li> <li> <p>Time 1:     The seller delivers the payoff \\(C\\) to the buyer while benefiting from their investment strategy \\(\\boldsymbol{\\eta}\\).     The discounted portfolio value minus the discounted payoff is:</p> \\[   V_1(\\boldsymbol{\\eta}) - \\frac{C}{1 + r} = \\pi(C) + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 - \\frac{C}{1 + r} \\] </li> </ol> <p>In an ideal situation, the seller of the option would like to get out with gains without downside risk, that is, fully hedge the position. Hence, the seller aims to ensure:</p> \\[ \\pi(C) + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}  \\] <p>Such a price \\(\\pi(C)\\) together with the smart strategy \\(\\boldsymbol{\\eta}\\) means that the seller super hedge his position. Considering all the possible prices and smart strategies that super hedge the position allows to define the lowest price at which the seller is willing to sell the option without taking risk, the super-hedging price</p> \\[ \\bar{\\pi}(C) = \\inf \\left\\{ x \\in \\mathbb{R} : x + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}, \\; \\text{for some } \\boldsymbol{\\eta} \\in \\mathbb{R}^d \\right\\}. \\] <p>Conversely, the buyer's perspective leads to the sub-hedging price, \\(\\underline{\\pi}(C)\\):</p> \\[ \\underline{\\pi}(C) = \\sup \\left\\{ y \\in \\mathbb{R} : y + \\boldsymbol{\\nu} \\cdot \\Delta\\boldsymbol{X}_1 \\leq \\frac{C}{1 + r}, \\; \\text{for some } \\boldsymbol{\\nu} \\in \\mathbb{R}^d \\right\\}. \\] <p>It seems economically reasonable that prices \\(y\\) from the buyer sub-hedging their position should be lower than the prices \\(x\\) of the seller super-hedging their positions. This is however true if the market is arbitrage free as seen in the subsequent proposition.</p> <p>To simplify our exposition, let us provide the notation for pricing measures</p> \\[ \\mathcal{P}^\\ast := \\left\\{ P^\\ast \\sim P \\colon E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right] = 0 \\text{ and } dP^\\ast/dP \\text{ is bounded}\\right\\} \\] <p>In particular, the FTAP can be formulated as \"The market is arbitrage free if and only if \\(\\mathcal{P}^\\ast\\) is not empty\".</p> Remark: Geometric Interpretation I <p>Define \\(I\\) and \\(J\\) as the set of super- and sub-hedging prices, respectively:</p> \\[ \\begin{align*}     I &amp; := \\left\\{ x \\in \\mathbb{R}\\colon x+\\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}\\text{ for some smart strategy }\\boldsymbol{\\eta} \\in \\mathbb{R}^d \\right\\}\\\\     J &amp; := \\left\\{ y \\in \\mathbb{R}\\colon y+\\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r}\\text{ for some smart strategy }\\boldsymbol{\\nu} \\in \\mathbb{R}^d \\right\\}\\\\ \\end{align*} \\] <p>For which holds \\(\\bar{\\pi}(C) = \\inf I\\) and \\(\\underline{\\pi}(C) = \\sup J\\).</p> <p>These two sets, \\(I\\) and \\(J\\), are eventually intervals</p> <p>Lemma</p> <ul> <li>\\(I\\) is either an interval of the form \\([\\bar{\\pi}(C), \\infty)\\) or \\((\\bar{\\pi}(C), \\infty)\\)</li> <li>\\(J\\) is either an interval of the form \\((-\\infty, \\underline{\\pi}(C)]\\) or \\((-\\infty, \\underline{\\pi}(C))\\)</li> </ul> <p>Proof</p> <p>We show only the first assertion, the second follows the same argumentation. Clearly \\(\\bar{\\pi}(C)\\) is the lower bound of the set \\(I\\), whether or not it is a minimum or an infimum. We just have to show that for any \\(x\\) in \\(I\\), if \\(m&gt;0\\), then \\(x+m\\) is also in \\(I\\). This follows however from the definition, as for a smart strategy \\(\\boldsymbol{\\eta}\\) such that</p> \\[x + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}\\] <p>It follows immediately that </p> \\[x +m + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq m +\\frac{C}{1+r} \\geq \\frac{C}{1+r}\\] <p>showing that \\(x+m\\) is in \\(I\\).</p> <p>We are now in position to show the first proposition regarding the super- and sub-hedging price</p> <p>Proposition</p> <p>If the market is arbitrage free, then for any super-hedging price \\(x\\), sub-hedging price \\(y\\) and any pricing measure \\(P^\\ast\\) it holds</p> \\[     y \\leq E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] \\leq x \\] <p>In particular, we get</p> \\[     \\underline{\\pi}(C) \\leq \\inf_{P^\\ast \\in \\mathcal{P}^\\ast} E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right]\\leq \\sup_{P^\\ast \\in \\mathcal{P}^\\ast} E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right]\\leq \\bar{\\pi}(C) \\] Proof <p>Let \\(x\\) be a super-hedging price and \\(y\\) be a sub-hedging price. By definition, there exists smart strategies \\(\\boldsymbol{\\eta}\\) and \\(\\boldsymbol{\\nu}\\) in \\(\\mathbb{R}^d\\) such that</p> \\[     y + \\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\leq x + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\] <p>Now, since the market is arbitrage free, according to the FTAP, for any pricing measure \\(P^\\ast\\) in \\(\\mathcal{P}^\\ast\\) which is not empty, by taking expectation of this inequality, it holds</p> \\[     y + \\underbrace{E^{P^\\ast}\\left[\\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1\\right]}_{=0} \\leq E^{P^\\ast}\\left[\\frac{C}{1+r} \\right]\\leq x + \\underbrace{E^{P^\\ast}\\left[\\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1\\right]}_{=0} \\] <p>showing the first assertion.</p> <p>Since this inequality holds for any super hedging price \\(x\\), any sub hedging price \\(y\\) and any pricing measure \\(P^\\ast\\), by the definition of \\(\\bar{\\pi}(C)\\) and \\(\\underline{\\pi}(C)\\) the second assertion follows.</p> <p>We however still need to define the notion of of a fair price for a contingent claim and how it relates to the super-/sub-hedging price.</p> <p>Definition: Fair Price of Contingent Claims</p> <p>Given a contingent claim \\(C\\), a price \\(\\pi(C)\\) is called a fair price if the original financial market extended with the new financial instrument \\(S^{d+1}\\) given by</p> \\[   S^{d+1}_0 = \\pi(C) \\quad \\text{and}\\quad S^{d+1}_1 = C \\] <p>is arbitrage free.</p> <p>We denote by \\(\\Pi(C)\\) the set of all possible fair prices for the contingent claim \\(C\\).</p> <p>In other terms, if the financial market considers the new financial instrument \\(C\\) traded at price \\(\\pi(C)\\) it remains arbitrage free. As pendant to the super- and sub-hedging price, with the help of the FTAP we can connect arbitrage free prices to pricing measures as follows.</p> <p>Proposition</p> <p>Let \\(C\\) be a contingent claim on an arbitrage-free financial market. Then the set of fair prices for the contingent claim \\(C\\) is non-empty and given by:</p> \\[   \\Pi(C) := \\left\\{ E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] : P^\\ast \\sim P \\text{ pricing measure with bounded density}  \\right\\}. \\] Proof <p>A price \\(\\pi(C)\\) for \\(C\\) is fair if the extended financial market is arbitrage-free. By the FTAP, it follows that there exists a pricing measure \\(\\hat{P}\\) equivalent to \\(P\\) with bounded density such that:</p> \\[     E^{\\hat{P}}\\left[\\frac{\\boldsymbol{S}_1}{1+r}\\right] = \\boldsymbol{S}_0, \\quad \\text{and} \\quad E^{\\hat{P}}\\left[\\frac{C}{1+r}\\right] = \\pi(C). \\] <p>In particular, \\(\\hat{P}\\) is a pricing measure equivalent to \\(P\\) for the smaller market \\(\\boldsymbol{S}\\), that is, an element of \\(\\mathcal{P}^\\ast\\), showing that:</p> \\[     \\Pi(C) \\subseteq \\{ E^{P^\\ast}[C/(1+r)] : P^\\ast \\in \\mathcal{P}^\\ast \\}. \\] <p>Reciprocally, let \\(\\pi(C)\\) be an element of \\(\\{ E^{P^\\ast}[C/(1+r)] : P^\\ast \\in \\mathcal{P}^\\ast \\}\\). It follows that \\(\\pi(C) = E^{P^\\ast}[C/(1+r)]\\) for some \\(P^\\ast \\sim P\\) with bounded density. Hence, \\(P^\\ast\\) is a pricing measure equivalent to \\(P\\) for the extended market, showing by the FTAP that the extended market is arbitrage-free. Hence, \\(\\pi(C) \\in \\Pi(C)\\), proving the reverse inclusion.(1)</p> <ol> <li> <p>The proof is not fully complete unless we can show that we can show that \\(\\Pi(C)\\) is non-empty.     As done previously, we pick a probability measure \\(\\tilde{P}\\) equivalent to \\(P\\) such that \\(E^{\\tilde{P}}[C] &lt; \\infty\\). Under \\(\\tilde{P}\\), the market is arbitrage-free.     The FTAP guarantees the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\) with bounded density.      In particular, \\(E^{P^\\ast}[C] &lt; \\infty\\), and therefore:</p> \\[     \\pi(C) = E^{P^\\ast}[C/(1+r)] \\in \\Pi(C). \\] </li> </ol> <p>We are now in place to show the relation ship between super- sub-hedging prices, pricing measures and fair prices. In a nuttshell that the following illustration holds</p> <p> </p> <p>Theorem: Super/Sub Hedging and Fair Prices</p> <p>Let \\(C\\) be a contingent claim. For</p> \\[     \\begin{align*}         J &amp; = \\left\\{ y\\in \\mathbb{R}\\colon y + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\text{ for some }\\boldsymbol{\\eta}\\in \\mathbb{R}^d \\right\\} &amp;&amp; \\text{Risk free subhedging prices}\\\\         \\underline{\\pi}(C) &amp; = \\sup J &amp;&amp; \\text{Sub-hedging price}\\\\         I &amp; = \\left\\{ x\\in \\mathbb{R}\\colon x + \\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\text{ for some }\\boldsymbol{\\nu}\\in \\mathbb{R}^d \\right\\} &amp;&amp; \\text{Risk free superhedging prices}\\\\         \\underline{\\pi}(C) &amp; = \\inf I &amp;&amp; \\text{Super-hedging price}\\\\         \\Pi(C) &amp; = \\left\\{ \\pi(C)\\colon \\text{fair prices} \\right\\} &amp;&amp; \\text{Fair prices}\\\\         \\mathcal{P}^\\ast &amp; = \\left\\{ P^\\ast \\sim P \\colon P^\\ast \\text{ is a pricing measure} \\right\\} &amp;&amp; \\text{Pricing measures}     \\end{align*} \\] <p>If the market is arbitrage free, then it holds that \\(J\\), \\(I\\), and \\(\\Pi(C)\\) are intervals such that \\(J\\leq \\Pi(C) \\leq I\\). Furthermore </p> \\[     \\begin{align*}         J &amp; = (-\\infty, \\underline{\\pi}(C)] &amp;         \\Pi(C) &amp; = \\left\\{ E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] \\colon P^\\ast \\in \\mathcal{P}^\\ast \\right\\} &amp;         I &amp; = [\\overline{\\pi}(C), \\infty )      \\end{align*} \\] <p>and</p> \\[     \\begin{align*}         \\underline{\\pi}(C) &amp; = \\inf \\Pi(C) &amp; \\overline{\\pi}(C) &amp; = \\sup \\Pi(C)     \\end{align*} \\] Proof <p>We already saw that \\(J\\) and \\(I\\) are intervals (see geometric interpretation remark above). We also say that \\(\\Pi(C) = \\{E^{P^\\ast}[C/(1+r)]\\colon P^\\ast \\in \\mathcal{P}^\\ast\\}\\) and that \\(J \\leq \\Pi(C) \\leq I\\). The fact that \\(\\Pi(C)\\) is also an interval follows directly from \\(\\mathcal{P}^\\ast\\) is a convex set, same argumentation as for \\(\\mathcal{C}\\) in the proof of the FTAP.</p> <p>We are left to show that \\(\\underline{\\pi}(C) \\in J\\) and \\(\\overline{\\pi}(C) \\in I\\) and that \\(\\underline{\\pi}(C) = \\inf \\Pi(C)\\) as well as \\(\\overline{\\pi}(C)  = \\sup \\Pi(C)\\).</p> <p>Let us proove that \\(\\overline{\\pi}(C) = \\sup \\Pi(C)\\). We already know that \\(\\overline{\\pi}(C) \\geq \\sup \\Pi(C)\\) Suppose \\(\\sup \\Pi(C) &lt; \\infty\\), otherwise the equality is trivial. Let \\(m &gt; \\sup \\Pi(C)\\). By definition, the market extended with \\((m, C)\\) admits an arbitrage opportunity. That is, there exist \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) and \\(\\mu \\in \\mathbb{R}\\) such that:</p> \\[     \\begin{cases}         P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right) \\geq 0\\right] = 1, \\\\         P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right) &gt; 0\\right] &gt; 0.     \\end{cases} \\] <p>Since the original market is arbitrage-free, it follows that \\(\\mu \\neq 0\\). Taking the expectation of the positive random variable \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right)\\) with respect to \\(P^\\ast \\in \\mathcal{P}^\\ast\\) yields:</p> \\[     \\mu E^{P^\\ast}\\left[\\frac{C}{1+r} - m\\right] \\geq 0. \\] <p>By definition of \\(m\\), this implies \\(\\mu &lt; 0\\). Defining \\(\\boldsymbol{\\nu} = -\\boldsymbol{\\eta}/\\mu \\in \\mathbb{R}^d\\) yields:</p> \\[     m + \\boldsymbol{\\nu} \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}, \\] <p>showing that \\(m\\) is in \\(I\\), and therefore \\(m \\geq \\bar{\\pi}(C)\\). Consequently:</p> \\[     \\sup \\Pi(C) \\geq \\bar{\\pi}(C). \\] <p>The same argumentation shows that \\(\\overline{\\pi}(C) = \\inf \\Pi(C)\\).</p> Warning, the last part of the assertion calls for compactness arguments <p>We are left to show that \\(\\overline{\\pi}(C)\\) is in \\(I\\). Without loss of generality, due to the law of one price, we may assume that there is no redundancy; that is, \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 = 0\\) implies \\(\\boldsymbol{\\eta} = 0\\).  </p> <p>Pick a sequence \\((m_n)\\) of elements in \\(I\\) such that \\(m_n \\downarrow \\overline{\\pi}(C)\\) and denote by \\(\\boldsymbol{\\eta}^n\\) the corresponding sequence of strategies such that:</p> \\[     m_n + \\boldsymbol{\\eta}^n \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}. \\] <p>If \\((\\boldsymbol{\\eta}^n)\\) is bounded, up to a subsequence, we may assume that \\(\\boldsymbol{\\eta}^n \\to \\boldsymbol{\\eta} \\in \\mathbb{R}^d\\), for which it holds:</p> \\[     \\frac{C}{1 + r} \\leq m_n + \\boldsymbol{\\eta}^n \\cdot \\Delta \\boldsymbol{X}_1 \\to \\bar{\\pi}(C) + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1, \\] <p>showing that \\(\\bar{\\pi}(C)\\) is in I.</p> <p>If \\(\\lim \\|\\boldsymbol{\\eta}^n\\| = \\infty\\), up to a subsequence, it follows that \\(\\boldsymbol{\\eta}^n / \\|\\boldsymbol{\\eta}^n\\| \\to \\boldsymbol{\\mu}\\) with \\(\\|\\boldsymbol{\\mu}\\| = 1\\).</p> <p>However, it follows that:</p> \\[     0 \\leq \\lim \\frac{C}{\\|\\boldsymbol{\\eta}^n\\|(1 + r)} = \\lim \\frac{\\boldsymbol{\\eta}^n}{\\|\\boldsymbol{\\eta}^n\\|} \\cdot \\Delta \\boldsymbol{X}_1 + \\frac{m_n}{\\|\\boldsymbol{\\eta}^n\\|} = \\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_1 \\] <p>Since the market is arbitrage-free, it must follow that \\(\\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_1 = 0\\), which by the non-redundancy assumption implies \\(\\boldsymbol{\\mu} = 0\\), leading to a contradiction since \\(\\|\\boldsymbol{\\mu}\\| = 1\\).</p> <p>Definition</p> <p>A contingent claim \\(C\\) is called replicable \u2014 attainable, hedgeable, or redundant \u2014 if there exists a portfolio with start value \\(\\bar{V}_0\\) and strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[     C = \\bar{V}_1 = \\bar{V}_0 + \\boldsymbol{\\eta} \\cdot \\left(\\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r)\\right). \\] <p>In other term, a contingent claim is replicable if its outcome can be fully attained by a self financing portfolio.</p> <p>Proposition</p> <p>Let \\(C\\) be a contingent claim in an arbitrage-free market. Then:</p> <ul> <li> <p>\\(C\\) is replicable if and only if \\(\\overline{\\pi}(C) = \\underline{\\pi}(C)\\) which is the unique price of the contingent claim</p> </li> <li> <p>If \\(C\\) is not replicable, then \\(\\overline{\\pi}(C) &gt; \\underline{\\pi}(C)\\), and:</p> </li> </ul> \\[     \\Pi(C) = \\left(\\overline{\\pi}(C), \\underline{\\pi}(C)\\right). \\] Proof <p>Clearly, if \\(C\\) is replicable, it follows that \\(\\underline{\\pi}(C) = \\overline{\\pi}(C)\\) by the definition of \\(\\underline{\\pi}\\) and \\(\\overline{\\pi}\\). The reciprocal follows from the second assertion. To prove the second assertion:</p> <ol> <li>\\(\\Pi(C)\\) is an interval</li> <li> <p>Non-replicability implies that \\(\\bar{\\pi}(C) \\not\\in \\Pi(C)\\):     Indeed, by the previous theorem, there exists a strategy \\(\\boldsymbol{\\eta}\\) such that:</p> \\[     \\bar{\\pi}(C) + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}. \\] <p>Since \\(C\\) is not replicable, this inequality cannot hold with equality \\(P\\)-almost surely. This demonstrates \\(\\bar{\\pi}(C) \\not\\in \\Pi(C)\\).</p> </li> </ol> <p>Since \\(\\overline{\\pi}(C) = \\sup \\Pi(C)\\), it follows that \\(\\Pi(C)\\) forms an open interval:</p> \\[     \\Pi(C) = \\left(\\underline{\\pi}(C), \\overline{\\pi}(C)\\right) \\] <p>A condition that garantees that every contingent claim is replicable and henceforth with a unique price is when \\(\\mathcal{P}^\\ast\\) contains a unique pricing measure. In such a market every contingent claim is uniquely priced and hedgable. In other terms every contingent claim in a complete financial market is redundant since they can all be achieved by a portfolio. A market with a unique pricing measure is called a complete market</p> <p>On the other hand, the proposition shows that unless the claim is attainable, then fair prices of a contingent claim are not unique. The choice of a fair price (and therefore a deal) for such a contingent claim is henceforth due to an agreement between the buyer and the seller to choose a price within the interval \\(\\Pi(C)\\). Therefore, they both have to accept some downside risk since neither will have a price in their confort risk free zone.</p> <p>Example: Forward Contract</p> <p>Recall that forward contract are contingent claims of the form(1)</p> <ol> <li>Note first that forward contract are not necessarily positive random variable, but usually for contingent claims we can assume that they are greater than some constant.</li> </ol> \\[   C^{fw}(K) = S_1 - K  \\] <p>Suppose that our market is arbitrage free and choose any pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Taking expectation of the the discounted value of the contingent claim yields</p> \\[   E^{P^\\ast}\\left[ \\frac{C^{fw}}{1+r} \\right] = E^{P^\\ast}\\left[ \\frac{S_1}{1+r} \\right] - \\frac{K}{1+r} = S_0 - \\frac{K}{1+r} \\] <p>showing that the fair price of the forward contract is unique. It is not surpising as the payoff can be immediately replicated by a portfolio.</p> <p>However in financial markets, people speaks and quote the so called forward price. The definition of a forward price \\(F\\) is the value of the strike \\(K\\) such that the fair price of the forward contract is equal to \\(0\\). In other term, the forward price \\(F\\) is given by</p> \\[   F = (1+r) S_0 \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#european-call-and-put-options","title":"European Call and Put Options","text":"<p>The European call and put options are ubiquitous in finance as the most simple types of options.</p> <p>Recall the payoff of such options</p> \\[ \\begin{align*}   C^{call}(K) &amp; = (S_1-K)^+ &amp;    C^{put}(K) &amp; = (K-S_1)^+ \\end{align*} \\] <p>We suppose that the market is arbitrage free and denote with \\(\\pi^{call}(K)\\) and \\(\\pi^{put}(K)\\) the fair prices for each option.</p> <p>Since both prices are fair, there exists a pricing measure \\(P^\\ast \\sim P\\) in the extended market where those two options are traded together with the underlying. It holds in particular that</p> \\[ \\pi^{call}(K) = E^{P^\\ast}\\left[ \\frac{(S_1 - K)^+}{1+r} \\right] \\quad \\text{and}\\quad \\pi^{put}(K) = E^{P^\\ast}\\left[ \\frac{(K - S_1)^+}{1+r} \\right] \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#put-call-parity","title":"Put Call Parity","text":"<p>Using the fact that \\((S_1-K)^+ - (K-S_1)^- = S_1-K\\) we can derive the so called put/call parity by taking expectation under \\(P^\\ast\\):</p> \\[ \\pi^{call}(K) - \\pi^{put}(K) =  E^{P^\\ast}\\left[\\frac{(S_1-K)^+ - (K-S_1)^+}{1+r}\\right] = E^{P^\\ast}\\left[ \\frac{S_1-K}{1+r} \\right] = S_0 - \\frac{K}{1+r} \\] <p>Put Call Parity</p> \\[   \\pi^{call}(K) - \\pi^{put}(K) = S_0 - \\frac{K}{1+r} \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#universal-price-bounds","title":"Universal Price Bounds","text":"<p>In an arbitrage free market, let \\(\\pi^{call} = E^{P^\\ast}[C^{call}/(1+r)]\\) be any fair price for this call option. We are interested at providing bounds for the fair price of this call option.</p> <p>On the one hand, it holds that \\(S-K \\leq (S-K)^+\\). Taking the expectation under \\(P\\) of the discounted value of this inequality together with the fact that \\(\\pi^{call} \\geq 0\\) yields</p> \\[   \\left(S_0 - \\frac{K}{1+r}\\right)^+ \\leq \\pi \\] <p>On the other hand, it holds that \\((S_1-K)^+ \\leq S_1\\), taking expectation of the discounted value of this inequality yields</p> \\[     \\pi^{call} \\leq S_0 \\] <p>showing the universal bounds for call options \\((S_0 - K/(1+r))^+ \\leq \\pi{call}\\leq S_0\\) for any fair price for the call.</p> <p>Using put call parity, for any fair price for the put \\(\\pi^{put}\\) it holds that \\(K/{1+r}\\geq \\pi^{put}\\geq (S_0-K/(1+r))^+ + K/(1+r) - S_0 = (K/(1+r) - S_0)^+\\).</p> <p>Universal Price Bounds</p> \\[   \\begin{equation*}   \\begin{cases}      \\left( S_0 -\\frac{K}{1+r} \\right)^+ \\leq \\underline{\\pi}\\left( C^{call}(K) \\right) \\leq \\overline{\\pi}\\left( C^{call}(K) \\right)\\leq S_0\\\\       \\\\       \\frac{K}{1+r} \\leq \\underline{\\pi}\\left( C^{put}(K) \\right) \\leq \\overline{\\pi}\\left( C^{put}(K) \\right)\\leq \\left( \\frac{K}{1+r} - S_0 \\right)^+   \\end{cases}   \\end{equation*} \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#jargon","title":"Jargon","text":"<p>A lot of jargon is connected to these options.</p> <ul> <li> <p>Intrinsic Value: The intrinsic value of the option is the value if it were executed now, that is</p> \\[IV^{call} = (S_0-K)^+ \\quad \\text{and}\\quad IV^{put} = (K-S_0)^+\\] </li> <li> <p>In/At/Out of the Money: An option is called in the money if its intrinsic value is strictly positive, at the money if the underlying price equal the strike, out of the money if the intrinsic value is \\(0\\) and the underlying price is not equal to the strike.</p> </li> <li> <p>Moneyness: Moneyness is a concept that has no rigorous definition but stems from a particular property of the call/put option, the positive homogeneity of their payoff, that it \\((\\lambda x)^+ = \\lambda x^+\\) for any \\(\\lambda &gt;0\\).</p> <p>We can therefore normalize the payoff of options by either \\(K\\), \\(S_0\\) or \\(K/(1+r)\\), etc. Most of those normalizations are brought in connection with the resulting Black-Scholes-Merton formula, but let us stress some aspects of this definition. The simple version of moneyness is related to the intrinsic value of the option. In the case of a call, we can normalize by the strike where the simple spot moneyness is defined as \\(S_0/K\\). Indeed, it holds</p> \\[   \\pi^{call}(K) = K E^{P^\\ast}\\left[ \\frac{1}{1+r}\\left( \\frac{S_1}{K} - 1 \\right)^+ \\right]  \\] <p>The intrinsic value of the normalize option in the inner part of the expectation is \\((S_0/K-1)^+\\) and therefore is in the money iff the simple (call) spot moneyness is greater than one and out of the money otherwise.</p> <p>In the case of the put option we normalize by the current underlying price \\(S_0\\), that is, the simple spot moneyness is defined as \\(K/S_0\\):</p> \\[   \\pi^{put}(K) = S_0 E^{P^\\ast}\\left[ \\frac{1}{1+r}\\left(\\frac{K}{S_0}- \\frac{S_1}{S_0} \\right)^+ \\right]  \\] <p>The intrinsic value of this normalized option in the inner part of the expectation is \\((K/S_0 -1)^+\\) which is positive iff the simple (put) spot moneyness is greater than one and out of the money otherwise.</p> <p>Since those definition is rather confusing, always rely on your mathematical knowledge about what each should mean.</p> </li> </ul>"},{"location":"lecture/02-risk-management/021-what-is-risk/","title":"What is Risk","text":"<p>Even if the notion of risk is colloquial and everyone intuitively understands it, it is far from clear what it is the exact definition.</p> <p>We saw in the previous chapter how to price contingent claims in a \"risk-neutral way\" ensured by an arbitrage-free financial market. However, such pricing does not tell us much about the amount of \"risk\" one undertakes when investing in one product or another.</p> <p>Let us consider the following example.</p> <p>Example</p> <p>Let \\(\\Omega=\\{\\omega_1,\\omega_2,\\omega_3\\}\\), \\(\\mathcal{F}=2^\\Omega\\), and the \"objective probability\" measure \\(P\\) given by \\(P[\\{\\omega_1\\}]=0.1\\), \\(P[\\{\\omega_2\\}]=0.85\\), and \\(P[\\{\\omega_3\\}]=0.05\\). Our bank account \\(B_0=1\\) and \\(B_1=(1+r)\\). We have two stocks with the same start price \\(S_0^1=S_0^2=100\\) and prices tomorrow:</p> \\[ S_1^1(\\omega)= \\begin{cases}     110 &amp; \\text{if } \\omega = \\omega_1 \\\\     105 &amp; \\text{if } \\omega = \\omega_2 \\\\     100 &amp; \\text{if } \\omega = \\omega_3 \\end{cases} \\quad \\text{and} \\quad S_1^2(\\omega)= \\begin{cases}     160 &amp; \\text{if } \\omega = \\omega_1 \\\\     110 &amp; \\text{if } \\omega = \\omega_2 \\\\     0   &amp; \\text{if } \\omega = \\omega_3 \\end{cases} \\] <p>Simple computation shows that for \\(r=\\frac{1}{15} \\approx 6.66\\%\\), there exists a unique risk-neutral pricing measure \\(P^\\ast\\) given by:</p> \\[ P^\\ast[\\{\\omega_1\\}] = p_1^\\ast = \\frac{2}{3}, \\quad P^\\ast[\\{\\omega_3\\}] = p_3^\\ast = \\frac{1}{3}, \\quad \\text{and} \\quad P^\\ast[\\{\\omega_2\\}] = p_2^\\ast = 0 \\] <p>Now, as a portfolio manager, you face the dilemma of which stock you would choose or what proportion you would allocate to one or the other. If the only rationale underlying your decision process is given in terms of the risk-neutral pricing, there is no difference between the two stocks, and you are indifferent.</p> <p>However, you intuitively see that the first stock is a blue chip, whereas the second one is rather the hot but \"risky\" kid on the playground\u2014a startup or so. Your decision process would likely be driven by a \"risk/reward\" analysis in the face of \"uncertainty,\" whatever that means.</p> <p>We make the analysis even simpler with the following second example.</p> <p>Example</p> <p>You own 1,000 RMB and have the choice between the following games:</p> <ol> <li> <p>Pay 1,000 and get immediately:</p> \\[ \\begin{cases}     2,000 &amp; \\text{with probability } 50\\% \\\\     0     &amp; \\text{otherwise} \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,200 &amp; \\text{with probability } \\frac{5}{6} \\approx 83.33\\% \\\\      0     &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,300 &amp; \\text{with probability } 25\\% \\\\      900   &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,100 &amp; \\text{with probability } 50\\% \\\\      900   &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Do nothing and keep your 1,000.</p> </li> </ol> <p>All these games have an expected return of 0. However, you would likely have a preference regarding which one is the best. Considering their standard deviations\u2014that is, \\(E[(X - E[X])^2]^{1/2}\\)\u2014it holds:</p> \\[   \\begin{aligned}       \\mathrm{STD}(\\text{game 1}) &amp; \\approx 1,000, \\\\       \\mathrm{STD}(\\text{game 2}) &amp; \\approx 447.21, \\\\       \\mathrm{STD}(\\text{game 3}) &amp; \\approx 173.21, \\\\       \\mathrm{STD}(\\text{game 4}) &amp; \\approx 100, \\\\       \\mathrm{STD}(\\text{game 5}) &amp; \\approx 0.   \\end{aligned} \\] <p>Remark</p> <p>Risk perception is a subjective view of how you assess uncertain prospective outcomes. This may differ from one person to another as well as from one context to another. How can we model this fact mathematically?</p>"},{"location":"lecture/02-risk-management/021-what-is-risk/#two-examples-for-risk-assessment-instruments","title":"Two Examples for Risk Assessment Instruments","text":""},{"location":"lecture/02-risk-management/021-what-is-risk/#markowitz-mean-variance","title":"Markowitz Mean Variance","text":"<p>The deviation from the mean appears to be a good indicator of our aversion to uncertainty. This is why Markowitz introduced the following criterion to assess the trade-off between risk and rewards in terms of variance and means.</p> <p>Definition</p> <p>Given a square integrable random variable \\( X \\)\u2014modeling some payoff such as a portfolio strategy, industrial projects, or any management decision\u2014the Markowitz mean/variance measure is defined as:</p> \\[ MV_{\\alpha}(X) = E[X] - \\frac{\\alpha}{2} \\text{VAR}(X) \\] <p>where:</p> \\[ \\text{VAR}(X) = E\\left[(X - E[X])^2\\right] \\] <p>is the variance of the random variable, and \\( \\alpha \\) is a positive number.</p> <p>For any value of \\( \\alpha \\), you can check that assessing previous games in terms of mean and variance will rank them, with the largest standard deviation corresponding to the worst game and the smallest standard deviation corresponding to the best game. </p> <p>The Markowitz mean-variance approach was a highly successful instrument for finding optimal portfolio strategies. It can also be used as a risk assessment measure. However, since we are more interested in the downside risks, we consider risk measures defined for the random variable \\( L = -X \\), where \\( X \\) represents returns.</p> <p>Definition</p> <p>The Markowitz risk measure is defined as:</p> \\[   RMV_{\\alpha}(L) = E[L] + \\frac{\\alpha}{2} \\text{VAR}(L) \\] <p>where \\( L \\) is a square integrable loss profile.</p> <p>Proposition</p> <p>The Markowitz risk measure satisfies the following properties:</p> <ol> <li> <p>Cash-invariance: For every loss profile \\( L \\) and \\( m \\in \\mathbb{R} \\),</p> \\[   RMV_{\\alpha}(L - m) = RMV_{\\alpha}(L) - m. \\] </li> <li> <p>Convexity: For any two loss profiles \\( L_1, L_2 \\) and \\( \\lambda \\in [0, 1] \\),</p> \\[   RMV_{\\alpha}(\\lambda L_1 + (1 - \\lambda)L_2) \\leq \\lambda RMV_{\\alpha}(L_1) + (1 - \\lambda)RMV_{\\alpha}(L_2) \\leq \\max \\left\\{ RMV_{\\alpha}(L_1), RMV_{\\alpha}(L_2)\\right\\}. \\] </li> <li> <p>Law Invariance: If two loss profiles \\( L_1 \\) and \\( L_2 \\) have the same CDF, then:</p> \\[   RMV_{\\alpha}(L_1) = RMV_{\\alpha}(L_2). \\] </li> </ol> Proof <ol> <li> <p>Cash-invariance: For every \\( m \\in \\mathbb{R} \\), and loss \\( L \\), it holds:</p> \\[   \\begin{align*}      RMV_{\\alpha}(L-m) &amp; = E[L-m] + \\frac{\\alpha}{2} E\\left[\\left(L-m-E[L-m]\\right)^2\\right]\\\\                        &amp; = E[L] + \\frac{\\alpha}{2} E\\left[\\left(L - E[L]\\right)^2\\right] - m = RMV_{\\alpha}(L) - m   \\end{align*} \\] </li> <li> <p>Convexity: Let \\( 0 \\leq \\lambda \\leq 1 \\) and \\( L_1 \\) and \\( L_2 \\) be two loss profiles. </p> <p>Since the function \\( x \\mapsto x^2 \\) is convex, it follows that:</p> \\[   \\begin{align*}      \\left(\\lambda L_1 + (1-\\lambda)L_2 - E[\\lambda L_1 + (1-\\lambda)L_2]\\right)^2        &amp;=\\left(\\lambda(L_1 - E[L_1]) + (1-\\lambda)(L_2 - E[L_2])\\right)^2\\\\       &amp;\\leq \\lambda \\left(L_1 - E[L_1]\\right)^2 + (1-\\lambda)\\left(L_2 - E[L_2]\\right)^2   \\end{align*} \\] <p>Taking expectation, it follows that:</p> \\[   \\text{VAR}(\\lambda L_1 + (1-\\lambda)L_2) \\leq \\lambda \\text{VAR}(L_1) + (1-\\lambda) \\text{VAR}(L_2) \\] <p>showing that:</p> \\[   \\begin{align*}      RMV_{\\alpha}(\\lambda L_1 + (1-\\lambda)L_2) &amp; = \\lambda E[L_1] + (1-\\lambda)E[L_2] + \\frac{\\alpha}{2} \\text{VAR}(\\lambda L_1 + (1-\\lambda)L_2)\\\\       &amp;\\leq \\lambda\\left(E[L_1] + \\frac{\\alpha}{2} \\text{VAR}(L_1)\\right) + (1-\\lambda)\\left(E[L_2] + \\frac{\\alpha}{2} \\text{VAR}(L_2)\\right)\\\\       &amp; = \\lambda RMV_{\\alpha}(L_1) + (1-\\lambda)RMV_{\\alpha}(L_2)\\\\       &amp; \\leq \\max \\left\\{ RMV_{\\alpha}(L_1), RMV_{\\alpha}(L_2) \\right\\}   \\end{align*} \\] </li> <li> <p>Law Invariance: For the last assertion, let \\( L_1 \\) and \\( L_2 \\) be such that \\( F_{L_1} = F_{L_2} \\).   It follows that:</p> \\[ \\begin{align*}    RMV_{\\alpha}(L_1) &amp; = \\int_{\\mathbb{R}} x dF_{L_1}(x) + \\frac{\\alpha}{2}\\int_{\\mathbb{R}} \\left[x - \\int_{\\mathbb{R}}x dF_{L_1}(x)\\right]^2 dF_{L_1}(x) \\\\       &amp; = \\int_{\\mathbb{R}} x dF_{L_2}(x) + \\frac{\\alpha}{2}\\int_{\\mathbb{R}} \\left[x - \\int_{\\mathbb{R}}x dF_{L_2}(x)\\right]^2 dF_{L_2}(x) \\\\       &amp; = RMV_{\\alpha}(L_2) \\end{align*} \\] </li> </ol>"},{"location":"lecture/02-risk-management/021-what-is-risk/#value-at-risk-vr","title":"Value at Risk (V@R)","text":"<p>The value at risk (V@R) is a widely used risk assessment measure introduced in the finance industry by JP Morgan around 1995. However as an instrument for measuring risk, it has been used for centuries in insurrance industry and turns out to be a very well known mathematical concept. It measures downside risk as follows:</p> <p>Definition</p> <p>Let \\( L \\) be a loss profile. The value at risk (\\( V@R_{\\alpha} \\)) with parameter \\( 0 &lt; \\alpha &lt; 1 \\) is defined as:</p> \\[   V@R_{\\alpha}(L) = \\inf\\{m \\in \\mathbb{R} : P[L &gt; m] \\leq \\alpha\\}. \\] <p>This can also be expressed as:</p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf\\{m \\in \\mathbb{R} : P[L &gt; m] \\leq \\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : 1-P[L\\leq m] \\leq \\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : F_L(m) \\geq 1-\\alpha\\}   \\end{align*} \\] <p>where \\( F_L(m):= P[L\\leq m] \\) is the cumulative distribution function (CDF) of \\( L \\).</p> <p> </p> <p>Note: Quantile Function</p> <p>Note that the CDF \\(F_L\\) is an increasing function from \\(0\\) to \\(1\\). Furthermore, it is right continuous meaning that \\(F_L(m_n)\\downarrow F_L(m)\\) for any sequence \\(m_n \\downarrow m\\). Indeed, let \\(A_n = \\{L \\leq m_n\\}\\) and \\(A =\\{L\\leq m\\}\\), it follows that \\(A_1\\supseteq A_2 \\ldots \\supseteq A_n \\supseteq \\ldots\\) with \\(\\cap A_n =A\\). As a consequence of the \\(\\sigma\\)-additivity of the probability measure, it follows that \\(P[A_n]\\downarrow P[A]\\).</p> <p>Now, if \\(F_L\\) is strictly increasing and continuous, it has an inverse \\(F_L^{-1}\\colon (0, 1)\\to \\mathbb{R}\\) which is also strictly increasing and continuous. Such an inverse is called the quantile of \\(L\\) and denoted by \\(q_L\\colon (0,1)\\to \\mathbb{R}\\). It follows that we can write the value at risk in terms of quantile:</p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf\\{m \\in \\mathbb{R} : F_L(m) \\geq 1-\\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : F^{-1}_L(F_L(m)) \\geq F^{-1}_L(1-\\alpha)\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : m \\geq F^{-1}_L(1-\\alpha)\\}\\\\                     &amp; = F^{-1}_L(1-\\alpha)   \\end{align*} \\] <p>In other terms, \\(V@R_{\\alpha}(L)=q_L(1-\\alpha)\\) is the \\(1-\\alpha\\) quantile of the distribution.</p> <p>In the case where \\(F_L\\) is not strictly increasing and continuous, we can still define the so called (left) pseudo-inverse or quantile as</p> <p>Definition: Quantile</p> <p>The quantile of the random variable \\(L\\) is defined as</p> \\[ \\begin{equation*}   \\begin{split}     q_L \\colon (0,1) &amp; \\longrightarrow \\mathbb{R}\\\\                 s &amp; \\longmapsto q_L(\\alpha) = \\inf\\left\\{ m \\in \\mathbb{R}\\colon P\\left[ L\\leq m \\right] \\geq s\\right\\}   \\end{split} \\end{equation*} \\] <p>The quantile is an increasing and left continuous function for which holds</p> \\[   F_L(q_L(s)-) \\leq s\\leq F_L(q_L(s))   \\] <p>The value at risk indicates the amount of cash or liquidity needed to reduce the loss size so that the probability of making losses exceeds \\( \\alpha \\) is small. Typical values for \\( \\alpha \\) are 5%, 1%, or 0.5%, depending on the horizon.</p> <p>Example</p> <p>Let \\( \\Omega = \\{\\omega_1, \\omega_2, \\omega_3, \\omega_4\\} \\) with probabilities \\( p = (0.7\\%, 3.3\\%, 46\\%, 50\\%) \\), and let \\( L \\) be a loss profile defined as:</p> \\[ L(\\omega) = \\begin{cases} 10,000 &amp; \\text{if } \\omega = \\omega_1, \\\\ -50    &amp; \\text{if } \\omega = \\omega_2, \\\\ -200   &amp; \\text{if } \\omega = \\omega_3, \\\\ -1,000 &amp; \\text{if } \\omega = \\omega_4. \\end{cases} \\] <p>The corresponding CDF \\( F_L(m) \\) is:</p> \\[ F_L(m) = \\begin{cases} 0       &amp; \\text{if } m &lt; -1,000, \\\\ 50\\%    &amp; \\text{if } -1,000 \\leq m &lt; -200, \\\\ 96\\%    &amp; \\text{if } -200 \\leq m &lt; -50, \\\\ 99.3\\%  &amp; \\text{if } -50 \\leq m &lt; 10,000, \\\\ 1       &amp; \\text{if } m \\geq 10,000. \\end{cases} \\] <p>From this, the quantile function is:</p> \\[ q_L(x) = \\begin{cases} -1,000 &amp; \\text{if } 0 &lt; x \\leq 50\\%, \\\\ -200   &amp; \\text{if } 50\\% &lt; x \\leq 96\\%, \\\\ -50    &amp; \\text{if } 96\\% &lt; x \\leq 99.3\\%, \\\\ 10,000 &amp; \\text{if } 99.3\\% &lt; x \\leq 1. \\end{cases} \\] <p>Thus: [ V@R_{5\\%} = q_L(95\\%) = -200, \\quad V@R_{1\\%} = q_L(99\\%) = -50, \\quad V@R_{0.5\\%} = q_L(99.5\\%) = 10,000. ]</p> <p>Note: Practical Computation of Value at Risk</p> <p>Unlike mean-variance risk measures, which involve computing expectations (analytical or via Monte Carlo methods, for instance), the computation of Value at Risk (VaR) is slightly more complex.  Even when a random variable has a probability density function, there is generally no analytical form for its quantile function. In cases where the cumulative distribution function (CDF) is strictly increasing and continuous, computing VaR requires inverting the function \\( m \\mapsto F_L(m) \\). This involves solving the equation:</p> \\[   F_L(m^\\ast) = s \\] <p>where \\( m^\\ast \\) is the quantile we are seeking. This is a classical root-finding problem.</p> <p>Most scientific libraries provide methods for root finding, such as Newton's method, the secant method, or more advanced mixed approaches like Brent's method.  It is important to note, however, that VaR often focuses on high quantiles (e.g., 0.99 or 0.999) of the CDF, which lie near the boundary of the inverse. This makes the problem particularly challenging, as the derivative of the CDF approaches zero near these limits, testing the bounds of numerical precision.  Fortunately, most scientific libraries with statistical functions provide predefined and highly optimized methods for quantile computation. </p> <p>Below, we illustrate this using Python, specifically with <code>scipy.optimize</code> and <code>scipy.stats</code>.</p> <p>Computation of value at risk<pre><code># import libraries\nimport numpy as np\nfrom scipy.stats import norm, t             # Normal and Student distribution\nfrom scipy.optimize import root, brentq     # root-&gt;newton method, brentq-&gt;bissecant flavor\nimport plotly.graph_objs as go              # professional but easy plotting\n\n# Straightforward quantile computation implementation\ndef quantile(cdf, s):\n  # definition of the root function(1) \n  def fun(m):\n    result = cdf(m) - s\n    return result\n\n  # return the root(2)\n  result = root(fun, 0)\n  return result.x[0]\n\n# Define two random variables\nX = norm()      # standard normal\nY = t(df = 2)   # student with 2 as degree of freedom\n\n# plot the cdf of both\n\nx = np.linespace(-4, 4, 100)\ny1 = X.cdf(x)\ny2 = Y.cdf(x)\n\nfig = go.Figure()\nfig.add_scatter(x=x, y=y1, name=\"normal distribution\")\nfig.add_scatter(x=x, y=y2, name=\"student distribution\")\nfig.update_layout(title = 'CDF of normal and student')\nfig.show()\n\n# compute the var 0.01 and 0.01 for each\n\nprint(f\"\"\"\n1% V@R for Normal:\\t{quantile(X.cdf, 0.99)}\n0.01% V@R for Normal:\\t{quantile(X.cdf, 0.999)}\n1% V@R for Student:\\t{quantile(Y.cdf, 0.99)}\n0.01% V@R for Student:\\t{quantile(Y.cdf, 0.999)}\n\"\"\")\n\n\n# using the pre programmed `ppf` functions\nprint(f\"\"\"\n1% V@R for Normal:\\t{X.ppf(0.99)}\n0.01% V@R for Normal:\\t{X.ppf(0.999)}\n1% V@R for Student:\\t{Y.ppf(0.99)}\n0.01% V@R for Student:\\t{Y.ppf(0.999)}\n\"\"\")\n\n# You can compare the speed between your implementation and the pre programmed using %timeit\n</code></pre></p> <ol> <li>Find <code>m</code> such that <code>F(m) = s</code> is equivalent to finding <code>m</code> such that <code>F(m) - s = 0</code> which is the usual implementation.</li> <li>We use here the Newton variant of root optimization problem. It only requires a start point and is usually fast.      However it might not converge if the derivative is quite close to <code>0</code> so it might not always be adequate.     Using <code>brentq</code>, as a bissecant type, requires to provide two bounds <code>a&lt;b</code> within which that root shall be found. In particular it should hold that <code>fun(a)</code> has a different sign as <code>fun(b)</code>.     Both have advantages and inconvenience.</li> </ol> <p>As for mean-variance, value at risk also fulfills some properties</p> <p>Proposition</p> <p>The Value at Risk V@R satisfies the following properties:</p> <ol> <li> <p>Cash-invariance: For every loss profile \\( L \\) and \\( m \\in \\mathbb{R} \\),</p> \\[   V@R_{\\alpha}(L - m) = V@R_{\\alpha}(L) - m. \\] </li> <li> <p>Monotonicity: For any two loss profiles \\( L_1, L_2 \\) with \\(L_1(\\omega) \\leq L_2(\\omega)\\) it holds,</p> \\[   V@R_{\\alpha}(L_1) \\leq V@R_{\\alpha}(L_2). \\] </li> <li> <p>Law Invariance: If two loss profiles \\( L_1 \\) and \\( L_2 \\) have the same CDF, then:</p> \\[   V@R_{\\alpha}(L_1) = V@R_{\\alpha}(L_2). \\] </li> </ol> Proof <ol> <li> <p>Cash-invariance: For every \\( m \\in \\mathbb{R} \\), and loss \\( L \\), it holds with variable change \\(\\hat{m} = \\tilde{m} - m\\):</p> \\[   \\begin{align*}      V@R_{\\alpha}(L-m) &amp; = \\inf\\left\\{ \\tilde{m} \\in \\mathbb{R} \\colon P[L-m&gt;\\tilde{m}] \\leq \\alpha \\right\\}\\\\                     &amp; = \\inf \\left\\{ \\hat{m} - m \\colon P[L&gt;\\hat{m}] \\leq \\alpha  \\right\\}\\\\                     &amp; = \\inf \\left\\{ \\hat{m} \\colon P[L&gt;\\hat{m}] \\leq \\alpha  \\right\\} - m = V@R_{\\alpha}(L) - m   \\end{align*} \\] </li> <li> <p>Monotonicity: Let \\( L_1 \\leq L_2 \\) be two loss profiles.</p> <p>For any \\(m\\), it holds</p> \\[     \\left\\{ \\omega \\colon L_1(\\omega)\\leq m \\right\\} \\supseteq \\left\\{ \\omega \\colon L_2(\\omega)\\leq m \\right\\} \\] <p>showing that for every \\(m\\) we have \\(P[L_1\\leq m] \\geq P[L_2 \\leq m]\\). Hence, we have</p> \\[     \\left\\{ m \\in \\mathbb{R} \\colon P\\left[ L_1\\leq m \\right]\\geq 1-\\alpha \\right\\} \\subseteq  \\left\\{ m \\in \\mathbb{R} \\colon P\\left[ L_2\\leq m \\right]\\geq 1-\\alpha \\right\\} \\] <p>showing that the infimum of the the left handside is smaller than the infimum of the right hand side, that is \\(V@R_{\\alpha}(L_1)\\leq V@R_{\\alpha}(L_2)\\). </p> </li> <li> <p>Law Invariance: This follows immediately since the value at risk depends only on the CDF.</p> </li> </ol>"},{"location":"lecture/02-risk-management/021-what-is-risk/#sound-properties","title":"Sound Properties?","text":"<p>Both risk assessments make sense and have a certain appeal. Let us discuss some of the properties they fulfill:</p> <ul> <li> <p>Cash Invariance: Given a risk assessment instrument \\( L \\mapsto R(L) \\), being cash invariant means that \\( R(L - m) = R(L) - m \\).     This property is appreciated by economists and regulators as it confers a clear monetary interpretation to risk assessment.     Regulators typically require financial institutions to maintain their total risk below zero.     For a financial institution with a loss exposure \\( L \\), the question is how much liquidity (or cash) must be held to reduce the overall risk to below zero.     With cash \\( m \\) and risky exposure \\( L \\), the resulting loss profile is \\( L - m \\), with a risk equal to \\( R(L - m) \\).     A risk assessment below zero implies that \\( m \\geq R(L) \\). In other words, the minimal cash requirement to make the risky exposure acceptable is \\( m = R(L) \\).</p> </li> <li> <p>Law Invariance: Law invariance is important because, even though we work with random variables, in practice we observe only their realizations and approximate their CDF.     Hence, a risk assessment instrument should depend solely on the CDF of the loss profile.</p> </li> <li> <p>Monotonicity: Monotonicity means that if the loss profile of one position is always greater than another, i.e., it results in higher losses in all scenarios, then its risk should also be higher.</p> </li> <li> <p>Diversification (Convexity): Diversification implies that combining two risky assets (a convex combination) should result in a risk lower than the worst of the two individual risks.</p> </li> </ul> Property \\( MVR_{\\alpha} \\) \\( V@R_{\\alpha} \\) Cash Invariance Law Invariance Monotonicity Diversification <p>Warning: Value at Risk might lead to Concentration</p> <p>Value at Risk (VaR) can, in some cases, counteract diversification. The primary reason is that the quantile is just a single point on the CDF of the loss distribution and does not account for the full risk in the tail. The following example illustrates this concentration issue:</p> <p>In the first scenario, you lend \\( 1000 \\) RMB to a friend, expecting repayment in one year with \\( 4\\% \\) interest. - If the friend repays the loan, you gain \\( 40 \\) RMB. - If the friend defaults, you lose \\( 1000 \\) RMB. - Assume the probability of default is \\( 4\\% \\).  </p> <p>The loss profile can be represented as:  </p> \\[     L =      \\begin{cases}         -40 &amp; \\text{with probability } 96\\% \\\\         1000 &amp; \\text{with probability } 4\\%     \\end{cases} \\] <p>This results in the following CDF and quantile function:  </p> \\[     \\begin{align*}         F_L(m) &amp; = \\begin{cases}             0 &amp; \\text{for } m &lt; -40 \\\\             96\\% &amp; \\text{for } -40 \\leq m &lt; 1000 \\\\             100\\% &amp; \\text{for } m \\geq 1000         \\end{cases} \\\\         q_L(s) &amp; = \\begin{cases}             -40 &amp; \\text{for } 0 &lt; s \\leq 96\\% \\\\             1000 &amp; \\text{for } s &gt; 96\\%         \\end{cases}     \\end{align*} \\] <p>The Value at Risk at the \\( 5\\% \\) level is:  </p> \\[     V@R_{5\\%}(L) = q_L(95\\%) = -40 \\] <p>Now, consider diversifying your exposure by lending \\( 500 \\) RMB to two independent friends:  </p> \\[     L =      \\begin{cases}         -40 &amp; \\text{with probability } 92.16\\% \\\\         480 &amp; \\text{with probability } 7.68\\% \\\\         1000 &amp; \\text{with probability } 0.16\\%     \\end{cases} \\] <p>This diversification reduces the probability of large losses to \\( 0.16\\% \\), but introduces a medium loss of \\( 480 \\) RMB with a \\( 7.68\\% \\) probability.  </p> <p>The CDF and quantile function for this case are:  </p> \\[     \\begin{align*}         F_L(m) &amp; = \\begin{cases}             0 &amp; \\text{for } m &lt; -40 \\\\             92.16\\% &amp; \\text{for } -40 \\leq m &lt; 480 \\\\             99.84\\% &amp; \\text{for } 480 \\leq m &lt; 1000 \\\\             100\\% &amp; \\text{for } m \\geq 1000         \\end{cases} \\\\         q_L(s) &amp; = \\begin{cases}             -40 &amp; \\text{for } 0 &lt; s \\leq 92.16\\% \\\\             480 &amp; \\text{for } 92.16\\% &lt; s \\leq 99.84\\% \\\\             1000 &amp; \\text{for } s &gt; 99.84\\%         \\end{cases}     \\end{align*} \\] <p>The Value at Risk at the \\( 5\\% \\) level is:  </p> \\[     V@R_{5\\%}(L) = q_L(95\\%) = 480 \\] <p>In this case, the Value at Risk increases from \\( -40 \\) to \\( 480 \\), contradicting the expectation that diversification reduces risk. The primary reason is that, in the non-diversified scenario, all potential losses are concentrated in the tail of the distribution beyond the chosen quantile. In other words, Value at Risk is blind to the magnitude of losses beyond the selected quantile level.</p> <p>Even though both instruments (mean-variance risk and Value at Risk) have intuitive appeal and practical applications, closer scrutiny reveals that each violates one or more fundamental properties expected of a robust risk measure.</p>"},{"location":"lecture/02-risk-management/022-risk-preferences/","title":"Risk Preferences and Measures","text":"<p>So far, we have introduced potential examples of risk measures and discussed their shortcomings regarding properties deemed sound for risk assessment. Additionally, the selection of these measures might appear arbitrary. In the following, we aim to formalize the concepts of risk and uncertainty.</p> <p>On the one hand, uncertainty refers to the possibility of multiple outcomes. In other words, it considers the set \\( \\Omega \\) within a probability space. This concept is inherently an objective matter, tied to the nature of the world.</p> <p>On the other hand, risk represents a subjective or personal perception of uncertainty. It depends on an individual's viewpoint and can be understood as a cautious response to uncertainty. To model this consistently within a mathematical framework, we rely on decision theory, which captures preferences among various choices. The set of possible choices is denoted by \\( \\mathcal{X} \\). In this context, uncertain outcomes are modeled as random variables, meaning we work with a vector space \\( \\mathcal{X} \\) of random variables (primarily bounded for mathematical convenience).</p> <p>Definition: Preference Order and Numerical Representation</p> <p>A preference order \\( \\preccurlyeq \\) on \\( \\mathcal{X} \\) is a binary relation \\( x \\preccurlyeq y \\) indicating that choice \\( y \\) is preferred to choice \\( x \\). We assume this relation satisfies the following normative properties:</p> <ul> <li>Transitivity: \\( x \\preccurlyeq y \\) and \\( y \\preccurlyeq z \\) imply \\( x \\preccurlyeq z \\);</li> <li>Completeness: For any two possible choices \\( x \\) and \\( y \\), either \\( x \\preccurlyeq y \\) or \\( y \\preccurlyeq x \\).</li> </ul> <p>A function \\( U\\colon \\mathcal{X} \\to \\mathbb{R} \\) is called a numerical representation (or utility) of a preference order \\( \\preccurlyeq \\) if:</p> \\[     x \\preccurlyeq y \\quad \\text{if and only if} \\quad U(x) \\leq U(y) \\] <p>Preference orders are a generic way to represent subjective views on outcomes. The first property, transitivity, ensures consistency: if \\( y \\) is preferred to \\( x \\), and \\( z \\) is preferred to \\( y \\), then \\( z \\) must also be preferred to \\( x \\). This property appears quite intuitive. The second property, completeness, requires that, for any two elements, one must always express a preference between them. This is a strong assumption, as it mandates the ability to decide between any two elements in a potentially infinite set \\( \\mathcal{X} \\).  </p> <p>These two rational (or normative, as decision theorists would say) assumptions often fail in empirical decision-making. However, they are intended to model fully rational behavior in decision-making processes involving prospective outcomes.  </p> <p>A numerical representation maps the preference ranking into \\( \\mathbb{R} \\), providing a quantitative measure of preferences.</p> Note <p>Note first that if we have a numerical representation \\( U \\) for a preference order \\( \\preccurlyeq \\), it is not unique. Any strictly increasing function \\( \\phi \\colon \\mathbb{R} \\to \\mathbb{R} \\) defines another numerical representation \\( \\tilde{U} = \\phi \\circ U \\). Indeed, \\( x \\preccurlyeq y \\) is equivalent to \\( U(x) \\leq U(y) \\), which is equivalent to \\( \\phi(U(x)) = \\tilde{U}(x) \\leq \\tilde{U}(y) = \\phi(U(y)) \\).</p> <p>Second, starting directly with a function \\( U \\colon \\mathcal{X} \\to \\mathbb{R} \\), it defines a preference order \\( \\preccurlyeq \\) by:</p> \\[     x \\preccurlyeq y \\Leftrightarrow U(x) \\leq U(y) \\] <p>As an exercise, show that \\( \\preccurlyeq \\), so defined through a function \\( U \\), is a preference order, satisfying transitivity and completeness.</p> <p>Third, even if a numerical function defines a preference order, the reciprocal is not necessarily true. Additional assumptions are required to ensure that, for a given preference order, a numerical representation \\( U \\) exists. However, under reasonable assumptions, this is often the case.</p> <p>Proposition</p> <p>If the set \\( \\mathcal{X} \\) is countable (1), then any preference order \\( \\preccurlyeq \\) on \\( \\mathcal{X} \\) admits a numerical representation.</p> <ol> <li>Meaning that \\( \\mathcal{X} \\) can be enumerated as a subset of \\( \\mathbb{N} \\).</li> </ol> <p>Proof</p> <p>Without loss of generality, assume \\( \\mathcal{X} = \\{x_1, x_2, \\ldots\\} \\). On \\( \\mathbb{N} \\), define a probability measure \\( P[\\{n\\}] = p_n = 1 / 2^n \\), since \\( \\sum p_n = 1 \\). For each \\( x_n \\), define \\( A_n = \\{k \\colon x_k \\preccurlyeq x_n\\} \\), the set of indices \\( k \\) for elements in \\( \\mathcal{X} \\) that are less preferred than \\( x_n \\). By definition, \\( x_n \\preccurlyeq x_m \\) if and only if \\( A_n \\subseteq A_m \\). The function:</p> \\[     \\begin{equation*}         \\begin{split}             U \\colon \\mathcal{X} &amp;\\longrightarrow \\mathbb{R}\\\\                 x_n &amp; \\longmapsto U(x_n) = P[A_n] = \\sum_{\\{k \\colon x_k \\preccurlyeq x_n\\}} p_k         \\end{split}     \\end{equation*} \\] <p>defines a numerical representation of \\( \\preccurlyeq \\). Indeed, \\( x_n \\preccurlyeq x_m \\) if and only if \\( A_n \\subseteq A_m \\). Since \\( P \\) assigns a unique probability to each element of \\( \\mathbb{N} \\), it follows that \\( A_n \\subseteq A_m \\) if and only if \\( U(x_n) = P[A_n] \\leq P[A_m] = U(x_m) \\). This completes the proof.</p> <p>This proposition uses probability measures to define a numerical representation. The argument extends to more general sets, provided you can relate sublevel sets \\( \\{\\tilde{x} \\colon \\tilde{x} \\preccurlyeq x\\} \\) using topological arguments like smoothness. If such smoothness is absent, preference orders may exist without a numerical representation.</p> <p>The Lexicographical Order Does Not Admit a Numerical Representation</p> <p>Consider \\( \\mathcal{X} = [0, 1] \\times [0, 1] \\) and define the lexicographical order as:</p> \\[     x = (x_1, x_2) \\preccurlyeq y = (y_1, y_2) \\quad \\text{if and only if} \\quad      \\begin{cases}       \\text{either } &amp; x_1 &lt; y_1, \\\\       \\text{or } &amp; x_1 = y_1 \\text{ and } x_2 \\leq y_2.     \\end{cases} \\] <p>This is a preference order (similar to library book ordering). However, since \\( \\mathcal{X} \\) is uncountable and the preference order lacks smoothness, it can be shown that no numerical representation exists. Try this as an exercise: assume a numerical representation exists and derive a contradiction.</p> <p>Decision theory typically frames preferences and utilities (where higher values are better). However, when discussing risk, we consider possible loss profiles \\( \\mathcal{L} \\)\u2014random variables representing losses. For simplicity, we consider complete binary relations \\( \\preccurlyeq \\), where \\( L_1 \\preccurlyeq L_2 \\) means \"\\( L_1 \\) is less risky than \\( L_2 \\).\" Thus, loss profiles are ranked by \\( \\preccurlyeq \\) based on perceived risk. However, the basic properties of a preference order \\( \\preccurlyeq \\) on \\( \\mathcal{L} \\) do not inherently convey insights about risk perception.</p> <p>Definition: Risk Order and Risk Measures</p> <p>A preference order \\( \\succcurlyeq \\) on \\( \\mathcal{L} \\) is called a risk order if the following two additional assumptions are satisfied:</p> <ul> <li> <p>Diversification: If \\( L_1 \\) is more risky than \\( L_2 \\), then any diversified position between the two is less risky than the worse one:</p> \\[     \\text{if } L_1 \\succcurlyeq L_2, \\quad \\text{then}\\quad L_1 \\succcurlyeq \\lambda L_1 + (1-\\lambda) L_2, \\quad \\text{for every } 0 \\leq \\lambda \\leq 1. \\] </li> <li> <p>Monotonicity (worse for sure is more risky): If the losses of \\( L_1 \\) are worse than those of \\( L_2 \\) in every state of the world, then \\( L_1 \\) is more risky than \\( L_2 \\):</p> \\[     \\text{if } L_1(\\omega) \\geq L_2(\\omega) \\text{ for every } \\omega, \\quad \\text{then } L_1 \\succcurlyeq L_2. \\] </li> </ul> <p>A numerical representation \\( R \\colon \\mathcal{L} \\to \\mathbb{R} \\) of a risk order is called a risk measure.</p> <p>These two additional properties express reasonable and intuitive features of risk perception. They also have implications for the properties of risk measures.</p> <p>Proposition</p> <p>Let \\( R \\) be a numerical representation of a preference order \\( \\succcurlyeq \\) on \\( \\mathcal{L} \\). Then the following assertions are equivalent:</p> <ul> <li>\\( \\succcurlyeq \\) is a risk order;</li> <li>\\( R \\) satisfies:<ul> <li>Quasi-convexity: \\( \\max\\{R(L_1), R(L_2)\\} \\geq R(\\lambda L_1 + (1-\\lambda) L_2) \\) for every \\( 0 \\leq \\lambda \\leq 1 \\);</li> <li>Monotonicity: If \\( L_1(\\omega) \\geq L_2(\\omega) \\) for every \\( \\omega \\), then \\( R(L_1) \\geq R(L_2) \\).</li> </ul> </li> </ul> Proof <p>Let \\( L_1 \\) and \\( L_2 \\) be two loss profiles. Assume that \\( \\succcurlyeq \\) is a risk order.  </p> <p>For quasi-convexity, due to the completeness of the relation, assume without loss of generality that \\( L_1 \\succcurlyeq L_2 \\), which is equivalent to \\( R(L_1) = \\max\\{R(L_1), R(L_2)\\} \\). For any \\( 0 \\leq \\lambda \\leq 1 \\), the diversification property implies \\( L_1 \\succcurlyeq \\lambda L_1 + (1-\\lambda) L_2 \\), which gives:</p> \\[     \\max\\{R(L_1), R(L_2)\\} = R(L_1) \\geq R(\\lambda L_1 + (1-\\lambda) L_2), \\] <p>showing quasi-convexity of \\( R \\).</p> <p>For monotonicity, assume \\( L_1(\\omega) \\geq L_2(\\omega) \\) for every \\( \\omega \\). By the monotonicity assumption, \\( L_1 \\succcurlyeq L_2 \\), which implies \\( R(L_1) \\geq R(L_2) \\).  </p> <p>The reverse implication\u2014that a numerical representation being quasi-convex and monotone implies \\( \\succcurlyeq \\) is a risk order\u2014is straightforward to verify.</p> <p>This proposition shows that neither the mean-variance risk measure nor the Value at Risk represents a risk order. Additional properties may be required of a risk measure, but they might not always align with the underlying risk order.</p> <p>Definition</p> <p>A risk measure \\( R \\) is called:</p> <ul> <li>Cash-Invariant: if \\( R(L-m) = R(L) - m \\) for every \\( m \\in \\mathbb{R} \\);</li> <li>Positive-Homogeneous: if \\( R(\\lambda L) = \\lambda R(L) \\) for every \\( \\lambda &gt; 0 \\);</li> <li>Law-Invariant: if \\( R(L) = R(\\tilde{L}) \\) whenever the CDFs of \\( L \\) and \\( \\tilde{L} \\) coincide.</li> </ul> <p>Aside from law invariance, the other two properties do not hold if the risk measure is transformed by a strictly increasing function. Nevertheless, they are commonly used and practical.</p> <p>Cash-Invariance</p> <p>Cash-invariance is typically required from regulatory or financial perspectives. For instance, consider a financial institution with a risky position \\( X \\). The question is how much liquidity \\( m \\) is needed in the bank account to ensure the overall position (cash plus risky assets) has acceptable risk. The threshold is that the total risk must be below zero. The total loss profile is \\( L - m \\), where \\( L = -X \\). By cash-invariance:</p> \\[     0 \\geq R(L - m) = R(L) - m \\implies m \\geq R(L). \\] <p>Thus, the minimal liquidity required to make the risky position acceptable is \\( m = R(L) \\). This interpretation ties the risk measure to capital requirements.</p> <p>Moreover, cash-invariance, combined with quasi-convexity, implies convexity.</p> <p>Lemma</p> <p>If \\( R \\) is a cash-invariant risk measure, then \\( R \\) is convex.</p> Proof <p>Let \\( R \\) be a cash-invariant risk measure, \\( 0 \\leq \\lambda \\leq 1 \\), and \\( L_1, L_2 \\) be loss profiles. To prove \\( R(\\lambda L_1 + (1-\\lambda) L_2) \\leq \\lambda R(L_1) + (1-\\lambda) R(L_2) \\), define \\( m_1 = R(L_1) \\) and \\( m_2 = R(L_2) \\). By cash-invariance and quasi-convexity:</p> \\[     \\begin{align*}         R(\\lambda L_1 + (1-\\lambda) L_2) - \\lambda m_1 - (1-\\lambda)m_2 &amp; = R\\left( \\lambda L_1 + (1-\\lambda) L_2 - \\lambda m_1 - (1-\\lambda)m_2 \\right) \\\\         &amp; = R\\left( \\lambda (L_1 - m_1) + (1-\\lambda)(L_2 - m_2) \\right) \\\\         &amp; \\leq \\max\\{R(L_1 - m_1), R(L_2 - m_2)\\} \\\\         &amp; = \\max\\{0, 0\\} = 0.     \\end{align*} \\] <p>Positive Homogeneity</p> <p>Positive homogeneity has a financial interpretation: if \\( L \\) represents the loss exposure of an investment with risk \\( R(L) \\), scaling the investment by \\( \\lambda &gt; 0 \\) scales the corresponding risk by \\( \\lambda \\). While desirable for mathematical reasons, super-linear scaling might be expected in some contexts. Positive homogeneity also implies sub-additivity, ensuring that risk is not exacerbated by combining positions.</p> <p>Lemma</p> <p>Let \\( R \\) be a cash-invariant risk measure. If \\( R \\) is positive homogeneous, then:</p> \\[     R(L_1 + L_2) \\leq R(L_1) + R(L_2). \\] Proof <p>Let \\( R \\) be a cash-invariant and positive-homogeneous risk measure. By convexity:</p> \\[     \\begin{align*}         R(L_1 + L_2) &amp; = R\\left( 2 \\cdot \\frac{1}{2}(L_1 + L_2) \\right) \\\\         &amp; = 2 R\\left(\\frac{1}{2}L_1 + \\frac{1}{2}L_2 \\right) \\quad \\text{(Positive Homogeneity)} \\\\         &amp; \\leq 2 \\left( \\frac{1}{2}R(L_1) + \\frac{1}{2}R(L_2) \\right) \\quad \\text{(Convexity)} \\\\         &amp; = R(L_1) + R(L_2).     \\end{align*} \\]"},{"location":"lecture/02-risk-management/023-oce/","title":"Expected Shortfall","text":"<p>We have thus far explored the fundamentals of risk assessment, focusing on the key principles it must satisfy to achieve sound quantification: monotonicity, diversification, and, for financial purposes, cash-invariance. This foundation has enabled us to highlight the fundamental flaws of mean-variance analysis and value at risk (VaR) in meeting these criteria. However, from a practical standpoint, we are still far from identifying a fully satisfactory approach.</p> <p>When considering a risk quantification instrument \\( R \\), the following points are crucial:</p> <ol> <li>Soundness: The instrument \\( R \\) must satisfy the properties of diversification and monotonicity to ensure robust risk quantification.</li> <li>Understandability: \\( R \\) should be intuitively comprehensible from a financial perspective, even for individuals not deeply versed in the intricacies of mathematics. Ultimately, you need to convince your boss, the regulator, and the public that the methodology you employ is sensible and reliable.</li> <li>Implementability: The computation of \\( R \\) must be feasible. At the end of the day, you need to produce a quantifiable result. This means it should be possible to create a programmatic function, based on available data, to compute the value of your risk measure (prototyping).</li> <li>Efficiency and Robustness: The implementation of \\( R \\) should meet industry standards\u2014being fast, reliable, and free of bugs. Risk computations are not a one-time experiment; they need to be conducted daily. Large financial institutions, by regulatory requirement, must aggregate and assess vast and complex positions to provide timely results on a daily basis.</li> </ol> <p>As for now, our focus has been primarily on the first point\u2014establishing the groundwork for soundness. However, the other points are equally vital in practice. Since the 2008 financial crisis, the shortcomings of value at risk (VaR) have been widely acknowledged. While these shortcomings (particularly related to soundness) were long known to academics, addressing the other points took time before a new industry standard could emerge. This standard is the expected shortfall (also known under equivalent terms such as average value at risk or conditional value at risk).</p>"},{"location":"lecture/02-risk-management/023-oce/#expected-shortfall_1","title":"Expected Shortfall","text":"<p>As the main issue of value at risk being the fact that it only provides information at one point of the CDF and being blind beyond it, the idea is to consider the tail beyond value at risk</p> <p>Definition: Expected Shortfall</p> <p>The expected shortfall of a random variable (integrable) at level \\(\\alpha\\) is defined as</p> \\[     ES_{\\alpha}(L) = \\frac{1}{\\alpha}\\int_0^\\alpha V@R_{s}(L) ds = \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 q_L(s) ds \\] <p>Note</p> <p>The Expected Shortfall (ES) was introduced by Artzner, Delbaen, Eber, and Heath in 1999 to address the shortcomings of Value at Risk (V@R). Expected Shortfall is known by several other names (with equivalent definitions, modulo some subtleties), including:  </p> <ul> <li>Average Value at Risk (AV@R),  </li> <li>Conditional Value at Risk (CV@R),  </li> <li>Expected Tail Loss (ETL), and  </li> <li>Superquantile.</li> </ul> <p> </p> <p>As shown in the figure, the expected shortfall (ES) addresses the shortcomings of value at risk (V@R) by considering the loss area beyond V@R. Specifically, if two loss distributions, \\( \\tilde{L} \\) and \\( L \\), share the same V@R but \\( \\tilde{L} \\) exhibits larger losses beyond the V@R (i.e., has fatter tails than \\( L \\)), then\u2014even with identical V@R values\u2014the expected shortfall (the area beyond V@R) of \\( \\tilde{L} \\) will exceed that of \\( L \\).</p> <p>This observation addresses the second point on our wish list, as ES naturally rectifies V@R's limitations regarding tail risk. However, it does not resolve the first issue on our list. Specifically, while it is clear that V@R fails to satisfy diversification, it remains puzzling why ES should satisfy this property. The desirable properties of V@R\u2014monotonicity, law invariance, cash-invariance, and positive homogeneity\u2014extend to ES through its integral formulation. However, since V@R is not convex, it is unclear why ES should exhibit convexity based on this representation.</p> <p>Furthermore, while this formulation satisfies the third point (as ES is computed as an integral of a quantifiable object), doubts remain about its efficiency. Calculating the integral of the quantile involves evaluating numerous quantiles between \\( 1-\\alpha \\) and \\( 1 \\), which is computationally intensive and prone to error. This challenge is especially pronounced for extreme quantiles (e.g., \\( 99.999\\% \\) or \\( 99.99999\\% \\)), where sampling the distribution in highly unlikely regions becomes unstable.</p> <p>To address these issues, we now explore another class of risk assessment instruments introduced by operations research scientists Ben-Tal and Teboulle: the optimized certainty equivalent.</p>"},{"location":"lecture/02-risk-management/023-oce/#optimized-certainty-equivalent","title":"Optimized Certainty Equivalent","text":"<p>At the core of the definition of the optimized certainty equivalent is a special penalization function called loss function.</p> <ul> <li> <p>Definition: Loss Function</p> <p>A function \\(\\ell \\colon \\mathbb{R} \\to \\mathbb{R}\\) is called a loss function if</p> <ul> <li>\\(\\ell\\) is convex</li> <li>\\(\\ell\\) is increasing    </li> <li> <p>\\(\\ell(0) = 0\\) and \\(\\ell^\\prime(0) = 1\\)(1)</p> <ol> <li>Note that \\(\\ell\\) does not necessarily need to be differentiable such as \\(\\ell(x) = x^+/\\alpha\\) for \\(0&lt; \\alpha &lt;1\\). It just needs to have \\(\\ell^{\\prime}_-(0) \\leq 1 \\leq \\ell^\\prime_+(0)\\) where \\(\\ell_-^\\prime\\) and \\(\\ell^\\prime_+\\) are the left and right derivative that always exists for convex functions.</li> </ol> </li> <li> <p>\\(\\lim_{x \\to \\infty}\\ell(x)/x &gt;1\\) and \\(\\lim_{x \\to -\\infty} \\ell(x)/x &lt;1\\).</p> </li> </ul> <p>Classical examples following this definition</p> <ul> <li>piecewise linear: \\(\\ell(x)= x^+/ \\alpha\\) with \\(0&lt; \\alpha &lt;1\\);</li> <li>quadratic: \\(\\ell(x)=x^++(x^+)^2/2\\);</li> <li>exponential: \\(\\ell(x)=e^x-1\\)</li> </ul> </li> </ul> <p> </p> <p>The loss function penalizes a loss (losses are considered positive in our case) \\( x \\geq 0 \\) by assigning a value \\( \\ell(x) \\geq x \\). For gains (negative values), it also penalizes by assigning an amount smaller than the gain itself.</p> <p>Thus, given a loss profile \\( L \\), you compute \\( E[\\ell(L)] \\geq E[L] \\), which represents the penalized loss estimation of the loss profile. The idea introduced by Ben-Tal and Teboulle is to reduce the value of these penalized losses by allocating some cash \\( m \\), transitioning from \\( E[\\ell(L)] \\) to \\( E[\\ell(L-m)] \\). However, in terms of total costs, you must account for the cash allocated, leading to the total cost valuation:</p> \\[ m + E[\\ell(L-m)]. \\] <p>With the decision variable being the amount of cash allocated, minimizing the total cost gives rise to the definition of the optimized certainty equivalent.</p> <p>Definition: Optimized Certainty Equivalent</p> <p>Given a loss function \\( \\ell \\), the optimized certainty equivalent \\( R \\) of a bounded random variable (under appropriate integrability conditions) is defined as:</p> \\[   R(L) = \\inf \\left\\{ m + E\\left[ \\ell(L - m) \\right] \\colon m \\in \\mathbb{R} \\right\\}. \\] <p>Proposition</p> <p>Given a loss function \\( \\ell \\), the optimized certainty equivalent \\( R \\) is a cash-invariant and law-invariant risk measure.</p> <p>Furthermore, it holds that:</p> \\[   R(L) = m^\\ast + E\\left[ \\ell(L - m^\\ast) \\right], \\] <p>where: (1)</p> <ol> <li> <p>If \\( \\ell \\) is not differentiable at \\( 0 \\), the condition changes to:</p> \\[ E[\\ell^\\prime_-(L-m^\\ast)] \\leq 1 \\leq E\\left[ \\ell^\\prime_+(L-m^\\ast) \\right], \\] </li> </ol> \\[     E[\\ell^\\prime(L - m^\\ast)] = 1. \\] Proof <p>We show that \\( R \\), as defined, is monotone, cash-invariant, and convex.</p> <ul> <li> <p>Monotonicity:      Suppose \\( L_1(\\omega) \\geq L_2(\\omega) \\) for all \\( \\omega \\).     Since \\( \\ell \\) is increasing:</p> \\[     m + \\ell\\left( L_1 - m \\right) \\geq m + \\ell\\left( L_2 - m \\right). \\] <p>Taking the expectation:</p> \\[     m + E\\left[\\ell\\left( L_1 - m \\right)\\right] \\geq m + E\\left[\\ell\\left( L_2 - m \\right)\\right]. \\] <p>Since \\( m + E[\\ell(L_2 - m)] \\geq R(L_2) \\), it follows that:</p> \\[     m + E\\left[\\ell\\left( L_1 - m \\right)\\right] \\geq R(L_2). \\] <p>Taking the infimum over \\( m \\) yields:</p> \\[     R(L_1) = \\inf\\left\\{ m + E\\left[\\ell\\left( L_1 - m \\right)\\right] \\colon m \\in \\mathbb{R} \\right\\} \\geq R(L_2). \\] </li> <li> <p>Cash-Invariance:     Let \\( m \\in \\mathbb{R} \\).     Then:</p> \\[     \\begin{align*}         R(L - m) &amp; = \\inf\\left\\{ \\tilde{m} + E\\left[\\ell\\left( L - m - \\tilde{m} \\right)\\right] \\colon \\tilde{m} \\in \\mathbb{R} \\right\\} \\\\             &amp; = \\inf\\left\\{ \\hat{m} - m + E\\left[\\ell\\left( L - \\hat{m} \\right)\\right] \\colon \\hat{m} \\in \\mathbb{R} \\right\\} \\quad \\text{(change of variable \\( \\hat{m} = m + \\tilde{m} \\))} \\\\             &amp; = R(L) - m.     \\end{align*} \\] </li> <li> <p>Convexity:   Let \\( L_1 \\) and \\( L_2 \\) be two loss profiles, and \\( 0 \\leq \\lambda \\leq 1 \\).     For \\( m_1, m_2 \\in \\mathbb{R} \\), define \\( m = \\lambda m_1 + (1-\\lambda)m_2 \\) and \\( L = \\lambda L_1 + (1-\\lambda)L_2 \\).     Since \\( \\ell \\) is convex:</p> \\[     m + \\ell(L - m) \\leq \\lambda\\left( m_1 + E\\left[ \\ell(L_1 - m_1) \\right] \\right) + (1-\\lambda)\\left( m_2 + E[\\ell(L_2 - m_2)] \\right). \\] <p>Since \\( R(L) \\leq m + E[\\ell(L - m)] \\), taking the infimum over \\( m_1 \\) and \\( m_2 \\) sequentially yields:</p> \\[     R(\\lambda L_1 + (1-\\lambda)L_2) = R(L) \\leq \\lambda R(L_1) + (1-\\lambda)R(L_2). \\] </li> <li> <p>Law-Invariance:   Law-invariance follows directly, as \\( R \\) depends only on the expectation \\( E[\\ell(\\cdot)] \\), which depends on the CDF of \\( L \\).</p> </li> </ul> <p>To show the final assertion: Define:</p> \\[     g(m) = m + E\\left[ \\ell(L - m) \\right], \\] <p>for which \\( R(L) = \\inf g(m) \\). Since \\( \\ell \\) is convex, \\( g \\) is also convex. It follows from \\(\\ell\\) being increasing and the asymptotic assumptions on \\(\\ell\\) that \\(\\ell(x) \\geq a_1 x -c_1\\) for \\(x\\) positively large enough with \\(a_1&gt;1\\) and \\(\\ell(x)\\geq a_2 x -c_2\\) for \\(x\\) negatively large enough and \\(a_2&lt;1\\). Since \\(L\\) is bounded, it follows that for \\(m\\) positively large enough (more than the bounds of \\(L\\) at least) we have</p> \\[     g(m) = m + E[\\ell(L-m)] \\geq m + a_2E\\left[ L -m \\right] - c_2 = \\underbrace{(1-a_2)}_{&gt;0} \\underbrace{m}_{&gt;0} + a_2 E[L] - c_2 \\xrightarrow[m \\to \\infty]{} \\infty \\] <p>The same argumentation for large enough negative values of \\(m\\) yields</p> \\[     g(m) = m + E[\\ell(L-m)] \\geq m + a_1E\\left[ L -m \\right] - c_1 = \\underbrace{(1-a_1)}_{&lt;0} \\underbrace{m}_{&lt;0} + a_1 E[L] - c_1 \\xrightarrow[m \\to -\\infty]{} \\infty \\] <p>All together, it shows that \\(g(m) \\to \\infty\\) for \\(m\\to \\pm \\infty\\), that is, in mathematical terms, \\(g\\) is coercive.</p> <p> </p> <p>This ensures that \\( g \\) attains its minimum at \\( m^\\ast \\), satisfying the first-order condition:</p> \\[     E\\left[ \\ell^\\prime_-(L-m^\\ast) \\right] \\leq 1 \\leq E\\left[ \\ell^\\prime_+(L-m^\\ast) \\right]. \\] <p>If \\( \\ell \\) is differentiable, this simplifies to:</p> \\[     E\\left[ \\ell^\\prime(L - m^\\ast) \\right] = 1. \\] <p>This completes the proof.</p> <p>This proposition provides several key takeaways:</p> <ol> <li>The optimized certainty equivalent (OCE) is a risk measure independent of the specific definition of \\( \\ell \\), as long as \\( \\ell \\) is a valid loss function.  </li> <li>By its definition and the convexity of the problem, the computation of OCE is straightforward, reducing to a one-dimensional unconstrained convex optimization problem. This allows for the application of efficient, state-of-the-art algorithms.  </li> <li>The simplicity of this optimization problem allows for circumventing classical gradient descent by providing an explicit expression for the first-order condition.</li> </ol> <p>The Exponential Function: Entropic Risk Measure</p> <p>Consider the loss function \\( \\ell(x) = (e^{\\gamma x} - 1)/\\gamma \\). By the first-order condition:</p> \\[   1 = E[\\ell^\\prime(L-m^\\ast)] = E[e^{\\gamma (L - m^\\ast)}] = e^{-\\gamma m^\\ast}E\\left[ e^{\\gamma L} \\right]. \\] <p>Solving for \\( m^\\ast \\):</p> \\[   m^\\ast = \\frac{\\ln\\left(E[e^{\\gamma L}]\\right)}{\\gamma}. \\] <p>Substituting \\( m^\\ast \\) back into \\( R \\) yields:</p> \\[   R(L) = \\frac{1}{\\gamma} \\ln \\left( E\\left[ e^{\\gamma L} \\right] \\right). \\] <p>Hence, for the exponential loss function, the OCE can be computed explicitly, and the resulting risk measure is known as the entropic risk measure.  </p> <p>While this measure is prevalent in other domains (e.g., statistical mechanics, physics, and machine learning) and is computationally efficient, it is unsuitable as a financial risk measure. The exponential penalization assigns extremely high values to large losses, making it impractical for scenarios with rare but severe losses.  </p> <p>For example, consider the loss profile:</p> \\[   \\begin{cases}       1,000,000,000 &amp; \\text{with probability } 0.00001, \\\\       -10,000 &amp; \\text{otherwise}.   \\end{cases} \\] <p>Despite the low probability of the extreme loss, the exponential penalization makes the risk computation infeasible due to numerical instability and even with exact values, the resulting risk would be stratospherical.</p> <p>The Piecewise Linear Function</p> <p>The exponential function example demonstrates how a strong penalization can lead to explicit representations but may not be practical for financial risk measures. Let us now consider the opposite extreme: a function that penalizes less, specifically a piecewise linear loss function:</p> \\[     \\ell(x) = \\frac{1}{\\alpha}x^+, \\] <p>where \\( 0 &lt; \\alpha &lt; 1 \\).  </p> <p>Since \\( \\ell \\) is not differentiable, the characterization uses the left and right derivatives:</p> \\[   \\ell_-^\\prime(x) = \\frac{1}{\\alpha} 1_{(0, \\infty)}(x) =        \\begin{cases}         \\frac{1}{\\alpha} &amp; x &gt; 0, \\\\         0 &amp; \\text{otherwise}.       \\end{cases}   \\quad \\text{and} \\quad   \\ell_+^\\prime(x) = \\frac{1}{\\alpha} 1_{[0, \\infty)}(x) =        \\begin{cases}         \\frac{1}{\\alpha} &amp; x \\geq 0, \\\\         0 &amp; \\text{otherwise}.       \\end{cases} \\] <p>Applying the first-order condition:</p> \\[   E[\\ell^\\prime_-(L-m^\\ast)] \\leq 1 \\leq E[\\ell^\\prime_+(L-m^\\ast)]. \\] <p>Substituting the derivatives:</p> \\[   \\frac{1}{\\alpha}P[L &gt; m^\\ast] \\leq 1 \\leq \\frac{1}{\\alpha}P[L \\geq m^\\ast]. \\] <p>This simplifies to:</p> \\[   P[L &lt; m^\\ast] \\leq 1-\\alpha \\leq P[L \\leq m^\\ast]. \\] <p>Thus, \\( m^\\ast \\) is the \\( 1-\\alpha \\) quantile of \\( L \\):</p> \\[   m^\\ast = q_L(1-\\alpha) = V@R_{\\alpha}(L). \\] <p>Therefore, for the piecewise linear loss function:</p> \\[     R(L) = \\inf\\left\\{ m + \\frac{1}{\\alpha}E\\left[ (L-m)^+ \\right] \\right\\} = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E\\left[ (L-V@R_{\\alpha}(L))^+ \\right]. \\]"},{"location":"lecture/02-risk-management/023-oce/#expected-shortfall-and-optimized-certainty-equivalent","title":"Expected Shortfall and Optimized Certainty Equivalent","text":"<p>On one hand, we previously noted that it is not entirely clear how to show that Expected Shortfall (ES) is a risk measure when derived as the integral of V@R. On the other hand, the optimized certainty equivalent (OCE) with a piecewise linear loss function shows some structural similarities to V@R. It turns out that these two concepts are strongly connected, as demonstrated by the following proposition:</p> <p>Proposition</p> <p>For bounded loss profiles (or even integrable ones), the Expected Shortfall with confidence level \\( 0 &lt; \\alpha &lt; 1 \\) coincides with the optimized certainty equivalent using a piecewise linear loss function with a factor of \\( 1/\\alpha \\).  </p> <p>In other words:</p> \\[   ES_{\\alpha}(L) = \\frac{1}{\\alpha}\\int_{0}^\\alpha V@R_{s}(L)ds = \\inf \\left\\{ m +\\frac{1}{\\alpha}E[(L-m)^+] \\colon m \\in \\mathbb{R} \\right\\} = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E\\left[ \\left( L-V@R_{\\alpha}(L) \\right)^+ \\right]. \\] <p>In particular, Expected Shortfall is a cash-invariant and law-invariant risk measure.</p> <p>This remarkable result addresses the key questions about ES: it confirms that ES is a sound risk measure and provides a computationally efficient approach. Instead of directly computing the integral of the quantile (which can be computationally intensive and error-prone), ES can be expressed as the sum of V@R (already an industry standard) and the expected loss beyond V@R, which can be computed easily either using the PDF of \\( L \\) or Monte Carlo methods with importance sampling.</p> Proof <p>The connection between ES and OCE arises from the fact that the quantile function \\( q_L(s) \\) of \\( L \\) shares the same CDF as \\( L \\) itself. Formally, given a loss profile (random variable) \\( L \\) with CDF \\( F_L(m) = P[L \\leq m] \\) and quantile function \\( q_L(s) = \\inf\\{m \\colon F_L(m)\\geq s\\} \\), the quantile \\( q_L(s) \\) can be viewed as a random variable defined on the probability space \\( (\\tilde{\\Omega}, \\tilde{\\mathcal{F}}, \\tilde{P}) \\), where:</p> <ul> <li>\\( \\tilde{\\Omega} = (0,1) \\),  </li> <li>\\( \\tilde{\\mathcal{F}} \\) is the \\( \\sigma \\)-algebra generated by intervals of \\((0,1)\\), and  </li> <li>\\( \\tilde{P} \\) is the Lebesgue measure \\( dx \\) (the measure of interval lengths).</li> </ul> <p>It can be shown that \\( q_L(s) \\) has the same CDF as \\( L \\), i.e., \\( F_{q_L}(m) = F_L(m) \\). Indeed, by the definition of \\( q_L(s) \\):</p> \\[ (0, F_L(m)) \\subseteq \\{s \\colon q_L(s) \\leq m\\} \\subseteq (0, F_L(m)], \\] <p>and under \\( \\tilde{P} \\), these sets yield:</p> \\[     F_L(m) = \\tilde{P}[(0, F_L(m))] \\leq \\tilde{P}[q_L \\leq m] \\leq \\tilde{P}[(0, F_L(m)]] = F_L(m). \\] <p>Therefore, \\( F_{q_L}(m) = F_L(m) \\).</p> <p>Using this fact, and noting that \\( q_L(s) \\geq q_L(1-\\alpha) \\) for \\( s \\geq 1-\\alpha \\):</p> \\[ \\begin{align*}   ES_{\\alpha}(L) &amp; = \\frac{1}{\\alpha} \\int_{0}^\\alpha V@R_{s}ds \\\\     &amp; = \\frac{1}{\\alpha} \\int_{1-\\alpha}^1 q_L(s) ds \\\\     &amp; = q_L(1-\\alpha) + \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 \\left( q_L(s) - q_{L}(1-\\alpha) \\right)ds \\\\     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}\\int_{\\mathbb{R}} \\left( m - V@R_{\\alpha}(L) \\right)^+ dF_{q_L}(m) \\\\     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}\\int_{\\mathbb{R}} \\left( m - V@R_{\\alpha}(L) \\right)^+ dF_{L}(m) \\\\     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E \\left[ \\left( L - V@R_{\\alpha}(L) \\right)^+ \\right]. \\end{align*} \\] <p>Remark on the Distribution of the Quantile and Random Sampling</p> <p>This kind of magic trick to show the relationship between the piecewise linear optimized certainty equivalent and the expected shortfall relies on the fundamental fact that the distribution of a random variable \\(X\\) on some probability space \\((\\Omega, \\mathcal{F}, P)\\) is the same as the distribution of its quantile \\(q_X\\) on \\((\\tilde{\\Omega}, \\tilde{\\mathcal{F}}, \\tilde{P})\\) where \\(\\tilde{\\Omega} = (0,1)\\), \\(\\tilde{F} = \\mathcal{B}((0,1))\\) the \\(\\sigma\\)-algebra generated by intervals and \\(\\tilde{P}\\) is the lebesgue measure \\(dx\\) that measure interval length, that it \\(\\tilde{P}[(a, b]] = b-a\\).</p> <p>This result is widely known and extensively used, particularly for random sampling. Suppose you want to sample \\( x_1, \\ldots, x_N \\) from the distribution of a random variable \\( X \\) (e.g., normal, Student's t, gamma). A computer, however, generates (quasi-)random numbers \\( u_1, \\ldots, u_N \\) uniformly distributed between \\( 0 \\) and \\( 1 \\). By the equivalence between the distributions of \\( X \\) and \\( q_X \\), defining \\( x_n = q_X(u_n) \\) for \\( n = 1, \\ldots, N \\) produces a random sample \\( x_1, \\ldots, x_N \\) from the distribution of \\( X \\).</p> <pre><code>import numpy as np\nfrom scipy.stats import norm      # (1)\nimport plotly.graph_objs as go    # (2)\n\nN = 10000\nu = np.random.rand(N)             # uniform sample\nx0 = norm.ppf(u)                  # quantile of normal distribution of u\nx1 = norm.rvs(size=N)             # sample from normal\n\n# Plot the two histograms\nfig = go.Figure()\nfig.add_histogram(\n    x=x0,\n    histnorm='probability',\n    name='Quantile of Uniform Sample',\n)\nfig.add_histogram(\n    x=x1,\n    histnorm='probability',\n    name='Standard Normal Sample',\n)\nfig.show()\n</code></pre> <ol> <li>The <code>scipy.stats</code> library provides access to many distributions, including their <code>cdf</code>, <code>pdf</code>, and <code>ppf</code> (quantile function).  </li> <li><code>plotly</code> is used here for plotting; alternatively, <code>matplotlib</code> can be used.</li> </ol> <p>This principle underpins Monte Carlo integration, where the goal is to compute \\( E[f(X)] \\). By the law of large numbers and the central limit theorem, it holds that:</p> \\[     \\frac{1}{N}\\sum_{n=1}^N f(x_n) \\xrightarrow[N \\to \\infty]{} E[f(X)], \\] <p>where \\( x_1, \\ldots, x_N \\) is a random sample from the distribution of \\( X \\). In practice, a random sample \\( u_1, \\ldots, u_N \\) is drawn from a uniform distribution on \\( (0, 1) \\), and then \\( x_n = q_X(u_n) \\) is computed and used in the arithmetic mean of \\( f(x_n) \\) for \\( n = 1, \\ldots, N \\).</p> <p>As of now, we know that Expected Shortfall (ES) is a sound risk measure: it is understandable, implementable, and, due to its representation, efficient to compute. Prior to the introduction of ES, financial institutions commonly computed \\( V@R \\). To transition to ES, they only need to compute the additional term \\( E[(L-V@R_{\\alpha}(L))^+]/\\alpha \\), which is computationally efficient (either analytically or via Monte Carlo methods).</p> <p>The computation of ES in simple cases is demonstrated below:</p> <pre><code>import numpy as np\nfrom scipy.stats import norm, t       # Normal and Student's t distributions\nfrom scipy.optimize import root       # Root finding\nfrom scipy.integrate import quad      # One-dimensional integration\nimport plotly.graph_objs as go        # Plotting library\n\n# Define the basic computation of the quantile (X is a random variable)\ndef quantile(X, s):\n    def fun(m):\n        return X.cdf(m) - s\n    result = root(fun, 0)  # Find the root\n    return result.x[0]\n\n# Compute ES using the integral of quantile representation\ndef ES1(X, alpha):\n    def fun(s):\n        return quantile(X, s)\n    result, err = quad(fun, 1 - alpha, 1)  # Integrate quantile between 1-alpha and 1\n    return result / alpha\n\n# Compute ES using the OCE representation\ndef ES2(X, alpha):\n    var = quantile(X, 1 - alpha)\n    def fun(x):\n        return (x - var) * X.pdf(x)\n    result, err = quad(fun, var, np.Inf)  # Integrate beyond V@R\n    return var + result / alpha\n\n# Define distributions\nX1 = norm\nX2 = t(df=2)  # Student's t distribution with df=2 (variance = 1)\n\nalpha = 0.01  # Confidence level (1%)\n\n# Display results\nprint(f\"\"\"\nV@R (Normal):\\t{quantile(X1, 1 - alpha)}\nES (slow, Normal):\\t{ES1(X1, alpha)}\nES (fast, Normal):\\t{ES2(X1, alpha)}\n\nV@R (Student):\\t{quantile(X2, 1 - alpha)}\nES (slow, Student):\\t{ES1(X2, alpha)}\nES (fast, Student):\\t{ES2(X2, alpha)}\n\"\"\")\n\n# Exercise:\n# Compare and plot the differences between V@R and ES for Normal and Student's t distributions for 0.0001 &lt; alpha &lt; 0.05.\n# Use %timeit to compare the computation times of ES1 and ES2.\n</code></pre> <p>We saw that the expected shortfall has multiple representations, and simple transformations can yield additional formulations.</p> <p>The expected shortfall has the following representations</p> \\[   \\begin{align*}     ES_{\\alpha}(L)  &amp; = \\frac{1}{\\alpha}\\int_0^\\alpha V@R_{s}(L)ds &amp;&amp; \\text{Quantile representation}\\\\                     &amp; = \\inf\\{m + \\frac{1}{\\alpha}E[(L-m)^+]\\colon m \\in \\mathbb{R}\\} &amp;&amp; \\text{OCE representation}\\\\                     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E\\left[ \\left( L - V@R_{\\alpha}(L) \\right)^+ \\right] \\\\                     &amp; = \\frac{1}{\\alpha}\\int_{V@R_{\\alpha}(L)}^\\infty x dF_L(x)   \\end{align*} \\] <p>Furthermore, the expected shortfall is positive homogeneous, that is</p> \\[ ES_{\\alpha}(\\lambda L) = \\lambda ES_{\\alpha}(L)\\] <p>for every \\(\\lambda&gt;0\\). In particular \\(ES_{\\alpha}(L_1 + L_2)\\leq ES_{\\alpha}(L_1) + ES_{\\alpha}(L_2)\\).</p>"},{"location":"lecture/03-Multi-Period/031-multi-period-financial-markets/","title":"Multi Period Financial Markets","text":"<p>Up to now, we have only considered a static version of a financial market, with a single decision at time \\(0\\) and a delivery at time \\(1\\). This analysis applies to many buy-and-hold investors. However, as time progresses, more information about the outcomes of contingent claims or portfolios becomes available, allowing investors to adapt their strategies to take advantage of new information.</p>"},{"location":"lecture/03-Multi-Period/031-multi-period-financial-markets/#mathematical-model","title":"Mathematical Model","text":"<p>As always, we consider a probability space \\( (\\Omega, \\mathcal{F}, P) \\), which describes the states of the world, the events, and their likelihood. The market still consists of a bank account \\( B \\) and \\( d \\) financial assets \\( \\boldsymbol{S} = (S^1, \\ldots, S^d) \\). Now, we extend the model to \\( T+1 \\) time periods \\( t = 0, \\ldots, T \\).</p> <ul> <li> <p>Bank Account:     As in the static case, the bank account \\( B \\) describes the evolution of one unit of currency over time.     However the bank now can revise the interest rate it delivers between \\(t\\) and \\(t+1\\) at every time \\(t\\) and this might not be know at time \\(0\\).     Hence, we define the growth of the bank account as following classical compounding for interest rates:</p> \\[   B_0 = 1, \\quad B_t(\\omega) = B_{t-1}(1+r_t) = \\prod_{s=1}^t (1+r_s), \\] <p>where \\(r_t = (B_t - B_{t-1})/B_t\\) is a random variable strictly greater than \\(-1\\).</p> <p>In other terms \\(r_t(\\omega)\\) represents the interest rate set by the bank at time \\(t-1\\) to remunerate cash deposited in the account at time \\(t-1\\) for the period between \\(t-1\\) and \\(t\\).</p> </li> <li> <p>Financial Assets:</p> <p>We have \\(d\\) of them and as the bank account, their price evolution can be observed at any time \\(t=0, \\ldots, T\\). Therefore we define the \\(k\\)-th financial asset \\(S^k = (S^k_t){t=0, \\ldots, T}\\) as a family of random variables</p> \\[ \\begin{equation*}   \\begin{split}     S_t^k \\colon \\Omega &amp; \\longrightarrow [0, \\infty)\\\\                 \\omega &amp; \\longmapsto S_t^k(\\omega) = \\text{Price at time $t$ in state $\\omega$ of asset $k$}   \\end{split} \\end{equation*} \\] <p>We assume however that \\(S_0^k&gt;0\\) for the price at time \\(0\\) meaning that the financial asset is not defaulted at time \\(0\\).</p> </li> </ul> <p>In general, a family \\(Z = (Z_t)_{t=0, \\ldots, T}\\) where each \\(Z_t\\) is a random variable, is called a stochastic process.</p> <ul> <li> <p>Portfolio:</p> <p>An investor starts with an initial wealth \\( \\bar{V}_0 \\) and may adjust their holdings over time. This strategy is modeled by a \\( d \\)-dimensional vector \\( \\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d) \\), which is also a (\\(d\\)-dimensional) stochastic process:</p> \\[ \\begin{equation*}     \\begin{split}         \\eta_t^k \\colon \\Omega &amp;\\longrightarrow \\mathbb{R}\\\\         \\omega &amp; \\longmapsto \\eta_t^k(\\omega),     \\end{split} \\end{equation*} \\] <p>for every \\( t = 1, \\ldots, T \\) and \\( k = 1, \\ldots, d \\). The decision about \\( \\boldsymbol{\\eta}_t \\) is made at time \\( t-1 \\) and represents the portfolio held from time \\( t-1 \\) to \\( t \\).</p> <p>Now given a portfolio value \\(\\bar{V}_{t-1}\\) at time \\(t-1\\) and a strategic decision \\(\\boldsymbol{\\eta}_{t}\\) of holdings until \\(t\\), yields an updated value of the portfolio at time \\(t\\) given by</p> \\[ \\begin{align*}     \\bar{V}_{t}  &amp; =  \\underbrace{\\left( \\bar{V}_{t-1} - \\boldsymbol{\\eta}_{t}\\cdot \\boldsymbol{S}_{t-1} \\right)}_{\\text{Cash minus cost of holdings}}(1+r_{t}) + \\underbrace{\\boldsymbol{\\eta}_{t}\\cdot \\boldsymbol{S}_{t}}_{\\text{Current holding value}} \\\\     &amp;= \\bar{V}_{t-1}(1+r_{t}) + \\boldsymbol{\\eta}_{t}\\cdot \\left( \\boldsymbol{S}_{t} - \\boldsymbol{S}_{t-1}(1+r_{t})\\right) \\end{align*} \\] </li> <li> <p>Discounted Values</p> <p>As in the one-period model, it is convenient to work with discounted values. The discounted stock prices \\( \\boldsymbol{X} = (X^1, \\ldots, X^d) \\) and discounted portfolio value \\( V_t \\) are defined as:</p> \\[     X_t^k = \\frac{S_t^k}{B_t} \\quad\\text{and}\\quad  V_t = \\frac{\\bar{V}_t}{B_t}, \\] <p>for \\( k = 1, \\ldots, d \\) and \\( t = 0, \\ldots, T \\). Clearly, \\( X_0 = S_0 \\) and \\( V_0 = \\bar{V}_0 \\).</p> <p>Just as in the one period model, it holds that</p> \\[     \\begin{align*}         V_t &amp; = \\frac{\\bar{V}_t}{B_t} \\\\         &amp; = \\frac{1}{B_{t-1}(1+r_{t})}\\left( \\bar{V}_{t-1}(1+r_{t}) + \\boldsymbol{\\eta}_{t}\\cdot \\left( \\boldsymbol{S}_{t} - \\boldsymbol{S}_{t-1}(1+r_{t}\\right) \\right)\\\\         &amp; = \\frac{\\bar{V}_{t-1}}{B_{t-1}} + \\boldsymbol{\\eta}_t\\cdot \\left( \\frac{\\boldsymbol{S}_t}{B_t} - \\frac{\\boldsymbol{S}_{t-1}}{B_{t-1}} \\right)\\\\         &amp; = V_{t-1} + \\boldsymbol{\\eta}_t \\cdot  \\underbrace{\\left(\\boldsymbol{X}_t - \\boldsymbol{X}_{t-1}\\right)}_{:= \\Delta \\boldsymbol{X}_t}         = V_0 + \\sum_{s=1}^t \\boldsymbol{\\eta}_s\\cdot\\Delta \\boldsymbol{X}_s     \\end{align*} \\] <p>leading to </p> <p>Lemma</p> <p>Let \\( \\boldsymbol{\\eta} \\) be a strategy and \\( V_0 \\) the initial value of a self-financing portfolio. Then:</p> \\[   V_t = V_0 + \\sum_{s=1}^t \\boldsymbol{\\eta}_s \\cdot \\Delta \\boldsymbol{X}_s \\] <p>where \\( \\Delta \\boldsymbol{X}_s = \\boldsymbol{X}_s - \\boldsymbol{X}_{s-1} \\).</p> </li> </ul>"},{"location":"lecture/03-Multi-Period/031-multi-period-financial-markets/#information","title":"Information","text":"<p>Up to now, we have not considered how decisions are influenced by additional information. Mathematically, information is represented by collections of events. A random variable is \"known\" at a given time if its value is determined by the events available at that time.</p> <p>Definition</p> <p>A filtration is a family \\( \\mathbb{F} = (\\mathcal{F}_t)_{0 \\leq t \\leq T} \\) of \\(\\sigma\\)-algebras such that:</p> \\[ \\mathcal{F}_0 \\subseteq \\mathcal{F}_1 \\subseteq \\cdots \\subseteq \\mathcal{F}_T \\subseteq \\mathcal{F}. \\] <p>Note</p> <p>Throughout, we assume that the initial information \\( \\mathcal{F}_0 \\) is the trivial \\(\\sigma\\)-algebra \\( \\mathcal{F}_0 = \\{\\emptyset, \\Omega\\} \\). In particular, any \\(\\mathcal{F}_0\\) random variable is a constant.(1)</p> <ol> <li>It is a basic exercise to check. Suppose that a random variable \\(X\\) is \\(\\mathcal{F}_0=\\{\\emptyset, \\Omega\\}\\)-measurable then it follows that \\(X\\) is constant. Indeed, if it where not, let \\(\\omega_1\\) and \\(\\omega_2\\) be two states on which \\(X(\\omega_1) &lt; X(\\omega_2)\\), let \\(x\\) be such that \\(X(\\omega_1)&lt;x&lt;X(\\omega_2)\\), it follows that \\(\\omega_1 \\in A=\\{X\\leq x\\}\\) while \\(\\omega_2 \\not \\in A\\). This is however not possible since the event \\(A\\) is either \\(\\Omega\\) or \\(\\emptyset\\).</li> </ol> <p>Definition</p> <p>A collection of random variables indexed by time is called a stochastic process. A stochastic process \\( X = (X_t)_{0 \\leq t \\leq T} \\) is:</p> <ol> <li>Adapted if \\( X_t \\) is \\(\\mathcal{F}_t\\)-measurable for all \\( t = 0, \\ldots, T \\).</li> <li>Predictable if \\( X_t \\) is \\(\\mathcal{F}_{t-1}\\)-measurable for all \\( t = 1, \\ldots, T \\).</li> </ol> <p>Adapted means that the process at time \\(t\\) only depends on the information up to time \\(t\\) while predictable means that it depends on the information of yesterday. With this definition in mind, it follows that in a multi-period financial market we have</p> <ul> <li>The stochastic process modeling financial assets \\( \\boldsymbol{S} \\) is adapted.</li> <li>The interest rate process \\( r \\) is predictable (announced beforehand the next period by the bank)</li> <li>Financial strategies \\( \\boldsymbol{\\eta} \\) are predictable (decided for the next period).</li> </ul> <p>Multi-period</p> <p>A multi-period financial market consists of:</p> <ol> <li>A probability space \\( (\\Omega, \\mathcal{F}, P) \\).</li> <li>A filtration \\( \\mathbb{F} = (\\mathcal{F}_t)_{0\\leq t\\leq T} \\).</li> <li>A \\(d\\)-dimensional adapted stochastic process \\( \\boldsymbol{S} = (\\boldsymbol{S}_t)_{0 \\leq t \\leq T} \\) of positive random variables.</li> <li>A bank account \\( B_0 = 1 \\), \\( B_t = \\prod_{s=1}^t (1 + r_s) \\), where \\( r \\) is a predictable process.</li> </ol> <p>Financial strategies \\( \\boldsymbol{\\eta} = (\\boldsymbol{\\eta}_t)_{0 \\leq t \\leq T} \\) are \\( d \\)-dimensional predictable processes.</p>"},{"location":"lecture/03-Multi-Period/031-multi-period-financial-markets/#arbitrage-pricing-measure","title":"Arbitrage, Pricing Measure","text":"<p>The primary notion of arbitrage in the static case is given by the fact that one can find a strategy such that it is possible to make strict positive gain without losing any money for sure. The same notion holds in the multi-period case.</p> <p>Definition: Arbitrage</p> <p>Given a financial market, a self-financing portfolio \\(\\bar{V}\\) with start value \\(\\bar{V}_0\\) and strategy \\(\\boldsymbol{\\eta}\\) is called an arbitrage opportunity if</p> \\[     P\\left[ \\bar{V}_T \\geq \\bar{V}_0 B_T \\right] = 1 \\quad \\text{and} \\quad P\\left[ \\bar{V}_T &gt; \\bar{V}_0 B_T \\right] &gt; 0. \\] <p>Note that as in the one-period model, this definition is independent of discounting and start since it is equivalent to</p> \\[   P\\left[ V_T \\geq V_0 \\right] = 1 \\quad \\text{and} \\quad P\\left[ V_T &gt; V_0 \\right] &gt; 0 \\] <p>and  </p> \\[   P\\left[ \\sum_{s=1}^T \\boldsymbol{\\eta}_s \\Delta \\boldsymbol{X}_s \\geq 0 \\right] = 1 \\quad \\text{and} \\quad P\\left[ \\sum_{s=1}^T \\boldsymbol{\\eta}_s \\cdot \\Delta \\boldsymbol{X}_s &gt; 0 \\right] &gt; 0 \\] <p>for a strategy \\(\\eta\\).</p> <p>This definition is global between \\(0\\) and \\(T\\) in the sense that along the way an arbitrage can be constructed. However, the following proposition shows that it is equivalent to a local definition where an arbitrage must exist between two consecutive times.</p> <p>Proposition</p> <p>Given a financial market, the following assertions are equivalent:</p> <ol> <li>Global arbitrage: There exists an arbitrage opportunity.</li> <li>Local arbitrage: There exists some time \\(t\\) between \\(1\\) and \\(T\\) and an \\(\\mathcal{F}_{t-1}\\)-measurable random variable \\(\\boldsymbol{\\mu} \\colon \\Omega \\to \\mathbb{R}^d\\) such that</li> </ol> \\[   P[\\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_t \\geq 0] = 1 \\quad \\text{and} \\quad P\\left[ \\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_t &gt; 0 \\right] &gt; 0. \\] Proof <ol> <li> <p>We show that the second assertion implies the first with some \\(\\mathcal{F}_{t-1}\\)-measurable strategy \\(\\boldsymbol{\\mu}\\) which is an arbitrage between \\(t-1\\) and \\(t\\).     Let \\(\\boldsymbol{\\eta}\\) be the \\(\\mathbb{R}^d\\)-valued process given by</p> \\[   \\eta_s =       \\begin{cases}         \\mu &amp; \\text{if } s = t \\\\         0 &amp; \\text{otherwise.}       \\end{cases} \\] <p>By definition, \\(\\boldsymbol{\\eta}\\) is predictable, for which holds \\(\\sum_{s=1}^T \\boldsymbol{\\eta}_s \\cdot \\Delta \\boldsymbol{X}_s = \\boldsymbol{\\mu}\\cdot \\Delta \\boldsymbol{X}_t\\) showing that \\(\\boldsymbol{\\eta}\\) is an arbitrage globally.</p> </li> <li> <p>Conversely, let \\(\\boldsymbol{\\eta}\\) be a global arbitrage strategy strategy with the corresponding discounted value process \\(V\\), and define</p> \\[   t := \\min\\left\\{s = 0, \\ldots, T : V_s \\geq V_0 \\text{ and } P\\left[ V_s &gt; V_0 \\right] &gt; 0 \\right\\}. \\] <p>being the first time where an arbitrage kicks in your portfolio. By assumption, \\(t \\leq T\\) and by definition, it follows that \\(V_{t-1} = V_0\\) or \\(P[V_{t-1} &lt; V_0] &gt; 0\\).</p> <p>In the first case, since</p> \\[   \\boldsymbol{\\eta}_t \\cdot \\Delta \\boldsymbol{X}_t = V_t - V_{t-1} = V_t - V_0 \\geq 0, \\] <p>it follows that \\(\\boldsymbol{\\mu} = \\boldsymbol{\\eta}_t\\), which is \\(\\mathcal{F}_{t-1}\\)-measurable and fulfills the assumptions of the local arbitrage.</p> <p>In the second case, let \\(\\boldsymbol{\\mu} = \\boldsymbol{\\eta}_t 1_{\\{V_{t-1} &lt; V_0\\}}\\), which is \\(\\mathcal{F}_{t-1}\\)-measurable. It follows that</p> \\[   \\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_t = \\left(V_t - V_{t-1}\\right)1_{\\{V_{t-1} &lt; V_0\\}} \\geq \\left(V_0 - V_{t-1}\\right)1_{\\{V_{t-1} &lt; V_0\\}} \\geq 0, \\] <p>and since \\(P[V_{t-1} &lt; V_0] &gt; 0\\), this inequality holds strictly with a strict positive probability showing that \\(\\boldsymbol{\\mu}\\) is a local arbitrage.</p> </li> </ol> <p>In the first section, we saw that a market is fair if and only if there exists a pricing measure \\(P^\\ast\\) such that</p> \\[   E^{P^\\ast}\\left[\\boldsymbol{X}_1\\right] = \\boldsymbol{X}_0 \\] <p>In a multiperiod setting, this equation translates into:</p> \\[ E^{P^\\ast}\\left[\\boldsymbol{X}_{t+1}|\\mathcal{F}_{t}\\right] = \\boldsymbol{X}_{t} \\] <p>saying that under the pricing measure, the expected discounted value of every asset at time \\(t+1\\) conditioned on the information available at time \\(t\\) is equal to the discounted value of those assets at time \\(t\\). This statement brings us to the following important notion in the theory of stochastic processes.</p> <p>Definition: Martingale</p> <p>Given a probability measure \\(Q\\), a stochastic process \\(M = (M_t)_{0 \\leq t \\leq T}\\) is called a \\(Q\\)-martingale if:</p> <ol> <li>\\(M\\) is an adapted process.</li> <li>\\(M\\) is \\(Q\\)-integrable.  </li> <li> <p>\\(M\\) satisfies the \\(Q\\)-martingale property, that is,  </p> \\[   E^Q\\left[M_{t+1}|\\mathcal{F}_t\\right] = M_t, \\] <p>for every \\(t = 0, \\ldots, T-1\\).</p> </li> </ol> <p>Note</p> <p>Given a probability \\(Q\\), the most simple example of a martingal is the expectation of a given (integrable random variable). Indeed, let \\(C\\) be an (integrable) random variable and define </p> \\[   M_t = E^Q\\left[ C | \\mathcal{F}_t \\right] \\] <p>By definition \\(M = (M_t)\\) is an adapted and integrable process. Furthermore, by the tower property of the conditional expectation we get</p> \\[   E^Q\\left[ M_{t+1} |\\mathcal{F}_t\\right] = E^{Q}\\left[ E^Q\\left[ C|\\mathcal{F}_{t+1} \\right] |\\mathcal{F}_t\\right] = E^Q\\left[ C|\\mathcal{F}_t \\right] = M_t \\] <p>which leads to the definition of a pricing measure</p> <p>Definition</p> <p>A probability measure \\(P^\\ast\\) is called a pricing measure if the discounted price process \\(\\boldsymbol{X}\\) is a \\(d\\)-dimensional \\(P^\\ast\\)-martingale.</p> <p>Proposition</p> <p>Let \\(P^\\ast\\) be a probability measure. The following conditions are equivalent</p> <ul> <li>\\(P^\\ast\\) is a pricing measure;</li> <li>Any (discounted) portfolio \\(V = V_0 + \\sum \\boldsymbol{\\eta}_s \\cdot \\Delta \\boldsymbol{X}_s\\) for some (bounded) strategy \\(\\boldsymbol{\\eta}\\) is a \\(P^\\ast\\)-martingale;</li> </ul> <p>Proof</p> <p>As for the first assertion implying the second, let \\(P^\\ast\\) be a risk pricing measure and \\(\\boldsymbol{\\eta}\\) a bounded strategy, then \\(V\\) is a \\(P^\\ast\\)-martingale.(1) Since \\(\\boldsymbol{\\eta}\\) is predictable, it follows that</p> <ol> <li> <p>In your context you just need to check the martingale property, however the other two assumption shall be checked too. Adaptiveness is usually given right away, in our case it follows from the fact that \\(V\\) is an adapted process as a scalar product between a predictable and an adapted process. Integrability is usually also straightforward, yet mathematically should be checked. In our case since \\(\\boldsymbol{\\eta}\\) is uniformly bounded, it follows that     [       \\begin{equation}         |V_t|\\leq |V_0|+\\sum_{s=1}^t\\sum_{k=0}^d|\\eta_s^k||\\Delta X_s^k|\\leq |V_0|+C\\sum_{s=1}^t\\sum_{k=0}^d|\\Delta X_s^k|       \\end{equation}     ]</p> <p>for every \\(t\\), where \\(C\\) is the constant such that \\(|\\eta_s^k|\\leq C\\) for every \\(k=0,\\ldots,d\\) and \\(s=0,\\ldots ,T\\). Since \\(\\boldsymbol{X}\\) is \\(P^\\ast\\) integrable, it follows that \\(V\\) is also too.</p> </li> </ol> \\[   \\begin{equation*}       E^{P^\\ast}\\left[ V_{t+1}|\\mathcal{F}_{t} \\right]=E^{P^\\ast}\\left[ V_{t} + \\boldsymbol{\\eta}_{t+1}\\cdot \\Delta \\boldsymbol{X}_{t+1}|\\mathcal{F}_{t} \\right]=V_t + \\boldsymbol{\\eta}_{t+1}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_{t+1}|\\mathcal{F}_{t} \\right]=0   \\end{equation*} \\] <p>Hence, \\(V\\) is a \\(P^\\ast\\)-martingale.</p> <p>Reciprocally, if every discounted portfolio is a \\(P^\\ast\\) martingale, fix \\(k\\) in \\(\\{1,\\ldots,d\\}\\), and define</p> \\[ \\begin{equation*}     \\eta_t^i=     \\begin{cases}         1 &amp;\\text{if }i=k\\\\         0 &amp;\\text{otherwise}     \\end{cases} \\end{equation*} \\] <p>for any \\(t=1,\\ldots,T\\) and \\(i=1,\\ldots, d\\) which defines a uniformly bounded strategy \\(\\boldsymbol{\\eta}\\). Furthermore, by definition, it holds that \\(V = X^k\\). Hence \\(V\\) being a \\(P^\\ast\\) martingale implies that \\(X^k\\) is a \\(P^\\ast\\) martingale too. Hence \\(P^\\ast\\) is a pricing measure.</p>"},{"location":"lecture/03-Multi-Period/031-multi-period-financial-markets/#fundamental-theorem-of-asset-pricing","title":"Fundamental Theorem of Asset Pricing","text":"<p>As exposed before, the multi period setting can be cast as a sequence of pasted successive one period models. Hence, it is not a surprise that all the results derived in one period model do extend into the multiperiod one. The intuition is the same, it just requires the infinite dimensional extension of the separation Theorem of Hahn-Banach which is beyond the scope of this lecture.</p> <p>Fundamental Theorem of Asset Pricing</p> <p>The financial market model is arbitrage free if, and only if, there exists a pricing measure \\(P^\\ast\\) equivalent to \\(P\\).</p> <p>This risk pricing neutral pricing measure can be chosen such that \\(dP^\\ast/dP\\) is bounded.</p> <p>Super- and sub-hedging results carries over the same way. In particular, given a contingent claim \\(C\\) paying off at maturity \\(T\\), a fair price \\(\\pi(C)=(\\pi_t(C))\\) is a stochastic process given by</p> \\[ \\pi_t(C) = B_t E^{P^\\ast}\\left[ \\frac{C}{B_T} | \\mathcal{F}_t \\right] \\] <p>As in the one period model you have the price at time \\(0\\) given by \\(\\pi_0(C) = E^{P^\\ast}[C/B_T]\\) which is the discounted expectation of the contingent claim, while \\(\\pi_T(C) = B_T E^{P^\\ast}[C/B_T |\\mathcal{F}_T] = C\\) is the contingent claim itself at time \\(T\\).</p>"},{"location":"lecture/03-Multi-Period/031-multi-period-financial-markets/#exotic-derivatives","title":"Exotic Derivatives","text":"<p>European derivatives (Put/Call, butterfly, Straddle, Forward) definition follows directly from the one period. However, since we have now several periods, new class of options can be defined where intermediary conditions depending on time can be part of the contract. Those options are typically called exotic derivatives.</p> <ul> <li> <p>European Options:</p> <p>As mentioned it is a straight forward extension, where the horizon \\(T\\) is called maturity. For instance European call and put options</p> \\[ \\begin{align*}   C^{call} &amp; = (S_T - K)^+ \\\\   C^{put} &amp; = (K-S_T)^+  \\end{align*} \\] </li> <li> <p>Asian Option: Asian option typically depends on the time average of an underlying.</p> <p>We define the rolling time average between \\(1\\) and \\(t\\) of an asset \\(S\\) as follows</p> \\[     S^{av}_t = \\frac{1}{t} \\sum_{s=1}^t S_s \\] <p>Asian options, are contracts written on this time average, for instance an Asian call or put option</p> \\[ \\begin{align*}   C^{asian\\,call} &amp; = (S^{av}_T - K)^+ = \\left( \\frac{1}{T}\\sum_{t=1}^T S_t -K \\right)^+\\\\   C^{asian\\,put} &amp; = (S^{av}_T - K)^+ = \\left( K-\\frac{1}{T}\\sum_{t=1}^T S_t \\right)^+ \\end{align*} \\] <p>In the following illustration thick lines stands for paths while dashed stands for exanding average. For an asian call, only the red scenario returns a positive outcome. In contrast, for the standard call, only the red scenario is void.</p> <p> </p> </li> <li> <p>Barrier Options: Barrier options are options that depends on the path of the underlying hitting or not a given barrier at a given previous time.</p> <p>To do so, for a financial asset \\(S\\), we define the rolling maximum \\(\\overline{S}\\) and minimum \\(\\underline{S}\\) as</p> \\[   \\begin{align*}     \\overline{S}_t &amp; =\\max_{s\\leq t} S_s\\\\     \\underline{S}_t &amp; =\\min_{s\\leq t} S_S   \\end{align*} \\] <p>With these rolling maximum and minimum, we can define several conditions for a standard contract to hold</p> <ul> <li>knocked up and in: The contract hold only if \\(\\overline{S}_T \\geq B\\);</li> <li>knocked up and out: The contract is void if \\(\\overline{S}_T \\geq B\\);</li> <li>knocked down and in: The contract hold only if \\(\\underline{S}_T \\leq B\\);</li> <li>knocked down and out: The contract is void if \\(\\underline{S}_T \\leq B\\);</li> </ul> <p>With these conditions at hand, myriad of options can be defined starting from European or Asian options. For instance</p> \\[   \\begin{align*}     C^{call}_{up\\&amp;in} &amp;      = (S_T - K)^+ 1_{\\{ \\overline{S}_T\\geq B \\}}     =      \\begin{cases}       (S_T-K)^+ &amp; \\text{if }\\overline{S}_T \\geq B \\\\       0 &amp; \\text{otherwize}     \\end{cases}\\\\     C^{call}_{down\\&amp;out} &amp;      = (S_T - K)^+ 1_{\\{ \\underline{S}_T &gt; B \\}}     =      \\begin{cases}       (S_T-K)^+ &amp; \\text{if }\\underline{S}_T &gt; B \\\\       0 &amp; \\text{otherwize}     \\end{cases}   \\end{align*} \\] <p>In the following illustration thick lines stands for paths while dashed stands for the running maximum. For an up and out call, only the orange scenario returns a positive outcome. The blue scenario is above the strike however knocked the barrier before \\(T\\).</p> <p> </p> </li> </ul> <p>Computational Issues</p> <p>Given a contingent claim \\(C\\), any fair price of this contingent claim is given as \\(E^{P^\\ast}[C/B_T]\\). Setting the discounting factor to \\(1\\), if \\(C = f(S_T)\\) for some function, such as a plain European option, it follows that the price can be computed as:</p> \\[   E^{P^\\ast}\\left[ f(C) \\right] = E^{P^\\ast}\\left[ f(S_T) \\right] = \\int_{\\mathbb{R}} f(s) dF^\\ast_{S_T}(s) \\] <p>However, if the contingent claim is of Asian or barrier type, the payoff does not only depend on the last value of the financial asset but on the whole path. In other terms, \\(C = f(S_1, \\ldots, S_T)\\), such as \\(f(s_1, \\ldots, s_T) = \\left(\\frac{\\sum s_t}{T} - K\\right)^+\\), meaning that the contingent claim depends on the multidimensional distribution of the price over time. Suppose that this price has a density, that is:</p> \\[ dF^{\\ast}(S_1, \\ldots, S_T)(s_1, \\ldots, s_T) = \\phi(s_1, \\ldots, s_T) ds_1 \\ldots ds_T. \\] <p>It follows that:  </p> \\[   E^{P^\\ast}\\left[ f(C) \\right] = E^{P^\\ast}\\left[ f(S_1, \\ldots, S_T) \\right] = \\int_{\\mathbb{R}} \\int_{\\mathbb{R}} \\ldots \\int_{\\mathbb{R}} f(s_1, \\ldots, s_T) \\varphi(s_1, \\ldots, s_T) ds_1 \\ldots ds_T \\] <p>which is a high-dimensional integration.</p> <p>Classical integration becomes unusable beyond 2-3 dimensions as it suffers from the curse of dimensionality. Monte Carlo methods are then the way to go, but reasonable accuracy requires very large samples. This is one drawback of those exotic options.</p> <p>However, for barrier options, it turns out that in specific contexts, regardless of the horizon \\(T\\), the integration can be reduced to a two-dimensional one, which is tractable. Therefore, the popularity of barrier options (or similarly, snowball options).</p>"},{"location":"lecture/03-Multi-Period/032-crr-model/","title":"Binomial Model aka Cox Ross Rubinstein Model","text":"<p>The Cox Ross Rubinstein model can litteraly be considered as the discrete time full analog to the Black-Scholes-Merton model. The dynamic is entirely determined by the result of a coin toss every day, hence the following model:</p>"},{"location":"lecture/03-Multi-Period/032-crr-model/#probability-model","title":"Probability Model","text":"<p>The space of coint toss sequences is given by \\(\\Omega = \\{\\omega = (\\omega_1, \\ldots, \\omega_T) : \\omega_t = \\pm 1\\}\\) where \\(\\omega=(\\omega_1, \\ldots, \\omega_T)\\) represents each sequence of \\(\\pm1\\) as result of the coin toss. As for the \\(\\sigma\\)-algebra of events we consider \\(\\mathcal{F}=2^\\Omega\\). We also consider a probability measure \\(P\\) such that \\(P[\\{\\omega\\}] &gt; 0\\) for every \\(\\omega\\).</p> <p>As for the information we consider the stochastic process \\(Y=(Y_t)_{t=1, \\ldots T}\\) given by</p> \\[ \\begin{equation*}   \\begin{split}     Y_t\\colon \\Omega &amp; \\longmapsto \\{-1, 1\\}\\\\               \\omega &amp; \\longrightarrow Y_t(\\omega) = \\omega_t =  \\text{result of coin toss at time }t   \\end{split} \\end{equation*} \\] <p>In other terms the stochastic process \\(Y\\) provides information about the result of the coin toss at each time. We therefore define the filtration</p> \\[ \\mathcal{F}_0 = \\{\\emptyset, \\Omega\\} \\quad \\text{and}\\quad \\mathcal{F}_t = \\sigma\\left( Y_s\\colon s\\leq t \\right) \\] <p>In other terms, \\(\\mathcal{F}_t\\) is the set of events which have been revealed by all coin tosses up to time \\(t\\). It can be shown that if \\(\\xi\\) is a \\(\\mathcal{F}_t\\)-measurable random variable, then this random variable only depends on the coin tosses up to time \\(t\\), that is </p> \\[ \\xi(\\omega) = \\xi( \\underbrace{\\omega_1, \\ldots, \\omega_t}_{\\text{Information up to $t$}}, \\underbrace{\\omega_{t+1}, \\ldots, \\omega_T}_{\\text{Information after $t$}} ) = \\xi( \\omega_1, \\ldots, \\omega_t ) \\]"},{"location":"lecture/03-Multi-Period/032-crr-model/#market-model","title":"Market Model","text":"<ul> <li> <p>Bank account \\(B=(B_t)_{t=0, \\ldots, T}\\) whith</p> \\[   B_0 = 1, \\quad \\text{and}\\quad B_t = B_{t-1}(1+r) = (1+r)^t \\] <p>for a fixed interest rate \\(r&gt;-1\\). Clearly, the bank account is predictable since the interest rate is constant.</p> </li> <li> <p>Single risky asset \\(S = (S_t)_{t=0, \\ldots, T}\\) where</p> \\[   S_0&gt;0 \\quad \\text{and}\\quad S_t = S_{t-1}\\left( 1+R_t\\right) \\] <p>where the returns of the stock \\(R=(R_t)_{t=1, \\ldots, T}\\) is a stochastic process given by</p> \\[   \\begin{align*}     R_t(\\omega) &amp; =      \\begin{cases}       u &amp; \\text{if }\\omega_t = 1\\\\       d &amp; \\text{if }\\omega_t = -1     \\end{cases} \\end{align*} \\] <p>where \\(-1&lt;d&lt;u\\) are constants. Clearly, \\(R_t\\) only depends on the result of the coin toss at time \\(t\\), which can also be seen from</p> \\[     R_t = u 1_{\\{Y_t = 1\\}} + d 1_{\\{Y_t = -1\\}} = (u-d)1_{\\{Y_t = 1\\}} +d \\] <p>showing that \\(S\\) is an adapted process.</p> </li> </ul>"},{"location":"lecture/03-Multi-Period/032-crr-model/#no-arbitrage-and-pricing-measure","title":"No arbitrage and Pricing Measure","text":"<p>This financial model is called the binomial model or Cox, Ross, and Rubinstein model (CRR for short).</p> <p>Proposition</p> <p>The CRR model is arbitrage-free if and only if \\(d &lt; r &lt; u\\). In this case, the CRR model is complete with unique pricing measure \\(P^\\ast\\) equivalent to \\(P\\). This risk pricing measure is characterized by the fact that the random variables \\(R_1, \\ldots, R_T\\) are iid with common distribution:</p> \\[   P^\\ast[R_t = u] = p = \\frac{r - d}{u - d}, \\quad t = 1, \\ldots, T \\] <p>Proof</p> <p>By the FTAP, arbitrage-free is equivalent to the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Under such \\(P^\\ast\\), the discounted price process is a martingale. In particular, it holds:</p> \\[   0 = E^\\ast\\left[ \\Delta X_t \\mid \\mathcal{F}_{t-1} \\right] = E^\\ast\\left[ X_{t-1} \\left( \\frac{1 + R_t}{1 + r} - 1 \\right) \\mid \\mathcal{F}_{t-1} \\right] = X_{t-1} E^\\ast\\left[ \\frac{R_t - r}{1 + r} \\mid \\mathcal{F}_{t-1} \\right] \\] <p>Since \\(X_{t-1} &gt; 0\\) and \\(R_t = (u-d)1_{\\{Y_t = 1\\}} +d\\), it follows that</p> \\[ r = E^\\ast[R_t \\mid \\mathcal{F}_{t-1}] = (u - d) P^\\ast\\left[ Y_t = 1 \\mid \\mathcal{F}_{t-1} \\right] + d \\] <p>Showing that</p> \\[ P^\\ast\\left[ Y_t = 1 \\mid \\mathcal{F}_t \\right] = \\frac{r - d}{u - d} \\] <p>for every \\(t = 0, \\ldots, T\\).</p> <p>From this relation, we conclude three facts:</p> <ul> <li>The conditional distribution of \\(P^\\ast\\) under \\(\\mathcal{F}_{t-1}\\), that is, \\(P^\\ast[\\cdot \\mid \\mathcal{F}_{t-1}]\\), is constant for every \\(t = 0, \\ldots, T-1\\).     Hence,     [       P^\\ast\\left[ Y_t = 1 \\mid \\mathcal{F}_t \\right] = P^\\ast\\left[ Y_t = 1 \\right] = P^\\ast\\left[ Y_1 = 1 \\right]     ]</li> <li> <p>Since \\(P^\\ast\\) is a probability measure equivalent to \\(P\\), it follows that</p> \\[   0 &lt; \\frac{r - d}{u - d} &lt; 1 \\] <p>That is, \\(d &lt; r &lt; u\\).</p> </li> <li> <p>The formula for the probability \\(P^\\ast\\) is uniquely determined, and therefore, if the market is arbitrage-free, it has to be complete.</p> </li> </ul> <p>As for the independence of \\(R\\), it follows readily from the definition of \\(P^\\ast\\).</p> <p>Remark</p> <p>Note that the distribution of the pricing measure \\(P^\\ast\\) is entirely given by \\(P^\\ast[R_t = u] = p\\). Indeed, since \\(\\{Y_t = 1\\} =\\{R_t=u\\}\\) as well as \\(\\{Y_t = -1\\} = \\{R_t = d\\}\\) it follows that \\((Y_1, \\ldots, Y_T)\\) are iid. Hence, for \\(\\omega = (\\omega_1, \\ldots, \\omega_T)\\) it holds that</p> \\[     \\begin{align*}       P^\\ast\\left[ \\{\\omega\\} \\right] &amp; = P^\\ast\\left[ Y_1 = \\omega_1, \\ldots, Y_T = \\omega_T \\right]\\\\       &amp; = P^\\ast\\left[ \\cap_{t=1}^T \\{Y_t = \\omega_t\\} \\right]\\\\       &amp; = \\prod_{t=1}^T P^\\ast[Y_t = \\omega_t] &amp; &amp; \\text{Independence of }Y_1, \\ldots, Y_T\\\\       &amp; = \\prod_{t=1}^T P^\\ast[Y_1 = \\omega_t] &amp; &amp; \\text{Identical distribution of }Y_1, \\ldots, Y_T\\\\        &amp; = p^l (1-p)^{T-l}     \\end{align*} \\] <p>where \\(l = \\# \\{t \\colon \\omega_t = 1\\}\\) is the number of \\(1\\) in the sequence of coin tosses \\(\\omega = (\\omega_1, \\ldots, \\omega_T)\\).</p> <p>Since the market is complete, we can therefore:</p> <ul> <li> <p>Price any European contingent claim \\(C\\) uniquely by means of</p> \\[   \\pi(C) = E^\\ast\\left[ \\frac{C}{(1 + r)^T} \\right] \\] </li> <li> <p>Replicate (or hedge) the claim by means of a strategy \\(\\eta\\) such that</p> \\[   \\pi(C) + \\sum_{s=1}^T \\eta_s \\Delta X_s = \\frac{C}{(1 + r)^T} \\] </li> </ul> <p>In particular, given the replicating strategy \\(\\eta\\), we can even provide the (discounted) price at any time by means of</p> \\[     V_t = \\pi(C) + \\sum_{s=1}^t \\eta_s \\Delta X_s = E^\\ast\\left[ \\frac{C}{(1 + r)^T} \\mid \\mathcal{F}_t \\right] \\] <p>Pricing (i.e., computing \\(\\pi(C)\\)) and Hedging (i.e., finding \\(\\eta\\)) are two of three (managing risk is a fundamental component) main activities of financial institutions engaging in derivative trading.</p> <p>Before any further assumptions, as for the price, since we have an explicit expression for \\(P^\\ast\\), it holds that</p> \\[ \\pi(C) = \\sum_{\\omega \\in \\Omega} \\frac{C(\\omega)}{(1+r)^T} P^\\ast[\\{\\omega\\}] = \\sum_{\\omega \\in \\Omega}\\frac{C(\\omega)}{(1+r)^T}p^{l(\\omega)}(1-p)^{T-l(\\omega)} \\] <p>where \\(l(\\omega) = \\# \\{t \\colon \\omega_t = 1\\}\\).</p> <p>Warning</p> <p>This simple expression that can be implemented easily programatically hides however a very important fact. The sum is processed over all possible paths of coin tosses, and the cardinality of which is equal to \\(2^T\\). Even with such a very simple market, if we consider one year maturity by daily trading, it amounts for \\(2^{260}\\) paths which largely outmatch any computational power. Hence, it is not efficiently implementable, and without further assumptions, this curse of dimensionality can only be overcome through Monte-Carlo methods, sampling a large number, though less than \\(2^{260}\\) of paths and approximating the expectation.</p>"},{"location":"lecture/03-Multi-Period/032-crr-model/#reducing-complexity-vanilla-derivatives","title":"Reducing Complexity: Vanilla Derivatives","text":"<p>Many of the derivatives are plain vanilla European options, that is derivatives which discounted value only depends on the last value of the underlying:</p> \\[ H = \\frac{C}{(1+r)^T} = h(S_T) \\] <p>where \\(h\\colon \\mathbb{R} \\to \\mathbb{R}\\). For instance \\(h(x) = (x-K)^+/(1+r)^T\\) the discounted profile of a call option. However this option can only take \\(T+1\\) values \\(S_0(1+u)^l(1+d)^{T-l}\\) for \\(l = 0, \\ldots, T\\) with each values corresponding to \\(C_T^l=T!/(l!(T-l)!)\\) different possible paths. The computation of the price at time \\(0\\) therefore simplifies to</p> \\[ \\begin{align*}   \\pi(C) &amp; = \\sum_{\\omega \\in \\Omega} H(\\omega)P^\\ast[\\{\\omega\\}]\\\\          &amp; = \\sum_{l=0}^T  h\\left(S_0 (1+u)^l(1+d)^{T-l}\\right) C_T^l p^l (1-p)^{T-l} \\end{align*} \\] <p>which turns the computation of the price from a \\(2^T\\) to a \\(T+1\\) sum.</p>"},{"location":"lecture/03-Multi-Period/032-crr-model/#dynamic-pricing","title":"Dynamic Pricing","text":"<p>A further particularity of those options, is that the value of the discounted portfolio can also be computed explicitely through a simple backward technique. This relies on the following mathematical result</p> <p>Proposition</p> <p>Let \\(X\\) and \\(Y\\) be two random variable where \\(X\\) is \\(\\mathcal{F}_t\\)-measurable and \\(Y\\) is independent of \\(\\mathcal{F}_t\\). Then for every function \\(h:\\colon \\mathbb{R} \\times \\mathbb{R} \\to \\mathbb{R}\\) it holds (modulo integrability)</p> \\[   E^{P^\\ast}\\left[ h(X, Y) |\\mathcal{F}_t \\right](\\omega) = v(X(\\omega)) \\] <p>where \\(v\\colon \\mathbb{R} \\to \\mathbb{R}\\) is a function defined as</p> \\[   v(x) = E^{P^\\ast}\\left[ h(x, Y) \\right] \\] <p>Remark</p> <p>This proposition basically says that since \\(Y\\) is independent of \\(\\mathcal{F}_t\\) and \\(X\\) is \\(\\mathcal{F}_t\\) measurable, then computing the conditional expectation corresponds to freezing \\(X(\\omega)\\) and computing the expectation. In not so adequate notations, </p> \\[   E^{P^\\ast}\\left[ h(X, Y) | \\mathcal{F}_t \\right](\\omega) = E^{P^\\ast}\\left[ h(x, Y) | x = X(\\omega) \\right] \\] <p>This allows us to state the discrete formulation of partial differential equation type for the portfolio value:</p> <p>Proposition</p> <p>For a european vanilla option \\(H = h(S_T)\\), it holds that that the discounted value of the hedging portfolio is equal to</p> \\[   V_t = v_t(S_t) \\] <p>where \\(v_t \\colon \\mathbb{R} \\to \\mathbb{R}\\) for \\(t=T, \\ldots, 0\\) is recursively defined as</p> \\[   \\begin{equation*}     \\begin{cases}       v_T(x)  = h(S_T)\\\\       \\\\       v_t(x)  = p v_{t+1}(x(1+u)) + (1-p)v_t(x(1+d)) &amp; \\text{for }t = T-1, \\ldots, 0     \\end{cases}   \\end{equation*} \\] <p>Proof</p> <p>By finite inverse induction.</p> <ul> <li>For \\(t=T\\) it holds that \\(V_t = H = h(S_T) = v_T(S_T)\\) by definition.</li> <li> <p>For \\(t=T-1\\), by the martingale property, it holds that \\(V_{T-1} = E^{P^\\ast}[V_T |\\mathcal{F}_{T-1}] = E^{P^\\ast}[v_T(S_T)|\\mathcal{F}_{T-1}]\\).     Now using the proposition above, since \\(S_{T-1}\\) is \\(\\mathcal{F}_{T-1}\\)-measurable and \\(R_T\\) is independent to \\(\\mathcal{F}_{T-1}\\) we get</p> \\[   \\begin{equation*}     V_T  = E^{P^\\ast}\\left[ v_T(S_{T-1}(1+R_T)) |\\mathcal{F}_{T-1} \\right] = v_{T-1}(S_{T-1})    \\end{equation*} \\] <p>for</p> \\[   \\begin{align*}     v_{T-1}(x) &amp; = E^{P^\\ast}\\left[ v_T(x (1+R_T)) \\right]\\\\                &amp; = E^{P^\\ast}\\left[ v_T(x(1+R_1)) \\right] &amp;&amp; R_1, \\ldots, R_T \\text{ are iid}\\\\                &amp; = pv_T(x(1+u)) + (1-p)v_T(x(1+d))   \\end{align*} \\] </li> </ul> <p>The next steps \\(T-2, \\ldots, 0\\) follows the same argumentation.</p>"},{"location":"lecture/03-Multi-Period/032-crr-model/#dynamic-hedging","title":"Dynamic Hedging","text":"<p>As for the second part of the job, hedging, we know that there exists a predictable strategy \\(\\eta = (\\eta_t)_{t=1, \\ldots, T}\\) that will hedge the claim. Again, in the setting of plain vanilla european option, these ones can be computed backwardly as soon as you computed the sequence of functions \\(v_0, \\ldots, v_T\\).</p> <p>Proposition</p> <p>For a european vanilla option \\(H= h(S_T)\\) the hedging strategy \\(\\eta = (\\eta_t)_{t=1, T}\\) is given by</p> \\[   \\eta_t = \\Delta_t(S_{t-1}) \\] <p>where \\(\\Delta_t \\colon \\mathbb{R} \\to \\mathbb{R}\\) for \\(t=1, \\ldots, T\\) are functions recursively computed as follows</p> \\[     \\displaystyle \\Delta_t(x) = (1+r)^t \\frac{v_t(x(1+u)) - v_t(x(1+d))}{x(1+u) - x(1+d)} \\] <p>Remark</p> <p>The function \\(\\Delta_t\\) is called the delta hedge in finance. The notation is a bit unfortunate in regards to our notation for difference, but is makes sense if you notice that this is the discrete version of the derivative of the portfolio value with respect to the underlying asset \\(\\partial v_t/\\partial S_t\\) coinciding with the Black and Sholes framework.</p> <p>Proof</p> <p>Let us consider a given time \\(1\\leq t\\leq T\\). The hedging strategy \\(\\eta = (\\eta_t)_{t=1, \\ldots, T}\\) is such that</p> \\[     V_{t} - V_{t-1} = \\eta_t (X_t - X_{t-1})  \\] <p>On the one hand, knowing \\(S_0, \\ldots, S_{t-1}\\), since \\(\\eta_t\\) is predictable the right hand side can only take two values</p> \\[   \\begin{align*}     \\eta_t (X_t - X_{t-1}) &amp; = \\displaystyle \\eta_t \\frac{S_{t-1}}{(1+r)^t}\\left( R_t - r  \\right)     \\\\     &amp; =\\displaystyle \\eta_t \\frac{S_{t-1}}{(1+r)^t}       \\begin{cases}         u-r &amp; \\text{if } \\omega_t = 1\\\\         \\\\         d-r &amp; \\text{if } \\omega_{t} = -1       \\end{cases}   \\end{align*} \\] <p>On the other hand, since \\(V_t = v_t(S_t) = v_t(S_{t-1}(1+R_t))\\) as well as \\(V_{t-1} = v_{t-1}(S_{t-1}) = p v_t(S_{t-1}(1+u)) + (1-p) v_t(S_{t-1}(1+d))\\), it follows that the left hand side can only take two values given \\(S_0, \\ldots, S_{t-1}\\).</p> \\[   \\begin{align*}     V_t - V_{t-1} &amp; = \\displaystyle v_t(S_{t-1}(1+R_t)) - p v_t(S_{t-1}(1+u)) - (1-p) v_t(S_{t-1}(1+d))\\\\     \\\\                   &amp; = \\displaystyle     \\begin{cases}      (1-p) \\left(v_t(S_{t-1}(1+u)) - v_t(S_{t-1}(1+d))\\right) &amp; \\text{if }\\omega_t =1\\\\     \\\\      p \\left(v_t(S_{t-1}(1+u)) - v_t(S_{t-1}(1+d))\\right) &amp; \\text{if }\\omega_t =-1\\\\     \\end{cases}   \\end{align*} \\] <p>Puting these two equation together and solving for \\(\\eta_t\\), knowing that \\(p = (r-d)/(u-d)\\) yields that knowing \\(S_0, \\ldots, S_{t-1}\\) we have</p> \\[   \\eta_t = (1+r)^t \\frac{v_t(S_{t-1}(1+u)) - v_t(S_{t-1}(1+d))}{S_{t-1}(1+u) - S_{t-1}(1+d)} = \\Delta_t(S_{t-1}) \\] <p>Remark</p> <p>The derivation of the functions \\(v_t\\) and \\(\\Delta_t\\) for \\(t=0, \\ldots, T\\) can be extended to the general case of options depending on the full path, that is with discounted formulation \\(H = h(S_0, \\ldots, S_T)\\) for some function \\(h:\\mathbb{R}^{T+1} \\to \\mathbb{R}\\) following the same argumentation where</p> \\[     \\begin{equation*}         \\begin{cases}             v_T(x_0, \\ldots, x_{T}) &amp; = h(x_0, \\ldots, x_T)\\\\             \\\\             v_t(x_0, \\ldots, x_t) &amp; = p v_{t+1}(x_0, \\ldots, x_{t}, x_t(1+u)) + (1-p)v_{t+1}(x_0, \\ldots, x_{t}, x_t(1+d))         \\end{cases}     \\end{equation*} \\] <p>as well as</p> \\[     \\Delta_t(x_0, \\ldots, x_{t-1}) = (1+r)^t \\frac{v_{t}(x_0, \\ldots, x_{t-1}, x_{t-1}(1+u)) - v_{t}(x_0, \\ldots, x_{t-1}, x_{t-1}(1+d))}{x_{t-1}(1+u) - x_{t-1}(1+d)} \\] <p>Though those expression are valid and simple to write down mathematically, to solve those numerically hits the problem of the curse of dimensionality, since those depends on every possible combinations of paths for the price \\((x_0, \\ldots, x_t)\\) at each time \\(t\\), which amounts to \\(2^T\\).</p>"},{"location":"lecture/03-Multi-Period/032-crr-model/#implementation","title":"Implementation","text":"<p>The implementation in a binomial model(1) for plain vanilla options is classical and relatively straightforward after reformulating the problem in terms of matrices. </p> <ol> <li>the BS model turns into resolving pde which unless you have an explicit expression turns into finite difference methods or alike kinds which are similar.</li> </ol> <p>The main computational issue is to derive \\(v_t(x)\\) for every attainable \\(x=S_t\\) and every \\(t\\). To do so as in numerical methods for PDE we consider matrix/vector notations(1) of values</p> <ol> <li>In terms of computer memory and efficiency, this certainly not the best approach. But in that case you don't use python but rather low level programming languages like rust or C and look at structures like Btreemaps and the likes. In python <code>numpy</code> does just fine and the dimension is no longer an issue for modern computers.</li> </ol> <p>We will store the value of the portfolio and the delta hedging into a diagonal matrices \\((T+1)\\times (T+1)\\) and \\(T\\times T\\) with column vectors \\(\\boldsymbol{v}_t\\) in \\(\\mathbb{R}^{T+1}\\) and \\(\\boldsymbol{\\Delta}_t\\) as follows</p> \\[ \\begin{equation*} \\boldsymbol{v}_t =  \\begin{bmatrix}     v_t(S_0(1+u)^t)\\\\     v_t(S_0(1+u)^{t-1}(1+d))\\\\     \\vdots      \\\\     v_t(S_0(1+d)^t)\\\\     0     \\\\     \\vdots     \\\\     0 \\end{bmatrix} \\quad \\text{and}\\quad \\boldsymbol{\\Delta}_t =  \\begin{bmatrix} \\Delta_t(S_0(1+u)^{t-1})\\\\ \\Delta_t(S_0(1+u)^{t-2}(1+d))\\\\ \\vdots \\\\ \\Delta_t(S_0(1+d)^{t-1}) \\\\ 0 \\\\ \\vdots 0 \\end{bmatrix} \\end{equation*} \\] <p>for \\(t=0, \\ldots, T\\).  and we apply the recursion up to \\(0\\). Once \\(\\boldsymbol{v}_t\\) are calculated, and stored, the heding strategy can be computed directly.</p> <pre><code>import numpy as np\n\n# Computation of the discounted portfolio value\n# claim is the function C = f(S_T)\n# not efficient in this form (python is bad with loops) but clear in terms of loops\n# does not verify if -1 &lt; d&lt; r&lt; u!!!\ndef portfolio_value(claim, S0, r, u, d, T):\n    # value of the portfolio\n    v = np.zeros((T+1, T+1))\n    # stock prices tree\n    s = np.zeros((T+1, T+1))\n    # hedging strategy\n    delta = np.zeros((T, T))\n\n    # initialize the stock tree\n    s[0, 0] = S0\n    for t in range(1, T+1):\n        for l in range(t+1):\n            s[t, j] = S0 * (1+u)**(t-l) * (1+d)**l\n\n    # risk neutral probability\n    p = (r - d)/(u - d)\n\n    # initialization of the portfolio value at time T\n    v[T, :] = claim(s[T,:]) / (1+r) ** T\n\n    # Compute backwardly the discounted portfolio value and the hedging\n    for t in range(T-1, -1, -1):\n        for l in range(t+1):\n            vup = v[t+1, l]\n            vdown = v[t+1, l+1]\n            sup = s[t, l] * (1+u)\n            sdown = s[t,l] * (1+d)\n            # delta hedging\n            delta[t, l] = (1+r) ** t * (vup - vdown) / (sup - sdown)\n            # portfolio value\n            v[t,j] = p * vup + (1-p) * vdown\n\n    return {\n        \"Stock\": s,\n        \"portfolio\": v,\n        \"delta\": delta\n    }\n</code></pre>"},{"location":"lecture/03-Multi-Period/033-exotic-options/","title":"Exotic Options","text":"<p>We saw in the previous simple binomial model that for options that depends on the path, the computational complexity increases exponentially when derivatives can depends on the path. This is for instance the case for exotic options such as asian options and barrer options:</p> \\[ C^{call}_{asian} = \\left( \\frac{1}{T}\\sum_{t=1}^T S_t - K \\right)^+ \\quad \\text{or}\\quad C^{call}_{up\\&amp;out} = \\left( S_T - K \\right)^+ 1_{\\{S_t &lt; B \\colon t=0, \\ldots, T\\}} \\] <p>This usually would require Monte Carlo methods which are less accurate and slower to compute. However, in the case of barrer option, a mathematical result known as the relexion principle will reduce the dimension of the integration from \\(T+1\\) to \\(2\\) which does not depends in complexity on the number of steps and is easy to compute.</p> <p>The key to price barrier options is to know the joint distribution of \\(S_T\\) and the running maximum \\(\\overline{S}_T\\). In order to keep the formulas easy, we make the following assumption:</p> \\[ 1+u=\\frac{1}{1+d} \\] <p>In this case, the price process takes the form:</p> \\[ S_t=S_0\\left( 1+u \\right)^{Z_t} \\] <p>where the stochastic process \\(Z=(Z_t)_{0\\leq t\\leq T}\\) is given by:</p> \\[ Z_0=0, \\quad \\text{and} \\quad Z_t=\\sum_{s=1}^t Y_s \\] <p>which is the so-called random walk. We also consider that \\(P\\) is the uniform distribution, that is:</p> \\[ P\\left[ \\{\\omega\\} \\right]=\\frac{1}{\\# \\Omega} \\] <p>Under this measure, the random variables \\(Y_t\\) are independent, and therefore, it holds:</p> \\[ P[Z_t=k]= \\begin{cases} 2^{-t} C_t^{(t+k)/2} &amp; \\text{if } t+k \\text{ is even}, \\\\\\\\ 0 &amp; \\text{otherwise}. \\end{cases} \\] <p>Denoting by:</p> \\[ \\overline{Z}_t=\\sup_{s\\leq t}Z_s \\] <p>the following reflection principle holds:</p> <p>Proposition: Reflexion Principle</p> <p>For all \\(k\\geq 1\\) and \\(l\\geq 0\\), it holds:</p> \\[   P\\left[ \\overline{Z}_T \\geq k \\text{ and } Z_T=k-l\\right]=P[Z_T=k+l] \\] <p>and</p> \\[   P\\left[ \\overline{Z}_T=k \\text{ and } Z_T=k-l \\right]=\\frac{k+l+1}{T+1}2P[Z_{T+1}=1+k+l] \\] <p>Proof</p> <p>Define \\(\\tau(\\omega)=\\inf\\{t\\colon Z_t(\\omega)=k\\}\\wedge T\\) and define:</p> \\[ f(\\omega)=(\\omega_1,\\ldots, \\omega_{\\tau(\\omega)}, -\\omega_{\\tau(\\omega)+1},\\ldots,-\\omega_T) \\] <p>The trajectories of \\(Z(\\omega)\\) and \\(Z(f(\\omega))\\) coincide up to the moment where \\(Z(\\omega)\\) reaches for the first time the level \\(k\\). From there on, the trajectories are mirrored with respect to the level \\(k\\). Since the random variables \\(Y_t\\) are independent of each other, it follows that \\(f\\) is a bijection between the set:</p> \\[   \\{\\omega \\in \\Omega\\colon \\overline{Z}_T(\\omega)\\geq k \\text{ and } Z_T(\\omega)=k-l\\} \\] <p>and the set:</p> \\[   \\{\\omega \\in \\Omega\\colon \\overline{Z}_T(\\omega)\\geq k \\text{ and } Z_T(\\omega)=k+l\\}=\\{\\omega \\in \\Omega \\colon Z_T=k+l\\} \\] <p>Since \\(P\\) is uniformly distributed, it follows that the first relation of the proposition holds.</p> <p>As for the second relation, if \\(T+k+l\\) is not even, suppose therefore that \\(j=(T+k+l)/2\\) is an integer. Applying the first relation, it holds:</p> \\[   P\\left[ \\overline{Z}_T=k;Z_T=k-l \\right] = P\\left[ Z_T=k+l \\right]-P\\left[ Z_T=k+l+2 \\right] = 2^{-T}C_T^j - 2^{-T} C_{T}^{j+1} \\] <p>which simplifies to:</p> \\[   P\\left[ \\overline{Z}_T=k;Z_T=k-l \\right]=\\frac{k+l+1}{T+1}2P[Z_{T+1}=1+k+l] \\] <p>The rest of the proof follows analogously.</p> <p>We can derive the same kind of formulas if we replace \\(P\\) by the equivalent martingale measure \\(P^\\ast\\). In that case, it holds:</p> \\[ P^\\ast\\left[ Z_t=k \\right]= \\begin{cases} p^{(t+k)/2}(1-p)^{(t-k)/2} C_{t}^{(t+k)/2} &amp; \\text{if } t+k \\text{ is even}, \\\\\\\\ 0 &amp; \\text{otherwise}. \\end{cases} \\] <p>Proposition</p> <p>For all \\(k\\geq 1\\) and \\(l\\geq 0\\), it holds:</p> \\[   P^\\ast\\left[ \\overline{Z}_T \\geq k \\text{ and } Z_T=k-l\\right]=\\left( \\frac{1-p}{p} \\right)^lP^\\ast[Z_T=k+l]=\\left( \\frac{p}{1-p} \\right)^kP^\\ast[Z_T=-k-l] \\] <p>and</p> \\[   P^\\ast\\left[ \\overline{Z}_T=k \\text{ and } Z_T=k-l \\right]=\\frac{1}{p}\\left( \\frac{1-p}{p} \\right)^l\\frac{k+l+1}{T+1}P^\\ast[Z_{T+1}=1+k+l]   =\\frac{1}{1-p}\\left( \\frac{p}{1-p} \\right)^k\\frac{k+l+1}{T+1}P^\\ast[Z_{T+1}=-1-k-l]. \\] Proof <p>First, inspection shows that:</p> \\[ \\frac{dP^\\ast}{dP}=2^T p^{\\frac{Z_T+T}{2}}(1-p)^{\\frac{T-Z_T}{2}}. \\] <p>From the density formula, we get:</p> \\[ P^\\ast\\left[ \\overline{S}_T \\geq k \\text{ and } Z_T=k-l\\right]=2^T p^{(T+k-l)/2}(1-p)^{(T+l-k)/2}P\\left[ \\overline{S}_T \\geq k \\text{ and } Z_T=k-l\\right]. \\] <p>As well as:</p> \\[ P\\left[ Z_T=k+l\\right]=2^T p^{-(T+l+k)/2}(1-p)^{-(T-k-l)/2}P^\\ast[Z_T=k+l]. \\] <p>Which combine with:</p> \\[ P\\left[ \\overline{S}_T \\geq k \\text{ and } Z_T=k-l\\right]=P[Z_T=k+l]. \\] <p>This yields the first relation, the second one being analogous.</p> <p>Example: Up &amp; In Call Option</p> <p>Let:</p> \\[ C^{call}_{up\\&amp;in}= \\begin{cases} (S_T-K)^+ &amp; \\text{if } \\max_{0\\leq t\\leq T}S_t=\\overline{S}_T \\geq B, \\\\\\\\ 0 &amp; \\text{otherwise}. \\end{cases} \\] <p>Where \\(K\\) is the strike and \\(B&gt;S_0\\vee K\\) is a barrier. Note that:</p> \\[ S_t=S_0(1+u)^{Z_t}, \\quad \\text{and} \\quad \\overline{S}_t=S_0(1+u)^{\\overline{Z}_t}. \\] <p>It holds:</p> \\[ \\pi(C)=\\frac{1}{(1+r)^T} E^\\ast\\left[C^{call}_{up\\&amp;in}\\right]. \\] <p>However:</p> \\[ E^\\ast\\left[C^{call}_{up\\&amp;in}\\right]= E^\\ast\\left[ (S_T-K)^+;\\overline{S}_T\\geq B \\right]= E^\\ast\\left[ (S_T-K)^+;S_T\\geq B \\right] + E^\\ast\\left[ (S_T-K)^+;\\overline{S}_T\\geq B;S_T&lt;B \\right]. \\] <p>The first expectation can be entirely computed using the distribution of \\(P^\\ast\\) since it only depends on the distribution of \\(S_T\\). As for the second expectation, without loss of generality, let \\(B=S_0(1+u)^k\\) and using our reflection principle:</p> \\[ E^\\ast\\left[ (S_T-K)^+;\\overline{S}_T\\geq B;S_T&lt;B \\right]= \\sum_{l\\geq 1} E^\\ast\\left[ (S_T-K)^+;\\overline{S}_T\\geq B;Z_T=k-l \\right]. \\] <p>This becomes:</p> \\[   \\begin{align*}     \\sum_{l\\geq 1}\\left( S_0(1+u)^{k-l}-K \\right)^+ P^\\ast\\left[ \\overline{Z}_T \\geq k \\text{ and } Z_T=k-l\\right]     &amp;=\\sum_{l\\geq 1}\\left( S_0(1+u)^{k-l}-K \\right)^+\\left( \\frac{p}{1-p} \\right)^kP^\\ast[Z_T=-k-l]     \\\\     &amp; =\\left( \\frac{p}{1-p} \\right)^k(1+u)^{2k}\\sum_{l\\geq 1}\\left( S_0(1+u)^{-k-l}-\\tilde{K} \\right)^+P^\\ast[Z_T=-k-l]   \\end{align*} \\] <p>where \\(\\tilde{K}=K(1+u)^{-2k}=K(S_0/B)^2\\). Hence, it follows that:</p> \\[   \\pi(C)=\\frac{1}{(1+r)^T} \\left( E^\\ast\\left[ (S_T-K)^+;S_T\\geq B \\right] + \\left( \\frac{p}{1-p} \\right)^k\\left( \\frac{B}{S_0} \\right)^2E^\\ast\\left[ (S_T-\\tilde{K})^+;S_T&lt;B \\right] \\right). \\] <p>Plugging in this distribution yields the explicit formula:</p> \\[ \\pi(C)=\\frac{1}{(1+r)^T} \\left[ \\sum_{n=0}^{n_k}\\left( S_0(1+u)^{T-2n}-K \\right)^+ p^{T-n}(1-p)^n C_{T}^{T-n} + \\left( \\frac{p}{1-p} \\right)^k\\left( \\frac{B}{S_0} \\right)^2 \\sum_{n=n_k+1}^T \\left( S_0(1+u)^{T-2n}-\\tilde{K} \\right)^+p^{T-n}(1-p)^n C_T^{T-n} \\right]. \\]"},{"location":"lecture/03-Multi-Period/034-american-options/","title":"American Options","text":"<p>So far, even if the outcome of European contingent claims may depend on the sequence of events previous to the maturity, the contract is settled for a given time horizon. In American type of contingent claim, the buyer can claim the payoff at any time before the settlement.</p> <p>Definition</p> <p>An American contingent claim is a non-negative adapted stochastic process:</p> \\[ C=(C_t)_{0\\leq t\\leq T}. \\] <p>The value \\(C_t(\\omega)\\) represents the outcome that a buyer can claim if he/she exercises at time \\(t\\) in state \\(\\omega\\).</p> <p>Example</p> <p>The most classical example of American contingent claims are the American call and put options:</p> \\[ C_t^{call}=\\left( S_t^i-K \\right)^+ \\quad \\text{and} \\quad C_t^{put}=\\left( K-S_t^i \\right)^+, \\] <p>for \\(t=0,\\ldots, T\\).</p> <p>Remark</p> <p>Note that a European contingent claim \\(C\\) can be viewed as a special case of an American one. Indeed, it would correspond to the stochastic process:</p> \\[ C_t= \\begin{cases} 0 &amp; \\text{if } t=0,\\ldots, T-1, \\\\\\\\ C &amp; \\text{if } t=T. \\end{cases} \\]"},{"location":"lecture/03-Multi-Period/034-american-options/#hedging-capital-for-the-seller","title":"Hedging Capital for the Seller","text":"<p>We first consider the problem of a hedging strategy for the seller of an American contingent claim \\(C\\). Hereby, we denote by \\(H\\) the discounted contingent process, that is:</p> \\[ H_t=\\frac{C_t}{B_t}, \\quad t=0,\\ldots, T. \\] <p>Warning</p> <p>We suppose throughout that the financial market is arbitrage-free and, even more, complete. This means there exists only one pricing measure \\(P^\\ast\\) equivalent to \\(P\\).</p> <p>We want to compute the minimal amount of capital \\(U_t\\) that the seller at time \\(t\\) should have in order to pay the buyer of the contingent claim in case this person exercises their claim. We make this computation backward:</p> <ul> <li> <p>Time \\(T\\):     Suppose that at time \\(T\\), the buyer did not exercise its claim previously.     Then the discounted amount of capital needed to satisfy the buyer is exactly:</p> \\[ U_T=H_T \\] </li> <li> <p>Time \\(T-1\\):     Suppose that we are at time \\(T-1\\). We face two situations.</p> <p>Either the buyer decides to exercise now, and we need at least:</p> \\[ U_{T-1} \\geq H_{T-1} \\] <p>Or it decides to wait another time period, and we have to hedge against the capital we need in the next period \\(U_T\\). Since the market is complete with a value \\(E^{P^\\ast}[U_T|\\mathcal{F}_{T-1}]\\) at time \\(T-1\\) I can find a strategy \\(\\boldsymbol{\\eta}_T\\) which will replicate \\(U_T\\), that is</p> \\[     E^{P^\\ast}[U_T |\\mathcal{F}_{T-1}] + \\boldsymbol{\\eta}_T\\cdot \\Delta \\boldsymbol{X}_T = U_T \\] <p>It follows that the capital required today to hedge this case must be:</p> \\[     U_{T-1} \\geq E^{P^\\ast}\\left[ U_T |\\mathcal{F}_{T-1} \\right] \\] <p>Altogether, this means:</p> \\[ U_{T-1} = \\max\\left\\{ H_{T-1}, E^{\\ast}\\left[ U_T | \\mathcal{F}_{T-1} \\right] \\right\\} = H_{T-1} \\vee E^{P^\\ast}\\left[ U_T | \\mathcal{F}_{T-1} \\right]. \\] </li> <li> <p>Time \\(t \\leq T-1\\):     The same argumentation means we have to reserve at least:</p> \\[     U_t \\geq H_t, \\] <p>as well as the minimum amount of capital \\(U_{t+1}\\) needed from tomorrow in expectation under the pricing measure, that is:</p> \\[ U_t \\geq E^{P^\\ast}\\left[ U_{t+1} | \\mathcal{F}_t \\right]. \\] <p>Altogether, it follows that:</p> \\[ U_t = \\max\\left\\{ H_t, E^{P^\\ast}\\left[ U_{t+1} | \\mathcal{F}_t \\right] \\right\\} = H_t \\vee E^{P^\\ast}\\left[ U_{t+1} | \\mathcal{F}_t \\right]. \\] </li> </ul> <p>This recursive scheme is called the Snell Envelope.</p> <p>Definition: The Snell Enveloppe</p> <p>Let \\(H\\) be an adapted process, \\(P^\\ast\\)-integrable. The Snell Envelope of \\(H\\) is defined inverse recursively as follows:</p> \\[ \\begin{equation*}     \\begin{cases}         U_T =H_T\\\\         \\\\         U_t=H_t \\vee E^{P^\\ast}\\left[ U_{t+1} | \\mathcal{F}_t \\right] &amp;\\text{for } t=T-1,\\ldots, 0.     \\end{cases} \\end{equation*} \\] <p>The Snell envelope satisfies the following inequality:</p> \\[ \\begin{align*}    E^{P^\\ast}\\left[ U_{t+1} | \\mathcal{F}_t \\right] &amp; \\leq  H_t \\vee E^{P^\\ast}\\left[ U_{t+1} | \\mathcal{F}_t \\right] \\\\       &amp; = U_t \\end{align*} \\] <p>Processes satisfying this inequality are called super-martingales:</p> <p>Definition: Super/Sub Martingales</p> <p>A process \\(X\\) is called a \\(P^\\ast\\)-super-martingale if:</p> <ol> <li>\\(X\\) is adapted;</li> <li>\\(X\\) is \\(Q\\)-integrable;</li> <li>\\(E^{P^\\ast}[X_{t+1}|\\mathcal{F}_t] \\leq X_t\\) for every \\(t=0,\\ldots,T-1\\).</li> </ol> <p>A process \\(X\\) is called a \\(Q\\)-sub-martingale if \\(-X\\) is a \\(Q\\)-super-martingale.</p> <p>The Snell envelope is an example of \\(P^\\ast\\)-super-martingale with particular property</p> <p>Proposition</p> <p>Let \\(H\\) be an adapted and \\(P^\\ast\\)-integrable process. The Snell envelope \\(U\\) of \\(H\\) is a \\(P^\\ast\\)-super-martingale and the smallest \\(P^\\ast\\)-super-martingale among those dominating \\(H\\). That is, if \\(V\\) is a \\(P^\\ast\\) super-martingale such that \\(V_t \\geq H_t\\) for all \\(t\\), then \\(V\\geq U\\).</p> <p>Proof</p> <p>From the definition of \\(U\\), it follows immediately that \\(U\\) is a \\(P^\\ast\\)-super-martingale. Let \\(V\\) be another \\(P^\\ast\\)-super-martingale such that \\(V_t \\geq H_t\\) for every \\(t\\). By backward induction we show that \\(V_t \\geq U_t\\).</p> <ul> <li> <p>For \\(t = T\\), by definition we have \\(V_T \\geq H_T = U_T\\)</p> </li> <li> <p>For \\(t = T-1\\), we have</p> <ul> <li>\\(V_{T-1} \\geq H_{T-1}\\) since \\(V\\) dominates \\(H\\)</li> <li>\\(V_{T-1}\\geq E^{P^\\ast}[V_T|\\mathcal{F}_{T-1}] = E^{P^\\ast}[U_T|\\mathcal{F}_{T-1}]\\) since \\(V\\) is a super martingale and \\(V_T \\geq U_T\\).</li> </ul> <p>All together it follows that \\(V_{T-1}\\geq H_{T-1}\\vee E^{P^\\ast}[U_T|\\mathcal{F}_{T-1}] = U_{T-1}\\).</p> </li> </ul> <p>The argumentation follows the same logic for every other step.</p> <p>Example</p> <p>Consider the CRR model where the American contingent claim is path-independent, that is:</p> \\[ H_t = h_t(S_t), \\] <p>for some functions \\(h_t:\\mathbb{R}\\to \\mathbb{R}\\). This is particularly the case for American put and call options since \\(S^0\\) does not depend on the states \\(\\omega \\in \\Omega\\). The American option scheme for the computation of the Snell envelope \\(U_t=u_t(S_t)\\) reads as follows:</p> \\[   u_T(x)=h_T(x), \\quad \\text{and} \\quad u_t(x)= h_t(x) \\vee \\left( u_{t+1}(x(1+u) )p + u_{t+1}(x(1+d))(1-p) \\right), \\] <p>for \\(t=0,\\ldots, T-1\\), where \\(p=(r-d)/(u-d)\\).</p>"},{"location":"lecture/03-Multi-Period/034-american-options/#execution-time-for-the-buyer","title":"Execution Time for the Buyer","text":"<p>The buyer of an American claim is no longer a passive owner of a contract for which he waits until the end of the period the result of the outcome. He can also strategically decide in any state \\(\\omega\\) to exercise its contract at a time \\(\\tau(\\omega)\\). In general, this stopping strategy is a set of conditions which triggered, yields the exercise of the claim. However the triggering conditions whether to stop or not at time \\(t\\) should only rely on the available information at time \\(t\\).</p> <p>Definition</p> <p>A stopping time is a random variable \\(\\tau:\\Omega \\to \\{0,1,\\ldots, T\\}\\cup\\{\\infty\\}\\) such that \\(\\{\\tau =t\\} = \\{\\omega \\in \\Omega\\colon \\tau(\\omega)=t\\}\\) is in \\(\\mathcal{F}_t\\) for every \\(0\\leq t\\leq T\\).</p> <p>In other terms, \\(\\{ \\tau=t\\}\\) represents the event on which the buyer will decide to exercise its American contingent claim. The event \\(\\{\\tau=\\infty\\}\\) represents the event where the triggering conditions have not been met before the time horizon, and therefore the buyer will exercise it at time \\(T\\).</p> <p>Remark</p> <p>Note that the following facts hold true (see math suplement on processes):</p> <ul> <li>Deterministic times are stopping times:* The constant random variable \\(\\tau(\\omega)=t\\) for every \\(\\omega\\) and a given \\(t\\) is a stopping time;</li> <li>A random variable \\(\\tau:\\Omega \\to \\{0,1,\\ldots,T\\}\\) is a stopping time if and only if \\(\\{\\tau\\leq t\\}\\) is in \\(\\mathcal{F}_t\\) for every \\(t=0,\\ldots, T\\).</li> <li>If \\(\\tau\\) is a stopping time, then \\(\\{t\\leq \\tau\\} = \\{\\tau \\leq t-1\\}^c\\) is in \\(\\mathcal{F}_{t-1}\\) for every \\(t=1,\\ldots, T\\);</li> <li>If \\(\\sigma\\) and \\(\\tau\\) are two stopping times, then so are \\(\\sigma \\vee \\tau\\), \\(\\tau\\wedge \\sigma\\). In particular \\(\\tau \\wedge t\\).</li> </ul> <p>Example</p> <p>Let \\(S\\) be an adapted process, for instance the price evolution of an asset. Given a threshold \\(c\\), the random variable</p> \\[     \\tau(\\omega)=\\inf\\left\\{ t\\colon S_t(\\omega)\\geq c \\right\\} \\] <p>is a stopping time.</p> Proof <p>It holds that</p> \\[   \\begin{align*}     \\{\\tau \\leq t\\} &amp; = \\left\\{\\omega \\in \\Omega\\colon S_s(\\omega) \\geq c \\text{ for some }0 \\leq s\\leq t\\right\\}\\\\                     &amp; = \\underbrace{\\cup_{s=0}^t \\underbrace{\\{S_s \\geq t\\}}_{\\in \\mathcal{F}_s \\subseteq \\mathcal{F}_t}}_{\\in \\mathcal{F}_t}   \\end{align*} \\] <p>Definition</p> <p>Let \\(S\\) be a stochastic process and \\(\\tau\\) a stopping time. We denote by \\(S^\\tau\\) the stopped process</p> \\[     \\begin{equation*}       S_t^\\tau(\\omega)=S_{t\\wedge \\tau(\\omega)}(\\omega) =       \\begin{cases}         S_t(\\omega) &amp;\\text{if }t&lt; \\tau(\\omega)\\\\         S_{\\tau(\\omega)}(\\omega) &amp; \\text{if }\\tau(\\omega)\\leq t       \\end{cases}     \\end{equation*} \\] <p> </p> <p>Theorem: Doob's Optional Sampling</p> <p>Let \\(M\\) be an adapted process and \\(Q\\) a probability measure such that \\(M_t\\) is \\(Q\\)-integrable for all \\(t=0,\\ldots,T\\). The following assertions are equivalent:</p> <ol> <li>\\(M\\) is a \\(Q\\)-martingale;</li> <li>For every stopping time \\(\\tau\\), the process \\(M^\\tau\\) is a martingale;</li> </ol> Proof <p>As for 1. implies 2, we already know that if \\(M\\) is a martingale and \\(\\eta = (\\eta_t)_{t=1, \\ldots, T}\\) is a predictable process, then the portfolio</p> \\[   V_t = V_0 + \\sum_{s=1}^t \\eta_s (M_s - M_{s-1}) \\] <p>is a martingale. Taking the portfolio \\(V_0 = M_0\\) and the strategy</p> \\[   \\begin{equation*}    \\eta_t = 1_{\\{t\\leq \\tau\\}} = \\begin{cases}     1 &amp; \\text{if }t\\leq \\tau\\\\     0 &amp; \\text{if }t&gt;\\tau   \\end{cases}   \\end{equation*} \\] <p>where you buy and hold \\(M\\) until time \\(\\tau\\), it follows that \\(\\eta\\) is predictable since \\(\\{t\\leq \\tau\\}=\\{\\tau \\leq t-1\\}^c\\) is in \\(\\mathcal{F}_{t-1}\\). Furthermore, by definition </p> \\[   \\begin{equation*}     V_t = \\begin{cases}       M_t &amp; \\text{if }t&lt; \\tau\\\\       M_\\tau &amp; \\text{if }\\tau \\leq t     \\end{cases}     = M_{t\\wedge \\tau} = M^\\tau_t   \\end{equation*} \\] <p>showing that \\(M^\\tau\\) is a martingale.</p> <p>As for 2. implies 1., it is immediate by considering the stopping time \\(\\tau = T\\).</p> <p>Remark</p> <p>Note that if \\(\\eta\\) is a positive predictable process and \\(M\\) is a super-/sub-martingale, then it is easy to show that the portfolio \\(V_t = V_0 + \\sum_{s=1}^t\\eta_s (M_s - M_{s-1})\\) is a super-/sub-martingale. It follows from the proof that Doob's optional sampling theorem also holds for super-/sub-martingales.</p> <p>Concerning our buyer of an American option. He will choose its exercise strategy among the following set</p> \\[     \\mathcal{T}=\\left\\{ \\tau\\colon \\tau \\text{ stopping time with } \\tau \\leq T \\right\\} \\] <p>Suppose now that the goal of the buyer is to maximize the expectation of its outcome under the pricing measure \\(P^\\ast\\), he therefore faces the following optimization problem</p> \\[     \\max\\left\\{ E^{\\ast}\\left[ H_{\\tau} \\right]\\colon \\tau \\in \\mathcal{T}\\right\\} \\] <p>Its goal is therefore to find an optimal stopping time \\(\\tau^\\ast\\) such that</p> \\[ E^\\ast\\left[ H_{\\tau^\\ast}  \\right] \\geq E^{\\ast}\\left[ H_{\\tau} \\right] \\] <p>for any other stopping strategy \\(\\tau\\).</p> <p>Remark</p> <p>Note that such a problem even if intuitive is highly non trivial. Indeed, the maximization is done among the set of possible stopping times which is usually infinite dimensional and difficult to describe or parametrize. Secondly, the optimization function \\(\\tau \\mapsto E^{\\ast}[H_{\\tau}]\\) is nothing close to be something like convex or even smooth (smooth in which sense). The classical optimization theory here do not apply at all.</p> <p>We start by showing that the optimization problem from the buyer's side is always smaller than the minimum hedging capital for the seller.</p> <p>Proposition</p> <p>For any stopping time \\(\\tau\\) in \\(\\mathcal{T}\\), it holds</p> \\[     U_0 \\geq E^\\ast\\left[ H_{\\tau} \\right] \\] <p>In particular,</p> \\[     \\underbrace{U_0}_{\\text{Seller's minimum hedging capital}} \\geq \\underbrace{\\sup \\left\\{ E^\\ast\\left[ H_\\tau \\right] \\colon \\tau \\in \\mathcal{T} \\right\\}}_{\\text{Buyer's maximal expected revenue}} \\] <p>Proof</p> <p>Let \\(\\tau\\) in \\(\\mathcal{T}\\) be any stopping time strategy for the buyer. We know that the Snell envelope is a super-martingale such that \\(U_t\\geq H_t\\) for every \\(t\\). In particular, on the one hand, it holds that \\(U_\\tau \\geq H_\\tau\\) and therefore \\(E^\\ast[U_\\tau] \\geq E^\\ast[H_\\tau]\\). On the other hand, \\(U^\\tau\\) is also a super-martingale due to Doob's optional sampling theorem. Hence \\(U_0 \\geq E^\\ast\\left[ U_T^\\tau \\right] = E^\\ast\\left[ U_{T\\wedge \\tau} \\right]=E^\\ast[U_\\tau]\\). Both together we deduce that</p> \\[     U_0 \\geq E^\\ast\\left[ H_\\tau \\right] \\] <p>This proposition shows that whatever stopping strategy the buyer is choosing, it will always reach less in (risk-neutral) expectation than what the seller is asking as minimum capital to hedge its contingent claim. If the buyer reaches equality, then it is an optimal strategy. Therefore, the following definition.</p> <p>Definition</p> <p>A stopping time \\(\\tau^\\ast\\) in \\(\\mathcal{T}\\) is called optimal if \\(U_0=E^\\ast\\left[ H_{\\tau^\\ast} \\right]\\).</p> <p>The question is whether, at least one, optimal stopping time is available to the buyer. Before addressing this question, we can obtain a better characterization of optimal stopping times.</p> <p>Proposition</p> <p>A stopping time \\(\\tau^\\ast\\) is optimal if and only if the two following conditions are satisfied</p> <ol> <li>\\(U_{\\tau^\\ast}=H_{\\tau^\\ast}\\);</li> <li>\\(U^{\\tau^\\ast}\\) is a \\(P^\\ast\\)-martingale.</li> </ol> <p>Proof</p> <p>Suppose that a stopping time \\(\\tau^\\ast\\) is such that:</p> <ul> <li>\\(U_{\\tau^\\ast}=H_{\\tau^\\ast}\\)</li> <li>\\(U^{\\tau^\\ast}\\) is a \\(P^\\ast\\)-martingale</li> </ul> <p>From the second point and Doob's optional sampling theorem, we deduce that</p> \\[     U_0 = E^\\ast\\left[ U^\\tau_T \\right] = E^\\ast\\left[ U_{\\tau^\\ast} \\right] \\] <p>And from the first, we get that \\(E^\\ast[U_{\\tau^\\ast}] = E^\\ast[H_{\\tau^\\ast}]\\). Hence \\(U_0 = E^\\ast[H_{\\tau^\\ast}]\\), showing that \\(\\tau^\\ast\\) is an optimal stopping time.</p> <p>Reciprocally, suppose that \\(\\tau^\\ast\\) is an optimal stopping time. Since \\(U\\) is a Snell envelope, and \\(\\tau^\\ast\\) is an optimal stopping time (last equality), we know that</p> \\[     U_0 \\geq E^\\ast\\left[ U_{\\tau^\\ast} \\right] \\geq E^\\ast\\left[ H_{\\tau^\\ast} \\right] = U_0 \\] <p>and \\(U_{\\tau^\\ast}\\geq H_{\\tau^\\ast}\\). If \\(U^{\\tau^\\ast}\\) were a strict martingale, then the first inequality would be strict. If \\(U_{\\tau^\\ast}\\) were strictly greater than \\(H_{\\tau^\\ast}\\) on a set of positive probability, the second inequality would be strict. Since both sides of the inequalities are equal to \\(U_0\\), we conclude that \\(U^{\\tau^\\ast}\\) is a martingale and \\(U_{\\tau^\\ast} = H_{\\tau^\\ast}\\).</p> <p>This mathematical characterization of optimal stopping times gives us a hint as how to derive an optimal stopping strategy.</p> <p>Given the Snell envelope \\(U\\) of \\(H\\) under \\(P^\\ast\\) with Doob-Meyer decomposition \\(U = M + A\\) where \\(M\\) is a martingale and \\(A\\) is a predictable decreasing process starting at \\(0\\). On the one hand, according to the first condition we define </p> \\[     \\tau_{\\min}=\\inf\\left\\{ t\\colon U_t=H_t \\right\\} \\] <p>which is a member of \\(\\mathcal{T}\\). Per definition, it is the smallest stopping time such that \\(U_{\\tau_{\\min}}=H_{\\tau_{\\min}}\\).</p> <p>On the other hand, according to the first condition we define</p> \\[     \\tau_{\\max}=\\inf \\left\\{ t\\colon E^{\\ast}\\left[ U_{t+1}-U_t |\\mathcal{F}_t \\right]\\neq 0 \\right\\}\\wedge T=\\inf\\left\\{ t\\colon A_{t+1}\\neq 0 \\right\\}\\wedge T \\] <p>which is also a stopping time in \\(\\mathcal{T}\\). By definition is this the largest stopping time for which \\(U^\\tau\\) is still a martingale before it starts to be a strict super martingale.</p> <p>According to the previous proposition, if the buyer is choosing a stopping time that might stop earlier than \\(\\tau_{\\min}\\) or stop after \\(\\tau_{\\max}\\) then is has to be sub-optimal.</p> <p>In other terms, any optimal stopping time \\(\\tau^\\ast\\) must satisfy</p> \\[ \\tau_{\\min} \\leq \\tau^\\ast \\leq \\tau_{\\max} \\] <p>The following proposition shows that eventually \\(\\tau_{\\min}\\) as well as \\(\\tau_{\\max}\\), which are explicit, are both optimal stopping times</p> <p>Proposition</p> <p>The stopping times \\(\\tau_{\\min}\\) and \\(\\tau_{\\max}\\) are optimal stopping times. Furthermore, any other optimal stopping time \\(\\tau^\\ast\\) must satisfy \\(\\tau_{\\min} \\leq \\tau^\\ast \\leq \\tau_{\\max}\\).</p> Proof <p>We first show that \\(\\tau_{\\min}\\) is a optimal stopping time. By the characterization, since by definition \\(U_{\\tau_{\\min}} = H_{\\tau_\\min}\\) we just need to show that \\(U^{\\tau_\\min}\\) is a martingale. By Doob's optional sampling theorem, the stopped process \\(U^{\\tau_{\\min}}_t=U_{t\\wedge \\tau_{\\min}}\\) is a \\(P^\\ast\\)-super-martingale. For a fixed \\(0\\leq t\\leq T-1\\), define \\(A=\\{t&lt;\\tau_{\\min}\\}\\). For \\(\\omega\\in A\\), it holds that \\(t&lt;\\tau_{\\min}(\\omega)\\) and therefore \\(U_t(\\omega)&gt;H_t(\\omega)\\). Hence,</p> \\[     U_t^{\\tau_{\\min}}(\\omega)=U_{t}(\\omega)=H_t(\\omega)\\vee E^{\\ast}\\left[ U_{t+1}|\\mathcal{F}_t \\right](\\omega)=E^{\\ast}\\left[ U_{t+1}|\\mathcal{F}_t \\right](\\omega)     =E^{\\ast}\\left[ U_{t+1}^{\\tau_{\\min}}|\\mathcal{F}_t \\right](\\omega) \\] <p>But for \\(\\omega \\in A^c\\), it holds that \\(t\\wedge \\tau_{\\min}(\\omega)=(t+1)\\wedge\\tau_{\\min}(\\omega)=\\tau_{\\min}(\\omega)\\) and therefore</p> \\[      U_t^{\\tau_{\\min}}(\\omega)=E^{\\ast}[U_{t+1}^{\\tau_{\\min}}|\\mathcal{F}_t](\\omega) \\] <p>All together with the fact that \\(A \\in \\mathcal{F}_t\\), it follows that</p> \\[     U_{t}^{\\tau_{\\min}}     =1_AU_{t}^{\\tau_{\\min}}+1_{A^c}U_{t}^{\\tau_{\\min}}     =1_A E^{\\ast}\\left[ U_{t+1}^{\\tau_{\\min}}|\\mathcal{F}_t \\right]+1_{A^c}E^{\\ast}\\left[ U_{t+1}^{\\tau_{\\min}}|\\mathcal{F}_t \\right]     =E^{\\ast}\\left[ U_{t+1}^{\\tau_{\\min}}|\\mathcal{F}_t \\right] \\] <p>showing that \\(U^{\\tau_{\\min}}\\) is a \\(P^\\ast\\)-martingale.</p> <p>We now show that \\(\\tau_{\\max}\\) is an optimal stopping time. By the characterization, since by definition \\(U^{\\tau_\\max}\\) is a martingale, we just need to show that \\(U_{\\tau_\\max} = H_{\\tau_\\max}\\). Let \\(U = M + A\\) be the Doob-Meyer decomposition of \\(U\\) into a martingale \\(M\\) and a predictable decreasing process \\(A\\) starting at \\(0\\). For \\(\\omega \\in \\{\\tau_{\\max}=T\\}\\) it is clear. For \\(\\omega \\in \\{\\tau_{\\max}=t\\}\\) for \\(t&lt;T\\), it follows that \\(A_t(\\omega)=0\\) and \\(A_{t+1}(\\omega)&gt;0\\). Hence,</p> \\[     E^{\\ast}\\left[ U_{t+1}-U_t|\\mathcal{F}_t \\right](\\omega)=-\\left( A_{t+1}(\\omega)-A_t(\\omega) \\right)&lt;0 \\] <p>showing that \\(U_{t}(\\omega)&gt;E^{\\ast}[U_{t+1}|\\mathcal{F}_t](\\omega)\\) and by the definition of the Snell envelope it follows that \\(U_t(\\omega)=H_t(\\omega)\\vee E^{\\ast}[U_{t+1}|\\mathcal{F}_t](\\omega) = H_t(\\omega)\\). Hence \\(H_{\\tau_{\\max}}=U_{\\tau_{\\max}}\\).</p>"},{"location":"lecture/03-Multi-Period/035-ruin-probability/","title":"Default (Ruin) Probability","text":"<p>We saw that the random walk often generates the evolution of the stock prices in the CRR model. In this section, we are interested in finding the probability of the ruin event. During the study of American Options, we introduced the concept of stopping times. Stopping times are also used to define ruin events, and the martingales with the help of Doob's Optional Sampling Theorem will provide a very elegant way to study the properties of this ruin event.</p> <p>We consider the following random walk of the CRR model starting at \\(0\\):</p> \\[     Z_0=0\\quad \\text{and}\\quad Z_t=\\sum_{s=1}^t Y_s,\\quad t\\geq 1 \\] <p>where \\(Y\\) are i.i.d. with \\(P[Y_t = 1] = p\\) and \\(P[Y_t = -1] = 1 - p = q\\).</p> <p>As for the filtration, we take</p> \\[     \\mathcal{F}_0=\\{\\emptyset,\\Omega\\}\\quad \\text{and}\\quad \\mathcal{F}_t=\\sigma(Z_s\\colon 1\\leq s\\leq t),\\quad t\\geq 1 \\] <p>We define \\(\\tau_{a}=\\inf\\left\\{ t\\colon Z_t=a \\right\\}\\), \\(\\tau_{b}=\\inf\\left\\{ t\\colon Z_t =-b \\right\\}\\), and \\(\\tau=\\tau_a\\wedge \\tau_b =\\inf\\{t\\colon Z_t=a\\text{ or }Z_t=-b\\}\\) for two integers \\(a,b\\).</p> <p>Remark</p> <p>As we saw in the CRR model, we often describe the stock price as:</p> \\[     S_t=S_0(1+u)^{Z_t} \\] <p>so that the stopping time \\(\\tau\\) can be interpreted as the first time that the stock price reaches the level \\(S_0(1+u)^a\\) or drops to the level \\(S_0/(1+u)^{b}\\).</p> <p>We are interested in the following probabilities:</p> \\[     P\\left[ Z_{\\tau}=a \\right], \\quad \\text{and}\\quad P \\left[ Z_{\\tau}=-b \\right] \\] <p>which are, respectively, the probability that \\(Z\\) reaches the level \\(a\\) before running bankrupt at level \\(-b\\), and the probability of running bankrupt at level \\(-b\\) before reaching level \\(a\\).</p>"},{"location":"lecture/03-Multi-Period/035-ruin-probability/#symmetric-random-walk","title":"Symmetric Random Walk","text":"<p>Suppose first that \\(p=q=1/2\\), the case of the symmetric random walk. It follows that \\(Z\\) is a martingale. Hence, due to the Optional Sampling Theorem, the stopped process \\(Z^\\tau\\) is a martingale, showing that:</p> \\[     0=Z_0=E\\left[ Z_t^\\tau \\right]=E\\left[ Z_{t\\wedge \\tau} \\right] \\] <p>for every \\(t\\). An intuitive inspection shows that for almost all \\(\\omega\\), the hitting time of one of the barriers will occur in a finite amount of time almost surely, that is \\(P[\\tau &lt;\\infty]=1\\). Hence,</p> \\[     \\lim_{t\\to \\infty}Z_{t\\wedge \\tau}=Z_\\tau \\] <p>\\(P\\)-almost surely. Furthermore, \\(|Z^\\tau_t|\\leq a\\wedge b\\) for every \\(t\\), and therefore, by Lebesgue's Dominated Convergence Theorem, it follows that:</p> \\[     0=\\lim_{t\\to \\infty}E\\left[ Z_t^\\tau \\right]=E\\left[ \\lim_{t\\to \\infty} Z_{t\\wedge \\tau} \\right]=E[Z_{\\tau}] \\] <p>On the other hand, it holds:</p> \\[     Z_{\\tau}=a1_{\\{Z_\\tau =a\\}}-b1_{\\{Z_\\tau=-b\\}}=a1_{\\{Z_\\tau=a\\}}-b(1-1_{\\{Z_\\tau=a\\}}) \\] <p>showing that:</p> \\[     E\\left[ Z_\\tau \\right]=(a+b)P\\left[ Z_\\tau=a \\right]-b \\] <p>Together with the fact that \\(E[Z_\\tau]=0\\), it follows that:</p> \\[     P\\left[ Z_\\tau=a \\right]=\\frac{b}{a+b}, \\quad \\text{and}\\quad P\\left[ Z_\\tau=-b \\right]=\\frac{a}{a+b} \\]"},{"location":"lecture/03-Multi-Period/035-ruin-probability/#asymmetric-random-walk","title":"Asymmetric Random Walk","text":"<p>Suppose now that \\(1&gt;p&gt;1/2\\). Then, \\(Z\\) is no longer a martingale, but a sub-martingale. Indeed, \\(Y\\) being independent and identically distributed, it follows that:</p> \\[     E\\left[ Z_{t+1}-Z_t|\\mathcal{F}_t \\right]=E\\left[ Y_{t+1}|\\mathcal{F}_t \\right]=E\\left[ Y_{1} \\right]= P\\left[ Y_1=1 \\right]-P\\left[ Y_1=-1 \\right]=2p-1&gt;0 \\] <p>We can therefore no longer apply the same strategy as before. However, a similar inspection as in the previous case shows that \\(\\tau(\\omega)&lt;\\infty\\) for \\(P\\)-almost all \\(\\omega \\in \\Omega\\). Despite the fact that \\(Z\\) is no longer a martingale, the process:</p> \\[     M_t=\\left(\\frac{q}{p}\\right)^{Z_t}, \\quad t=0,1,\\ldots \\] <p>is a martingale where \\(q = 1-p\\). Indeed, it is clearly adapted and integrable. Furthermore, using the independent and identically distributed assumption for \\(Y\\), it holds:</p> \\[     E\\left[ M_{t+1}-M_t|\\mathcal{F}_t \\right]     =M_tE\\left[ \\left( \\frac{q}{p} \\right)^{Y_{t+1}}-1|\\mathcal{F}_t \\right]     =M_tE\\left[ \\left( \\frac{q}{p} \\right)^{Y_{1}}-1 \\right]     =M_t\\left( p\\frac{q}{p}+q\\frac{p}{q}-1 \\right)=0 \\] <p>Considering the stopped process \\(M^\\tau\\), it follows from Doob's Optional Sampling Theorem that:</p> \\[     1=M_0=E\\left[M_{t}^\\tau  \\right]=E\\left[ M_{t\\wedge \\tau} \\right] \\] <p>for every \\(t\\). However, since \\(\\tau(\\omega)&lt;\\infty\\) for every \\(\\omega\\), it follows that \\(\\lim_{t\\to \\infty}M_{t\\wedge \\tau}=M_{\\tau}\\) \\(P\\)-almost surely. Furthermore \\(|M_{t\\wedge \\tau}|\\leq 1\\), allowing us to apply Lebesgue's Dominated Convergence:</p> \\[     1=\\lim_{t\\to \\infty}E\\left[ M_{t\\wedge \\tau} \\right]=E\\left[ \\lim_{t\\to \\infty}M_{t\\wedge \\tau} \\right]=E\\left[ M_\\tau \\right] \\] <p>On the other hand, it holds:</p> \\[     E\\left[ M_\\tau \\right]     =\\left(\\frac{q}{p}\\right)^aP\\left[ Z_\\tau=a \\right]+\\left( \\frac{q}{p} \\right)^{-b} P\\left[ Z_\\tau=-b \\right]     =\\left(\\frac{q}{p}\\right)^{-b}\\left(\\left(\\frac{q}{p}\\right)^{a+b}P[Z_\\tau=a]+(1-P[ Z_\\tau=a]) \\right) \\] <p>Combined with \\(E[M_\\tau]=1\\), it yields:</p> \\[     P\\left[ Z_\\tau=a \\right]=\\frac{(q/p)^b-1}{(q/p)^{a+b}-1}, \\quad \\text{and}\\quad P\\left[ Z_{\\tau}=-b \\right]=\\frac{(q/p)^{a}-1}{(q/p)^{a}-(q/p)^{-b}} \\]"},{"location":"lecture/03-Multi-Period/035-ruin-probability/#application-to-credit-rating","title":"Application to Credit Rating","text":"<p>Given a company, we want to estimate its probability to default at some point. In our simple framework, we define:</p> \\[     \\inf\\left\\{ t: b+Z_t =0 \\right\\}=\\inf\\left\\{ t \\colon Z_t = -b \\right\\}=\\tau_b \\] <p>which is the first time that a firm with cumulative returns \\(Z\\) and start capital \\(b\\) reaches bankruptcy. We also assume here that \\(1/2 &lt;p&lt;1\\). We want to estimate:</p> \\[     P\\left[ \\tau_b &lt;\\infty \\right] \\] <p>which is the probability that the firm goes bankrupt at some point in time. Since \\(\\tau_a \\to \\infty\\) as \\(a\\to \\infty\\), it follows that:</p> \\[     P\\left[ \\tau_b&lt;\\infty \\right]=\\lim_{a \\to \\infty}P\\left[ Z_{\\tau}=-b \\right]=\\lim_{a\\to \\infty}\\frac{(q/p)^{a}-1}{(q/p)^{a}-(q/p)^{-b}}=\\left( \\frac{q}{p} \\right)^b \\] <p>We see therefore two factors impacting the probability of default of the company:</p> <ul> <li>The returns of the company (\\(p\\)): Since \\(E[Z_{t+1}-Z_t|\\mathcal{F}_t]=2p-1&gt;0\\), if \\(p\\) is very close to \\(1\\), that is strong returns, then \\(q/p\\) is very small and so is the probability of default \\((q/p)^b\\).</li> <li>The present capital of the company (\\(b\\)): Since \\(0&lt;q/p&lt;1\\), it follows that the higher \\(b\\), the smaller \\((q/p)^b\\) in an exponential way.</li> </ul>"},{"location":"material/ex01/","title":"Exercise: One Period Financial Market","text":"<p>Exercise</p> <p>We consider the following two financial market models with state space \\( \\Omega=\\{\\omega_1,\\omega_2, \\omega_3\\} \\) and a probability measure \\( P \\) with</p> \\[     P\\left[ \\{\\omega_i\\} \\right] = p_i \\quad \\text{for} \\quad          \\begin{cases}             p_i  &gt; 0 &amp; \\text{for every } i=1,2,3, \\\\             p_1 + p_2 + p_3 = 1         \\end{cases} \\] <ol> <li> <p>Financial Market I: \\( B_0 = 1 \\) and \\( B_1 = 2 \\) as bank account and three stocks given by</p> \\[     \\begin{align*}         \\boldsymbol{S}_0 &amp; = (S_0^1, S_0^2, S_0^3) = (7, 31, 62)\\\\         \\boldsymbol{S}_1 &amp; =          \\begin{bmatrix}             S^1_1(\\omega_1) &amp; S^2_1(\\omega_1) &amp; S^3_1(\\omega_1) \\\\             S^1_1(\\omega_2) &amp; S^2_1(\\omega_2) &amp; S^3_1(\\omega_2) \\\\             S^1_1(\\omega_3) &amp; S^2_1(\\omega_3) &amp; S^3_1(\\omega_3)         \\end{bmatrix} =          \\begin{bmatrix}             40 &amp; 60 &amp; 120 \\\\             0 &amp; 40 &amp; 80 \\\\             20 &amp; 100 &amp; 200         \\end{bmatrix}     \\end{align*} \\] </li> <li> <p>Financial Market I: \\( B_0 = 1 \\) and \\( B_1 = 1 \\) as bank account and two stocks given by</p> \\[     \\begin{align*}         \\boldsymbol{S}_0 &amp; = (S_0^1, S_0^2) = (8, 10)\\\\         \\boldsymbol{S}_1  &amp;=             \\begin{bmatrix}                 S^1_1(\\omega_1) &amp; S^2_1(\\omega_1) \\\\                 S^1_1(\\omega_2) &amp; S^2_1(\\omega_2) \\\\                 S^1_1(\\omega_3) &amp; S^2_1(\\omega_3)             \\end{bmatrix} =              \\begin{bmatrix}             6 &amp; 11 \\\\             5 &amp; 11 \\\\             12 &amp; 9             \\end{bmatrix}     \\end{align*} \\] </li> </ol> <p>Are these models arbitrage-free? If yes, give all risk-neutral pricing measures. Otherwise, provide an arbitrage strategy.</p> <p>Exercise</p> <p>Given a generic financial market as in the lecture on some probability space \\( (\\Omega, \\mathcal{F},P) \\). Recall that the vector of returns of the financial assets is the random variable given by</p> \\[ \\boldsymbol{R}_1 = \\left( \\frac{S_1^1-S_0^1}{S_0^1}, \\ldots, \\frac{S_1^d-S_0^d}{S_0^d} \\right) \\] <p>Show that the following assertions are equivalent:</p> <ol> <li>The financial market is arbitrage-free;</li> <li> <p>There exists no \\( \\boldsymbol{\\eta}\\) in \\(\\mathbb{R}^d \\) such that</p> \\[     P\\left[ \\boldsymbol{\\eta} \\cdot \\boldsymbol{R}_1 \\geq r \\sum_{k=1}^d \\eta^k \\right]=1 \\quad \\text{and} \\quad P\\left[ \\boldsymbol{\\eta} \\cdot \\boldsymbol{R}_1 &gt; r \\sum_{k=1}^d \\eta^k \\right]&gt;0 \\] </li> <li> <p>For any strategy \\( \\boldsymbol{\\eta}\\) in \\(\\mathbb{R}^d \\), it holds that</p> \\[     P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right]=1 \\quad \\text{implies} \\quad P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 = 0 \\right]=1 \\] </li> </ol> <p>Exercise</p> <p>We consider a binomial financial market model with interest rate \\( r \\geq 0 \\),</p> \\[     \\Omega=\\{\\omega^+,\\omega^-\\}, \\quad p:=P(\\{\\omega^+\\})=\\frac{1}{2} \\] <p>and one risky asset with initial value \\( S_0=100 \\) and at time 1,</p> \\[     S_1(\\omega) =          \\begin{cases}             120 &amp; \\text{if } \\omega = \\omega^+ \\\\             90 &amp; \\text{if } \\omega = \\omega^-         \\end{cases} \\] <p>Let \\( C=(S_1-K)^+ \\) be a call option on \\( S \\) with strike price \\( K=100 \\).</p> <ol> <li>For which \\( r \\) is the model arbitrage-free?     For those \\( r \\) for which the model is arbitrage-free, give the risk-neutral pricing measure \\( P^* \\) by finding \\( p^*=P^*(\\{\\omega^+\\}) \\).</li> <li> <p>If you compute the call option's price as the expectation \\( E\\left[\\frac{C}{1+r}\\right] \\) under the objective measure \\( P \\), then there exists an arbitrage in the model.     Show that the risk-free arbitrage gain equals the difference</p> \\[     E\\left[\\frac{C}{1+r}\\right] - E^*\\left[\\frac{C}{1+r}\\right]. \\] </li> <li> <p>For the call option, find a portfolio with start value \\( V_0 \\) and hedging strategy \\( \\eta \\) in \\(\\mathbb{R}\\) such that</p> \\[     \\frac{C}{1+r}=V_0 + \\eta \\Delta X_1 \\] <p>Show that the necessary amount of money to finance this strategy is the risk-neutral price \\( V_0=E^*\\left[\\frac{C}{1+r}\\right] \\).</p> </li> </ol> <p>Exercise: Put/Call Parity</p> <p>On an arbitrage-free financial market, we consider a call and a put</p> \\[ C^{call}=(S_1-K)^+, \\quad \\text{and} \\quad C^{put}=(K-S_1)^+ \\] <p>on the same financial asset \\( S^1 \\) and with the same strike \\( K \\). Show that if \\( \\pi(C^{call}) \\) and \\( \\pi(C^{put}) \\) are fair prices for the call and put respectively, then it has to hold</p> \\[ \\pi(C^{call})=\\pi(C^{put})+S_0-\\frac{K}{1+r} \\] <p>Exercise</p> <p>We consider a financial market with bank account \\( B_0 = 1 \\) and \\( B_1 = 1 + r \\) for some \\( r &gt; -1 \\). We have a single financial asset \\( S \\). We suppose that the financial market is arbitrage-free, and that on this market every call option \\( C(K) = (S_1 - K)^+ \\) is traded for a fair price \\( \\pi(K) \\). Using the \"law of one price,\" compute the prices of the following derivatives:</p> <ol> <li>\\( \\min(S_1, K) \\).</li> <li> <p>\"Butterfly spread\" with payoff \\( f(S_1) \\), whereby \\( f \\) is given by</p> \\[ f(x) =     \\begin{cases}         x-a &amp; \\text{if } a \\leq x \\leq \\frac{a+b}{2}, \\\\         b-x &amp; \\text{if } \\frac{a+b}{2} \\leq x \\leq b, \\\\         0 &amp; \\text{otherwise}     \\end{cases} \\] <p>for some \\( 0 \\leq a \\leq b \\).</p> </li> </ol> <p>Exercise</p> <p>On an arbitrage-free market, we consider a financial asset \\( S \\). A \\( S^2 \\)MART certificate with loss barrier \\( 0 &lt; K_1 \\), strike price \\( K &gt; K_1 \\), and participation rate \\( \\alpha \\) is a certificate given by:</p> <ul> <li>If the financial asset falls below the loss barrier \\( K_1 \\), the certificate pays \\( \\frac{K}{K_1} \\) times the price of the asset at this point.</li> <li>If the financial asset falls between \\( K_1 \\) and \\( K \\), the certificate pays \\( K \\).</li> <li>If the financial asset is above \\( K \\), the certificate pays a portion \\( \\alpha \\) of the asset plus a portion \\( (1-\\alpha) \\) of the strike price.</li> </ul> <p>Given this certificate:</p> <ol> <li>Write the index as a function of \\( S, K_1, K, \\) and \\( \\alpha \\).</li> <li>Show that this certificate can be written as a linear combination of the financial asset and adequate call options.</li> <li>Given \\( K_1, K \\), and the fair price of the call options, determine what should be the participation rate \\( \\alpha \\) such that the fair price of the certificate equals the price of the financial asset.</li> </ol>"},{"location":"material/ex02/","title":"Exercise: Risk Management","text":"<p>Exercise</p> <p>A random variable \\( L \\) is called normally distributed with mean \\( \\mu \\) in \\(\\mathbb{R} \\) and variance \\( \\sigma &gt; 0 \\) if it has a probability density given by</p> \\[   f_{\\mu,\\sigma}(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right) \\] <p>and we use the notation \\( L \\sim \\mathcal{N}(\\mu, \\sigma^2) \\). We denote by</p> \\[ F_{\\mu,\\sigma}(m) = P[L \\leq m] = \\int_{-\\infty}^{m} f_{\\mu,\\sigma}(y) \\, dy, \\quad x \\in \\mathbb{R} \\quad \\text{and} \\quad q_{\\mu,\\sigma}(s) = F^{-1}_{\\mu,\\sigma}(s), \\quad s \\in (0,1) \\] <p>the CDF and quantile of the normal distribution with mean \\( \\mu \\) and variance \\( \\sigma \\). We use the simplified notations for the standard normal:</p> \\[ f = f_{0,1}, \\quad F = F_{0,1}, \\quad q = q_{0,1}. \\] <ol> <li>Show that if \\( L \\sim \\mathcal{N}(0,1) \\), it holds \\( \\mu + \\sigma L \\sim \\mathcal{N}(\\mu, \\sigma^2) \\).</li> <li>Show that if \\( L \\sim \\mathcal{N}(\\mu, \\sigma^2) \\), it holds \\( -L \\sim \\mathcal{N}(-\\mu, \\sigma^2) \\).</li> <li> <p>Show that</p> \\[ f_{\\mu,\\sigma}(x) = \\frac{1}{\\sigma} f\\left( \\frac{x-\\mu}{\\sigma} \\right), \\quad \\sigma^2 f^\\prime_{\\mu,\\sigma} (x) = (\\mu-x)f_{\\mu,\\sigma}(x) \\] \\[ F_{\\mu,\\sigma}(x) = F\\left( \\frac{x-\\mu}{\\sigma} \\right), \\quad q_{\\mu,\\sigma}(s) = \\mu + \\sigma q(s). \\] </li> </ol> <p>Recall that </p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf \\{m \\colon P[L&gt;m]\\geq \\alpha\\} = q_L(1-\\alpha)\\\\     ES_{\\alpha}(L) &amp; = \\frac{1}{\\alpha}\\int_0^\\alpha V@R_{\\alpha}(s) ds = \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 q_L(s)ds   \\end{align*} \\] <p>and that both functionals are positive homogoneous.</p> <p>Show that for \\(L\\sim \\mathcal{N}(\\mu, \\sigma^2)\\)</p> \\[     V@R_{\\alpha}(L) = \\mu + \\sigma V@R_{\\alpha}(\\bar{L}) \\quad \\text{and} \\quad ES_{\\alpha}(L) = \\mu + \\sigma ES_{\\alpha}(\\bar{L}) \\] <p>where \\(\\bar{L} \\sim \\mathcal{N}(0, 1)\\) (in other terms, to compute the value at risk or expected shortfal of normal distribution, you just need the V@R and ES of the standard normal distribution).</p> <p>Deduce that for normally distributed random variable \\(L\\) with zero mean, \\(V@R\\) and \\(ES\\) are related through</p> \\[     ES_{\\alpha}(L) = C V@R_{\\alpha}(L) \\] <p>for some constant \\(C\\) which you provide explicitely.</p> <p>Dual Representation</p> <p>We already know that the expected shortfall has two possible representations:</p> \\[   \\begin{align*}      ES_\\alpha(L) &amp; = \\frac{1}{\\alpha} \\int_{1-\\alpha}^{1} q_L(s) ds\\\\                   &amp; = \\inf\\left\\{ m + \\frac{1}{\\alpha} E\\left[ (L-m)^+ \\right] \\right\\}\\\\                   &amp; = q_L(1-\\alpha) + \\frac{1}{\\alpha} E\\left[ \\left( L - q_L(1-\\alpha) \\right)^+ \\right]   \\end{align*} \\] <p>We derive an alternative formulation in terms of duality, namely:</p> \\[ ES_{\\alpha}(L) = \\sup\\left\\{ E^Q[L] \\colon 0 \\leq \\frac{dQ}{dP} \\leq \\frac{1}{\\alpha} \\right\\} \\] <p>This general statement says that the expected shortfall accounts for computing the expected loss under any alternative probability model \\( Q \\) such that \\( Q \\) is not \"too\" far away from \\( P \\) in the sense that the density is bounded by \\( 1/\\alpha \\).</p> <ol> <li> <p>Show that for every \\( x \\) and every \\( y \\) with \\( 0 \\leq y \\leq 1/\\alpha \\) it holds:</p> \\[ \\frac{1}{\\alpha} x^+ \\geq xy \\] <p>In other terms, \\( x^+ / \\alpha = \\sup\\{ xy \\colon 0 \\leq y \\leq 1/\\alpha \\} \\), which is called Fenchel-Moreau duality.</p> </li> <li> <p>Using the fact that \\( E[dQ/dP] = 1 \\), show that if \\( 0 \\leq dQ/dP \\leq 1/\\alpha \\), then it holds:</p> \\[ m + \\frac{1}{\\alpha} E\\left[ (L-m)^+ \\right] \\geq E^Q[L] \\] <p>and deduce that:</p> \\[ ES_{\\alpha}(L) \\geq \\sup\\left\\{ E^Q[L] \\colon 0 \\leq \\frac{dQ}{dP} \\leq \\frac{1}{\\alpha} \\right\\} \\] </li> <li> <p>Assuming that \\( F_L \\) is continuous and strictly increasing, show that if we define the random variable:</p> \\[ \\frac{dQ^\\ast}{dP} = \\frac{1}{\\alpha} 1_{\\{L \\geq q_L(1-\\alpha)\\}} \\] <p>then it defines a probability measure \\( Q^\\ast \\) such that \\( 0 \\leq dQ^\\ast/dP \\leq 1/\\alpha \\) and for which it holds:</p> \\[ ES_{\\alpha}(L) = E^{Q^\\ast}[L] \\] <p>and deduce the duality formula \u2014 for which you now have an explicit \\( Q^\\ast \\) that depends on \\( L \\).</p> </li> </ol>"},{"location":"material/ex_math/","title":"Exercises: Probability and Stochastic Processes","text":"<p>Remark</p> <p>For the Radon Nykodym theorem, the notion of absolute continuity and equivalence between probability measure is central.</p> <p>Definition</p> <p>Given two probability measure \\(P\\) and \\(Q\\) we say that</p> <ol> <li> <p>\\(Q\\) is absolutely continuous with repext to \\(P\\) and denote \\(Q\\ll P\\) if </p> \\[ P[A] = 0 \\quad \\text{implies} \\quad Q[A] = 0\\] </li> <li> <p>\\(Q\\) is equivalent to \\(P\\) and denote \\(Q\\sim P\\) if both \\(Q\\ll P\\) and \\(P\\ll Q\\).     That is</p> \\[ P[A] = 0 \\quad \\text{if and only if} \\quad Q[A] = 0\\] </li> </ol> <p>By definition it clearly holds that</p> \\[     Q \\ll P \\quad \\text{if and only if} \\quad P[A] = 1 \\, \\text{implies}\\, Q[A] = 1 \\] <p>or</p> \\[     Q \\ll P \\quad \\text{if and only if} \\quad Q[A] &gt; 0 \\, \\text{implies}\\, P[A] &gt; 0 \\] <p>and in the equivalent case</p> \\[     Q \\sim P \\quad \\text{if and only if} \\quad P[A] = 1 \\, \\text{if and only if}\\, Q[A] = 1 \\] <p>or</p> \\[     Q \\sim P \\quad \\text{if and only if} \\quad P[A] &gt; 0 \\, \\text{if and only if}\\, Q[A] &gt; 0 \\] <p>Exercise</p> <p>The Radon-Nykodym theorem states that if a probability measure \\( Q \\ll P \\), then there exists a (\\( P \\)-almost surely) unique random variable \\(Z\\) such that</p> \\[   \\begin{equation*}     \\begin{cases}       Z &amp; \\geq 0 \\\\       E^P[Z] &amp; = 1 \\\\       E^Q[X] &amp; = E^P[Z X] \\quad \\text{ for any positive bounded random variable }X     \\end{cases}   \\end{equation*} \\] <p>This unique random variable is called the density of \\(Q\\) with respect to \\(P\\) and denoted by \\(dQ/dP\\).</p> <p>This density allows to compute expectation of random variable under \\(Q\\) in terms of expectation under \\(P\\). If \\(Q\\sim P\\) then \\(dQ/dP\\) is strictly positive and \\(dP/dQ = (dQ/dP)^{-1}\\).</p> <p>This fundamental theorem is complex to prove in the general case, relying on other fundamental theorems of functional analysis. However, you can prove it easily in the finite state setting.</p> <p>Let \\( \\Omega=\\{\\omega_1,\\ldots,\\omega_n\\} \\) be a finite state space with \\( \\sigma \\)-algebra \\( \\mathcal{F}=2^\\Omega \\) and probability measure \\( P \\) given by the vector \\( \\boldsymbol{p}=(p_1,\\ldots,p_n) \\) where \\( P[\\{\\omega_i\\}]=p_i&gt;0 \\) for every \\( i \\) and \\( \\sum p_i=1 \\).</p> <p>Let now \\( Q \\) be another probability measure on \\( (\\Omega,\\mathcal{F}) \\) given by the vector \\( \\boldsymbol{q}=(q_1,\\ldots,q_n) \\) where \\( Q[\\{\\omega_i\\}]=q_i\\geq 0 \\) and \\( \\sum q_i=1 \\). Since \\( P[A]=0 \\) implies \\( A=\\emptyset \\), it follows that \\( Q[A]=Q[\\emptyset]=0 \\). Hence, \\( Q \\) is absolutely continuous with respect to \\( P \\).</p> <p>Find a random variable \\( \\frac{dQ}{dP}:\\Omega \\to \\mathbb{R} \\) such that \\( \\frac{dQ}{dP}\\geq 0 \\), \\( E_P[\\frac{dQ}{dP}]=1 \\), and </p> \\[ E_Q[X]=E_P\\left[ \\frac{dQ}{dP}X \\right] \\] <p>for every random variable \\( X:\\Omega\\to \\mathbb{R} \\). Show that \\( \\frac{dQ}{dP} \\) is also unique.</p> <p>Note that since it is a finite setting, the random variable \\(dQ/dP\\) can be represented by an \\( n \\)-dimensional vector \\(\\boldsymbol{z} = (z_1, \\ldots, z_n)\\) with \\(z_i = dQ/dP(\\omega_i)\\). The conditions therefore translate into finding such a vector \\(\\boldsymbol{z}\\) with \\(z_i \\geq 0\\), \\(\\sum z_i p_i = 1\\) and such that for every vector \\(\\boldsymbol{x}=(x_1, \\ldots, x_n)\\) it holds</p> \\[   \\sum x_i q_i =E^Q[X] = E\\left[ \\frac{dQ}{dP}X \\right] = \\sum x_i z_i p_i \\] <p>Exercise</p> <p>Let \\( (\\Omega, \\mathcal{F}, P) \\) be a probability space. Given a positive random variable \\( X \\), we define </p> \\[ A = \\left\\{ X &gt; 0 \\right\\} := \\left\\{ \\omega \\colon X(\\omega) &gt; 0 \\right\\} \\quad \\text{and} \\quad A_n = \\left\\{ X &gt; \\frac{1}{n} \\right\\}, \\quad n \\in \\mathbb{N}. \\] <p>Show that:</p> <ol> <li>\\( A_n \\subseteq A_{n+1} \\) and \\( \\cup_{k \\leq n} A_k = A_n \\nearrow A \\).</li> <li> <p>\\( P[A_n] \\nearrow P[A] \\).</p> <p>Hint: Show that the sequence of events \\( B_1 = A_1 \\), \\( B_2 = A_2 \\setminus A_1 \\), \\( B_3 = A_3 \\setminus A_2 \\), \\( \\ldots \\) is such that:</p> \\[ B_k \\cap B_j = \\emptyset \\text{ for } k \\neq j, \\quad \\cup_{k=1}^n B_k = A_n, \\quad \\text{and} \\quad \\cup_{k=1}^\\infty B_k = A, \\] <p>and conclude with the property of a probability measure which implies:</p> \\[ P\\left[ \\cup_{k=1}^n B_k \\right] = \\sum_{k=1}^{n} P\\left[ B_k \\right] \\nearrow \\sum_{k=1}^\\infty P[B_k] = P\\left[\\cup_{k=1}^\\infty B_k \\right]. \\] </li> <li> <p>Show that \\( X \\leq Y \\) implies \\( E[X] \\leq E[Y] \\), and deduce:</p> \\[ \\frac{1}{n} P\\left[ A_n \\right] \\leq E\\left[ X 1_{A_n} \\right] \\leq E\\left[ X \\right]. \\] </li> <li> <p>Deduce that if \\( X \\geq 0 \\) and \\( E[X] = 0 \\), then \\( P[X &gt; 0] = 0 \\).</p> </li> <li>Deduce that if \\( X \\geq 0 \\) and \\( P\\left[ X &gt; 0 \\right] &gt; 0 \\), then \\( E\\left[ X \\right] &gt; 0 \\).</li> </ol> <p>Exercise</p> <p>Let \\( (\\Omega, \\mathcal{F}, P) \\) be a probability space. Let further \\( (A_n) \\) be a sequence of pairwise disjoint elements\\footnote{That is \\( A_n \\cap A_m = \\emptyset \\) for every \\( n \\neq m \\).} of \\( \\mathcal{F} \\) such that \\( P[A_n] &gt; 0 \\) for every \\( n \\). Define \\( \\mathcal{G} = \\sigma(A_n \\colon n) \\), the \\( \\sigma \\)-algebra generated by the sequence \\( (A_n) \\). That is,</p> \\[ A \\in \\mathcal{G} \\quad \\text{if and only if} \\quad A = \\cup_{i \\in I} A_i, \\quad I \\subseteq \\mathbb{N}. \\] <p>Show that:</p> <ol> <li> <p>For every \\( B \\in \\mathcal{F} \\), it holds</p> \\[ P\\left[ B|\\mathcal{G} \\right] := E\\left[ 1_B |\\mathcal{G} \\right] = \\sum P\\left[ B | A_n \\right] 1_{A_n} \\] <p>where \\( P[B|A_n] := \\frac{P[B \\cap A_n]}{P[A_n]} \\).</p> </li> <li> <p>For every \\( X \\), a bounded random variable, it holds</p> \\[ E\\left[ X|\\mathcal{G} \\right] = \\sum \\frac{E\\left[ 1_{A_n} X \\right]}{P[A_n]} 1_{A_n}. \\] </li> </ol> <p>Exercise</p> <ol> <li> <p>Let \\( X \\) and \\( Y \\) be two identically distributed random variables. Show that</p> \\[ E\\left[ X \\big| \\sigma(X+Y) \\right] = \\frac{X+Y}{2}. \\] <p>Hint: Note that \\( E[X+Y | \\sigma(X+Y)] = X+Y \\).</p> </li> <li> <p>Let \\( X = (X_t)_{0 \\leq t \\leq T} \\) be a martingale on a probability space \\( (\\Omega, \\mathcal{F}, P) \\) with a filtration \\( \\mathbb{F} = (\\mathcal{F}_t)_{0 \\leq t \\leq T} \\). Show that \\( E[X_s|\\mathcal{F}_t]=X_t \\) for every \\( 0 \\leq t \\leq s \\leq T \\).</p> </li> <li> <p>Let \\( Y_1, \\ldots, Y_T \\) be independent random variables on a probability space \\( (\\Omega, \\mathcal{F}, P) \\) with \\( Y_t &gt; 0 \\) \\( P \\)-almost surely and \\( E[Y_t]=1 \\) for every \\( t \\). Show that</p> \\[ X_0 = 1, \\quad X_t = \\prod_{s=1}^t Y_s, \\quad t = 1, \\ldots, T \\] <p>is a martingale with respect to the filtration \\( \\mathcal{F}_0 = \\{\\emptyset, \\Omega\\} \\) and \\( \\mathcal{F}_t = \\sigma(Y_1, \\ldots, Y_t) \\).</p> </li> <li> <p>Let \\( Y_1, \\ldots, Y_t \\) be independent random variables such that \\( Y_t \\sim \\mathcal{N}(0,1) \\) on some probability space \\( (\\Omega, \\mathcal{F}, P) \\). Consider the filtration \\( \\mathcal{F}_0 = \\{\\emptyset, \\Omega\\} \\) and \\( \\mathcal{F}_t = \\sigma(Y_1, \\ldots, Y_t) \\). We consider the price process</p> \\[ S_0 &gt; 0, \\quad S_t = S_0 \\exp\\left( \\sum_{s=1}^t \\left(\\sigma Y_s + \\mu\\right) \\right) \\] <p>where \\( \\sigma, \\mu \\) are constants such that \\( \\sigma &gt; 0 \\). Let further the bank account be</p> \\[ B_t = (1 + r)^t. \\] <p>For which values of \\( \\mu \\) is the discounted price process</p> \\[ X_t = \\frac{S_t}{B_t} \\] <p>a martingale?</p> <p>Hint: Note that if \\( Z \\sim \\mathcal{N}(0, \\sigma^2) \\), then it holds that \\( E[e^Z] = e^{\\sigma^2 / 2} \\).</p> </li> </ol> <p>Exercise: Measure Change</p> <p>Consider a probability space \\( (\\Omega, \\mathcal{F}, P) \\) and a filtration \\( \\{\\emptyset, \\Omega\\} = \\mathcal{F}_0 \\subseteq \\mathcal{F}_1 \\subseteq \\cdots \\subseteq \\mathcal{F}_T \\).</p> <p>Let \\( Q \\) be a probability measure equivalent to \\( P \\), and we denote by \\( Z = dQ / dP \\) its density, that is, the unique positive integrable random variable with expectation \\( 1 \\) such that for any \\( Q \\)-integrable random variable \\( H \\) it holds</p> \\[ E^Q\\left[ H \\right] = E\\left[ Z H \\right] \\] <p>We further denote by</p> \\[ Z_t = E\\left[ Z \\, | \\, \\mathcal{F}_t \\right], \\quad t = T, T-1, \\ldots, 0 \\] <p>the conditional density.</p> <p>Show that:</p> <ul> <li>\\( Z_t \\) is a positive random variable with expectation \\( 1 \\). It defines therefore a probability measure \\( Q_t \\sim P \\) on \\( \\mathcal{F}_t \\).</li> <li>Show that the stochastic process \\( Z = Z_0, Z_1, \\ldots \\) is a \\( P \\)-martingale.</li> <li> <p>Show that for any \\( Q \\)-integrable random variable \\( H \\) it holds</p> \\[ E^Q\\left[ H \\big| \\mathcal{F}_t \\right] = \\frac{1}{Z_t} E^P\\left[ Z H \\big| \\mathcal{F}_t \\right] \\] </li> <li> <p>Let \\( M = M_0, M_1, \\ldots \\) be an adapted and \\( Q \\)-integrable stochastic process. Show that \\( M \\) is a \\( Q \\)-martingale if and only if \\( Z M \\) is a \\( P \\)-martingale.</p> </li> </ul>"},{"location":"material/probability/","title":"Probability","text":""},{"location":"material/probability/#probability-space","title":"Probability Space","text":"<p>In probability, we consider:</p> <ul> <li>A state space \\( \\Omega \\) of states \\( \\omega \\in \\Omega \\):      Description of possible states of an outcome for which there is uncertainty.</li> <li>Events \\( A \\subseteq \\Omega \\) as a collection of states that can happen.     The family of all considered events \\( A \\subseteq \\Omega \\) is denoted by \\( \\mathcal{F} \\).</li> </ul> <p>Examples</p> <ol> <li> <p>Coin Flipping:</p> <ul> <li> <p>State space: \\( \\Omega = \\{H, T\\} \\), where \\( H \\) and \\( T \\) denote the states \"Head occurs\" and \"Tail occurs\" as the possible outcomes of throwing a coin.</p> </li> <li> <p>Events: \\( A = \\{H\\} \\) is the event that head will occur.</p> </li> </ul> </li> <li> <p>Temperature tomorrow:</p> <ul> <li> <p>State space: \\( \\Omega = \\mathbb{R} \\), where \\( x \\in \\Omega \\) represents the possible temperature at 8:00 am tomorrow.</p> </li> <li> <p>Events: \\( A = [13,19] \\) is the event that tomorrow at 8:00 am, the temperature will lie between \\( 13 \\) and \\( 19 \\) degrees.</p> </li> </ul> </li> <li> <p>Financial decision: </p> <ul> <li> <p>State space: \\( \\Omega = [-1,10]^2 \\), where for \\( (x, y) \\in \\Omega \\), \\( x \\) and \\( y \\) represent the interest rates that the central banks of the USA and EU, respectively, will fix next month.</p> </li> <li> <p>Events: \\( A = [0.25,0.75] \\times [0.9,1.8] \\cup \\{1\\} \\times [1.7,2.1] \\) is the event that next month the USA fixes an interest rate between \\( 0.25\\% \\) and \\( 0.75\\% \\) while the EU fixes one between \\( 0.9\\% \\) and \\( 1.8\\% \\), OR the USA fixes an interest rate of \\( 1\\% \\) while the EU fixes one between \\( 1.7\\% \\) and \\( 2.1\\% \\).</p> </li> </ul> </li> <li> <p>Texas Holdem:</p> <p>For Texas Holdem, we have 52 cards deck \\(D\\) with cards  ,  ,  , ...</p> <p>After pre-flop, flop, turn and river (if you're still there), you have to choose 5 best cards out of the best combinations you can get from the 5 on the table and the two in your hand.</p> <ul> <li> <p>State space: \\( \\Omega = \\{\\{c_1, c_2, c_3, c_4, c_5\\} \\colon c_i \\in D, \\text{ and } c_i \\neq c_j\\} \\).   Note here the notation in terms of set, since the order does not count. Furthermore, each card is different since distributing occurs without replacement.</p> </li> <li> <p>Event: The event \\(A\\) that I have a royal flush corresponds to \\(A\\) containing the elements \\(\\{\\) , , , , \\(\\}\\), \\(\\{\\) , , , , \\(\\}\\), \\(\\{\\) , , , , \\(\\}\\), \\(\\{\\) , , , , \\(\\}\\).</p> </li> </ul> </li> </ol> <p>Events are supposed to be measured afterwards, however we require some structure among events. We want to speak about the occurence of one or the other event, two events happening coincidentally, or an event not happening. Therefore, the definition of measurable space</p> <p>Measurable Space</p> <p>A measurable space is a tuple \\( (\\Omega, \\mathcal{F}) \\), where </p> <ul> <li>\\(\\Omega\\) is a set (state space)</li> <li>\\(\\mathcal{F}\\) is an algebra of subsets of \\(\\Omega\\) (Events)</li> </ul> <p>An algebra is a collection of sets satisfying the following properties</p> <ul> <li>\\( \\emptyset \\) (nothing happens) and \\( \\Omega \\) (anything can happen) are events.</li> <li>If \\(A\\) is an event, then so is \\(A^c\\);</li> <li>If \\(A\\) and \\(B\\) are events, then \\(A\\cup B\\) is an event (the event that \\(A\\) or \\(B\\) happen is itself an event)</li> </ul> <p>Warning</p> <p>Note that this is the intuitive definition of a measurable space, but for mathematical reason, we require the algebra of events \\(\\mathcal{F}\\) to be \\(\\sigma\\)-stable, that is instead of requiring union of two or finitely many events to be an events, we also require </p> <p>If the state space \\(\\Omega\\) is finite or countable, the classical assumption is to consider as algebra of events the power set \\(2^{\\Omega}\\) which is the collection of any subsets. If the state space is infinite, such as \\(\\mathbb{R}\\), the power set would be truly large and leading to mathematical issues. In the case of \\(\\mathbb{R}\\) for instance, the measurable sets are those generated by intervals.</p> <p>Proposition</p> <p>The third assumption for an algebra is equivalent to replace by </p> <ul> <li>If \\(A\\) and \\(B\\) are events, then \\(A\\cap B\\) is an event.</li> </ul> <p>Proof</p> <p>Let \\(A\\) and \\(B\\) be event, from the second assumption it follows follows that \\(A^c\\). Now the equivalence between the two assertion (intersection vs union) follows from Morgan's rule</p> \\[     A\\cap B = (A^c \\cup B^c)^c \\quad \\text{and}\\quad A\\cup B = (A^c \\cap B^c)^c \\] <p>Examples</p> <p>Here are some classical exmaples we will see throughout the lecture.</p> <ul> <li> <p>Coin toss:</p> <ul> <li>State Space: \\(\\Omega = \\{-1, 1\\}\\) two states for head and tail</li> <li>Events: \\(\\mathcal{F} = 2^\\Omega = \\{\\emptyset, \\Omega, \\{1\\}, \\{-1\\}\\}\\)</li> </ul> <p>There are here exactly \\(2^2 =4\\) events.</p> </li> <li> <p>Finite state space:</p> <ul> <li>State Space: \\(\\Omega = \\{\\omega_1, \\ldots, \\omega_N\\}\\)</li> <li>Events: \\(\\mathcal{F} = 2^\\Omega\\)</li> </ul> <p>There are here exactly \\(2^{\\#\\Omega} = 2^N\\) events (already with \\(N\\) beyond 100 this is more than a computer can take).</p> </li> <li> <p>Random Walk:</p> <p>The random walk consists to draw a coin several times in a row, recording every single result.</p> <ul> <li>State Sapce: \\(\\Omega = \\{\\omega = (\\omega_1, \\ldots, \\omega_T)\\colon \\omega_i = \\pm 1\\}\\) where each state is the sequence of results of the coin toss.</li> <li>Events: \\(\\mathcal{F}=2^\\Omega\\).</li> </ul> <p>As above, the cardinality of \\(\\mathcal{F}\\) is equal to \\(2^{\\# \\Omega}\\). However there are \\(2^N\\) possible sequences, and so the cardinality of events is equal to \\(2^{2^N}\\). You can imagine that for small \\(N\\) this size is already gigantic.</p> </li> </ul>"},{"location":"material/probability/#random-variables","title":"Random Variables","text":"<p>Aside from being able to measure events, we also want to know how to measure the events that a function of this state satisfies. For instance, in the case of the coin toss, suppose that you play a game where if head you win 100 and if tail you lose everything. As a function of the state it writes as \\(X \\colon \\Omega \\to \\mathbb{R}\\) where \\(X(\\omega) = 100\\) if \\(\\omega = 1\\) and \\(X(\\omega) = 0\\) otherwize. We want to be able to speak about the event \\(A\\) you strictly win something which clearly if \\(\\{1\\}\\). In the general case we define random variables as such functions where you can measure this function to reach some certain level.</p> <p>Definition</p> <p>Let \\( (\\Omega, \\mathcal{F}) \\) be a measurable space. A function</p> \\[   \\begin{equation*}     \\begin{split}       X\\colon \\Omega \\longrightarrow \\mathbb{R}\\\\           \\omega &amp; \\longmapsto X(\\omega)     \\end{split}   \\end{equation*} \\] <p>is called a random variable if for every level \\(x\\), the set</p> \\[     A = \\left\\{ \\omega \\in \\Omega \\colon X(\\omega)\\leq x \\right\\}:= \\{X\\leq x\\} \\] <p>is an event, that is \\(A \\in \\mathcal{F}\\).</p> <p>The fact that we require the event smaller than some value seems arbitrary, however, since we have a (\\(\\sigma\\))-algebra this is quite general</p> <p>Proposition</p> <p>It is equivalent for \\( X: \\Omega \\to \\mathbb{R} \\) to be a random variable to require:</p> <ol> <li>\\( \\{X &gt; x\\} \\in \\mathcal{F} \\) for any \\( x \\).</li> <li>\\( \\{X &lt; x\\} \\in \\mathcal{F} \\) for any \\( x \\).</li> <li>\\( \\{X \\geq x\\} \\in \\mathcal{F} \\) for any \\( x \\).</li> <li>\\( \\{x \\leq(&lt;) X \\leq(&lt;) y\\} \\in \\mathcal{F} \\) for any \\( x \\leq y \\).</li> </ol> Proof <ol> <li>Follows from \\( \\{X &gt; x\\} = \\{X \\leq x\\}^c \\), and \\( \\mathcal{F} \\) is closed under complementation.</li> <li>\\( \\{X &lt; x\\} = \\cap_{n} \\{X \\leq x +1/n\\} \\), and \\( \\mathcal{F} \\) is closed under countable union.</li> </ol> <p>The other assertions follows similar argumentations.</p> <p>This definition is compatible with many of the standard operations. In other terms the sum, product, composition with continuous function of random variables remain random variables.</p> <p>Proposition</p> <p>Let \\( X \\) be a random variable and \\( f:\\mathbb{R}\\to \\mathbb{R} \\) be a continuous function. Then</p> \\[   \\begin{equation*}     \\begin{split}       Y\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}\\\\       \\omega &amp; \\longmapsto Y(\\omega) = f(X(\\omega))     \\end{split}   \\end{equation*} \\] <p>is a random variable denoted \\( Y = f(X) \\).</p> <p>Let \\( X, Y \\) be random variables as well as \\( (X_n) \\) be a converging sequence of random variables. The following are random variables:</p> <ul> <li>\\( aX + bY \\) for every \\( a, b \\in \\mathbb{R} \\);</li> <li>\\( XY \\);</li> <li>\\( \\max(X, Y) \\) and \\( \\min(X, Y) \\);</li> <li>\\( \\sup X_n \\) and \\( \\inf X_n \\);</li> <li>\\( \\lim X_n \\).</li> </ul> Proof <p>The first part of the proof is not trivial and has to do with topology as well as the definition of continuous functions. The argument goes as follows, for \\(y\\) in \\(\\mathbb{R}\\), the set \\(F = \\{x \\in \\mathbb{R}\\colon f(x) \\leq y\\}\\) is a close set since \\(f\\) is continuous (lower semi-continuous would be enought). Now it is possible to show following the previous proposition that if \\(X\\) is a random variable, then \\(\\{X \\in F\\}\\) is an event since \\(F\\) is closed. It follows that</p> \\[   \\begin{align*}     \\{Y \\leq y\\} &amp; = \\left\\{\\omega \\in \\Omega\\colon f(X(\\omega))\\leq y\\right\\}\\\\                   &amp; = \\left\\{ \\omega \\in \\Omega \\colon X(\\omega) \\in \\{x \\in \\mathbb{R}\\colon f(x)\\leq y\\} \\right\\}\\\\                   &amp; = \\left\\{ X \\in F \\right\\} &amp;&amp; \\text{which is an event.}   \\end{align*} \\] <p>For the other three points, it follows from the continuity of functions. For the \\(\\sup\\) and \\(\\inf\\), it follows from \\(\\{\\sup X_n \\leq x\\} = \\cap \\{X_n \\leq x\\}\\) and \\(\\{\\inf X_n &lt;x\\} = \\cup \\{X_n &lt;x\\}\\), with similar argumentation of the limit of converging sequence of random variables.</p> <p>If you are interested, you can ask for lecture notes on probability.</p> <p>Example: Indicator and Simple Random Variables</p> <p>We turn to the most simple yet one of the most important example of random variable in probability.</p> <ul> <li> <p>Indicator Function</p> <p>Definition</p> <p>Let \\( (\\Omega, \\mathcal{F}) \\) be a measurable space and let \\( A \\in \\mathcal{F} \\) be an event. The function</p> \\[ \\begin{equation*} \\begin{split}   1_A \\colon &amp; \\Omega \\longrightarrow \\mathbb{R}\\\\   \\omega &amp; \\longmapsto 1_A(\\omega) =       \\begin{cases}        1 &amp; \\text{if } \\omega \\in A, \\\\        0 &amp; \\text{if } \\omega \\notin A      \\end{cases} \\end{split} \\end{equation*} \\] <p>is called the indicator function of \\( A \\).</p> <p>Exercise</p> <p>The indicator function \\(1_A\\) of an event \\(A\\) is a random variable. Indeed, let \\(x\\) be in \\(\\mathbb{R}\\). It follows that</p> \\[   \\{1_A \\leq x\\} =    \\begin{cases}   \\emptyset &amp; \\text{if } x&lt;0\\\\   A^c &amp; \\text{if }0\\leq x &lt;1 \\\\   \\Omega &amp; \\text{if }x \\geq 1   \\end{cases} \\] </li> <li> <p>Plot</p> <p> </p> </li> </ul> <p>This definition is strongly related to a table of truth: \\( 1 \\) for true, \\( 0 \\) for false. Clearly \\( 1_{\\emptyset} = 0 \\) and \\( 1_{\\Omega} = 1 \\). Show that:</p> <ol> <li>If \\( A \\) and \\( B \\) are events such that \\( A \\cap B = \\emptyset \\), then \\( 1_{A \\cup B} = 1_A + 1_B \\).</li> <li>If \\( A \\) and \\( B \\) are events, then \\( 1_{A \\cap B} = 1_A 1_B \\).</li> <li>If \\( A \\subseteq B \\) are events, then \\( 1_A \\leq 1_B \\).</li> </ol> <ul> <li> <p>Simple Random Variable</p> <p>Definition: Simple Random Variables</p> <p>For a family \\( A_1, A_2, \\ldots, A_n \\) of disjoint events and numbers \\( \\alpha_1, \\ldots, \\alpha_n \\), we can define the simple random variable</p> \\[   X(\\omega) = \\sum_{k=1}^n \\alpha_k 1_{A_k}(\\omega) =      \\begin{cases}       \\alpha_k &amp; \\text{if } \\omega \\in A_k, \\\\       0 &amp; \\text{otherwize}     \\end{cases} \\] <p>According to the previous proposition, it follows that \\( X \\) is also a random variable.</p> <p>Note that intuitively, multiplication and addition of simple random variables remain simple random variables, however one has to be careful to show it on the events where both random variable coincide.</p> </li> <li> <p>Plot</p> <p> </p> </li> </ul> <p>Example: Random Variable on Finite State Space</p> <p>Let \\( \\Omega = \\{\\omega_1, \\omega_2, \\ldots, \\omega_N\\} \\) be a finite state space and \\( \\sigma \\)-algebra \\( \\mathcal{F} = 2^\\Omega \\). We consider a financial market with one stock \\( S \\) where \\( S_0 &gt; 0 \\) denotes the price today and \\( S_1 \\) represents the possible price of the stock tomorrow. The possible evolution for the stock is given as a function:</p> \\[   \\begin{equation*}     \\begin{split}       S_1\\colon \\Omega &amp; \\longrightarrow [0, \\infty)\\\\           \\omega_n &amp;\\longmapsto S_1(\\omega_n) = s_n     \\end{split}   \\end{equation*} \\] <p>We can also write the stock price function as a simple random variable (showing therefore that it is a random variable):</p> \\[ S_1 = \\sum_{n=1}^N s_n 1_{A_n} \\] <p>where \\( A_n = \\{\\omega_n\\} \\). In other terms, the stock price is entirely given by the vector \\( (s_1, \\ldots, s_N) \\). Without any loss of generality, since we have one stock, we may assume that \\( s_1 &lt; s_2 &lt; \\ldots &lt; s_N \\). Also, since the stock price is positive, we also have \\( 0 \\leq s_1 \\). The returns \\( R_1 = \\frac{S_1 - S_0}{S_0} \\) are also a random variable that can be described as a vector \\( (r_1, \\ldots, r_N) \\), where</p> \\[ r_n = \\frac{s_n - S_0}{S_0} \\]"},{"location":"material/probability/#probability-measure","title":"Probability Measure","text":"<p>Definition: Probability Measure</p> <p>A probability measure \\( P \\) on the measurable space \\( (\\Omega, \\mathcal{F}) \\) is a function \\( P: \\mathcal{F} \\to [0,1] \\) that associate to each event \\(A\\) the likelyhood of this event.</p> <p>It has the following basic properties:</p> <ul> <li> <p>\\( P[\\emptyset] = 0 \\) and \\( P[\\Omega] = 1 \\)(1)</p> <ol> <li>Clearly, the probability that nothing or anything can happen is \\(0\\) or \\(1\\).</li> </ol> </li> <li> <p>\\(P[A \\cup B] = P[A] + P[B]\\) if \\(A\\) and \\(B\\) are two disjoint events.(1)</p> <ol> <li>The countable property is however assumed, that is \\( P[\\cup A_n] = \\sum P[A_n] \\) for every sequence of pairwise disjoint(1) events \\( (A_n) \\subseteq \\mathcal{F} \\).</li> </ol> </li> </ul> <p>The triple \\( (\\Omega, \\mathcal{F}, P) \\) is called a probability space.</p> <p>The assumptions for a probability measure are few, however together with the definition of the algebra we can rapidly derive classical properties that are common knowledge.</p> <p>Lemma</p> <p>Let \\( P \\) be a probability measure. For any events \\( A \\), \\( B \\), or sequence \\( (A_n) \\) of events, the following hold:</p> <ul> <li>\\( P[B] = P[A] + P[B \\setminus A] \\geq P[A] \\) whenever \\( A \\subseteq B \\);</li> <li>\\( P[A^c] = 1 - P[A] \\);</li> <li>\\( P[A \\cup B] + P[A \\cap B] = P[A] + P[B] \\);</li> <li> <p>If \\( A_1 \\subseteq A_2 \\subseteq \\ldots \\subseteq A_n \\subseteq \\ldots \\), then:</p> \\[   P\\left[ \\cup A_n \\right] = \\lim P[A_n] \\] </li> <li> <p>If \\( A_1 \\supseteq A_2 \\supseteq \\ldots \\supseteq A_n \\supseteq \\ldots \\), then:</p> \\[   P\\left[ \\cap A_n \\right] = \\lim P[A_n] \\] <p>In particular, it equals \\( 0 \\) if \\( \\cap A_n = \\emptyset \\).</p> </li> </ul> Proof <p>We prove some of the points, leaving the others as an exercise.</p> <p>For the first point, let \\( A \\subseteq B \\). We have \\( B = A \\cup (B \\setminus A) \\), where this union is disjoint. By the second property of a probability measure and the positivity of probability:</p> \\[ P[B] = P[A \\cup (B \\setminus A)] = P[A] + P[B \\setminus A] \\geq P[A] \\] <p>Taking \\( B = \\Omega \\), and using \\( P[\\Omega] = 1 \\), the second point follows.</p> <p>Using similar arguments, prove the third point.</p> <p>For the fourth point, construct the sequence of disjoint sets:</p> \\[     B_1 = A_1, \\quad B_2 = A_2 \\setminus A_1, \\quad \\ldots, \\quad B_n = A_n \\setminus A_{n-1} \\] <p>By induction, it is easy to show:</p> \\[ A_n = \\cup_{k=1}^n A_k = \\cup_{k=1}^n B_k, \\quad \\text{and} \\quad \\cup_n A_n = \\cup_n B_n \\] <p>By additivity of the probability measure:</p> \\[   P[A_n] = P\\left[ \\cup_{k=1}^n A_k \\right] = P\\left[ \\cup_{k=1}^n B_k \\right] = \\sum_{k=1}^n P[B_k] \\nearrow \\sum_{k=1}^\\infty P[B_k] \\] <p>Thus:</p> \\[   \\lim P[A_n] = \\sum_{k=1}^\\infty P[B_k] \\] <p>By the second property of a probability measure:</p> \\[ P\\left[ \\cup_{k=1}^\\infty A_k \\right] = P\\left[ \\cup_{k=1}^\\infty B_k \\right] = \\sum_{k=1}^\\infty P[B_k] \\] <p>Combining these equations shows \\( \\lim P[A_n] = P[\\cup A_n] \\).</p> <p>Follow similar reasoning to prove the last point.</p> <p>Note: Shorthand Notations in Probability</p> <p>In probability theory, the following shorthand notations are commonly used:</p> \\[ P[X \\in B] := P[\\{\\omega \\in \\Omega : X(\\omega) \\in B\\}], \\quad  P[X = x] := P[\\{\\omega \\in \\Omega : X(\\omega) = x\\}] \\] \\[ P[X \\leq x] := P[\\{\\omega \\in \\Omega : X(\\omega) \\leq x\\}], \\quad \\ldots \\] <p>Examples</p> <ol> <li> <p>Probability on Finite Sets:     Suppose \\( \\Omega = \\{\\omega_1, \\ldots, \\omega_N\\} \\) is finite.     Each probability measure \\( P \\) on \\( \\mathcal{F} = 2^\\Omega \\) is entirely determined by the values \\( p_n = P[\\{\\omega_n\\}] \\) for \\( n = 1, \\ldots, N \\).     Indeed, for every event \\(A\\) is of the form \\(A=\\{\\omega_n\\colon n \\in I\\}\\) for some \\(I\\subseteq \\{1, \\ldots, N\\}\\).     It follows that</p> \\[   P[A] = \\sum_{\\omega \\in A} P[\\{\\omega\\}] = \\sum_{n \\in I} p_n \\] <p>This vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N) \\) has the property that \\(p_n = P[\\{\\omega_n\\}]\\geq 0\\) and \\(\\sum p_n =P[\\Omega] = 1\\).</p> <p>Reciprocally, if you give yourself a vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N)\\) with \\(p_n \\geq 0\\) and \\(\\sum p_n\\), it defines a probability \\(P\\) on \\(\\mathcal{F}\\) with the definition</p> \\[   P[A]:=\\sum_{n \\in I} p_n \\] <p>where \\(A = \\{\\omega_n \\colon n \\in I\\}\\). As an exercise, verify that this defines a probability measure.</p> <p>The set of such vectors is denoted by</p> \\[   \\Delta := \\left\\{ \\boldsymbol{p} \\in \\mathbb{R}^N \\colon : p_n \\geq 0, \\, \\sum p_n = 1 \\right\\} \\] <p>An important case is when \\( p_n = 1/N \\) for all \\( n \\). This is called the uniform probability distribution.</p> </li> <li> <p>Probability on the Coin Toss Space:     Let \\( \\Omega = \\{\\omega = (\\omega_1, \\ldots, \\omega_T) : \\omega_t = \\pm 1\\} \\), a finite state space.     Assuming the probability of heads is \\( p \\) and coin tosses are independent, the probability is:</p> \\[   P[\\{\\omega = (\\omega_1, \\ldots, \\omega_T)\\}] = p^l q^{T-l} \\] <p>where \\( l \\) is the number of times \\( \\omega_t = 1 \\) for \\( t = 1, \\ldots, T \\).</p> </li> <li> <p>Normal Distribution:     For \\( \\Omega = \\mathbb{R} \\) and \\( \\mathcal{F} \\) the \\( \\sigma \\)-algebra of \\( \\mathbb{R} \\) generated by intervals, define for any event \\(A\\) the probability</p> \\[   P[A] = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\int_A e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\lambda(dx) \\] <p>where \\( \\lambda \\) is the Lebesgue measure on \\( \\mathbb{R} \\), the one measuring intervals. This is the normal distribution. For example, temperatures in Shanghai at this time of year may follow a normal distribution around 24\u00b0C with variance 1.</p> </li> </ol>"},{"location":"material/probability/#integration","title":"Integration","text":"<p>The historical idea behind integration was to measure areas below a function. The expectation in probability brings exactly the same intuition to this more abstract level.</p> <p>Consider the simple example of the indicator function \\(1_A\\), it represents a rectangle of height \\(1\\) and width represented by the measure of \\(A\\), that is \\(P[A]\\). Hence, the area of the rectangle, or expectation of the indicator function, is given by \\(E[1_A]=1 \\times P[A]\\).</p> <p>Extending this concept is straightforward for any positive simple random variable.</p> <ul> <li> <p>Integration of Simple Random Variable</p> <p>Definition: Expectation 1.0</p> <p>Let \\((\\Omega,\\mathcal{F},P)\\) be a probability space. Given a simple random variable  </p> \\[   X = \\sum_{k\\leq n} \\alpha_k 1_{A_k} \\] <p>we define the expectation of \\(X\\) with respect to \\(P\\) as  </p> \\[   E[X]:=\\sum_{k\\leq n} \\alpha_k P[A_k] \\] </li> <li> <p>Plot</p> <p> </p> </li> </ul> <p>Warning</p> <p>One needs to be careful that this definition is independent of the representation of the simple random variable. Indeed, we have \\(X= 1_A + 1_B = 1_{A\\cup B}\\) if \\(A\\) and \\(B\\) are disjoint for instance. Luckily, by the properties of the probability measure, this random variable has the same expectation for the two representations.</p> <p>Proposition</p> <p>The two following important properties of the expectation on simple random variables can be rapidely checked.</p> <ul> <li>Monotony: \\(E[X]\\leq E[Y]\\) whenever \\(X\\leq Y\\).  </li> <li>Linearity: \\(E[aX+bY]=aE[X]+bE[Y]\\).  </li> </ul> <p>The proof of which is easy and left to you.</p> <p>Exercise</p> <p>Given a simple random variable \\(X\\) show that</p> <ol> <li>If \\(X\\) is positive, then \\(E[X]&gt;0\\) if and only if \\(P[X&gt;0] &gt;0\\).  </li> <li>If \\(X\\) is positive, then \\(E[X] = 0\\) if and only if \\(P[X = 0]=1\\).  </li> </ol> <p>We can now define the expectation of an arbitrary positive random random variable. The idea is to approximate from below this random variable by simple ones and take the limit.</p> <ul> <li> <p>First Approximation</p> <p> </p> </li> <li> <p>Second Approximation</p> <p> </p> </li> </ul> Note <p>Though the definition of the expectation does not implies the explicit construction of a sequence approximating, it is however possible to formalize the idea in the picture.</p> <p>Given a random variable \\(X\\), the strategy is as follows: For every natural number \\(n\\), divide the ever growing vertical interval \\([0, n)\\) into \\(2^n\\) sub intervals \\(\\left[k \\frac{n}{2^Nn}, (k+1)\\frac{n}{2^n}\\right)\\) for \\(k=0, \\ldots, 2^n-1\\). Define now</p> \\[   \\alpha_k^n = k \\frac{N}{2^n} \\quad \\text{and}\\quad A_k^n = \\left\\{ k\\frac{N}{2^n} \\leq X &lt; (k+1)\\frac{n}{2^N} \\right\\} \\] <p>It follows that the sequence \\((X_n)\\) of simple random variables defined as</p> \\[     X_n = \\sum_{k=0}^{2^N-1} \\alpha_k^n 1_{A_k^n} \\] <p>is increasing and converges to \\(X\\).</p> <p>Definition: Expectation 1.5</p> <p>Given a positive random variable, the expectation of which is defined as</p> \\[   E[X] := \\sup \\left\\{ E[Y] \\colon Y\\text{ simple random variable and } Y\\leq X \\right\\} \\] <p>This is well defined but eventually equal to \\(\\infty\\). For this is also holds that for two positive random variable \\(X\\) and \\(Y\\) with positive numbers \\(a\\) and \\(b\\) then \\(E[aX + bY] = aE[X] + b E[Y]\\) as well as \\(E[X]\\leq E[Y]\\) if \\(X\\leq Y\\).</p> <p>To consider general random variable, we need to assume integrability.</p> <p>Definition: Expectation 2.0</p> <p>A random variable is called integrable if \\(E[X^+]&lt;\\infty\\) and \\(E[X^-]&lt;\\infty\\). The expectation of an integrable random variable is then defined as</p> \\[E[X] = E[X^+]-E[X^-]\\] <p>On the set of integrable random variables, which is a vector space, the expectation is also linear and monotone.</p> <p>The following fundamental theorem is due to Lebesgue. It tells under which conditions it is possible to swap limit and expectation.</p> <p>Theorem</p> <p>Let \\((X_n)\\) be a sequence of random variables.  The following holds true</p> <ol> <li> <p>Monotone Convergence: If \\((X_n)\\) are positive and increasing, that is, X_1\\leq X_2 \\leq \\cdots$  it holds that</p> \\[     \\sup E[X_n] = \\lim E[X_n] = E[\\sup X_n] = E[\\lim X_n] \\] </li> <li> <p>Fatou's Lemma: If \\((X_n)\\) are positive then it holds</p> \\[     E\\left[ \\liminf X_n \\right]:=E\\left[ \\sup_n \\inf_{k\\geq n} X_k\\right] \\leq \\liminf E[X_n] \\] </li> <li> <p>Lebesgue's Dominated Convergence: If \\(X_n(\\omega) \\to X(\\omega)\\) for all (at least in probability) and \\(|X_n|\\leq Y\\) for some integrable random variable \\(Y\\), then it holds</p> \\[   \\lim E[X_n] = E[\\lim X_n] = E[X] \\] </li> </ol> Proof <p>We start by the monotone convergence.</p> <p>By monotonicity, we clearly have \\(E[X_n]\\leq E[X]\\) for every \\(n\\), therefore \\(\\sup E[X_n]\\leq E[X]\\).</p> <p>Reciprocally, suppose that \\(E[X]&lt;\\infty\\) and pick \\(\\varepsilon&gt;0\\) and a positive simple random variable \\(Y \\) such that \\(Y\\leq X\\) and \\(E[X]-\\varepsilon\\leq E[Y]\\). For \\(0&lt;c&lt;1\\), define the sets \\(A_n=\\{X_n\\geq cY\\}\\). Since \\(X^n\\) is increasing to \\(X\\), it follows that \\(A_n\\) is an increasing sequence of events. Furthermore, since \\(cY\\leq Y\\leq X\\) and \\(cY&lt;X\\) on \\(\\{X&gt;0\\}\\), it follows that \\(\\cup A_n=\\Omega\\). By non-negativity of \\(X_n\\) and monotonicity, it follows that</p> \\[     cE[1_{A_n}Y]\\leq E[1_{A_n}X_n]\\leq E[X_n] \\] <p>and so</p> \\[     c\\sup E[1_{A_n}Y]\\leq \\sup E[X_n] \\] <p>Since \\(Y=\\sum_{l\\leq k} \\alpha_l 1_{B_l}\\) for positive numbers \\(\\alpha_1,\\ldots,\\alpha_k\\) and events \\(B_1,\\ldots, B_k\\), it follows that  </p> \\[     E\\left[ 1_{A_n}Y \\right]=\\sum_{l\\leq k}\\alpha_l P[A_n\\cap B_l]. \\] <p>However, since \\(P\\) is a probability measure, and \\(A_n\\) is increasing to \\(\\Omega\\), it follows from the lower semi-continuity of probability measures, that \\(P[A_n\\cap B_l]\\nearrow P[\\Omega\\cap B_l]=P[B_l]\\), and so  </p> \\[     \\sup E[1_{A_n}Y]=\\sum_{l\\leq k}\\alpha_l \\sup P[A_n\\cap B_l]=\\sum \\alpha_l P[B_l]=E[Y]. \\] <p>Consequently</p> \\[     E[X]\\geq \\lim E[X_n]=\\sup E[X_n]\\geq cE[Y] \\geq cE[X]-c\\varepsilon \\] <p>which, by letting \\(c\\) converge to \\(1\\) and \\(\\varepsilon\\) to \\(0\\), yields the result.  </p> <p>The case where \\(E[X]=\\infty\\) is similar and left to the reader.</p> <p>As for Fatou's lemma, define \\(Y_n =\\inf_{k\\geq n} X_k\\) which defines by assumption an increasing sequence of positive random variables. It follows from monotone convergence that</p> \\[     \\sup_n E\\left[ Y_n  \\right] = E[\\sup_n Y_n] = E[\\sup_n \\sup_{k\\geq n}X_n] = E[\\liminf X_n] \\] <p>On the other hand, it clearly holds that \\(X_k \\geq Y_n\\) for every \\(k\\geq n\\) and therefore \\(\\inf_{k\\geq n} E[X_k] \\geq E[Y_n]\\). Combined with the previous inequality we get</p> \\[   E[\\liminf X_n] = \\sup_n E[Y_n]\\leq \\sup_n \\inf_{k\\geq n}E[X_k] = \\liminf E[X_n] \\] <p>As for the dominated convergence of Lebesgue, we have by assumption that \\(X_n+Y\\) is a sequence of positive random variables, which by Fatou's lemma yields</p> \\[   E[X+Y] =E[\\liminf X_n +Y ] \\leq \\liminf E[X_n] +E[Y] \\] <p>Reciprovally \\(Y = X_n\\) is a sequence of positive random variable for which also holds</p> \\[   E[Y-X] = E[\\liminf Y - X_n] \\leq E[Y] +\\liminf -E[X_n] = E[Y] - \\limsup E[X_n] \\] <p>Combining both inequality yields</p> \\[   \\limsup E[X_n] \\leq E[X] \\leq \\liminf E[X_n] \\] <p>Since $\\liminf \\leq \\limsup $ if and only if there exists a limit we deduce that \\(E[X] = \\lim E[X_n]\\).</p> <p>Example</p> <ul> <li> <p>Integration for the simple coin toss:     Let \\(\\Omega =\\{\\omega_1,\\omega_2\\}\\) and \\(p=P[\\{\\omega_1\\}]\\) and \\(q=(1-p)\\).     Every random variable \\(X:\\Omega \\to \\mathbb{R}\\) is entirely determined by the values \\(X(\\omega_1) = x_1\\) and \\(X(\\omega_2)=x_2\\).     It follows that  </p> \\[     E[X]=pX(\\omega_1)+qX(\\omega_2) = p x_1 + (1-p)x_2 \\] </li> <li> <p>Integration in the finite state case:     Let \\(\\Omega=\\{\\omega_1,\\ldots,\\omega_N\\}\\) be a finite state space.     The probability measure is entirely given by the vector \\(\\boldsymbol{p}=(p_1,\\ldots,p_N)\\in \\mathbb{R}^N\\), where \\(p_n=P[\\{\\omega_n\\}]\\geq 0\\) and \\(\\sum p_n=1\\).     Every random variable \\(X:\\Omega \\to \\mathbb{R}\\) can be seen as a vector \\(\\boldsymbol{x} \\in \\mathbb{R}^N\\), where \\(x_n=X(\\omega_n)\\).     It follows that the expectation of \\(X\\) under \\(P\\) is given by</p> \\[     E[X]=\\sum p_n X(\\omega_n)=\\sum p_n x_n=\\boldsymbol{p}\\cdot \\boldsymbol{x} \\] <p>In other terms, the expectation of \\(X\\) boils down to the scalar product of the probability vector \\(\\boldsymbol{p}\\) with the vector of values \\(\\boldsymbol{x}\\) of the random variable.</p> </li> </ul>"},{"location":"material/probability/#measure-change","title":"Measure Change","text":"<p>The concept of the expectation of a random variable \\( E[X] \\) depends, by definition, on the probability measure \\( P \\). We should therefore write \\( E^P[X] \\) to signify this dependence. If, on the same measurable space \\( (\\Omega, \\mathcal{F}) \\), we are given another probability \\( Q \\), the question arises: how is \\( E^P[X] \\) related to \\( E^Q[X] \\)?</p> <p>Remark</p> <p>Before diving into this question, let us first see how, starting from a probability \\( P \\), we can define a new probability \\( Q \\). Suppose we are given a random variable \\( Z \\) such that:</p> <ol> <li>\\( Z \\) is positive.</li> <li>\\( E^P[Z] = 1 \\).</li> </ol> <p>We can define the function:</p> \\[ \\begin{aligned}     Q \\colon \\mathcal{F} &amp; \\longrightarrow [0,1] \\\\       A &amp; \\longmapsto Q[A] = E^P[Z \\cdot 1_A] \\end{aligned} \\] <p>This function, for any event \\( A \\), returns the expectation of \\( Z \\) over \\( A \\). It turns out that this function, under the assumptions on \\( Z \\), defines a new probability measure. Specifically:</p> <ul> <li>\\( Q[\\emptyset] = E^P[Z \\cdot 1_\\emptyset] = E^P[0] = 0 \\),</li> <li>\\( Q[\\Omega] = E^P[Z \\cdot 1_\\Omega] = E^P[Z] = 1 \\).</li> </ul> <p>Additivity also holds: for any two disjoint events \\( A \\) and \\( B \\), \\( 1_{A \\cup B} = 1_A + 1_B \\). Hence:</p> \\[ Q[A \\cup B] = E^P[Z \\cdot 1_{A \\cup B}] = E^P[Z \\cdot 1_A] + E^P[Z \\cdot 1_B] = Q[A] + Q[B]. \\] Warning <p>To fully define \\( Q \\) as a probability measure, you must also check \\(\\sigma\\)-additivity. That is, for every sequence \\( (A_n) \\) of pairwise disjoint events, it must hold:</p> \\[ Q\\left[\\bigcup A_n\\right] = \\sum Q[A_n]. \\] <p>Define the random variables \\( X_n = Z \\cdot 1_{\\cup_{k \\leq n} A_k} = Z \\cdot \\left( \\sum_{k \\leq n} 1_{A_k} \\right) \\) and let \\( X = Z \\cdot 1_{\\cup A_n} \\). Since \\( |X_n| \\leq Z \\), where \\( Z \\) is integrable, dominated convergence implies:</p> \\[ \\lim E^P[X_n] = E^P[X]. \\] <p>Meanwhile:</p> \\[ E^P[X_n] = \\sum_{k \\leq n} E^P[Z \\cdot 1_{A_k}] = \\sum_{k \\leq n} Q[A_k], \\] <p>and \\( E^P[X] = Q\\left[\\bigcup A_n\\right] \\).</p> <p>Hence, any positive random variable \\( Z \\) with expectation 1 under \\( P \\) defines a new probability measure \\( Q \\).</p> <p>Furthermore, for any bounded random variable \\( X \\), it holds that: [ E^Q[X] = E^P[Z \\cdot X]. ]</p> <p>To see this, consider a simple random variable \\( X = \\sum \\alpha_k \\cdot 1_{A_k} \\):</p> \\[ \\begin{aligned}     E^Q[X] &amp;= \\sum \\alpha_k Q[A_k] \\\\            &amp;= \\sum \\alpha_k E^P[Z \\cdot 1_{A_k}] \\\\            &amp;= E^P[Z \\cdot X]. \\end{aligned} \\] <p>The general case follows by approximating \\( X \\) with simple random variables.</p> <p>Additionally, \\( Q \\) is dominated by \\( P \\) in the sense that \\( P[A] = 0 \\) implies \\( Q[A] = E^P[Z \\cdot 1_A] = 0 \\).</p> <p>From this, we see that a positive random variable \\( Z \\) with expectation 1 allows us to define a new probability \\( Q \\), dominated by \\( P \\), and connects expectations under \\( Q \\) to those under \\( P \\). The challenging and powerful task is to establish the reciprocal relationship. The key lies in the concepts of absolute continuity or equivalence between probability measures, and the Radon-Nikodym Theorem.</p> <p>Definition</p> <p>Given two probability measures \\( P \\) and \\( Q \\), we define:</p> <ol> <li> <p>\\( Q \\) is absolutely continuous with respect to \\( P \\) (\\( Q \\ll P \\)) if:</p> \\[ P[A] = 0 \\quad \\text{implies} \\quad Q[A] = 0. \\] </li> <li> <p>\\( Q \\) is equivalent to \\( P \\) (\\( Q \\sim P \\)) if both \\( Q \\ll P \\) and \\( P \\ll Q \\), i.e.:</p> \\[ P[A] = 0 \\quad \\text{if and only if} \\quad Q[A] = 0. \\] </li> </ol> <p>By definition:</p> \\[ Q \\ll P \\quad \\text{if and only if} \\quad P[A] = 1 \\text{ implies }Q[A] = 1, \\] <p>or equivalently:</p> \\[ Q \\ll P \\quad \\text{if and only if} \\quad Q[A] &gt; 0 \\text{ implies }P[A] &gt; 0. \\] <p>In the equivalent case:</p> \\[ Q \\sim P \\quad \\text{if and only if} \\quad P[A] = 1 \\text{if and only if } Q[A] = 1, \\] <p>or equivalently:</p> \\[ Q \\sim P \\quad \\text{if and only if} \\quad P[A] &gt; 0 \\text{ if and only if } Q[A] &gt; 0. \\] <p>Absolute continuity implies that events unlikely under \\( P \\) are also unlikely under \\( Q \\). Equivalence means that \\( P \\) and \\( Q \\) agree on which sets are unlikely.</p> <p>Radon-Nikodym Theorem</p> <p>On a measurable space \\( (\\Omega, \\mathcal{F}) \\), if a probability measure \\( Q \\) is absolutely continuous with respect to another probability measure \\( P \\), there exists a (\\( P \\)-almost surely) unique random variable \\( Z \\) such that:</p> \\[ \\begin{aligned}     Z &amp;\\geq 0, \\\\     E^P[Z] &amp;= 1, \\\\     E^Q[X] &amp;= E^P[Z \\cdot X] \\quad \\text{ for any bounded random variable } X. \\end{aligned} \\] <p>This unique random variable is called the density of \\( Q \\) with respect to \\( P \\) and is denoted \\( \\frac{dQ}{dP} \\).</p> <p>The notation \\( \\frac{dQ}{dP} \\) is cosmetic; it does not represent a literal ratio. It simplifies expressions such as:</p> \\[ E^P\\left[ \\frac{dQ}{dP} \\cdot X \\right] = \\int X \\frac{dQ}{dP} \\, dP = \\int X \\, dQ = E^Q[X]. \\] <p>This theorem underpins many results in stochastic processes and finance, such as the Black-Scholes-Merton formula. However, proving it requires knowledge of functional analysis, which is beyond this lecture's scope. The proof is simpler in a finite state space.</p> <p>Exercise</p> <p>Let \\( \\Omega = \\{\\omega_1, \\ldots, \\omega_n\\} \\) be a finite state space with \\( \\sigma \\)-algebra \\( \\mathcal{F} = 2^\\Omega \\). Suppose \\( P \\) is a probability measure given by \\( \\boldsymbol{p} = (p_1, \\ldots, p_n) \\), where \\( P[\\{\\omega_i\\}] = p_i &gt; 0 \\) and \\( \\sum p_i = 1 \\). Let \\( Q \\) be another probability measure on \\( (\\Omega, \\mathcal{F}) \\) given by \\( \\boldsymbol{q} = (q_1, \\ldots, q_n) \\), where \\( Q[\\{\\omega_i\\}] = q_i \\geq 0 \\) and \\( \\sum q_i = 1 \\).</p> <p>Since \\( P[A] = 0 \\) implies \\( A = \\emptyset \\), it follows that \\( Q[A] = Q[\\emptyset] = 0 \\). Hence, \\( Q \\ll P \\).</p> <p>Find a random variable \\( \\frac{dQ}{dP} \\colon \\Omega \\to \\mathbb{R} \\) such that \\( \\frac{dQ}{dP} \\geq 0 \\), \\( E^P\\left[\\frac{dQ}{dP}\\right] = 1 \\), and:</p> \\[ E^Q[X] = E^P\\left[\\frac{dQ}{dP} \\cdot X\\right] \\] <p>for every random variable \\( X \\colon \\Omega \\to \\mathbb{R} \\). Show that \\( \\frac{dQ}{dP} \\) is unique.</p> <p>In this finite setting, \\( \\frac{dQ}{dP} \\) can be represented by a vector \\( \\boldsymbol{z} = (z_1, \\ldots, z_n) \\) with \\( z_i = \\frac{dQ}{dP}(\\omega_i) \\). The conditions reduce to finding \\( \\boldsymbol{z} \\) such that \\( z_i \\geq 0 \\), \\( \\sum z_i p_i = 1 \\), and for every vector \\( \\boldsymbol{x} = (x_1, \\ldots, x_n) \\):</p> \\[ \\sum x_i q_i = E^Q[X] = E^P\\left[\\frac{dQ}{dP} \\cdot X\\right] = \\sum x_i z_i p_i. \\]"},{"location":"material/probability/#independence","title":"Independence","text":"<p>A fundamental concept in probability, distinct from general measure theory, is independence. Intuitively, two events \\( A \\) and \\( B \\) are independent if their probability of joint occurrence equals the product of their respective probabilities.</p> <p>This concept can be extended to random variables and families of events, with significant implications for results in probability theory.</p> <p>Definition</p> <p>Given a probability space \\( (\\Omega, \\mathcal{F}, P) \\):</p> <ol> <li> <p>Two events \\( A \\) and \\( B \\) are called independent if:</p> \\[ P[A \\cap B] = P[A] P[B]. \\] </li> <li> <p>Two families of events \\( \\mathcal{C} \\) and \\( \\mathcal{D} \\) are independent if any event \\( A \\) in \\(\\mathcal{C}\\) is independent of any event \\( B \\) in \\(\\mathcal{D}\\).</p> </li> <li> <p>Two random variables \\( X \\) and \\( Y \\) are independent if the \\(\\sigma\\)-algebras generated by their information,</p> \\[ \\sigma(X) = \\sigma(\\{X \\leq x\\} : x \\in \\mathbb{R}) \\quad \\text{and} \\quad \\sigma(Y) = \\sigma(\\{Y \\leq x\\} : x \\in \\mathbb{R}), \\] <p>are independent.</p> </li> <li> <p>A collection of families of events \\( \\mathcal{C}^i \\) (with \\( i \\) indexing the families) is independent if for every finite selection of events \\( A^{i_1}, \\ldots, A^{i_n} \\), where \\( A^{i_k}\\) is in \\(\\mathcal{C}^{i_k} \\), it holds that:</p> \\[ P\\left[ A^{i_1} \\cap \\cdots \\cap A^{i_n} \\right] = \\prod_{k=1}^n P[A^{i_k}]. \\] </li> <li> <p>A family (or sequence) of random variables \\( (X_i) \\) is independent if the family of \\(\\sigma\\)-algebras \\( \\sigma(X_i) \\) is independent.</p> </li> </ol> <p>Warning</p> <p>The first three points focus on pairwise independence for events, families, or random variables. However, for collections with more than two elements, pairwise independence is insufficient.  For example, a sequence of random variables requires a stronger notion of independence that accounts for all finite subsets.  </p> <p>Exercise</p> <p>Consider a four-element probability space \\( \\Omega = \\{\\omega_1, \\omega_2, \\omega_3, \\omega_4\\} \\) with uniform probability \\( P[\\{\\omega_i\\}] = \\frac{1}{4} \\). Construct three events \\( A_1 \\), \\( A_2 \\), and \\( A_3 \\) such that: - \\( A_1 \\) is independent of \\( A_2 \\), - \\( A_1 \\) is independent of \\( A_3 \\), - \\( A_2 \\) is independent of \\( A_3 \\), - but \\( A_1 \\), \\( A_2 \\), and \\( A_3 \\) together are not independent.</p> <p>Formally:</p> \\[ \\begin{aligned}     P[A_1 \\cap A_2] &amp;= P[A_1] P[A_2], \\\\     P[A_1 \\cap A_3] &amp;= P[A_1] P[A_3], \\\\     P[A_2 \\cap A_3] &amp;= P[A_2] P[A_3], \\\\     P[A_1 \\cap A_2 \\cap A_3] &amp;\\neq P[A_1] P[A_2] P[A_3]. \\end{aligned} \\] <p>If you struggle, ask ChatGPT\u2014it can handle this.</p> <p>Independence is a strong assumption, but it depends on the probability measure. Even if two events are independent under a specific \\( P \\), independence might fail under a different measure. This concept is crucial in foundational results such as the law of large numbers and the central limit theorem, which are cornerstones of Monte Carlo methods.</p> <p>Let us now present a proposition related to independent random variables, which will be further explored in the context of stochastic processes and conditional expectations.</p> <p>Proposition</p> <p>Let \\( X \\) and \\( Y \\) be two independent bounded random variables. Then:</p> \\[ E[X Y] = E[X] E[Y]. \\] <p>Proof sketch</p> <p>Consider the case where \\( X = 1_A \\) and \\( Y = 1_B \\) are indicator functions. Independence of \\( X \\) and \\( Y \\) implies that \\( A \\) and \\( B \\) are independent. Hence: [ E[XY] = E[1_A 1_B] = E[1_{A \\cap B}] = P[A \\cap B] = P[A] P[B] = E[X] E[Y]. ]</p> <p>This reasoning extends easily to simple random variables, as the \\(\\sigma\\)-algebras generated by \\( X \\) and \\( Y \\) correspond to the events on which they are defined.</p> <p>For the general case, approximate \\( X \\) and \\( Y \\) by sequences of simple random variables \\( (X_n) \\) and \\( (Y_n) \\), and use the properties of independence and limits of expectations.</p>"},{"location":"material/probability/#conditional-expectation","title":"Conditional Expectation","text":"<p>The conditional expectation is the first step towards stochastic processes. It is basically the best approximation in terms of expectation given some information. In other terms, let \\(\\mathcal{G}\\subseteq \\mathcal{F}\\) be a sub-\\(\\sigma\\)-algebra of events, what is the best approximation of the expectation of \\(X\\) knowing the events in \\(\\mathcal{G}\\).</p> <p>Conditional Expectation</p> <p>Let \\((\\Omega, \\mathcal{F}, P)\\) be a probability space, \\(X\\) a random variable and \\(\\mathcal{G}\\subseteq \\mathcal{F}\\) a \\(\\sigma\\)-algebra.</p> <p>Then, there exists a unique(1) random variable \\(Y\\) with the properties</p> <ol> <li>\\(Y\\) is \\(\\mathcal{G}\\)-measurable;</li> <li>\\(E[Y1_A] = E[X1_A]\\) for any event \\(A\\) in \\(\\mathcal{G}\\).</li> </ol> Proof <p>The proof of the theorem is a consequence of Radon-Nykodym derivative. Indeed, define the measurs \\(Q^+\\) and \\(Q^-\\)</p> \\[     \\begin{equation*}         \\begin{split}             Q^\\pm \\colon \\mathcal{G} &amp;\\longrightarrow [0, \\infty)\\\\                         A &amp; \\longmapsto Q^\\pm[A] = E[X^\\pm 1_A]         \\end{split}     \\end{equation*} \\] <p>which are measures defined on the smallest \\(\\sigma\\)-algebra of events \\(\\mathcal{G}\\). These measures are absolutely continuous with respect to \\(P\\), and therefore there exists unique \\(dQ^\\pm/dP\\) their densities that are \\(\\mathcal{G}\\)-measurable.</p> <p>Defining </p> \\[     Y = \\frac{dQ^+}{dP} - \\frac{dQ^-}{dP} \\] <p>give a unique \\(\\mathcal{G}\\)-measurable random variable satistying by definition the expectation property.</p> <p>Since the random variable satisfying the two conditions is unique(1) we can therefore use it as definition.</p> <p>Conditional Expectation</p> <p>The conditional expectation of a random variable \\(X\\) with respect to \\(\\mathcal{G}\\) is denoted by \\(E[X|\\mathcal{G}]\\) and is defined as the unique random variable which is \\(\\mathcal{G}\\)-measurable and such that \\( E[ E[X |\\mathcal{G}]1_A] = E[X 1_A]\\) for all events \\(A\\) in \\(\\mathcal{G}\\).</p> <p>The conditional expectation shares most of the properties of the traditional expectation</p> <p>Proposition</p> <p>Let \\(X\\) be a random variable, \\(\\mathcal{G} \\subseteq \\mathcal{F}\\). It holds that</p> <ul> <li>Expectation: \\(E[E[X|\\mathcal{G}]] = E[X]\\)</li> <li>Conditional Linearity: \\(E[Y X + Z |\\mathcal{G}] = Y E[X |\\mathcal{G}] + Z\\) for any random variables \\(Y\\) and \\(Z\\) which are \\(\\mathcal{G}\\)-measurable.</li> <li>Tower Property: \\(E[E[X | \\mathcal{G_2}] | \\mathcal{G}_1] = E[X|\\mathcal{G}_1]\\) if \\(\\mathcal{G}_1\\subseteq \\mathcal{G}_2\\).</li> <li>Trivial: \\(E[X |\\mathcal{F}_0] = E[X]\\) if \\(\\mathcal{F}_0 = \\{\\emptyset, \\Omega\\}\\),</li> <li>Independence: \\(E[X | \\mathcal{G}] = E[X]\\) if \\(X\\) is independent of \\(\\mathcal{G}\\).</li> </ul>"},{"location":"material/stochastic/","title":"Stochastic Processes","text":"<p>Stochastic processes mean that you want to carry over time the idea that outcomes will be revealed as time goes by. Considering for instance your view of the evolution of a financial asset. At the very begining your decisions towards it relies only on what you can forsee in the future about its evolution however as times goes buy you learn more and more infromation about the nature of this financial asset.</p> <p>Example</p> <p>We consider a probability space \\((\\Omega, \\mathcal{F}, P)\\) and a sequence \\((Y_t)\\) of independent identically distributed (iid) random variables such that</p> \\[   P[Y_t = 1] = P[Y_1 = 1] = \\frac{1}{2} = P[Y_1 = -1] = P[Y_t = -1] \\] <p>In other terms, \\(Y_n\\) represent the result of tossing a fair coin at time \\(t\\) with \\(1\\) if tail and \\(-1\\) if head.</p> <p>We define the (symetric) random walk as</p> \\[   S_0 = 100 \\quad \\text{and} \\quad S_t = S_{t-1} + Y_t = 100 + \\sum_{s=1}^t Y_s \\] <p>this produces the following possible paths</p> <p> </p> <p>Now for a price of \\(100\\) RMB you have the choice between the different games.</p> <ol> <li>All In: Receive the value of the random walk after 100 coin tosses, that is \\(S_{100}\\).</li> <li>Stop Gain: If the random walk reaches \\(120\\), you stop the game and cash \\(120\\), otherwize you get \\(S_{100}\\)</li> <li>Stop Loss: If the random walk falls to \\(90\\), you stop the game and cash \\(90\\), otherwize you get \\(S_{100}\\).</li> <li>Stop Gain/Loss: If the random walk reaches \\(120\\) or \\(90\\) you stop the gain an cash \\(120\\) or \\(90\\) respectively, otherwize you get \\(S_{100}\\).</li> <li>Not a gambler: I don't play and keep my \\(100\\) RMB</li> </ol> <p>Now which game would you venture in and why? Which game would bring you in expectation the best outcome?</p>"},{"location":"material/stochastic/#information-conditional-expectation","title":"Information, Conditional Expectation","text":"<p>Information is considered as a \\(\\sigma\\)-algebra of events. Now information means that we have an increasing sequence of events that we are aware of, called a filtration.</p> <p>Definition: Filtration</p> <p>A filtration \\(\\mathbb{F} = (\\mathcal{F}_t)_{t=0, \\ldots, T}\\) is a collection of \\(\\sigma\\)-algebra of events such that</p> \\[ \\mathcal{F}_0 \\subseteq \\mathcal{F}_1 \\subseteq \\cdots \\subseteq \\mathcal{F}_T\\] <p>In other terms, the collection of events known at time \\(s\\) is included in the set of events known at time \\(t\\geq s\\).</p> <p>Warning</p> <p>It is not necessary but throughout we make the assumption that </p> \\[\\mathcal{F}_0 = \\{\\emptyset, \\Omega\\} \\quad \\text{and}\\quad \\mathcal{F}_T = \\mathcal{F}\\] <p>In other terms, we assume that at time zero we know nothing and at time \\(T\\) we know everything.</p> <p>Lemma</p> <p>If a random variable \\(\\xi\\) is \\(\\mathcal{F}_0=\\{\\emptyset, \\Omega\\}\\)-measurable, then it must be constant.</p> Proof <p>It is a basic exercise to check. Suppose that a random variable \\(\\xi\\) is \\(\\mathcal{F}_0=\\{\\emptyset, \\Omega\\}\\)-measurable then it constant. Indeed, if it where not, let \\(\\omega_1\\) and \\(\\omega_2\\) be two states on which \\(\\xi(\\omega_1) &lt; \\xi(\\omega_2)\\), let \\(x\\) be such that \\(\\xi(\\omega_1)&lt;x&lt;\\xi(\\omega_2)\\). It follows that \\(\\omega_1 \\in A=\\{\\xi\\leq x\\}\\) while \\(\\omega_2 \\not \\in A\\). This is however not possible since the event \\(A\\) is either \\(\\Omega\\) or \\(\\emptyset\\).</p> <p>In this case, it follows that any random variable \\(\\xi\\) which is \\(\\mathcal{F}_0\\) measurable must be constant.</p> <p>Definition</p> <p>A family \\(X = (X_t)\\) of random variable indexed by time is called a stochastic process.</p> <p>A stochastic process \\(X\\) is called </p> <ul> <li>Adapted: if \\(X_t\\) is \\(\\mathcal{F}_t\\)-measurable for every \\(t\\);</li> <li>Predictable: if \\(X_t\\) is \\(\\mathcal{F}_{t-1}\\)-measurable for every \\(t\\)</li> </ul> Remark <p>For predictability, one needs to specify a convention for \\(X_0\\). either we say that predictable processes starts at time \\(1\\) or we say that \\(\\mathcal{F}_{-1} = \\mathcal{F}_0 = \\{\\emptyset, \\Omega\\}\\).</p>"},{"location":"material/stochastic/#martingales","title":"Martingales","text":"<p>Martingales are the most important object to study the properties of stochastic processes.</p> <p>Definition</p> <p>A stochastic process \\(X = (X_t)_{t=0, \\ldots, T}\\) is called a martingale if</p> <ol> <li>\\(X\\) is adapted</li> <li>\\(X\\) is integrable</li> <li> <p>\\(X\\) satisfies the martingale property</p> \\[     E[X_{t+1}|\\mathcal{F}_t] = X_t \\] </li> </ol> <p>It is a super-martingale if </p> <ol> <li>\\(X\\) is adapted</li> <li>\\(X\\) is integrable</li> <li> <p>\\(X\\) satisfies the super martingale property</p> \\[     E[X_{t+1}|\\mathcal{F}_t] \\leq X_t \\] </li> </ol> <p>It is a sub-martingale if </p> <ol> <li>\\(X\\) is adapted</li> <li>\\(X\\) is integrable</li> <li> <p>\\(X\\) satisfies the super martingale property</p> \\[     E[X_{t+1}|\\mathcal{F}_t] \\geq X_t \\] </li> </ol> <p>Clearly, \\(X\\) is a sub-martingale if and only if \\(-X\\) is a super-martingale and \\(X\\) is a martingale if and only if it is a super and sub martingale at the same time.</p> <p>Warning</p> <p>Note that the notion of martingale (sup or super) depends on the measure considered. A martingale under a probability measure \\(P\\) might no longer be a martingale under another probability measure.</p> <p>Doob-Meyer Decomposition</p> <p>Let \\(X\\) be an integrable and adapted process. It can be uniquely decomposed into:</p> \\[ X=M+A, \\] <p>where \\(A\\) is a predictable process with \\(A_0=0\\) and \\(M\\) is a martingale.  </p> <p>The process \\(X\\) is a super-martingale if and only if \\(A\\) is decreasing and a sub-martingale if and only if \\(A\\) is increasing.</p> <p>Proof</p> <p>Existence:  Suppose that we have a decomposition \\(X = M+A\\) with \\(M\\) martingale and \\(A\\) predictable, then it must hold that</p> \\[     \\begin{align*}         0 &amp; = E[M_{t+1} - M_t|\\mathcal{F}_t]\\\\             &amp; = E[X_{t+1} - X_t - A_{t+1} + A_t | \\mathcal{F}_t]\\\\             &amp; = E[X_{t+1} - X_t  | \\mathcal{F}_t] - A_{t+1} + A_t &amp;&amp;A \\text{ is predictable}     \\end{align*} \\] <p>showing that \\(A_{t+1} =  E[X_{t+1} - X_t |\\mathcal{F}_t] - A_t\\).</p> <p>We therefore define recursively</p> \\[     \\begin{equation*}         \\begin{cases}             A_0 &amp; = 0\\\\             A_{t+1} &amp; = E[X_{t+1} - X_{t}|\\mathcal{F}_t] - A_t         \\end{cases}     \\end{equation*} \\] <p>which by induction can be shown to be predictable and starting at \\(0\\). Then \\(M = X+A\\) by the previous computations is a martingale defining the decomposition.</p> <p>Uniqueness: Suppose that \\(X = M+A = \\tilde{M} + \\tilde{A}\\) be two decompositions. It follows that \\(M - \\tilde{M}\\) is a martingale and predictable. It follows that for every \\(t\\) it must hold</p> \\[     \\begin{align*}         0 &amp;= E\\left[ (M_{t+1} - M_t) - (\\tilde{M}_{t+1} - \\tilde{M}_t) |\\mathcal{F}_t \\right] &amp;&amp; \\text{Martingale property}\\\\         &amp; = (M_{t+1} - M_t) - (\\tilde{M}_{t+1} - \\tilde{M}_t) &amp;&amp; M-\\tilde{M}\\text{ is predictable}     \\end{align*} \\] <p>We therefore get that</p> \\[     M_{t+1} - \\tilde{M}_{t+1} = M_{t} - \\tilde{M}_{t} = \\cdots = M_0 - \\tilde{M}_0 = \\tilde{A}_0 - A_0 = 0-0 = 0  \\] <p>showing that \\(M=\\tilde{M}\\) and therefore \\(A=\\tilde{A}\\).</p> <p>Proposition</p> <p>Let \\(M\\) be an adapted and integrable process. The two following assertions are equivalent:</p> <ol> <li>\\(M\\) is a martingale</li> <li> <p>for any bounded predictable process \\(\\eta = (\\eta_t)\\), the process \\(V= (V_t)\\)</p> \\[     V_t = V_0 + \\sum_{s=1}^t \\eta_s (M_s - M_{s-1}) \\] <p>is a martingale.</p> </li> </ol> <p>Proof</p> <p>Suppose that \\(M\\) is a martingale and let \\(\\eta\\) be a bounded predictable process. By definition \\(V\\) is adapted. Furthermore, denoting by \\(c\\) the constant bounding \\(\\eta\\), it holds that</p> \\[     |V_t| \\leq |V_0| + c \\sum_{s=1}^t (|M_s| + |M_{s-1}|) \\] <p>which is a a sum of integrable random variables hence integrable. As for the martingale property</p> \\[     \\begin{align*}         E[V_{t+1} - V_t|\\mathcal{F}_t] &amp; = E[\\eta_{t+1} (M_{t+1} - M_t) | \\mathcal{F}_t]\\\\         &amp; = \\eta_{t+1} E[M_{t+1}- M_t |\\mathcal{F}_t] &amp;&amp; \\eta\\text{ is predictable}\\\\         &amp; = 0 &amp;&amp; M\\text{ is a martingale}\\\\     \\end{align*} \\] <p>Reciprocally, for \\(V_0 = M_0\\) and \\(\\eta_t = 1\\) for every \\(t\\) by hypotheses, \\(V\\) is a martingale. However \\(V_t = M_t\\) for every \\(t\\).</p>"}]}