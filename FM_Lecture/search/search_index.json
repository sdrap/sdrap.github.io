{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Financial Mathematics: Lecture Notes","text":"<p>These lecture notes, still a work in progress, are for a course taught at Shanghai Advanced Institute for Finance, Shanghai Jiao Tong University, for graduate students.</p>"},{"location":"#course-objective","title":"Course Objective","text":"<p>Stochastics as a mathematical field evolved in parallel with the development of the finance industry, starting with insurance, followed by stock markets, derivatives, and more. This lecture serves as an introduction to the mathematical theory underpinning modern finance. The course aims to introduce mathematical concepts in finance through the following topics:</p> <ul> <li> <p>One-period financial markets: Financial assets, self-financing strategies, arbitrage, the fundamental theorem of asset pricing, and option pricing.   From a mathematical perspective, this introduces probability spaces, expectations, pricing measures, and measure changes.</p> </li> <li> <p>Modern risk management and quantification: Value at Risk (V@R), Expected Shortfall (ES), and systemic risk.   From a mathematical perspective, this introduces the concept of probability distribution (CDF, PDF, quantile), joint distributions and tail risk.</p> </li> <li> <p>Multi-period financial markets: Concepts of information, the CRR model, pricing and hedging, exotic options, stopping times, and American options.   This includes mathematical concepts such as filtrations, conditional expectations, martingales, and stopping times.</p> </li> <li> <p>Basics of ruin theory and default pricing.</p> </li> <li> <p>Continuous-time financial markets: Introduction to the Black-Scholes framework.</p> </li> </ul>"},{"location":"#concrete-approach","title":"Concrete Approach","text":"<p>The course combines blackboard lectures with practical applications in Python. Lecture notes will be provided and updated during the course. Simple homework exercises (not graded but corrected and discussed by the TA) will be assigned. Additionally, students will complete two group projects (5-6 members per group), alongside a midterm and final exam.</p> <p>For further reading, we recommend Shreve<sup>1</sup> for an introduction to mathematical finance in discrete time and F\u00f6llmer and Schied<sup>2</sup> for a more advanced treatment.</p>"},{"location":"#references","title":"References","text":"<ol> <li> <p>Steven E. Shreve. Stochastic Calculus for Finance. Volume I of Springer Finance. Springer-Verlag, New York, 2004. ISBN 0-387-40100-8. The binomial asset pricing model.\u00a0\u21a9</p> </li> <li> <p>Hans F\u00f6llmer and Alexander Schied. Stochastic Finance. An Introduction in Discrete Time. De Gruyter Studies in Mathematics. Walter de Gruyter, Berlin, New York, 3rd edition, 2011.\u00a0\u21a9</p> </li> </ol>"},{"location":"javascripts/node_modules/mathjax/","title":"MathJax","text":""},{"location":"javascripts/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"javascripts/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"javascripts/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"javascripts/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\n  loader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\n  const svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\n  console.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"javascripts/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"javascripts/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"},{"location":"lecture/00-Introduction/000-index/","title":"Introduction","text":""},{"location":"lecture/00-Introduction/000-index/#what-is-mathematical-finance","title":"What is Mathematical Finance?","text":"<p>Finance concerns the allocation and pricing of assets\u2014goods, stocks, etc.\u2014and liabilities\u2014debts, loans, bonds, etc.\u2014in the presence of uncertainty and risk. This definition raises several fundamental questions:</p> <ul> <li>What is trade, money, or pricing?  </li> <li>What are uncertainty and risk?  </li> <li>Which academic fields address these questions?  </li> <li>What role does mathematics\u2014particularly stochastics\u2014play in finance?  </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#a-brief-and-biased-history-of-trade-money-and-finance","title":"A Brief and Biased History of Trade, Money, and Finance","text":""},{"location":"lecture/00-Introduction/000-index/#trade-of-goods-and-the-emergence-of-money","title":"Trade of Goods and the Emergence of Money","text":"<ul> <li> <p>Exchange of goods (around 150,000 BC):</p> <ul> <li>Advantages: Better allocation of comparative advantages.  </li> <li>Question:  <ul> <li>How is exchange value determined (bilateral agreement)?  </li> <li>Need for intermediaries.  </li> </ul> </li> </ul> </li> <li> <p>Money as a medium of exchange (around 12,000 BC):  </p> <ul> <li>Advantages:  <ul> <li>Solves the double coincidence problem, enabling efficient allocation.  </li> <li>Serves as a unit of account (num\u00e9raire).  </li> <li>Stores value over time.  </li> </ul> </li> <li>Questions:  <ul> <li>How is value established (multilateral agreements between numerous goods)? Law of demand and supply.  </li> <li>How does money preserve value over time?  </li> <li>Introduces the concept of the time value of money.  </li> </ul> </li> </ul> </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#assessing-uncertainty-the-rise-of-financial-markets","title":"Assessing Uncertainty: The Rise of Financial Markets","text":"<ul> <li> <p>Commodity markets (4,000 BC):     Development of forward contracts to hedge against price fluctuations.  </p> <ul> <li>Question: How are prices determined?  </li> </ul> </li> <li> <p>Loans and banking systems (2,000 BC):     Facilitated leveraged investments.  </p> <ul> <li>Question: How to price future payments?  </li> </ul> </li> <li> <p>Insurance (1400s):     Emerged during overseas trading, with premiums exchanged for risk.  </p> <ul> <li>Sparked the beginnings of probability theory.  </li> </ul> </li> <li> <p>Stock markets (1600s):     Enabled capital raising and introduced challenges such as dividend payments and stock price modeling (e.g., Bachelier model, Brownian motion).  </p> </li> <li> <p>Options (1600s, standardized in 1973):     Put and call options provided bounded insurance against price movements.  </p> </li> <li> <p>Derivatives:     Broader contracts written on assets, indices, interest rates, etc.  </p> </li> </ul> <p>Pricing remains the central problem for all these financial instruments. While agreements between counterparties can set prices, mathematical models provide fair and robust valuations. A specialized subfield of mathematical finance also focuses on assessing financial risk.</p>"},{"location":"lecture/00-Introduction/000-index/#academic-fields-involved-in-finance","title":"Academic Fields Involved in Finance","text":"<ul> <li>Economics: Macroeconomics, microeconomics, decision theory.  </li> <li>Psychology: Behavioral finance.  </li> <li>Law.  </li> <li>Computer Science: Algorithmic trading, machine learning.  </li> <li>Mathematics:  <ul> <li>Stochastics (modeling).  </li> <li>Statistics (calibration, machine learning...).  </li> <li>Optimization.  </li> <li>Functional analysis and partial differential equations (e.g., Black-Scholes model).  </li> </ul> </li> </ul>"},{"location":"lecture/00-Introduction/001-notations/","title":"Notations","text":""},{"location":"lecture/00-Introduction/001-notations/#mathematical-notations","title":"Mathematical Notations","text":"<p>The following notations will be used throughout the course:</p> <ul> <li>Natural Numbers: \\(\\mathbb{N} = \\{1, 2, \\ldots\\}\\), \\(\\mathbb{N}_0 = \\{0, 1, 2, \\ldots\\}\\).</li> <li>Integers: \\(\\mathbb{Z} = \\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\)</li> <li>Rational Numbers: \\(\\mathbb{Q} = \\{ p/q\\colon p \\in \\mathbb{Z}, q \\in \\mathbb{N}\\}\\)</li> <li>Real Numbers: \\(\\mathbb{R}\\)</li> <li>Vectors in \\(\\mathbb{R}^d\\) are denoted in bold font, \\(\\boldsymbol{x} = (x^1, \\dots, x^d)\\), and are assumed to be column vectors.  </li> <li>Vectors with positive components \\(\\mathbb{R}^d_+ = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k \\geq 0, k=1,\\ldots,d\\}\\) and vectors with strictly positive components \\(\\mathbb{R}^d_{++} = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k &gt; 0, k=1,\\ldots,d\\}\\).  </li> <li>Scalar Product: \\(\\boldsymbol{x} \\cdot \\boldsymbol{y} := \\sum x_k y_k\\) denotes the scalar product of \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\) in \\(\\mathbb{R}^d\\).  </li> <li>\\(\\beta \\boldsymbol{x} := (\\beta x_1, \\ldots, \\beta x_d)\\) represents the multiplication of \\(\\boldsymbol{x}\\) in \\(\\mathbb{R}^d\\) by a scalar \\(\\beta \\in \\mathbb{R}\\).  </li> <li>\\(\\boldsymbol{x} + \\boldsymbol{y} := (x_1 + y_1, \\ldots, x_d + y_d)\\) represents vector addition in \\(\\mathbb{R}^d\\).  </li> <li>Component wise operations: \\(\\boldsymbol{x}\\boldsymbol{y}= (x_1 y_1, \\ldots, x_d y_d)\\), \\(\\boldsymbol{x}/ \\boldsymbol{y} = (x_1/ y_1, \\ldots, x_d/y_d)\\), \\(f(\\boldsymbol{x}) = (f(x_1), \\ldots, f(x_d))\\) for any function \\(f\\colon \\mathbb{R}\\to \\mathbb{R}\\).</li> <li> <p>For scalars \\(x, y \\in \\mathbb{R}\\), the following notations are used:  </p> \\[   x \\vee y = \\max\\{x, y\\}, \\quad x \\wedge y = \\min\\{x, y\\}, \\quad x^+ = \\max\\{x, 0\\}, \\quad x^- = \\max\\{-x, 0\\}. \\] <p>Notably, \\(x = x^+ - x^-\\) and \\(|x| = x^+ + x^-\\).  </p> </li> </ul>"},{"location":"lecture/00-Introduction/001-notations/#colorenvironment-conventions","title":"Color/Environment conventions","text":"<p>Definition</p> <p>For a ... we define</p> <p>Remark</p> <p>Note that  </p> <p>Example</p> <p>As an example we consider </p> <p>Theorem</p> <p>Let \\((\\Omega, \\mathcal{F}, P)\\) be a probability space...</p> <p>Proposition</p> <p>Assuming no-arbitrage for the financial market, the followign assertions holds...</p> <p>Corollary</p> <p>As a corrolary to the previous proposition, it holds</p> <p>Lemma</p> <p>In the case where \\(P^\\ast\\) is equivalent to \\(P\\), it holds...</p> <p>Proof</p> <p>In a first step we show that \\((i)\\) implies \\((ii)\\)...</p> <p>Exercise</p> <p>Solve in a a binomial financial market...</p>"},{"location":"lecture/01-One-Period/011-mathematical-model/","title":"Mathematical Model","text":"<p>In this section, we model a one-period financial market evolving between two points in time:</p> <ul> <li>Today: The current state of the world is known, including the prices of equities, commodities, and the overall economic condition.</li> <li>Tomorrow: Various possible states of the world may emerge, where changes in the economy or the prices of stocks and commodities occur based on these states.</li> </ul> <p>In this financial market, we have \\(d\\) risky assets available for investment and a bank account to store or borrow liquidity.</p> <ul> <li>At time \\(0\\): The prices of these \\(d\\) financial assets and the amount in the bank account are known.     Investors can decide on a strategy, specifying how much to invest in each asset by purchasing a certain number of shares. The bank account is used to finance these investments.</li> <li>At time \\(1\\): The portfolio's value is determined by:<ul> <li>The remaining balance in the bank account after buying the shares at time \\(0\\), including interest earned.</li> <li>The uncertain value of the financial assets at time \\(1\\), multiplied by the number of shares held.</li> </ul> </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#bank-account","title":"Bank Account","text":"<p>The bank account is denoted by \\(B\\), where \\(B_0 = 1\\) represents the price of one unit of currency at time \\(0\\). The bank offers an interest rate \\(r\\), announced at time \\(0\\) and applied at time \\(1\\). With one unit deposited at time \\(0\\), the amount in the account at time \\(1\\) becomes:</p> \\[ \\begin{equation*}   B_1 = B_0(1 + r) = 1 + r \\end{equation*} \\] <p>We assume \\(r &gt; -1\\), meaning the bank does not default. The bank account evolution is summarized as:</p> \\[ \\begin{equation*}   \\begin{cases}     B_0 = 1 \\\\     B_1 = 1 + r   \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#financial-assets","title":"Financial Assets","text":"<p>These assets are represented by the vector:</p> \\[ \\begin{equation*}   \\boldsymbol{S} = (S^1, \\ldots, S^d) \\end{equation*} \\] <p>Each \\(S^k\\) for \\(k = 1, \\ldots, d\\) describes the price evolution of financial asset \\(k\\) between time \\(0\\) and \\(1\\).</p> <ul> <li> <p>At time \\(0\\): The price of asset \\(k\\) is \\(S_0^k\\), which is strictly positive and known:</p> \\[ \\begin{equation*}   \\boldsymbol{S}_0 = (S_0^1, \\ldots, S_0^d) \\quad \\text{where} \\quad S_0^k &gt; 0 \\; \\text{for all }k \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The price of asset \\(k\\) is \\(S_1^k\\), which is uncertain but non-negative (if \\(S_1^k = 0\\), the asset \\(k\\) has defaulted):</p> \\[ \\begin{equation*}   \\boldsymbol{S}_1 = (S_1^1, \\ldots, S_1^d) \\quad \\text{where} \\quad S_1^k \\geq 0 \\; \\text{for all }k \\end{equation*} \\] </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#self-financing-portfolio","title":"Self-Financing Portfolio","text":"<p>A portfolio consists of holdings in each financial asset and the balance in the bank account. The portfolio's total value is denoted by \\(\\bar{V}\\).</p> <ul> <li> <p>At time \\(0\\): You observe the prices \\(S_0^k\\) for \\(k = 1, \\ldots, d\\) and decide on a strategy, holding \\(\\eta^k \\in \\mathbb{R}\\) shares of each asset. The cost of purchasing these assets is:</p> \\[ \\begin{equation*}   \\sum_{k=1}^d \\eta^k S_0^k = \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\end{equation*} \\] <p>where \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\) represents your holdings. The self-financing condition requires that this cost is fully covered by the bank account. Thus:</p> \\[ \\begin{equation*}   \\bar{V}_0 \\leadsto \\underbrace{\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Bank account value}} +  \\underbrace{\\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Asset holdings value}}= \\bar{V}_0 - \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 + \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 = \\bar{V}_0 \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The portfolio value evolves as asset prices change:</p> \\[ \\begin{align*}     \\bar{V}_1 &amp; = \\left(\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0\\right)(1+r) + \\sum_{k=1}^d \\eta^k S^k_1 \\\\               &amp; = \\left( \\bar{V}_0 - \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\right)(1+r) +\\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_1  \\\\               &amp; = \\bar{V}_0(1+r) +\\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r) \\right) \\end{align*} \\] </li> </ul> <p>Hence a portfolio over time is entirely determined by its start value \\(\\bar{V}_0\\) as well as the strategy \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\).</p> Remark: How realistic are those assumptions? <p>In this setting, we make somewhat restrictive assumptions that are disputable namely:</p> <ul> <li>No dividends.</li> <li>No transaction costs when buying assets: fixed fees, taxes, transaction fees, liquidity.</li> <li>The amount of shares in a financial asset is a real number.       Usually you are only allowed to buy/sell a round lot.       Furthermore, you are allowed to hold a negative amount of shares.       In other terms short selling is allowed and without particular transaction costs related to it.</li> <li>You can buy/sell unlimited amount of shares, in particular for very large amount you face no liquidity costs.</li> <li>The bank account provides the same rate \\(r\\) for deposit and lending which is very unlikely.     And this rate is independent of the amount.</li> <li>You can lend infinite amount of money from the bank.</li> </ul> <p>We consider the ideal scenario of a small investor operating in a frictionless financial market\u2014an assumption that closely approximates modern realities. Some aspects, such as taxes, transaction fees, dividends, and round lot restrictions, are either negligible or can be incorporated with minimal adjustments. However, factors like differing lending and deposit rates, liquidity costs, short-selling constraints, and price impacts are more complex and can significantly influence the results.    </p>"},{"location":"lecture/01-One-Period/011-mathematical-model/#discounting","title":"Discounting","text":"<p>It is often convenient to consider discounted values of financial assets and the portfolio to express their worth in terms of today's currency. Define the discounted prices \\(\\boldsymbol{X}=\\boldsymbol{S}/B\\) and portfolio value \\(V=\\bar{V}/B\\) as follows:</p> \\[ \\begin{align*}     X_0^k &amp; = \\frac{S^k_0}{B_0}=S^k_0         &amp; \\text{and} &amp;  &amp; X_1^k &amp; = \\frac{S_1^k}{B_1}=\\frac{S_1^k}{1+r}         \\\\     V_0   &amp; = \\frac{\\bar{V}_0}{B_0}=\\bar{V}_0 &amp; \\text{and} &amp;  &amp; V_1   &amp; = \\frac{\\bar{V}_1}{B_1}=\\frac{\\bar{V}_1}{1+r} \\end{align*} \\] <p>In particular, it follows that</p> \\[ \\begin{align*}     V_1     &amp; = \\frac{\\bar{V}_1}{1+r}\\\\             &amp; = \\frac{1}{1+r}\\left(\\bar{V}_0(1+r) +\\sum_{k=1}^d \\eta^k\\left( S^k_1  - (1+r)S_0^k\\right)\\right)\\\\             &amp; = \\bar{V}_0 +\\sum_{k=1}^d \\eta^k\\left( \\frac{S^k_1}{1+r}  - S_0^k\\right)\\\\                 &amp; = V_0 + \\sum_{k=1}^n \\eta^k\\left( X^k_1 - X^k_0 \\right)\\\\           &amp; = V_0 + \\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{X}_1 - \\boldsymbol{X}_0 \\right) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\end{align*} \\] <p>for which we get an interpretation of the evolution of the discounted value of the portfolio:</p> \\[ \\begin{equation*}   V_1 = \\underbrace{V_0}_{\\text{Initial Value}} + \\underbrace{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1}_{\\text{Incremental gain/loss of discounted prices}} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#uncertainty","title":"Uncertainty","text":"<p>So far, we have described a simple financial market and how investments can be made while adhering to self-financing principles. However, while we acknowledged that the prices of assets at time \\(1\\) are subject to uncertainty, we have not detailed how this uncertainty is modeled.  In other words, while we treated the financial assets at time \\(1\\) as a vector of prices, we have not specified how this vector reflects the uncertainty associated with its values.</p> <p>The price evolution depends on the \"state of the world\" that will be realized. If we denote by \\(\\omega\\) one such possible state, then \\(S_1^k(\\omega)\\) represents the price of asset \\(k\\) at time \\(1\\) in state \\(\\omega\\). If \\(\\Omega\\) denotes the collection of all possible states, the stock price \\(S_1^k\\) is a function:</p> \\[ \\begin{align*}   S_1^k\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_+\\\\   \\omega &amp; \\longmapsto \\underbrace{S_1^k(\\omega)}_{\\text{Price of financial asset $k$ at time $1$ in state $\\omega$}} \\end{align*} \\] <p>Combining all such functions, we obtain state-dependent price vectors:</p> \\[ \\begin{align*}   \\boldsymbol{S}_1\\colon \\Omega &amp; \\longrightarrow \\mathbb{R}_+^d\\\\   \\omega &amp; \\longmapsto \\boldsymbol{S}_1(\\omega) = (S_1^1(\\omega), \\ldots, S_1^d(\\omega)) \\end{align*} \\] <p>Similarly, the discounted self-financing portfolio value at time \\(1\\) and the discounted asset prices become state-dependent functions:</p> \\[ \\begin{align*}   \\boldsymbol{X}_1\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_{+}^d &amp; V_1 \\colon \\Omega &amp;\\longrightarrow \\mathbb{R} \\\\   \\omega &amp; \\longmapsto \\boldsymbol{X}_1(\\omega) = \\left( \\frac{S_1^1(\\omega)}{1+r}, \\ldots, \\frac{S_1^d(\\omega)}{1+r} \\right) &amp; \\omega &amp;\\longmapsto V_1(\\omega) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1(\\omega) \\end{align*} \\] <p>The objective of financial mathematics is to estimate or price these state-dependent portfolios. To achieve this, we need further assessments of how likely each event is to occur. This is where stochastic theory plays a crucial role.</p> <p>Definition: One Period Financial Market</p> <p>Given a probability space \\((\\Omega, \\mathcal{F}, P)\\), a financial market is defined as follows:</p> <ul> <li> <p>A bank account \\(B\\), where:</p> \\[ B_0 = 1 \\quad \\text{and} \\quad B_1 = 1 + r \\] <p>for \\(r&gt;-1\\)</p> </li> <li> <p>\\(d\\)-financial assets \\(\\boldsymbol{S} = (S^1, \\ldots, S^d)\\), where:</p> \\[   S_0^k &gt; 0 \\quad \\text{and} \\quad S_1^k : \\Omega \\to \\mathbb{R}_+ \\] <p>for \\(k = 1, \\ldots, d\\), with \\(S_1^k\\) being a measurable random variable.</p> </li> </ul> <p>A Portfolio \\(\\bar{V}\\) is given by a start value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and a holding strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). Self financing condition implies</p> \\[   \\bar{V}_1 = \\bar{V}_0(1+r) + \\sum \\eta^k \\left(S_1^k - S_0^k(1+r)\\right) = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\left(\\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r)\\right) \\] <p>The discounded portfolio \\(V = \\bar{V}/B\\) and financial assets \\(\\boldsymbol{X} = \\boldsymbol{S}/B\\) allows to write</p> \\[   V_1 = V_0 + \\sum \\eta^k \\left(X_1^k - X_0^k\\right) = V_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\] Warning: What about returns, portfolio weights? <p>Very often in finance, the exposition is done in terms of returns and portfolio weights. Talking in terms of returns and weights requires some particular care.</p> <p>It is possible to speak of returns for the financial market as the prices at time \\(0\\) are strictly positive. In other terms, if we define the interest rate \\(r\\) as:</p> \\[ r = \\frac{B_1 - B_0}{B_0}, \\quad \\text{then it holds} \\quad B_1 = B_0(1 + r) \\] <p>Similarly, for the return \\(R_1^k\\) of a financial asset \\(k\\), we define:</p> \\[ R_1^k = \\frac{S_1^k - S_0^k}{S_0^k}, \\quad \\text{then it holds} \\quad S_1^k = S_0^k(1 + R_1^k) \\] <p>Thus, the definition of a financial market as described earlier is equivalent to specifying:</p> <ul> <li>A vector \\(\\boldsymbol{S}_0\\) of strictly positive initial prices.</li> <li>An interest rate \\(r &gt; -1\\), with \\(r \\in \\mathbb{R}\\).</li> <li> <p>A vector \\(\\boldsymbol{R}_1 = (R_1^1, \\ldots, R_1^d)\\) of random returns, where:</p> \\[ R_1^k: \\Omega \\longrightarrow [-1, \\infty), \\quad \\omega \\longmapsto R_1^k(\\omega) \\] <p>for each \\(k = 1, \\ldots, d\\).</p> </li> </ul> <p>It is also possible for a portfolio to speak in terms of holding value rather than number of shares, that is \\(\\boldsymbol{h} = \\boldsymbol{\\eta}\\boldsymbol{S}_0 = (\\eta^1 S_0^1, \\ldots, \\eta^d S_0^d)\\). In this case we can write the portfolio evolution as</p> \\[ \\begin{align*}   \\bar{V_1} &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k\\left(S_1^k - S_0^k (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k S_0^k \\left(\\frac{S_1^k}{S_0^k} - (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum h^k \\left(R_1^k - r\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\boldsymbol{h}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>Now we would like to consider the returns of the portfolio \\((\\bar{V}_1 - \\bar{V}_0)/\\bar{V}_0\\) as well as the portfolio weight \\(\\boldsymbol{w} = \\boldsymbol{h}/\\bar{V_0}\\). Indeed, the portfolio weight in asset \\(k\\) is equal to the asset value holding divided by the portfolio value at time \\(0\\). Following on the previous computation we have</p> \\[ \\begin{align*}   \\frac{\\bar{V}_1 - \\bar{V}_0}{\\bar{V}_0} &amp; = r + \\sum \\frac{h^k}{\\bar{V}_0}\\left(R^k_1 - r\\right)\\\\       &amp; = r + \\boldsymbol{w}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>We get the classical interpretation that the portfolio returns is equal to the risk free rate plus the weighted excess returns in the financial assets. In particular if \\(\\sum w^k = 1\\), meaning that you hold your portfolio entirely in assets, the returns of the portfolio is equal to \\(\\boldsymbol{w}\\cdot \\boldsymbol{R}_1\\).</p> <p>This looks familar and used widely, it is however  mathematically not correct without further assumptions. Consider the following situations where \\(\\bar{V}_0 &lt;0\\) or \\(\\bar{V}_0 = 0\\), returns and weights do not make much sense isn't it?</p> <p>Furthermore, even if you assume that \\(\\bar{V}_0&gt;0\\) (usually \\(\\bar{V}_0 = 1\\)), suppose that you can short, then you may well end-up with a strictly negative or zero portfolio value at time \\(1\\). How would you then compute the portfolio returns between time \\(1\\) and time \\(2\\)?</p> <p>Such a way to look at portfolio returns are consistent mathematically if some strong assumptions are made to garantee that \\(\\bar{V}_0\\) and \\(\\bar{V}_1\\) remain strictly positive (no shorting plus budget constraint for instance). This is the reason why we do not consider during this lecture this kind of approach (portfolio returns or portfolio weights).</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/","title":"Arbitrage and Pricing","text":"<p>A fundamental concept in financial market is the notion of Arbitrage. Consider the following example</p> <p>Example: Arbitrage in a coint toss model</p> <p>Consider the example of a simple coin toss model. Formally:</p> <ul> <li>\\(\\Omega = \\{-1, 1\\}\\)</li> <li>\\(\\mathcal{F} = \\{\\emptyset, \\{1\\}, \\{-1\\}, \\{-1, 1\\}\\}\\)</li> <li> <p>Given \\(0&lt;p&lt;1\\)</p> \\[ P[\\{\\omega\\}] = \\begin{cases}     p &amp; \\text{if } \\omega = 1, \\\\     1-p &amp; \\text{if } \\omega = -1 \\end{cases} \\] </li> </ul> <p>We define for our bank account \\(B_0 = 1\\) and \\(B_1 = 1 + r\\) where \\(r &gt; -1\\). We also consider a single stock with:</p> \\[ S_0 &gt; 0, \\quad S_1(\\omega) = S_0(1 + R(\\omega)) \\] <p>where the return \\(R\\) is given by:</p> \\[ R(\\omega) = \\begin{cases}     u &amp; \\text{if } \\omega = 1, \\\\     d &amp; \\text{if } \\omega = -1 \\end{cases} \\] <p>with \\(d &lt; u\\). We assume that \\(S_1\\) is strictly positive, so \\(d &gt; -1\\).</p> <p>Suppose I enter the market with no money and observe that \\(r \\leq d\\). I borrow \\(\\eta S_0\\) from the bank to buy \\(\\eta&gt;0\\) shares of the stock. At time \\(1\\), the value of my portfolio is:</p> \\[     \\bar{V}_1(\\omega) = -\\eta S_0(1 + r) + \\eta S_1(\\omega) =     \\begin{cases}         \\eta S_0(u - r) &amp; \\text{if } \\omega = 1, \\\\         \\eta S_0(d - r) &amp; \\text{if } \\omega = -1     \\end{cases} \\] <p>Since \\(r \\leq d &lt; u\\), my strategy does not lose money in any cases and I always make a strictly positive gain with probability \\(p&gt;0\\). By scaling this strategy, I could generate unlimited wealth without risk. A similar scenario arises if \\(d &lt; u \\leq r\\), where I could short-sell the stock infinitely.</p> <p>As this example shows, such a market would be dysfunctional. Economically, arbitrageurs would exploit this situation, driving the stock price back within boundaries to eliminate these opportunities. Hence, we require the concept of an arbitrage-free market.</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#arbitrage","title":"Arbitrage","text":"<p>Definition Arbitrage and Arbitrage Free Market</p> <p>A portfolio \\(\\bar{V}\\) with initial value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) is called an arbitrage if</p> \\[ \\begin{equation*}         \\underbrace{P\\left[\\bar{V}_1(\\omega) \\geq \\bar{V}_0(1 + r)\\right] = 1}_{\\text{No downside risk}}\\quad \\text{and}\\quad \\underbrace{P\\left[\\bar{V}_1(\\omega) &gt; \\bar{V}_0(1 + r)\\right] &gt;0}_{\\text{Strict positive gains with strict positive probability}} \\end{equation*} \\] <p>A financial market is call arbitrage free, if there exists no arbitrage.</p> <p>In other words, a self-financing strategy is an arbitrage if it guarantees a net gain at time \\(1\\) in every possible state and a strictly positive gain with nonzero probability.</p> <p>There exists several equivalent way to express arbitrage as the following proposition states</p> <p>Proposition Arbitrage Equivalence</p> <p>The following statements are equivalent:</p> <ol> <li>The financial market admits an arbitrage portfolio.</li> <li> <p>There exists a discounted portfolio \\(V\\) such that:</p> \\[ P\\left[V_1 \\geq V_0\\right] = 1 \\quad \\text{and} \\quad P\\left[V_1 &gt; V_0\\right] &gt; 0 \\] </li> <li> <p>There exists a strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\right] = 1 \\quad \\text{and} \\quad P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0\\right] &gt; 0 \\] </li> </ol> Proof <ol> <li> <p>Equivalence of (i) and (ii):     For a portfolio \\(\\bar{V}\\), \\(\\bar{V}_1 \\geq (1 + r)\\bar{V}_0\\) is equivalent to \\(V_1 \\geq V_0\\) by dividing the inequality by \\(1 + r &gt; 0\\). The same holds for the strict inequality.</p> </li> <li> <p>Equivalence of (ii) and (iii):     For a discounted portfolio \\(V\\), \\(V_1 = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq V_0\\) is equivalent to \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\) by subtracting \\(V_0\\).</p> </li> </ol> Exercise <p>Recall that the returns vector \\(\\boldsymbol{R}_1\\) are defined as</p> \\[     R^k_1 = \\frac{S_1^k - S_0^k}{S_0^k}\\quad \\text{for }k=1, \\ldots, d \\] <p>Show that the following assertions are equivalent:</p> <ol> <li> <p>The financial market admits and arbitrage.</p> </li> <li> <p>There exists \\(\\boldsymbol{h} \\in \\mathbb{R}^d\\) such that:</p> \\[     P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\geq 0 \\right] = 1      \\quad \\text{and} \\quad      P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) &gt; 0 \\right] = 1  \\] </li> </ol>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#pricing-measure","title":"Pricing Measure","text":"<p>As we will consequently see in the Fundamental Theorem of Asset Pricing, another central concept in financial market are pricing measures</p> <p>Definition: Pricing Measure</p> <p>A probability measure \\(P^\\ast\\) is called a pricing measure(1) if:</p> <ol> <li> Also known as a pricing kernel in financial engineering or martingale measure in mathematics.</li> </ol> \\[     E^{P^\\ast}\\left[\\frac{S_1^k}{1 + r}\\right] = S_0^k, \\quad \\text{for } k = 1, \\ldots, d \\] <p>In other words, under a pricing measure the discounted expected value of each asset equals its present price.</p> <p>Remark: Vector notation and equivalent formulations</p> <p>For a vector of random variables \\(\\boldsymbol{Z} = (Z^1, \\ldots, Z^d)\\) and a probability measure \\(Q\\), we denote:</p> \\[ E^Q[\\boldsymbol{Z}] := \\left(E^Q[Z^1], \\ldots, E^Q[Z^d]\\right) \\] <p>In particular, \\(P^\\ast\\) is a pricing measure if:</p> \\[ E^{P^\\ast}\\left[\\frac{\\boldsymbol{S}_1}{1 + r}\\right] = \\boldsymbol{S}_0, \\quad \\text{or equivalently}\\quad E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0 \\] <p>This implies that under a pricing measure, the average return of each financial asset equals the bank's interest rate:</p> \\[ E^{P^\\ast}[R_1^k] = r, \\quad \\text{for every } k = 1, \\ldots, d \\] <p>Lemma</p> <p>Suppose that the financial market admits a pricing measure \\(P^\\ast\\). Then</p> <ol> <li> <p>for every portfolio \\(\\bar{V}\\), it holds</p> \\[     \\bar{V}_0 = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right] \\] </li> <li> <p>for every (discounted) portfolio \\(V\\), it holds</p> \\[     V_0 = E^{P^\\ast}\\left[ V_1 \\right] \\] </li> <li> <p>for every strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\), it holds</p> \\[     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0 \\] </li> </ol> Proof <p>We just show the last assertion, the other two follows directly. Let \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) and \\(P^\\ast\\) be a pricing measure. By definition of \\(P^\\ast\\) and the properties of the expectation, it follows that</p> \\[ \\begin{equation*}     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right]  = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right]= \\sum \\eta^k E^{P^\\ast}\\left[ \\Delta X_1^k  \\right] = \\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right] = 0 \\end{equation*} \\] <p>In the following, we will consider those pricing measures \\(P^\\ast\\) that are equivalent to \\(P\\)(1). By the very definition, it follows in particular that if \\(P^\\ast\\sim P\\) and \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, then </p> <ol> <li> <p>See appendix on probability theory for details and consequence in terms of Radon-Nykodym derivative.</p> <p>Just recalling the definition, a probability measure \\(Q\\) is equivalent to \\(P\\) and denoted by \\(Q\\sim P\\) if</p> \\[P[A] = 0 \\quad \\text{if and only if} \\quad Q[A]=0\\] <p>In other terms the two measures agrees on negligible events.</p> <p>This is however equivalent to</p> \\[P[A] = 1 \\quad \\text{if and only if} \\quad Q[A]=1\\] <p>or</p> \\[P[A] &gt; 0 \\quad \\text{if and only if} \\quad Q[A]&gt;0\\] </li> </ol> \\[ \\begin{equation*} \\begin{cases}   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\quad \\text{is equivalent to } \\quad \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#fundamental-theorem-of-asset-pricing","title":"Fundamental Theorem of Asset Pricing","text":"<p>Fundamental Theorem of Asset Pricing (FTAP)</p> <p>In a financial market, the following conditions are equivalent:</p> <ol> <li>The market is arbitrage-free.</li> <li>There exists at least one pricing measure \\(P^\\ast \\sim P\\) with bounded density \\(dP^\\ast/dP\\).</li> </ol> Proof: (sketch) <ol> <li> <p>Step 1 (easy direction): condition 2. implies 1..     By contradiction, assume that there exists a pricing measure \\(P^\\ast \\sim P\\) and an arbitrage strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). We show that this is not possible.</p> <p>On one hand, having a pricing measure \\(P^\\ast\\) implies that \\(E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0\\). It follows that for the arbitrage strategy \\(\\boldsymbol{\\eta}\\), we have:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right] = 0 \\] <p>On the other hand, since \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, it holds that:</p> \\[ \\begin{cases}   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>Since \\(P^\\ast \\sim P\\), this is equivalent to:</p> \\[ \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>The first line implies that the random variable \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\) is positive \\(P^\\ast\\)-almost surely. The second line indicates that this variable is strictly positive somewhere. Taking the expectation of this strictly positive random variable results in a strictly positive expectation:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 \\] <p>However, this contradicts the earlier result that \\(E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0\\). This shows that 2. implies 1..</p> </li> <li> <p>Step 2 (difficult direction): condition 1. implies 2.. </p> <p>Here, we show that if 1.$ does not hold (i.e., there exists no pricing measure \\(P^\\ast\\) with bounded density), then there exists an arbitrage. To state that there exists no pricing measure \\(P^\\ast\\) with bounded density, consider the set:</p> \\[   \\mathcal{C} = \\left\\{ E^Q[\\Delta \\boldsymbol{X}_1] : Q \\sim P \\text{ and } \\frac{dQ}{dP} \\text{ is bounded} \\right\\} \\] <p>This set includes all vectors of expectations of discounted gains under pricing measures with bounded density \\(Q\\). There exists a pricing measure \\(P^\\ast \\sim P\\) with bounded density if and only if the vector \\(0\\) is in \\(\\mathcal{C}\\). Hence, the condition that 2. does not hold is equivalent to \\(0 \\notin \\mathcal{C}\\).</p> <p>We show that the set \\(\\mathcal{C} \\subseteq \\mathbb{R}^d\\) has the following properties:</p> <ul> <li> <p>Non-emptiness: \\(\\mathcal{C} \\neq \\emptyset\\). Since \\(P \\sim P\\) and \\(\\frac{dP}{dP} = 1\\), it follows that \\(E^P[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C}\\)(1).</p> </li> <li> <p>Note: We never assumed \\(\\boldsymbol{X}_1\\) is integrable under \\(P\\). This can be addressed in the appendix.</p> </li> <li> <p>Convexity: \\(\\mathcal{C}\\) is convex(1).</p> <ol> <li>That is, for any two points \\(\\boldsymbol{x}, \\boldsymbol{y} \\in \\mathcal{C}\\) and any \\(\\lambda \\in [0, 1]\\), the interval \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y}\\) is also in \\(\\mathcal{C}\\).  </li> </ol> <p>By definition, there exist \\(Q^{\\boldsymbol{x}}\\) and \\(Q^{\\boldsymbol{y}}\\) equivalent to \\(P\\) with bounded density such that \\(E^{Q^{\\boldsymbol{x}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{x}\\) and \\(E^{Q^{\\boldsymbol{y}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{y}\\). By the Radon-Nikodym theorem, define:</p> \\[   \\frac{dQ}{dP} = \\lambda \\frac{dQ^{\\boldsymbol{x}}}{dP} + (1 - \\lambda) \\frac{dQ^{\\boldsymbol{y}}}{dP} \\] <p>This \\(dQ/dP\\) is a strictly positive bounded random variable (since \\(dQ^{\\boldsymbol{x}}/dP\\) and \\(dQ^{\\boldsymbol{y}}/dP\\) are) with expectation equal to \\(1\\):</p> \\[   E^P\\left[ \\frac{dQ}{dP} \\right] = \\lambda E^P\\left[ \\frac{dQ^{\\boldsymbol{x}}}{dP} \\right] + (1 - \\lambda) E^P\\left[ \\frac{dQ^{\\boldsymbol{y}}}{dP} \\right] = \\lambda + (1 - \\lambda) = 1 \\] <p>Hence, \\(dQ/dP\\) defines a probability measure \\(Q \\sim P\\) with bounded density, and:</p> \\[   \\boldsymbol{z} = E^Q[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C} \\] <p>Moreover:</p> \\[   \\boldsymbol{z} = \\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\] <p>showing that \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\in \\mathcal{C}\\).</p> </li> </ul> <p>The fact that \\(0 \\notin \\mathcal{C}\\), where \\(\\mathcal{C}\\) is not a convex set, the Hahn-Banach theorem allows to separate with a line (an hyperplane) the point from the convex set.</p> <p> </p> <p>It translates mathematicaly into the existence of a vector \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ \\begin{cases}    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x} \\geq 0 &amp; \\text{for all } \\boldsymbol{x} \\in \\mathcal{C}, \\\\    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x}_0 &gt; 0 &amp; \\text{for some } \\boldsymbol{x}_0 \\in \\mathcal{C}. \\end{cases} \\] <p>By definition of \\(\\mathcal{C}\\), this translates to:</p> \\[ \\begin{cases}    E^Q\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] \\geq 0 &amp; \\text{for all } Q \\sim P \\text{ with bounded } \\frac{dQ}{dP}, \\\\    E^{Q_0}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 &amp; \\text{for some } Q_0 \\sim P \\text{ with bounded } \\frac{dQ_0}{dP}. \\end{cases} \\] <p>The last condition implies that \\(Q_0[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\), and since \\(Q_0\\) is equivalent to \\(P\\), it also implies that </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\] <p>As for the first condition, we claim that it implies </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\] <p>showing then that \\(\\boldsymbol{\\eta}\\) is an arbitrage.</p> <p>To this end, define \\(A = \\{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &lt; 0\\}\\) and consider the sequence of strict positive random variables:</p> \\[   Y_n := \\left( 1 - \\frac{1}{n} \\right)1_A + \\frac{1}{n}1_{A^c} \\] <p>which is bounded by \\(1\\) and satisfies \\(Y_n \\to 1_A\\) \\(P\\)-almost surely. Since \\(Y_n &gt; 0\\), it generates a sequence of probability measures \\(Q_n\\) equivalent to \\(P\\) with bounded densities:</p> \\[   \\frac{dQ_n}{dP} = \\frac{Y_n}{E[Y_n]} \\] <p>Hence</p> \\[   0 \\leq E^{Q_n}\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\right] = \\frac{1}{E[Y_n]} E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right]. \\] <p>Taking the limit (1), it follows that:</p> <ol> <li>To be rigorous you invoke the dominated convergence theorem applied to \\(Y_n\\).</li> </ol> \\[   0 \\leq E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right] \\to E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 1_A\\right] \\] <p>which, by the definition of \\(A\\), shows that \\(P[A] = 0\\). In other words, \\(P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\). Hence, \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, contradicting the assumption of an arbitrage-free market.  </p> <p>Thus, there exists a pricing measure equivalent to \\(P\\) with bounded density, which concludes the proof.</p> </li> </ol> <p>This Theorem is called a theorem and fundamental because it states an if and only if assertion between a somehow economical concept (no arbitrage) and a mathematical concept (the existence of a pricing measure). This statement will have many consequences that will unfold while studying derivative pricing.</p> <p>However, an immediate consequence of which is the so called Law of One Price, often stated as given in finance, yet is a consequence of the FTAP.</p> <p>Theorem: Law of One Price</p> <p>If the market is arbitrage free, then for any two portfolios \\(\\bar{V}\\) and \\(\\tilde{V}\\) with exact same outcome tomorrow, that is</p> \\[   P\\left[ \\bar{V}_1 = \\tilde{V}_1\\right] = 1 \\] <p>the value of each portfolio at time \\(0\\) is the same, that is \\(\\bar{V}_0 = \\tilde{V}_0\\)</p> Proof <p>By the fundamental theorem of asset pricing, no arbitrage is equivalent to the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Let further \\(\\bar{V}\\) and \\(\\tilde{V}\\) be two portfolio such that</p> \\[   P\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>Since \\(P^\\ast \\sim P\\), it follows that</p> \\[   P^\\ast\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>showing that \\(E^{P^\\ast}\\left[ \\bar{V}_1 \\right] = E^{P^\\ast}\\left[ \\tilde{V}_1 \\right]\\).</p> <p>Furthermore, it holds that</p> \\[   \\frac{\\bar{V}_1}{1+r} = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\quad \\text{and}\\quad \\frac{\\tilde{V}_1}{1+r} = \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1 \\] <p>for some \\(\\boldsymbol{\\eta}\\) and \\(\\tilde{\\boldsymbol{\\eta}}\\) in \\(\\mathbb{R}^d\\).</p> <p>Taking expectation under the pricing measure, it follows that</p> \\[ \\begin{align*}   \\bar{V}_0 &amp; = \\bar{V}_0 + \\underbrace{\\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right]}_{=0\\text{ since }P^\\ast \\text{ is a pricing measure}}\\\\   &amp; = E^{P^\\ast}\\left[  \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\tilde{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[  \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = \\tilde{V}_0 \\end{align*} \\] <p>This statement stipulates that if a market is arbitrage free, regardless the portfolio you have in the market, if those deliver the same outcome, then their financing costs has to be the same.</p> <p>The statement of the FTAP seems to be quite abstract, but is has a very easy interpretation in terms of linear algebra when the set of possible states is finite. Indeed, consider the following financial market where </p> <ul> <li>\\(\\Omega = \\{\\omega_1, \\ldots, \\omega_N\\}\\)</li> <li>\\(\\mathcal{F} = 2^\\Omega\\).  </li> <li>\\(P\\) is a probability measure specified by the vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N)\\) where \\(p_i = P[\\{\\omega_i\\}] &gt;0\\) and \\(\\sum p_i =1\\).</li> </ul> <p>We have a bank account with:</p> \\[ B_0 = 1, \\quad B_1 = 1 + r \\] <p>for some \\(r&gt;-1\\).</p> <p>As for the finanical asset, suppose that we have a single one:</p> \\[ S_0 &gt; 0 \\quad \\text{and} \\quad S_1(\\omega_i) = s_i &gt; 0. \\] <p>Up to reordering, we assume that \\(0 &lt; s_1 &lt; s_2 &lt; \\ldots &lt; s_N\\), and denote \\(\\boldsymbol{s} = (s_1, \\ldots, s_N)\\) as the vector of payoffs for \\(S^1\\) at time \\(1\\). </p> <p>Since the state space is finite, any expectation of the asset price can be written as</p> \\[ \\begin{equation*}   E^{Q}\\left[ S_1 \\right] = \\boldsymbol{s}\\cdot \\boldsymbol{q} \\end{equation*} \\] <p>where \\(\\boldsymbol{q} = (q_1, \\ldots, q_N)\\) represent a probability equivalent to \\(P\\) if and only if \\(q_i&gt;0\\) for every \\(i\\).</p> <p>Hence the  market is arbitrage-free if and only if</p> \\[ (1 + r)S_0 \\in \\left\\{\\boldsymbol{s} \\cdot \\boldsymbol{q} \\colon \\boldsymbol{q} \\in \\mathbb{R}^d, \\sum q_i =1 , \\; q_i &gt; 0 \\text{ for every } i\\right\\} = (s_1, s_N) \\] <p>This means the market is arbitrage-free if and only if the following system of equations:</p> \\[ \\begin{cases}     q_1 s_1 + \\cdots + q_n s_n = (1 + r)S_0 \\\\     q_1 + \\cdots + q_n = 1 \\\\     q_i &gt; 0 &amp; \\text{for all } i \\end{cases} \\] <p>admits at least one solution.  </p> <p>If a solution exists, it is unique if and only if \\(N = 2\\).</p> <p>If you extend to several assets \\(d\\), then you will end up with \\(d+1\\) equations in the system.  If a solution exists then it is unique if and only if \\(N = d+1\\)</p>"},{"location":"lecture/01-One-Period/013-derivative-securities/","title":"Derivative Securities","text":"<p>A contingent claim is a contract between a seller and a buyer where the seller agrees to deliver a certain payoff at a future time. A contingent claim is called a derivative if this contract is written as a payoff depending on some underlying, such as stocks, bonds, indices, portfolios, or funds. Options are specific derivatives characterized by parameters like strike price and expiration date. While definitions may vary, the mathematical interpretation remains consistent.</p> <p>Examples of Derivatives</p> <p>In the presentation of the different derivatives we consider a financial market with a generic asset \\(S\\).</p> <ul> <li> <p>Forward/Future Contract</p> <p>A forward contract is an agreement between two parties to buy or sell an asset \\(S\\) at a future time for a price \\(K\\) fixed today. The payoff for the contract owner is determined by the difference between the asset price and the agreed price:  </p> \\[     C^{fw} = S - K \\] </li> <li> <p>Forward Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>European Put/Call Option</p> <p>A European Call or Put option grants the right, but not the obligation, to buy or sell an asset \\(S\\) at a future time for a strike price \\(K\\) fixed today.       The payoff is</p> \\[     \\begin{align*}       C^{call} &amp; = (S - K)^+                 =     \\begin{cases}       S - K &amp; \\text{if } S \\geq K, \\\\       0 &amp; \\text{otherwise}.     \\end{cases}\\\\     C^{put} &amp; = (K - S)^+              =     \\begin{cases}       K - S &amp; \\text{if } K \\geq S, \\\\       0 &amp; \\text{otherwise}.     \\end{cases}     \\end{align*} \\] <p>European call and put options are related by the formula </p> \\[   C^{call} - C^{put} = S - K \\] </li> <li> <p>European Call/Put Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>Straddle Option</p> <p>The goal of a straddle option is to profit from significant price movements of the underlying asset, regardless of the direction. It grants the right to get the price deviation (positive or negative) of the underlying asset with respect to a strike \\(K\\).</p> <p>The payoff is:</p> \\[   C^{straddle} = |S - K| =   \\begin{cases}     S-K &amp; \\text{ if } S\\geq K\\\\     K-S &amp; \\text{ if } S &lt;K   \\end{cases} \\] <p>Note that a straddle option is equivalent to holding a call and a put option with the same strike.</p> \\[   C^{straddle}(K) = C^{call}(K) + C^{put}(K) \\] </li> <li> <p>Straddle Option Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>Butterfly Option</p> <p>A butterfly option has somehow the counter effect to a straddle option in the sense that it is designed to profit from price movement around a given target \\(K\\) within an interval \\(\\underline{K} &lt; K &lt;\\overline{K}\\).</p> <p>The payoff is:</p> \\[   C^{butterfly} =    \\begin{cases}     0 &amp; \\text{if }S&lt;\\underline{K} \\text{ or }S&gt;\\overline{K}\\\\     S-\\underline{K} &amp; \\text{if } \\underline{K}\\leq S\\leq K\\\\     \\overline{K} - S &amp; \\text{if } K&lt;S \\leq \\overline{K}   \\end{cases} \\] <p>Note that such a straddle option can also be written as a combination of put and call options strikes</p> \\[   C^{butterfly}(\\underline{K}, K, \\overline{K}) = C^{call}(\\underline{K}) + C^{call}(\\overline{K}) - 2 C^{call}(K) \\] <p>Usually, the strike \\(K\\) is at the mid point between \\(\\underline{K}\\) and \\(\\overline{K}\\).</p> </li> <li> <p>Butterfly Option Payoff</p> <p> </p> </li> </ul> <p>Note that each of these options can be expressed as \\(f(S)\\), where \\(S\\) is the underlying asset, and \\(f: \\mathbb{R} \\to \\mathbb{R}\\) is some continuous function.</p> <p>Definition: Contingent Claim</p> <ul> <li> <p>A contingent claim \\(C\\) is a positive random variable.(1)</p> <ol> <li>In a strictly more general sense it does not need to be strictly positive but usually bounded from below. See for instance forward contracts.</li> </ol> </li> <li> <p>A derivative \\(C\\) is a contingent claim that depends only on the information provided by the underlying on which it is written.     In other terms, \\(C = f(\\boldsymbol{S}_1)\\) for some continuous function \\(f:\\mathbb{R}^d \\to [0, \\infty)\\).(1)</p> <ol> <li>In a more general fashion, it means that \\(C\\) is \\(\\sigma(\\boldsymbol{S}_1)\\)-measurable, which with some proof work can be shown to be equivalent to \\(C = f(\\boldsymbol{S}_1)\\) for some measurable function \\(f\\).</li> </ol> </li> </ul>"},{"location":"lecture/01-One-Period/013-derivative-securities/#pricing-a-contingent-claim","title":"Pricing a Contingent Claim","text":"<p>Given a contingent claim \\(C\\), the goal is to determine a fair price \\(\\pi(C)\\) at which it can be sold. To do this, we analyze the situation from the seller's perspective:</p> <ol> <li> <p>Time 0:      The seller receives \\(\\pi(C)\\) and deposits it into their bank account. This amount is used to invest in a strategy \\(\\boldsymbol{\\eta}\\) in \\(\\mathbb{R}^d\\).     The holdings in the bank account become \\(\\pi(C) - \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0\\) and the golding in assets becomes \\(\\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0\\).     The initial portfolio value is \\(\\bar{V}_0(\\boldsymbol{\\eta}) = \\pi(C)\\).</p> </li> <li> <p>Time 1:     The seller delivers the payoff \\(C\\) to the buyer while benefiting from their investment strategy \\(\\boldsymbol{\\eta}\\).     The discounted portfolio value minus the discounted payoff is:</p> \\[   V_1(\\boldsymbol{\\eta}) - \\frac{C}{1 + r} = \\pi(C) + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 - \\frac{C}{1 + r} \\] </li> </ol> <p>In an ideal situation, the seller of the option would like to get out with gains without downside risk, that is, fully hedge the position. Hence, the seller aims to ensure:</p> \\[ \\pi(C) + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}  \\] <p>Such a price \\(\\pi(C)\\) together with the smart strategy \\(\\boldsymbol{\\eta}\\) means that the seller super hedge his position. Considering all the possible prices and smart strategies that super hedge the position allows to define the lowest price at which the seller is willing to sell the option without taking risk, the super-hedging price</p> \\[ \\bar{\\pi}(C) = \\inf \\left\\{ x \\in \\mathbb{R} : x + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}, \\; \\text{for some } \\boldsymbol{\\eta} \\in \\mathbb{R}^d \\right\\}. \\] <p>Conversely, the buyer's perspective leads to the sub-hedging price, \\(\\underline{\\pi}(C)\\):</p> \\[ \\underline{\\pi}(C) = \\sup \\left\\{ y \\in \\mathbb{R} : y + \\boldsymbol{\\nu} \\cdot \\Delta\\boldsymbol{X}_1 \\leq \\frac{C}{1 + r}, \\; \\text{for some } \\boldsymbol{\\nu} \\in \\mathbb{R}^d \\right\\}. \\] <p>It seems economically reasonable that prices \\(y\\) from the buyer sub-hedging their position should be lower than the prices \\(x\\) of the seller super-hedging their positions. This is however true if the market is arbitrage free as seen in the subsequent proposition.</p> <p>To simplify our exposition, let us provide the notation for pricing measures</p> \\[ \\mathcal{P}^\\ast := \\left\\{ P^\\ast \\sim P \\colon E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right] = 0 \\text{ and } dP^\\ast/dP \\text{ is bounded}\\right\\} \\] <p>In particular, the FTAP can be formulated as \"The market is arbitrage free if and only if \\(\\mathcal{P}^\\ast\\) is not empty\".</p> Remark: Geometric Interpretation I <p>Define \\(I\\) and \\(J\\) as the set of super- and sub-hedging prices, respectively:</p> \\[ \\begin{align*}     I &amp; := \\left\\{ x \\in \\mathbb{R}\\colon x+\\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}\\text{ for some smart strategy }\\boldsymbol{\\eta} \\in \\mathbb{R}^d \\right\\}\\\\     J &amp; := \\left\\{ y \\in \\mathbb{R}\\colon y+\\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r}\\text{ for some smart strategy }\\boldsymbol{\\nu} \\in \\mathbb{R}^d \\right\\}\\\\ \\end{align*} \\] <p>For which holds \\(\\bar{\\pi}(C) = \\inf I\\) and \\(\\underline{\\pi}(C) = \\sup J\\).</p> <p>These two sets, \\(I\\) and \\(J\\), are eventually intervals</p> <p>Lemma</p> <ul> <li>\\(I\\) is either an interval of the form \\([\\bar{\\pi}(C), \\infty)\\) or \\((\\bar{\\pi}(C), \\infty)\\)</li> <li>\\(J\\) is either an interval of the form \\((-\\infty, \\underline{\\pi}(C)]\\) or \\((-\\infty, \\underline{\\pi}(C))\\)</li> </ul> <p>Proof</p> <p>We show only the first assertion, the second follows the same argumentation. Clearly \\(\\bar{\\pi}(C)\\) is the lower bound of the set \\(I\\), whether or not it is a minimum or an infimum. We just have to show that for any \\(x\\) in \\(I\\), if \\(m&gt;0\\), then \\(x+m\\) is also in \\(I\\). This follows however from the definition, as for a smart strategy \\(\\boldsymbol{\\eta}\\) such that</p> \\[x + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}\\] <p>It follows immediately that </p> \\[x +m + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq m +\\frac{C}{1+r} \\geq \\frac{C}{1+r}\\] <p>showing that \\(x+m\\) is in \\(I\\).</p> <p>We are now in position to show the first proposition regarding the super- and sub-hedging price</p> <p>Proposition</p> <p>If the market is arbitrage free, then for any super-hedging price \\(x\\), sub-hedging price \\(y\\) and any pricing measure \\(P^\\ast\\) it holds</p> \\[     y \\leq E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] \\leq x \\] <p>In particular, we get</p> \\[     \\underline{\\pi}(C) \\leq \\inf_{P^\\ast \\in \\mathcal{P}^\\ast} E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right]\\leq \\sup_{P^\\ast \\in \\mathcal{P}^\\ast} E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right]\\leq \\bar{\\pi}(C) \\] Proof <p>Let \\(x\\) be a super-hedging price and \\(y\\) be a sub-hedging price. By definition, there exists smart strategies \\(\\boldsymbol{\\eta}\\) and \\(\\boldsymbol{\\nu}\\) in \\(\\mathbb{R}^d\\) such that</p> \\[     y + \\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\leq x + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\] <p>Now, since the market is arbitrage free, according to the FTAP, for any pricing measure \\(P^\\ast\\) in \\(\\mathcal{P}^\\ast\\) which is not empty, by taking expectation of this inequality, it holds</p> \\[     y + \\underbrace{E^{P^\\ast}\\left[\\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1\\right]}_{=0} \\leq E^{P^\\ast}\\left[\\frac{C}{1+r} \\right]\\leq x + \\underbrace{E^{P^\\ast}\\left[\\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1\\right]}_{=0} \\] <p>showing the first assertion.</p> <p>Since this inequality holds for any super hedging price \\(x\\), any sub hedging price \\(y\\) and any pricing measure \\(P^\\ast\\), by the definition of \\(\\bar{\\pi}(C)\\) and \\(\\underline{\\pi}(C)\\) the second assertion follows.</p> <p>We however still need to define the notion of of a fair price for a contingent claim and how it relates to the super-/sub-hedging price.</p> <p>Definition: Fair Price of Contingent Claims</p> <p>Given a contingent claim \\(C\\), a price \\(\\pi(C)\\) is called a fair price if the original financial market extended with the new financial instrument \\(S^{d+1}\\) given by</p> \\[   S^{d+1}_0 = \\pi(C) \\quad \\text{and}\\quad S^{d+1}_1 = C \\] <p>is arbitrage free.</p> <p>We denote by \\(\\Pi(C)\\) the set of all possible fair prices for the contingent claim \\(C\\).</p> <p>In other terms, if the financial market considers the new financial instrument \\(C\\) traded at price \\(\\pi(C)\\) it remains arbitrage free. As pendant to the super- and sub-hedging price, with the help of the FTAP we can connect arbitrage free prices to pricing measures as follows.</p> <p>Proposition</p> <p>Let \\(C\\) be a contingent claim on an arbitrage-free financial market. Then the set of fair prices for the contingent claim \\(C\\) is non-empty and given by:</p> \\[   \\Pi(C) := \\left\\{ E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] : P^\\ast \\sim P \\text{ pricing measure with bounded density}  \\right\\}. \\] Proof <p>A price \\(\\pi(C)\\) for \\(C\\) is fair if the extended financial market is arbitrage-free. By the FTAP, it follows that there exists a pricing measure \\(\\hat{P}\\) equivalent to \\(P\\) with bounded density such that:</p> \\[     E^{\\hat{P}}\\left[\\frac{\\boldsymbol{S}_1}{1+r}\\right] = \\boldsymbol{S}_0, \\quad \\text{and} \\quad E^{\\hat{P}}\\left[\\frac{C}{1+r}\\right] = \\pi(C). \\] <p>In particular, \\(\\hat{P}\\) is a pricing measure equivalent to \\(P\\) for the smaller market \\(\\boldsymbol{S}\\), that is, an element of \\(\\mathcal{P}^\\ast\\), showing that:</p> \\[     \\Pi(C) \\subseteq \\{ E^{P^\\ast}[C/(1+r)] : P^\\ast \\in \\mathcal{P}^\\ast \\}. \\] <p>Reciprocally, let \\(\\pi(C)\\) be an element of \\(\\{ E^{P^\\ast}[C/(1+r)] : P^\\ast \\in \\mathcal{P}^\\ast \\}\\). It follows that \\(\\pi(C) = E^{P^\\ast}[C/(1+r)]\\) for some \\(P^\\ast \\sim P\\) with bounded density. Hence, \\(P^\\ast\\) is a pricing measure equivalent to \\(P\\) for the extended market, showing by the FTAP that the extended market is arbitrage-free. Hence, \\(\\pi(C) \\in \\Pi(C)\\), proving the reverse inclusion.(1)</p> <ol> <li> <p>The proof is not fully complete unless we can show that we can show that \\(\\Pi(C)\\) is non-empty.     As done previously, we pick a probability measure \\(\\tilde{P}\\) equivalent to \\(P\\) such that \\(E^{\\tilde{P}}[C] &lt; \\infty\\). Under \\(\\tilde{P}\\), the market is arbitrage-free.     The FTAP guarantees the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\) with bounded density.      In particular, \\(E^{P^\\ast}[C] &lt; \\infty\\), and therefore:</p> \\[     \\pi(C) = E^{P^\\ast}[C/(1+r)] \\in \\Pi(C). \\] </li> </ol> <p>We are now in place to show the relation ship between super- sub-hedging prices, pricing measures and fair prices. In a nuttshell that the following illustration holds</p> <p> </p> <p>Theorem: Super/Sub Hedging and Fair Prices</p> <p>Let \\(C\\) be a contingent claim. For</p> \\[     \\begin{align*}         J &amp; = \\left\\{ y\\in \\mathbb{R}\\colon y + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\text{ for some }\\boldsymbol{\\eta}\\in \\mathbb{R}^d \\right\\} &amp;&amp; \\text{Risk free subhedging prices}\\\\         \\underline{\\pi}(C) &amp; = \\sup J &amp;&amp; \\text{Sub-hedging price}\\\\         I &amp; = \\left\\{ x\\in \\mathbb{R}\\colon x + \\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\text{ for some }\\boldsymbol{\\nu}\\in \\mathbb{R}^d \\right\\} &amp;&amp; \\text{Risk free superhedging prices}\\\\         \\underline{\\pi}(C) &amp; = \\inf I &amp;&amp; \\text{Super-hedging price}\\\\         \\Pi(C) &amp; = \\left\\{ \\pi(C)\\colon \\text{fair prices} \\right\\} &amp;&amp; \\text{Fair prices}\\\\         \\mathcal{P}^\\ast &amp; = \\left\\{ P^\\ast \\sim P \\colon P^\\ast \\text{ is a pricing measure} \\right\\} &amp;&amp; \\text{Pricing measures}     \\end{align*} \\] <p>If the market is arbitrage free, then it holds that \\(J\\), \\(I\\), and \\(\\Pi(C)\\) are intervals such that \\(J\\leq \\Pi(C) \\leq I\\). Furthermore </p> \\[     \\begin{align*}         J &amp; = (-\\infty, \\underline{\\pi}(C)] &amp;         \\Pi(C) &amp; = \\left\\{ E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] \\colon P^\\ast \\in \\mathcal{P}^\\ast \\right\\} &amp;         I &amp; = [\\overline{\\pi}(C), \\infty )      \\end{align*} \\] <p>and</p> \\[     \\begin{align*}         \\underline{\\pi}(C) &amp; = \\inf \\Pi(C) &amp; \\overline{\\pi}(C) &amp; = \\sup \\Pi(C)     \\end{align*} \\] Proof <p>We already saw that \\(J\\) and \\(I\\) are intervals (see geometric interpretation remark above). We also say that \\(\\Pi(C) = \\{E^{P^\\ast}[C/(1+r)]\\colon P^\\ast \\in \\mathcal{P}^\\ast\\}\\) and that \\(J \\leq \\Pi(C) \\leq I\\). The fact that \\(\\Pi(C)\\) is also an interval follows directly from \\(\\mathcal{P}^\\ast\\) is a convex set, same argumentation as for \\(\\mathcal{C}\\) in the proof of the FTAP.</p> <p>We are left to show that \\(\\underline{\\pi}(C) \\in J\\) and \\(\\overline{\\pi}(C) \\in I\\) and that \\(\\underline{\\pi}(C) = \\inf \\Pi(C)\\) as well as \\(\\overline{\\pi}(C)  = \\sup \\Pi(C)\\).</p> <p>Let us proove that \\(\\overline{\\pi}(C) = \\sup \\Pi(C)\\). We already know that \\(\\overline{\\pi}(C) \\geq \\sup \\Pi(C)\\) Suppose \\(\\sup \\Pi(C) &lt; \\infty\\), otherwise the equality is trivial. Let \\(m &gt; \\sup \\Pi(C)\\). By definition, the market extended with \\((m, C)\\) admits an arbitrage opportunity. That is, there exist \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) and \\(\\mu \\in \\mathbb{R}\\) such that:</p> \\[     \\begin{cases}         P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right) \\geq 0\\right] = 1, \\\\         P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right) &gt; 0\\right] &gt; 0.     \\end{cases} \\] <p>Since the original market is arbitrage-free, it follows that \\(\\mu \\neq 0\\). Taking the expectation of the positive random variable \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right)\\) with respect to \\(P^\\ast \\in \\mathcal{P}^\\ast\\) yields:</p> \\[     \\mu E^{P^\\ast}\\left[\\frac{C}{1+r} - m\\right] \\geq 0. \\] <p>By definition of \\(m\\), this implies \\(\\mu &lt; 0\\). Defining \\(\\boldsymbol{\\nu} = -\\boldsymbol{\\eta}/\\mu \\in \\mathbb{R}^d\\) yields:</p> \\[     m + \\boldsymbol{\\nu} \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}, \\] <p>showing that \\(m\\) is in \\(I\\), and therefore \\(m \\geq \\bar{\\pi}(C)\\). Consequently:</p> \\[     \\sup \\Pi(C) \\geq \\bar{\\pi}(C). \\] <p>The same argumentation shows that \\(\\overline{\\pi}(C) = \\inf \\Pi(C)\\).</p> Warning, the last part of the assertion calls for compactness arguments <p>We are left to show that \\(\\overline{\\pi}(C)\\) is in \\(I\\). Without loss of generality, due to the law of one price, we may assume that there is no redundancy; that is, \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 = 0\\) implies \\(\\boldsymbol{\\eta} = 0\\).  </p> <p>Pick a sequence \\((m_n)\\) of elements in \\(I\\) such that \\(m_n \\downarrow \\overline{\\pi}(C)\\) and denote by \\(\\boldsymbol{\\eta}^n\\) the corresponding sequence of strategies such that:</p> \\[     m_n + \\boldsymbol{\\eta}^n \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}. \\] <p>If \\((\\boldsymbol{\\eta}^n)\\) is bounded, up to a subsequence, we may assume that \\(\\boldsymbol{\\eta}^n \\to \\boldsymbol{\\eta} \\in \\mathbb{R}^d\\), for which it holds:</p> \\[     \\frac{C}{1 + r} \\leq m_n + \\boldsymbol{\\eta}^n \\cdot \\Delta \\boldsymbol{X}_1 \\to \\bar{\\pi}(C) + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1, \\] <p>showing that \\(\\bar{\\pi}(C)\\) is in I.</p> <p>If \\(\\lim \\|\\boldsymbol{\\eta}^n\\| = \\infty\\), up to a subsequence, it follows that \\(\\boldsymbol{\\eta}^n / \\|\\boldsymbol{\\eta}^n\\| \\to \\boldsymbol{\\mu}\\) with \\(\\|\\boldsymbol{\\mu}\\| = 1\\).</p> <p>However, it follows that:</p> \\[     0 \\leq \\lim \\frac{C}{\\|\\boldsymbol{\\eta}^n\\|(1 + r)} = \\lim \\frac{\\boldsymbol{\\eta}^n}{\\|\\boldsymbol{\\eta}^n\\|} \\cdot \\Delta \\boldsymbol{X}_1 + \\frac{m_n}{\\|\\boldsymbol{\\eta}^n\\|} = \\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_1 \\] <p>Since the market is arbitrage-free, it must follow that \\(\\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_1 = 0\\), which by the non-redundancy assumption implies \\(\\boldsymbol{\\mu} = 0\\), leading to a contradiction since \\(\\|\\boldsymbol{\\mu}\\| = 1\\).</p> <p>Definition</p> <p>A contingent claim \\(C\\) is called replicable \u2014 attainable, hedgeable, or redundant \u2014 if there exists a portfolio with start value \\(\\bar{V}_0\\) and strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[     C = \\bar{V}_1 = \\bar{V}_0 + \\boldsymbol{\\eta} \\cdot \\left(\\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r)\\right). \\] <p>In other term, a contingent claim is replicable if its outcome can be fully attained by a self financing portfolio.</p> <p>Proposition</p> <p>Let \\(C\\) be a contingent claim in an arbitrage-free market. Then:</p> <ul> <li> <p>\\(C\\) is replicable if and only if \\(\\overline{\\pi}(C) = \\underline{\\pi}(C)\\) which is the unique price of the contingent claim</p> </li> <li> <p>If \\(C\\) is not replicable, then \\(\\overline{\\pi}(C) &gt; \\underline{\\pi}(C)\\), and:</p> </li> </ul> \\[     \\Pi(C) = \\left(\\overline{\\pi}(C), \\underline{\\pi}(C)\\right). \\] Proof <p>Clearly, if \\(C\\) is replicable, it follows that \\(\\underline{\\pi}(C) = \\overline{\\pi}(C)\\) by the definition of \\(\\underline{\\pi}\\) and \\(\\overline{\\pi}\\). The reciprocal follows from the second assertion. To prove the second assertion:</p> <ol> <li>\\(\\Pi(C)\\) is an interval</li> <li> <p>Non-replicability implies that \\(\\bar{\\pi}(C) \\not\\in \\Pi(C)\\):     Indeed, by the previous theorem, there exists a strategy \\(\\boldsymbol{\\eta}\\) such that:</p> \\[     \\bar{\\pi}(C) + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}. \\] <p>Since \\(C\\) is not replicable, this inequality cannot hold with equality \\(P\\)-almost surely. This demonstrates \\(\\bar{\\pi}(C) \\not\\in \\Pi(C)\\).</p> </li> </ol> <p>Since \\(\\overline{\\pi}(C) = \\sup \\Pi(C)\\), it follows that \\(\\Pi(C)\\) forms an open interval:</p> \\[     \\Pi(C) = \\left(\\underline{\\pi}(C), \\overline{\\pi}(C)\\right) \\] <p>A condition that garantees that every contingent claim is replicable and henceforth with a unique price is when \\(\\mathcal{P}^\\ast\\) contains a unique pricing measure. In such a market every contingent claim is uniquely priced and hedgable. In other terms every contingent claim in a complete financial market is redundant since they can all be achieved by a portfolio. A market with a unique pricing measure is called a complete market</p> <p>On the other hand, the proposition shows that unless the claim is attainable, then fair prices of a contingent claim are not unique. The choice of a fair price (and therefore a deal) for such a contingent claim is henceforth due to an agreement between the buyer and the seller to choose a price within the interval \\(\\Pi(C)\\). Therefore, they both have to accept some downside risk since neither will have a price in their confort risk free zone.</p> <p>Example: Forward Contract</p> <p>Recall that forward contract are contingent claims of the form(1)</p> <ol> <li>Note first that forward contract are not necessarily positive random variable, but usually for contingent claims we can assume that they are greater than some constant.</li> </ol> \\[   C^{fw}(K) = S_1 - K  \\] <p>Suppose that our market is arbitrage free and choose any pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Taking expectation of the the discounted value of the contingent claim yields</p> \\[   E^{P^\\ast}\\left[ \\frac{C^{fw}}{1+r} \\right] = E^{P^\\ast}\\left[ \\frac{S_1}{1+r} \\right] - \\frac{K}{1+r} = S_0 - \\frac{K}{1+r} \\] <p>showing that the fair price of the forward contract is unique. It is not surpising as the payoff can be immediately replicated by a portfolio.</p> <p>However in financial markets, people speaks and quote the so called forward price. The definition of a forward price \\(F\\) is the value of the strike \\(K\\) such that the fair price of the forward contract is equal to \\(0\\). In other term, the forward price \\(F\\) is given by</p> \\[   F = (1+r) S_0 \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#european-call-and-put-options","title":"European Call and Put Options","text":"<p>The European call and put options are ubiquitous in finance as the most simple types of options.</p> <p>Recall the payoff of such options</p> \\[ \\begin{align*}   C^{call}(K) &amp; = (S_1-K)^+ &amp;    C^{put}(K) &amp; = (K-S_1)^+ \\end{align*} \\] <p>We suppose that the market is arbitrage free and denote with \\(\\pi^{call}(K)\\) and \\(\\pi^{put}(K)\\) the fair prices for each option.</p> <p>Since both prices are fair, there exists a pricing measure \\(P^\\ast \\sim P\\) in the extended market where those two options are traded together with the underlying. It holds in particular that</p> \\[ \\pi^{call}(K) = E^{P^\\ast}\\left[ \\frac{(S_1 - K)^+}{1+r} \\right] \\quad \\text{and}\\quad \\pi^{put}(K) = E^{P^\\ast}\\left[ \\frac{(K - S_1)^+}{1+r} \\right] \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#put-call-parity","title":"Put Call Parity","text":"<p>Using the fact that \\((S_1-K)^+ - (K-S_1)^- = S_1-K\\) we can derive the so called put/call parity by taking expectation under \\(P^\\ast\\):</p> \\[ \\pi^{call}(K) - \\pi^{put}(K) =  E^{P^\\ast}\\left[\\frac{(S_1-K)^+ - (K-S_1)^+}{1+r}\\right] = E^{P^\\ast}\\left[ \\frac{S_1-K}{1+r} \\right] = S_0 - \\frac{K}{1+r} \\] <p>Put Call Parity</p> \\[   \\pi^{call}(K) - \\pi^{put}(K) = S_0 - \\frac{K}{1+r} \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#universal-price-bounds","title":"Universal Price Bounds","text":"<p>In an arbitrage free market, let \\(\\pi^{call} = E^{P^\\ast}[C^{call}/(1+r)]\\) be any fair price for this call option. We are interested at providing bounds for the fair price of this call option.</p> <p>On the one hand, it holds that \\(S-K \\leq (S-K)^+\\). Taking the expectation under \\(P\\) of the discounted value of this inequality together with the fact that \\(\\pi^{call} \\geq 0\\) yields</p> \\[   \\left(S_0 - \\frac{K}{1+r}\\right)^+ \\leq \\pi \\] <p>On the other hand, it holds that \\((S_1-K)^+ \\leq S_1\\), taking expectation of the discounted value of this inequality yields</p> \\[     \\pi^{call} \\leq S_0 \\] <p>showing the universal bounds for call options \\((S_0 - K/(1+r))^+ \\leq \\pi{call}\\leq S_0\\) for any fair price for the call.</p> <p>Using put call parity, for any fair price for the put \\(\\pi^{put}\\) it holds that \\(K/{1+r}\\geq \\pi^{put}\\geq (S_0-K/(1+r))^+ + K/(1+r) - S_0 = (K/(1+r) - S_0)^+\\).</p> <p>Universal Price Bounds</p> \\[   \\begin{equation*}   \\begin{cases}      \\left( S_0 -\\frac{K}{1+r} \\right)^+ \\leq \\underline{\\pi}\\left( C^{call}(K) \\right) \\leq \\overline{\\pi}\\left( C^{call}(K) \\right)\\leq S_0\\\\       \\\\       \\frac{K}{1+r} \\leq \\underline{\\pi}\\left( C^{put}(K) \\right) \\leq \\overline{\\pi}\\left( C^{put}(K) \\right)\\leq \\left( \\frac{K}{1+r} - S_0 \\right)^+   \\end{cases}   \\end{equation*} \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#jargon","title":"Jargon","text":"<p>A lot of jargon is connected to these options.</p> <ul> <li> <p>Intrinsic Value: The intrinsic value of the option is the value if it were executed now, that is</p> \\[IV^{call} = (S_0-K)^+ \\quad \\text{and}\\quad IV^{put} = (K-S_0)^+\\] </li> <li> <p>In/At/Out of the Money: An option is called in the money if its intrinsic value is strictly positive, at the money if the underlying price equal the strike, out of the money if the intrinsic value is \\(0\\) and the underlying price is not equal to the strike.</p> </li> <li> <p>Moneyness: Moneyness is a concept that has no rigorous definition but stems from a particular property of the call/put option, the positive homogeneity of their payoff, that it \\((\\lambda x)^+ = \\lambda x^+\\) for any \\(\\lambda &gt;0\\).</p> <p>We can therefore normalize the payoff of options by either \\(K\\), \\(S_0\\) or \\(K/(1+r)\\), etc. Most of those normalizations are brought in connection with the resulting Black-Scholes-Merton formula, but let us stress some aspects of this definition. The simple version of moneyness is related to the intrinsic value of the option. In the case of a call, we can normalize by the strike where the simple spot moneyness is defined as \\(S_0/K\\). Indeed, it holds</p> \\[   \\pi^{call}(K) = K E^{P^\\ast}\\left[ \\frac{1}{1+r}\\left( \\frac{S_1}{K} - 1 \\right)^+ \\right]  \\] <p>The intrinsic value of the normalize option in the inner part of the expectation is \\((S_0/K-1)^+\\) and therefore is in the money iff the simple (call) spot moneyness is greater than one and out of the money otherwise.</p> <p>In the case of the put option we normalize by the current underlying price \\(S_0\\), that is, the simple spot moneyness is defined as \\(K/S_0\\):</p> \\[   \\pi^{put}(K) = S_0 E^{P^\\ast}\\left[ \\frac{1}{1+r}\\left(\\frac{K}{S_0}- \\frac{S_1}{S_0} \\right)^+ \\right]  \\] <p>The intrinsic value of this normalized option in the inner part of the expectation is \\((K/S_0 -1)^+\\) which is positive iff the simple (put) spot moneyness is greater than one and out of the money otherwise.</p> <p>Since those definition is rather confusing, always rely on your mathematical knowledge about what each should mean.</p> </li> </ul>"},{"location":"lecture/02-risk-management/021-what-is-risk/","title":"What is Risk","text":"<p>Even if the notion of risk is colloquial and everyone intuitively understands it, it is far from clear what it is the exact definition.</p> <p>We saw in the previous chapter how to price contingent claims in a \"risk-neutral way\" ensured by an arbitrage-free financial market. However, such pricing does not tell us much about the amount of \"risk\" one undertakes when investing in one product or another.</p> <p>Let us consider the following example.</p> <p>Example</p> <p>Let \\(\\Omega=\\{\\omega_1,\\omega_2,\\omega_3\\}\\), \\(\\mathcal{F}=2^\\Omega\\), and the \"objective probability\" measure \\(P\\) given by \\(P[\\{\\omega_1\\}]=0.1\\), \\(P[\\{\\omega_2\\}]=0.85\\), and \\(P[\\{\\omega_3\\}]=0.05\\). Our bank account \\(B_0=1\\) and \\(B_1=(1+r)\\). We have two stocks with the same start price \\(S_0^1=S_0^2=100\\) and prices tomorrow:</p> \\[ S_1^1(\\omega)= \\begin{cases}     110 &amp; \\text{if } \\omega = \\omega_1 \\\\     105 &amp; \\text{if } \\omega = \\omega_2 \\\\     100 &amp; \\text{if } \\omega = \\omega_3 \\end{cases} \\quad \\text{and} \\quad S_1^2(\\omega)= \\begin{cases}     160 &amp; \\text{if } \\omega = \\omega_1 \\\\     110 &amp; \\text{if } \\omega = \\omega_2 \\\\     0   &amp; \\text{if } \\omega = \\omega_3 \\end{cases} \\] <p>Simple computation shows that for \\(r=\\frac{1}{15} \\approx 6.66\\%\\), there exists a unique risk-neutral pricing measure \\(P^\\ast\\) given by:</p> \\[ P^\\ast[\\{\\omega_1\\}] = p_1^\\ast = \\frac{2}{3}, \\quad P^\\ast[\\{\\omega_3\\}] = p_3^\\ast = \\frac{1}{3}, \\quad \\text{and} \\quad P^\\ast[\\{\\omega_2\\}] = p_2^\\ast = 0 \\] <p>Now, as a portfolio manager, you face the dilemma of which stock you would choose or what proportion you would allocate to one or the other. If the only rationale underlying your decision process is given in terms of the risk-neutral pricing, there is no difference between the two stocks, and you are indifferent.</p> <p>However, you intuitively see that the first stock is a blue chip, whereas the second one is rather the hot but \"risky\" kid on the playground\u2014a startup or so. Your decision process would likely be driven by a \"risk/reward\" analysis in the face of \"uncertainty,\" whatever that means.</p> <p>We make the analysis even simpler with the following second example.</p> <p>Example</p> <p>You own 1,000 RMB and have the choice between the following games:</p> <ol> <li> <p>Pay 1,000 and get immediately:</p> \\[ \\begin{cases}     2,000 &amp; \\text{with probability } 50\\% \\\\     0     &amp; \\text{otherwise} \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,200 &amp; \\text{with probability } \\frac{5}{6} \\approx 83.33\\% \\\\      0     &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,300 &amp; \\text{with probability } 25\\% \\\\      900   &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,100 &amp; \\text{with probability } 50\\% \\\\      900   &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Do nothing and keep your 1,000.</p> </li> </ol> <p>All these games have an expected return of 0. However, you would likely have a preference regarding which one is the best. Considering their standard deviations\u2014that is, \\(E[(X - E[X])^2]^{1/2}\\)\u2014it holds:</p> \\[   \\begin{aligned}       \\mathrm{STD}(\\text{game 1}) &amp; \\approx 1,000, \\\\       \\mathrm{STD}(\\text{game 2}) &amp; \\approx 447.21, \\\\       \\mathrm{STD}(\\text{game 3}) &amp; \\approx 173.21, \\\\       \\mathrm{STD}(\\text{game 4}) &amp; \\approx 100, \\\\       \\mathrm{STD}(\\text{game 5}) &amp; \\approx 0.   \\end{aligned} \\] <p>Remark</p> <p>Risk perception is a subjective view of how you assess uncertain prospective outcomes. This may differ from one person to another as well as from one context to another. How can we model this fact mathematically?</p>"},{"location":"lecture/02-risk-management/021-what-is-risk/#two-examples-for-risk-assessment-instruments","title":"Two Examples for Risk Assessment Instruments","text":""},{"location":"lecture/02-risk-management/021-what-is-risk/#markowitz-mean-variance","title":"Markowitz Mean Variance","text":"<p>The deviation from the mean appears to be a good indicator of our aversion to uncertainty. This is why Markowitz introduced the following criterion to assess the trade-off between risk and rewards in terms of variance and means.</p> <p>Definition</p> <p>Given a square integrable random variable \\( X \\)\u2014modeling some payoff such as a portfolio strategy, industrial projects, or any management decision\u2014the Markowitz mean/variance measure is defined as:</p> \\[ MV_{\\alpha}(X) = E[X] - \\frac{\\alpha}{2} \\text{VAR}(X) \\] <p>where:</p> \\[ \\text{VAR}(X) = E\\left[(X - E[X])^2\\right] \\] <p>is the variance of the random variable, and \\( \\alpha \\) is a positive number.</p> <p>For any value of \\( \\alpha \\), you can check that assessing previous games in terms of mean and variance will rank them, with the largest standard deviation corresponding to the worst game and the smallest standard deviation corresponding to the best game. </p> <p>The Markowitz mean-variance approach was a highly successful instrument for finding optimal portfolio strategies. It can also be used as a risk assessment measure. However, since we are more interested in the downside risks, we consider risk measures defined for the random variable \\( L = -X \\), where \\( X \\) represents returns.</p> <p>Definition</p> <p>The Markowitz risk measure is defined as:</p> \\[   RMV_{\\alpha}(L) = E[L] + \\frac{\\alpha}{2} \\text{VAR}(L) \\] <p>where \\( L \\) is a square integrable loss profile.</p> <p>Proposition</p> <p>The Markowitz risk measure satisfies the following properties:</p> <ol> <li> <p>Cash-invariance: For every loss profile \\( L \\) and \\( m \\in \\mathbb{R} \\),</p> \\[   RMV_{\\alpha}(L - m) = RMV_{\\alpha}(L) - m. \\] </li> <li> <p>Convexity: For any two loss profiles \\( L_1, L_2 \\) and \\( \\lambda \\in [0, 1] \\),</p> \\[   RMV_{\\alpha}(\\lambda L_1 + (1 - \\lambda)L_2) \\leq \\lambda RMV_{\\alpha}(L_1) + (1 - \\lambda)RMV_{\\alpha}(L_2) \\leq \\max \\left\\{ RMV_{\\alpha}(L_1), RMV_{\\alpha}(L_2)\\right\\}. \\] </li> <li> <p>Law Invariance: If two loss profiles \\( L_1 \\) and \\( L_2 \\) have the same CDF, then:</p> \\[   RMV_{\\alpha}(L_1) = RMV_{\\alpha}(L_2). \\] </li> </ol> Proof <ol> <li> <p>Cash-invariance: For every \\( m \\in \\mathbb{R} \\), and loss \\( L \\), it holds:</p> \\[   \\begin{align*}      RMV_{\\alpha}(L-m) &amp; = E[L-m] + \\frac{\\alpha}{2} E\\left[\\left(L-m-E[L-m]\\right)^2\\right]\\\\                        &amp; = E[L] + \\frac{\\alpha}{2} E\\left[\\left(L - E[L]\\right)^2\\right] - m = RMV_{\\alpha}(L) - m   \\end{align*} \\] </li> <li> <p>Convexity: Let \\( 0 \\leq \\lambda \\leq 1 \\) and \\( L_1 \\) and \\( L_2 \\) be two loss profiles. </p> <p>Since the function \\( x \\mapsto x^2 \\) is convex, it follows that:</p> \\[   \\begin{align*}      \\left(\\lambda L_1 + (1-\\lambda)L_2 - E[\\lambda L_1 + (1-\\lambda)L_2]\\right)^2        &amp;=\\left(\\lambda(L_1 - E[L_1]) + (1-\\lambda)(L_2 - E[L_2])\\right)^2\\\\       &amp;\\leq \\lambda \\left(L_1 - E[L_1]\\right)^2 + (1-\\lambda)\\left(L_2 - E[L_2]\\right)^2   \\end{align*} \\] <p>Taking expectation, it follows that:</p> \\[   \\text{VAR}(\\lambda L_1 + (1-\\lambda)L_2) \\leq \\lambda \\text{VAR}(L_1) + (1-\\lambda) \\text{VAR}(L_2) \\] <p>showing that:</p> \\[   \\begin{align*}      RMV_{\\alpha}(\\lambda L_1 + (1-\\lambda)L_2) &amp; = \\lambda E[L_1] + (1-\\lambda)E[L_2] + \\frac{\\alpha}{2} \\text{VAR}(\\lambda L_1 + (1-\\lambda)L_2)\\\\       &amp;\\leq \\lambda\\left(E[L_1] + \\frac{\\alpha}{2} \\text{VAR}(L_1)\\right) + (1-\\lambda)\\left(E[L_2] + \\frac{\\alpha}{2} \\text{VAR}(L_2)\\right)\\\\       &amp; = \\lambda RMV_{\\alpha}(L_1) + (1-\\lambda)RMV_{\\alpha}(L_2)\\\\       &amp; \\leq \\max \\left\\{ RMV_{\\alpha}(L_1), RMV_{\\alpha}(L_2) \\right\\}   \\end{align*} \\] </li> <li> <p>Law Invariance: For the last assertion, let \\( L_1 \\) and \\( L_2 \\) be such that \\( F_{L_1} = F_{L_2} \\).   It follows that:</p> \\[ \\begin{align*}    RMV_{\\alpha}(L_1) &amp; = \\int_{\\mathbb{R}} x dF_{L_1}(x) + \\frac{\\alpha}{2}\\int_{\\mathbb{R}} \\left[x - \\int_{\\mathbb{R}}x dF_{L_1}(x)\\right]^2 dF_{L_1}(x) \\\\       &amp; = \\int_{\\mathbb{R}} x dF_{L_2}(x) + \\frac{\\alpha}{2}\\int_{\\mathbb{R}} \\left[x - \\int_{\\mathbb{R}}x dF_{L_2}(x)\\right]^2 dF_{L_2}(x) \\\\       &amp; = RMV_{\\alpha}(L_2) \\end{align*} \\] </li> </ol>"},{"location":"lecture/02-risk-management/021-what-is-risk/#value-at-risk-vr","title":"Value at Risk (V@R)","text":"<p>The value at risk (V@R) is a widely used risk assessment measure introduced in the finance industry by JP Morgan around 1995. It measures downside risk as follows:</p> <p>Definition</p> <p>Let \\( L \\) be a loss profile. The value at risk (\\( V@R_{\\alpha} \\)) with parameter \\( 0 &lt; \\alpha &lt; 1 \\) is defined as:</p> \\[   V@R_{\\alpha}(L) = \\inf\\{m \\in \\mathbb{R} : P[L &gt; m] \\leq \\alpha\\}. \\] <p>This can also be expressed as:</p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf\\{m \\in \\mathbb{R} : P[L &gt; m] \\leq \\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : 1-P[L\\leq m] \\leq \\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : F_L(m) \\geq 1-\\alpha\\}   \\end{align*} \\] <p>where \\( F_L(m):= P[L\\leq m] \\) is the cumulative distribution function (CDF) of \\( L \\).</p> <p> </p> <p>Note: Quantile Function</p> <p>Note that the CDF \\(F_L\\) is an increasing function from \\(0\\) to \\(1\\). Furthermore, it is right continuous meaning that \\(F_L(m_n)\\downarrow F_L(m)\\) for any sequence \\(m_n \\downarrow m\\). Indeed, let \\(A_n = \\{L \\leq m_n\\}\\) and \\(A =\\{L\\leq m\\}\\), it follows that \\(A_1\\supseteq A_2 \\ldots \\supseteq A_n \\supseteq \\ldots\\) with \\(\\cap A_n =A\\). As a consequence of the \\(\\sigma\\)-additivity of the probability measure, it follows that \\(P[A_n]\\downarrow P[A]\\).</p> <p>Now, if \\(F_L\\) is strictly increasing and continuous, it has an inverse \\(F_L^{-1}\\colon (0, 1)\\to \\mathbb{R}\\) which is also strictly increasing and continuous. Such an inverse is called the quantile of \\(L\\) and denoted by \\(q_L\\colon (0,1)\\to \\mathbb{R}\\). It follows that we can write the value at risk in terms of quantile:</p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf\\{m \\in \\mathbb{R} : F_L(m) \\geq 1-\\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : F^{-1}_L(F_L(m)) \\geq F^{-1}_L(1-\\alpha)\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : m \\geq F^{-1}_L(1-\\alpha)\\}\\\\                     &amp; = F^{-1}_L(1-\\alpha)   \\end{align*} \\] <p>In other terms, \\(V@R_{\\alpha}(L)=q_L(1-\\alpha)\\) is the \\(1-\\alpha\\) quantile of the distribution.</p> <p>In the case where \\(F_L\\) is not strictly increasing and continuous, we can still define the so called (left) pseudo-inverse or quantile as</p> <p>Definition: Quantile</p> <p>The quantile of the random variable \\(L\\) is defined as</p> \\[ \\begin{equation*}   \\begin{split}     q_L \\colon (0,1) &amp; \\longrightarrow \\mathbb{R}\\\\                 s &amp; \\longmapsto q_L(\\alpha) = \\inf\\left\\{ m \\in \\mathbb{R}\\colon P\\left[ L\\leq m \\right] \\geq s\\right\\}   \\end{split} \\end{equation*} \\] <p>The quantile is an increasing and left continuous function for which holds</p> \\[   F_L(q_L(s)-) \\leq s\\leq F_L(q_L(s))   \\] <p>The value at risk indicates the amount of cash or liquidity needed to reduce the loss size so that the probability of making losses exceeds \\( \\alpha \\) is small. Typical values for \\( \\alpha \\) are 5%, 1%, or 0.5%, depending on the horizon.</p> <p>Example</p> <p>Let \\( \\Omega = \\{\\omega_1, \\omega_2, \\omega_3, \\omega_4\\} \\) with probabilities \\( p = (0.7\\%, 3.3\\%, 46\\%, 50\\%) \\), and let \\( L \\) be a loss profile defined as:</p> \\[ L(\\omega) = \\begin{cases} 10,000 &amp; \\text{if } \\omega = \\omega_1, \\\\ -50    &amp; \\text{if } \\omega = \\omega_2, \\\\ -200   &amp; \\text{if } \\omega = \\omega_3, \\\\ -1,000 &amp; \\text{if } \\omega = \\omega_4. \\end{cases} \\] <p>The corresponding CDF \\( F_L(m) \\) is:</p> \\[ F_L(m) = \\begin{cases} 0       &amp; \\text{if } m &lt; -1,000, \\\\ 50\\%    &amp; \\text{if } -1,000 \\leq m &lt; -200, \\\\ 96\\%    &amp; \\text{if } -200 \\leq m &lt; -50, \\\\ 99.3\\%  &amp; \\text{if } -50 \\leq m &lt; 10,000, \\\\ 1       &amp; \\text{if } m \\geq 10,000. \\end{cases} \\] <p>From this, the quantile function is:</p> \\[ q_L(x) = \\begin{cases} -1,000 &amp; \\text{if } 0 &lt; x \\leq 50\\%, \\\\ -200   &amp; \\text{if } 50\\% &lt; x \\leq 96\\%, \\\\ -50    &amp; \\text{if } 96\\% &lt; x \\leq 99.3\\%, \\\\ 10,000 &amp; \\text{if } 99.3\\% &lt; x \\leq 1. \\end{cases} \\] <p>Thus: [ V@R_{5\\%} = q_L(95\\%) = -200, \\quad V@R_{1\\%} = q_L(99\\%) = -50, \\quad V@R_{0.5\\%} = q_L(99.5\\%) = 10,000. ]</p> <p>Note: Practical Computation of Value at Risk</p> <p>Unlike risk mean variance that only implies the computation of expectations (analytical or with monte carlo for instance), the case of V@R is slightly more complex. Indeed, even if a random variable does have a probability density function, there does not exist in general an analytical form for the quantile function. Therefore in case of a strictly increasing and continuous CDF, to compute the Value at risk you need to invert the function \\(m \\mapsto F_L(m)\\). Inverting a function implies finding the solution \\(m^\\ast\\) to the equation</p> \\[   F_L(m^\\ast) = = s  \\] <p>which is a classical root finding. Every scientific library has methods for (either newton methods or bisecant of advanced mixed therefore like Brentq).</p> <p>Note however that we are trying to find high quantiles (0.99 or 0.999) for the CDF, which lies very close to the boundary of the inverse. The problem is therefore quite difficult as the derivative there starts to be very close to \\(0\\) in the limits of computer accuracy. There exists however in most scientific libraries having statistical functions, predefined way to compute quantile which are heavily optimized.</p> <p>We illustrate this in the following using <code>python</code> and <code>scipy.optimize</code> and <code>scipy.stats</code>.</p> <p>Computation of value at risk<pre><code># import libraries\nimport numpy as np\nfrom scipy.stats import norm, t             # Normal and Student distribution\nfrom scipy.optimize import root, brentq     # root-&gt;newton method, brentq-&gt;bissecant flavor\nimport plotly.graph_objs as go              # professional but easy plotting\n\n# Straightforward quantile computation implementation\ndef quantile(cdf, s):\n  # definition of the root function(1) \n  def fun(m):\n    result = cdf(m) - s\n    return result\n\n  # return the root(2)\n  result = root(fun, 0)\n  return result.x[0]\n\n# Define two random variables\nX = norm()      # standard normal\nY = t(df = 2)   # student with 2 as degree of freedom\n\n# plot the cdf of both\n\nx = np.linespace(-4, 4, 100)\ny1 = X.cdf(x)\ny2 = Y.cdf(x)\n\nfig = go.Figure()\nfig.add_scatter(x=x, y=y1, name=\"normal distribution\")\nfig.add_scatter(x=x, y=y2, name=\"student distribution\")\nfig.update_layout(title = 'CDF of normal and student')\nfig.show()\n\n# compute the var 0.01 and 0.01 for each\n\nprint(f\"\"\"\n1% V@R for Normal:\\t{quantile(X.cdf, 0.99)}\n0.01% V@R for Normal:\\t{quantile(X.cdf, 0.999)}\n1% V@R for Student:\\t{quantile(Y.cdf, 0.99)}\n0.01% V@R for Student:\\t{quantile(Y.cdf, 0.999)}\n\"\"\")\n\n\n# using the pre programmed `ppf` functions\nprint(f\"\"\"\n1% V@R for Normal:\\t{X.ppf(0.99)}\n0.01% V@R for Normal:\\t{X.ppf(0.999)}\n1% V@R for Student:\\t{Y.ppf(0.99)}\n0.01% V@R for Student:\\t{Y.ppf(0.999)}\n\"\"\")\n\n# You can compare the speed between your implementation and the pre programmed using %timeit\n</code></pre></p> <ol> <li>Find <code>m</code> such that <code>F(m) = s</code> is equivalent to finding <code>m</code> such that <code>F(m) - s = 0</code> which is the usual implementation.</li> <li>We use here the Newton variant of root optimization problem. It only requires a start point and is usually fast.      However it might not converge if the derivative is quite close to <code>0</code> so it might not always be adequate.     Using <code>brentq</code>, as a bissecant type, requires to provide two bounds <code>a&lt;b</code> within which that root shall be found. In particular it should hold that <code>fun(a)</code> has a different sign as <code>fun(b)</code>.     Both have advantages and inconvenience.</li> </ol> <p>As for mean-variance, value at risk also fulfills some properties</p> <p>Proposition</p> <p>The Value at Risk V@R satisfies the following properties:</p> <ol> <li> <p>Cash-invariance: For every loss profile \\( L \\) and \\( m \\in \\mathbb{R} \\),</p> \\[   V@R_{\\alpha}(L - m) = V@R_{\\alpha}(L) - m. \\] </li> <li> <p>Monotonicity: For any two loss profiles \\( L_1, L_2 \\) with \\(L_1(\\omega) \\leq L_2(\\omega)\\) it holds,</p> \\[   V@R_{\\alpha}(L_1) \\leq V@R_{\\alpha}(L_2). \\] </li> <li> <p>Law Invariance: If two loss profiles \\( L_1 \\) and \\( L_2 \\) have the same CDF, then:</p> \\[   V@R_{\\alpha}(L_1) = V@R_{\\alpha}(L_2). \\] </li> </ol> Proof <ol> <li> <p>Cash-invariance: For every \\( m \\in \\mathbb{R} \\), and loss \\( L \\), it holds with variable change \\(\\hat{m} = \\tilde{m} - m\\):</p> \\[   \\begin{align*}      V@R_{\\alpha}(L-m) &amp; = \\inf\\left\\{ \\tilde{m} \\in \\mathbb{R} \\colon P[L-m&gt;\\tilde{m}] \\leq \\alpha \\right\\}\\\\                     &amp; = \\inf \\left\\{ \\hat{m} - m \\colon P[L&gt;\\hat{m}] \\leq \\alpha  \\right\\}\\\\                     &amp; = \\inf \\left\\{ \\hat{m} \\colon P[L&gt;\\hat{m}] \\leq \\alpha  \\right\\} - m = V@R_{\\alpha}(L) - m   \\end{align*} \\] </li> <li> <p>Monotonicity: Let \\( L_1 \\leq L_2 \\) be two loss profiles.</p> <p>For any \\(m\\), it holds</p> \\[     \\left\\{ \\omega \\colon L_1(\\omega)\\leq m \\right\\} \\supseteq \\left\\{ \\omega \\colon L_2(\\omega)\\leq m \\right\\} \\] <p>showing that for every \\(m\\) we have \\(P[L_1\\leq m] \\geq P[L_2 \\leq m]\\). Hence, we have</p> \\[     \\left\\{ m \\in \\mathbb{R} \\colon P\\left[ L_1\\leq m \\right]\\geq 1-\\alpha \\right\\} \\subseteq  \\left\\{ m \\in \\mathbb{R} \\colon P\\left[ L_2\\leq m \\right]\\geq 1-\\alpha \\right\\} \\] <p>showing that the infimum of the the left handside is smaller than the infimum of the right hand side, that is \\(V@R_{\\alpha}(L_1)\\leq V@R_{\\alpha}(L_2)\\). </p> </li> <li> <p>Law Invariance: This follows immediately since the value at risk depends only on the CDF.</p> </li> </ol>"},{"location":"lecture/02-risk-management/021-what-is-risk/#sound-properties","title":"Sound Properties?","text":"<p>Both risk assessement do make sense and have a certain appeal. Let us discuss some of the properties they fulfill.</p> <ul> <li> <p>Cash Invariance: given a risk assessment instrument \\(L \\mapsto R(L)\\), being cash invariant means that \\(R(L-m) = R(L) - m\\).     This is a property that economists as well as regulator do like as it confers a certain monetary meaning to the risk assessment.</p> <p>Indeed, usually regulators wants financial institutions to keep their total risk below \\(0\\). Now as a financial institution, I have a loss exposure \\(L\\) in financial assets. The question is how much liquidiy (or cash) shall be in the bank account to make the overall risk lower than \\(0\\). Together with cash \\(m\\) and risky exposure \\(L\\), the resulting loss profile is \\(L-m\\) for which the risk is equal to \\(R(L-m)\\). A risk acceptance being smaller than \\(0\\) means that \\(m\\geq R(L)\\). In other terms, the minimal cash requirement to make the risky exposure acceptable in terms of liquidity is \\(m = R(L)\\).</p> </li> <li> <p>Law Invariance:</p> <p>The law invariance is important in so far that even if we consider random variables, in practive we can only observe the realization of which and therefore an approximation of the CDF. Hence a risk assessment instrument shall only depend on the CDF of the loss profile.</p> </li> <li> <p>Monotonicity: Monotonicity means that whenever the loss profile of one position is in any case larger than another position, i.e. loose more money in any cases, then its risk should be higher.</p> </li> <li> <p>Diversification: (here convexity) means that diversifying between to risky assets (a convex combination), the resulting risk is going to be lower than the worse of the other two risks.</p> </li> </ul> Property \\(MVR_{\\alpha}\\) \\(V@R_{\\alpha}\\) Cash Invariance Law Invariance Monotonicity Diversification <p>Warning: Value at Risk might lead to Concentration</p> <p>The Value at Risk goes in some cases against diversification. The main reason is that the quantile is just a single point in the CDF of the loss distribution and can not account for the whole risk contained in the tail of the distribution.</p> <p>The following single example illustrate the concentration in the tail.</p> <p>In the first situation, you lend \\(1000\\) RMB to a friend with payment back in one year with \\(4%\\) interest. If the friend repays the loan you make a gain of \\(40\\) RMB, if the friend goes away your make a loss of \\(1000\\) RMB. We assume that the friend will run away with a probability of \\(4\\%\\). In terms of loss it, it reads as follows </p> \\[     \\begin{equation*}         L =          \\begin{cases}             -40 &amp; \\text{with probability }96\\% \\\\             1000 &amp; \\text{with probability }4\\%         \\end{cases}     \\end{equation*} \\] <p>which leads to the following CDF and quantile</p> \\[     \\begin{align*}         F_L(m) &amp; = \\begin{cases}             0 &amp; \\text{for }m&lt; -40\\\\             96\\% &amp; \\text{for }-40 \\leq m &lt; 1000 \\\\             100\\% &amp; \\text{for } m \\geq 1000         \\end{cases}         &amp;         q_L(s) &amp; = \\begin{cases}             -40 &amp; \\text{for } 0&lt;s \\leq 96\\%\\\\             1000 &amp; \\text{for } s &gt; 96\\%         \\end{cases}     \\end{align*} \\] <p>which in other terms yields a value at risk at \\(5\\%\\) level of</p> \\[     V@R_{5\\%}(L) = q_L(95\\%) = -40  \\] <p>Now in view of the potential default of this friend, instead of lending \\(1000\\) to one, you diversify your exposure by lending \\(500\\) to two different (supposedly independent) friends. In terms of loss it gives</p> \\[     \\begin{equation*}         L =          \\begin{cases}             -40 &amp; \\text{with probability }92.16\\% \\\\             480 &amp; \\text{with probability } 7.68\\% \\\\             1000 &amp; \\text{with probability }0.16\\%         \\end{cases}     \\end{equation*} \\] <p>showing that the probability of large losses reduced radically to \\(0.16\\%\\) in trade off for medium loss of 480 with a \\(7.68\\%\\) probabliity.</p> <p>This leads to the following CDF and quantile</p> \\[     \\begin{align*}         F_L(m) &amp; = \\begin{cases}             0 &amp; \\text{for }m&lt; -40\\\\             92.16\\% &amp; \\text{for } -40 \\leq m &lt; 480 \\\\             99.84\\% &amp; \\text{for } 480 \\leq m &lt; 1000 \\\\             100\\% &amp; \\text{for } m \\geq 1000         \\end{cases}         &amp;         q_L(s) &amp; = \\begin{cases}             -40 &amp; \\text{for } 0&lt;s \\leq 92.16\\%\\\\             480 &amp; \\text{for } 92.16\\% &lt; s \\leq 99.84 \\%\\\\             1000 &amp; \\text{for } s &gt; 99.84\\%         \\end{cases}     \\end{align*} \\] <p>which yields a value at risk at \\(5\\%\\) level of</p> \\[     V@R_{5\\%}(L) = q_L(95\\%) = 480 \\] <p>In other terms, the value at risk jumps from \\(-40\\) to \\(480\\) while diversifying our investment which goes against what is expected from a risk assessment measure.</p> <p>The main reason is that the losses in the non diversified situation are all concentrated in the tail of the distribution beyond the quantile level choosen. In other terms, value at risk is blind to the loss size (or tail of the distribution) beyond the choosen quantile level.</p> <p>Even if those two instruments have intuitively a certain appeal as assessment of risk (and they are useful in their own rights), it turns out that a closer look shows that both are do violate one or another fundamental properties we are expecting from a risk measure.</p>"},{"location":"lecture/02-risk-management/022-risk-preferences/","title":"Risk Preferences and Measures","text":"<p>Up to now, we have presented potential examples of risk measures and discussed their shortcomings regarding particular properties we consider sound for risk assessment. Furthermore, the selection of these measures might appear arbitrary. In the following, we aim to formalize what risk and uncertainty mean.</p> <p>On the one hand, uncertainty refers to the fact that multiple outcomes might occur. In other terms, this can be understood as the consideration of a set \\(\\Omega\\) within a probability space. The concept of uncertainty is thus an objective matter, inherently related to the nature of the world.</p> <p>On the other hand, risk represents a subjective or personal perception of uncertainty. It depends on one's viewpoint and can be seen as a prudent response to uncertainty. To model this in a consistent mathematical framework, we rely on the so-called decision theory, which captures preferences among different possible choices. We denote the set of possible choices \\(x\\) by \\(\\mathcal{X}\\) In our context, uncertain outcomes are modeled as random variables, meaning we consider a vector space \\(\\mathcal{X}\\) of random variables (primarily bounded for mathematical convenience).</p> <p>Definition: Preference Order and Numerical Representation</p> <p>A preference order \\(\\preccurlyeq\\) on \\(\\mathcal{X}\\) is a binary relation \\(x \\preccurlyeq y\\) that states choice \\(y\\) is preferred to choice \\(x\\). We assume this relation fulfills the following normative properties:</p> <ul> <li>Transitivity: \\(x \\preccurlyeq y\\) and \\(y \\preccurlyeq z\\) implies \\(x \\preccurlyeq z\\);</li> <li>Completeness: for any two possible choices \\(x\\) and \\(y\\), then either \\(x \\preccurlyeq y\\) or \\(y \\preccurlyeq x\\).</li> </ul> <p>A function \\(U\\colon \\mathcal{X} \\to \\mathbb{R}\\) is called a numerical representation (sometimes called utility) of a preference order \\(\\preccurlyeq\\) if </p> \\[     x \\preccurlyeq y \\quad \\text{if and only if} \\quad U(x)\\leq U(y) \\] <p>Preference orders are generic to represent the subjective view on those outcomes. The first property tells you that if you find \\(y\\) preferable to \\(x\\) and \\(z\\) preferable to \\(y\\), then you should also find \\(z\\) preferable to \\(y\\). This property seems quite natural. The second property tells you that if you are given any two elements, you are always able to express a preference between them. This second property is eventually strong as it requires you to always be  able to decide among any two out of a possibly infinitly large set \\(\\mathcal{X}\\) which one is the more risky. These two rational (decision theorist would call them normative) assumptions are often falsified in empirical decision theory but these are meant to model a fully rational behavior in terms of decision towards these prospective outcomes. A for a numerical representation it is a mapping of this preference ranking into \\(\\mathbb{R}\\).</p> Note <p>Note first, that if we have a numerical representation \\(U\\) for a preference order \\(\\preccurlyeq\\), it is not unique. Any strictly increasing function \\(\\phi \\colon \\mathbb{R} \\to \\mathbb{R}\\) will define another numerical representation \\(\\tilde{U} = \\phi \\circ U\\). Indeed, \\(x \\preccurlyeq y\\) is equivalent to \\(U(x)\\leq U(y)\\) which is equivalent to \\(\\phi(U(x)) = \\tilde{U}(x) \\geq \\tilde{U}(y) = \\phi(U(y))\\).</p> <p>Second, starting directly with a function \\(U \\colon \\mathcal{X} \\to \\mathbb{R}\\) it defines a preference order \\(\\succcurlyeq\\) by </p> \\[     x \\preccurlyeq y : \\Leftrightarrow U(x)\\leq U(y) \\] <p>As an exercice, show that \\(\\succcurlyeq\\) so defined through a function \\(R\\) is a preference order, that is, satisfies transitivity and completness.</p> <p>Third, even if a numerical function defines a preference order, the reciprocal is not necessarily true. Indeed, it requires some additional assumptions so that for a given preference order you can find a numerical representation \\(R\\) of which. This is however most of the time the case under resonable assumptions.</p> <p>Proposition</p> <p>If the set \\(\\mathcal{X}\\) is countable(1) then any preference order \\(\\preccurlyeq\\) on \\(\\mathcal{X}\\) admits a numerical representation.</p> <ol> <li>Meaning that you can enumerate it by a subset of \\(\\mathbb{N}\\).</li> </ol> <p>Proof</p> <p>Without loss of generality, we assume that \\(\\mathcal{X} = \\{x_1, \\ldots, x_n, \\ldots\\}\\).</p> <p>On \\(\\mathbb{N}\\) we consider the probability measure \\(P[\\{n\\}] = p_n = 1/{2^n}\\) since \\(\\sum p_n = 1\\). Now, for each \\(x_n\\), define \\(A_n = \\{k\\colon x_k \\preccurlyeq x_n\\}\\) which is the set of indices \\(k\\) of those elements in \\(\\mathcal{X}\\) which are less prefered than \\(x_n\\). By definition, it holds that \\(x_n \\preccurlyeq x_m\\) if and only if \\(A_n \\subseteq A_m\\). The function</p> \\[   \\begin{equation*}     \\begin{split}       U \\colon \\mathcal{X} &amp; \\longrightarrow \\mathbb{R}\\\\                 x_n &amp; \\longmapsto U(x_n) = P\\left[ A_n \\right] = \\sum_{\\{k\\colon L_k \\preccurlyeq L_n\\}} p_k     \\end{split}   \\end{equation*} \\] <p>defines a numerical representation of \\(\\preccurlyeq\\). Indeed, \\(x_n \\preccurlyeq x_m\\) if and only if \\(A_n \\subseteq A_m\\). Since the probability measure \\(P\\) assign a strict probability to any element of \\(\\mathbb{N}\\), it also holds that \\(A_n \\subseteq A_m\\) if and only if \\(U(x_n) = P[A_n] \\leq P[A_m] = U(x_m)\\) which ends the proof. </p> <p>This proposition makes use of probability measures to define the numerical representation. Such an argumentation extends to more general sets as long as you can connect somehow the sublevel sets \\(\\{\\tilde{x}\\colon \\tilde{x}\\preccurlyeq x\\}\\), usually using some topological arguments with smoothness.</p> <p>If such smoothness does not hold, then it is possible to construct examples of preference orders that might not have a numerical representation.</p> <p>The lexicographical order does not admit a numerical representation</p> <p>Consider \\(\\mathcal{X} = [0, 1]\\times [0, 1]\\) and define the lexicographical order as</p> \\[     x = (x_1, x_2) \\preccurlyeq (y_1, y_2)=y \\quad \\text{if and only if}\\quad      \\begin{cases}       \\text{either } &amp;x_1 &lt; x_2 \\\\       \\text{or } &amp;x_1 = x_2 \\quad \\text{and}\\quad y_1\\leq y_2     \\end{cases} \\] <p>It is relatively easy to show that this is indeed a preference order (akin to the book ordering in a library). However since the set if not countable and the preference order is somehow not very smooth, it is possible to show that there can not be a numerical representation of \\(\\preccurlyeq\\). You can give a try as an exercise by assuming that there exists such a numerical representation and show that you get a contradiction.</p> <p>Decision theory usually takes the viewpoint of preference and utility (the higher the better). To speak about risk we however think in terms of risk and consider as choices the possible loss profiles \\(\\mathcal{L}\\), that is, random variables representing losses. Furthermore for just notatios, we consider complete binary relations \\(\\succcurlyeq\\) in the sense of \\(L_1 \\succcurlyeq L_2\\) meaning that \"\\(L_1\\) is more risky than \\(L_2\\)\". In other terms you rank loss profiles with \\(\\succcurlyeq\\) according to the preception of risk you have of both. However, the simple properties of a preference order \\(\\succcurlyeq\\) on \\(\\mathcal{L}\\) do tno really tell us about risk perception per-se.</p> <p>Definition: Risk Order and Risk Measures</p> <p>A preference order \\(\\succcurlyeq\\) on \\(\\mathcal{L}\\) is called a risk order if the following two additional assumptions are fulfilled:</p> <ul> <li> <p>Diversification: if \\(L_1\\) is more risky than \\(L_2\\) then any diversified position between the two is less risky than the worse one:</p> \\[     \\text{if } L_1 \\succcurlyeq L_2 \\quad \\text{then}\\quad L_1 \\succcurlyeq \\lambda L_1 + (1-\\lambda) L_2, \\quad \\text{for every } 0 \\leq \\lambda \\leq 1 \\] </li> <li> <p>Monotonicity (worse for sure is more risky): if the loss of \\(L_1\\) are worse than the loss of \\(L_2\\) in any states of the world, then \\(L_1\\) is more risky than \\(L_2\\):</p> \\[     \\text{if } L_1(\\omega) \\geq L_2 (\\omega) \\text{ for every } \\omega \\quad \\text{then }\\quad L_1 \\succcurlyeq L_2 \\] </li> </ul> <p>A numerical representation \\(R\\colon \\mathcal{L} \\to \\mathbb{R}\\) of a risk order is called a risk measure.</p> <p>These two additional properties are expressing quite reasonable key features of what one might expect as a risk perception.</p> <p>They do have consequences in terms of resulting properties for risk measure. </p> <p>Proposition</p> <p>Let \\(R\\) be a numerical representation of a preference order \\(\\succcurlyeq\\) on \\(\\mathcal{L}\\). Then the following assertions are equivalent:</p> <ul> <li>\\(\\succcurlyeq\\) is a risk order;</li> <li>\\(R\\) is:<ul> <li>Quasi-convex: \\(\\max\\{R(L_1), R(L_2)\\} \\geq R(\\lambda L_1 + (1-\\lambda) L_2)\\) for every \\(0 \\leq \\lambda \\leq 1\\);</li> <li>Monotone: \\(L_1(\\omega) \\geq L_2(\\omega)\\) for every \\(\\omega\\) implies \\(R(L_1) \\geq R(L_2)\\).</li> </ul> </li> </ul> Proof <p>Let \\(L_1\\) and \\(L_2\\) be two loss profiles. Assume that \\(\\succcurlyeq\\) is a risk order. As for the quasi-convexity, due to the completeness of the relation, we may assume without loss of generality that \\(L_1 \\succcurlyeq L_2\\) which is equivalent to \\(R(L_1) = \\max\\{R(L_1), R(L_2)\\}\\). Now for every \\(0 \\leq \\lambda \\leq 1\\) it follows from the diversification property that \\(L_1 \\succcurlyeq \\lambda L_1 + (1-\\lambda) L_2\\) which implies \\(\\max\\{R(L_1), R(L_2)\\} = R(L_1) \\geq R(\\lambda L_1 + (1-\\lambda) L_2)\\) showing quasi-convexity of \\(R\\).</p> <p>As for the monotonicity, assume that \\(L_1(\\omega) \\geq L_2(\\omega)\\) for every \\(\\omega\\). It follows from the monotonicity assumtion that \\(L_1 \\succcurlyeq L_2\\) which implies that \\(R(L_1) \\geq R(L_2)\\) showing the monotonicity of \\(R\\).</p> <p>The fact that a numerical representation is quasi-convex and monotone implies that \\(\\succcurlyeq\\) is a risk order follows the reverse argumentation and is straightforward to verify.</p> <p>This proposition states in particular that neither the mean variance risk measure nor the value at risk do represent in any way an order that is a risk order. Some additional properties can be required from a risk measure, however they might not be representative of the risk order itself.</p> <p>Definition</p> <p>A risk measure \\(R\\) is called</p> <ul> <li>Cash-Invariance: if \\(R(L-m) = R(L) - m\\) for every \\(m\\) in \\(\\mathbb{R}\\);</li> <li>Positive-Homogeneous: if \\(R(\\lambda L) = \\lambda R(L)\\) for every \\(\\lambda &gt;0\\);</li> <li>Law-Invariant: if \\(R(L) = R(\\tilde{L})\\) whenever the CDF of \\(L\\) and \\(\\tilde{L}\\) coincide.</li> </ul> <p>Aside from the law-invariance, the other two properties do no longer hold if I transform the risk measure with a strictly increasing transformation. Nevertheless they are common and useful for practical reasons.</p> <p>Cash-Invariance</p> <p>The cash-invariance is something that is usually required from a regulatory or financial viewpoint. The reasoning goes as follows: a financial institution has a position \\(X\\) in risky assets. The question is how much liquidity (cash) \\(m\\) shall be present in the bank account so that the overall position (cash plus risky assets) yields an acceptable risk. The threshold required is that an overall position is deemed acceptable if the total risk assessment is below \\(0\\). The total loss profile being \\(L-m\\) where \\(L= - X\\), it means that \\(0\\geq R(L-m) = R(L) - m\\) due to cash invariance or \\(m\\geq R(L)\\). In other terms, the minimal amount of liquidity so that the risky position in assets of the institution is deemd acceptable is \\(m = R(L)\\). Therefore the interpretation of the risk measure as a capital requirement. The cash-invariance has also some interesting consequences for a risk measure since cash-invariance plus quasi-convexity implies convexity.</p> <p>Lemma</p> <p>Let \\(R\\) be a cash-invariant risk measure, then \\(R\\) is convex.</p> Proof <p>Let \\(R\\) be a cash-invariant risk measure, \\(0\\leq \\lambda \\leq 1\\) and \\(L_1\\), \\(L_2\\) be two loss profiles. We want to show that \\(R(\\lambda L_1 + (1-\\lambda)L_2)\\leq \\lambda R(L_1) + (1-\\lambda)R(L_2)\\). Defining \\(m_1 = R(L_1)\\) and \\(m_2 = R(L_2)\\), it is equivalent to show \\(R(\\lambda L_1 + (1-\\lambda)L_2) - \\lambda m_1 - (1-\\lambda)m_2 \\leq 0\\). By cash invariance and quasiconvexity we get</p> \\[   \\begin{align*}     R(\\lambda L_1 + (1-\\lambda)L_2) - \\lambda m_1 - (1-\\lambda)m_2 &amp; = R\\left( \\lambda L_1 + (1-\\lambda) L_2 - \\lambda m_1 - (1-\\lambda)L_2 \\right) &amp;&amp; \\text{(Cash Invariance)}\\\\       &amp; = R\\left( \\lambda (L_1 - m_1) + (1-\\lambda)(L_2 - m_2) \\right)\\\\       &amp; \\leq \\max \\left\\{ R(L_1 - m_1), R(L_2 - m_2) \\right\\} &amp;&amp; \\text{(Quasiconvexity)}\\\\       &amp; = \\max \\left\\{ R(L_1) - m_1, R(L_2) - m_2 \\right\\} &amp;&amp; \\text{(Cash Invariance)}\\\\       &amp; = \\max \\{0, 0\\} = 0 &amp;&amp; (m_i = R(L_i))\\\\       &amp; = 0   \\end{align*} \\] <p>Positive Homogeneity</p> <p>Positive homogeneity also has a financial interpretation. If \\(L\\) represents the loss exposure of an investment with risk \\(R(L)\\), then scaling this investment by a factor \\(\\lambda &gt;0\\) will also scale the corresponding risk by \\(\\lambda\\). That such a property is desirable is not totally clear, one would rather expect a super linear scaling of the risk. However positive homogeneity do have many properties that are desirable from a mathematical/implementation viewpoint.  As seen later in the next chapter, it is the underlying reason that one can get a decomposition in terms of marginal risk of the total risk. Furthermore it has the property of sub-additivity</p> <p>Lemma</p> <p>Let \\(R\\) be a cash-invariant risk measure. If \\(R\\) is positive homogeneous, it holds that</p> \\[     R(L_1 + L_2) \\leq R(L_1) + R(L_2) \\] Proof <p>Let \\(R\\) be a cash-invariant risk measure which is positive homogeneous. Due to the cash invariance, \\(R\\) is convex. It follows from convexity and positive homogeneity that</p> \\[   \\begin{align*}     R( L_1 + L_2) &amp; = R\\left( 2 \\left(\\frac{1}{2}L_1 +\\frac{1}{2}L_2\\right)\\right)\\\\       &amp; = 2 R\\left(\\frac{1}{2}L_1 +\\frac{1}{2}L_2\\right)&amp;&amp; \\text{(Positive Homogeneity)}\\\\       &amp; \\leq 2 \\left( \\frac{1}{2}R(L_1) + \\frac{1}{2}R(L_2)\\right) &amp;&amp; \\text{(Convexity)}\\\\       &amp; = R(L_1) +R(L_2)   \\end{align*} \\]"},{"location":"material/ex01/","title":"Simple exercises","text":"<p>This is a subsample of the 100 exercises on Python that can be found here. Exists also in Chinese</p> <p>100+ Python challenging programming exercises</p> <ul> <li>Question 1</li> <li>Level 1</li> </ul> Question: Write a program which will find all such numbers which are divisible by 7 but are not a multiple of 5, between 2000 and 3200 (both included). The numbers obtained should be printed in a comma-separated sequence on a single line. Hints: Consider use <code>range(#begin, #end)</code> method Solution <pre><code>l=[]\nfor i in range(2000, 3201):\n    if (i%7==0) and (i%5!=0):\n        l.append(str(i))\n\nprint ','.join(l)\n</code></pre> <ul> <li>Question 2</li> <li>Level 1</li> </ul> Question: Write a program which can compute the factorial of a given numbers. The results should be printed in a comma-separated sequence on a single line. Suppose the following input is supplied to the program: 8 Then, the output should be: 40320 Hints: In case of input data being supplied to the question, it should be assumed to be a console input. Solution <pre><code>def fact(x):\n    if x == 0:\n        return 1\n    return x * fact(x - 1)\n\nraw_input = 10\nx=int(raw_input)\nprint fact(x)\n</code></pre> <ul> <li>Question 3</li> <li>Level 1</li> </ul> Question: With a given integral number n, write a program to generate a dictionary that contains (i, i*i) such that is an integral number between 1 and n (both included). and then the program should print the dictionary. Suppose the following input is supplied to the program: 8 Then, the output should be: <code>{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64}</code> Hints: In case of input data being supplied to the question, it should be assumed to be a console input. Consider use <code>dict()</code> Solution <pre><code>n=20\nd=dict()\nfor i in range(1,n+1):\n    d[i]=i*i\n\nprint d\n</code></pre>"},{"location":"material/final/","title":"Final Report","text":"Overall Info Due date: 2024-06-23 Returns in terms of a <code>*.py</code> file with comments for the code One report per person"},{"location":"material/final/#question-1-numpy","title":"Question 1: Numpy","text":"<ul> <li> <p>Write a function <code>random_choice_matrix</code>:</p> <ul> <li>Input: <code>omega</code> which will be an integer fixing the random seed</li> <li>Output: <code>10x10</code> numpy array</li> </ul> <p>This function:</p> <p>a) fixes a seed using <code>np.random.default_rng</code>.</p> <p>b) create a random matrix with this seed where each row is an independent shuffeling of numbers between <code>1</code> and <code>10</code></p> <p>For instance</p> <pre><code>[\n  [ 8, 10,  2,  7,  4,  5,  6,  3,  9,  1 ],\n  [ 7,  9,  3,  4,  1,  5,  6,  2,  8, 10 ],\n  [ 6,  4,  9,  7,  2,  5, 10,  8,  3,  1 ],\n  [ 6,  1,  8,  5,  7, 10,  9,  3,  2,  4 ],\n  [ 1,  2,  6,  9, 10,  5,  8,  4,  7,  3 ],\n  [ 7,  1,  4,  9, 10,  6,  8,  5,  3,  2 ],\n  [ 6,  7,  2,  3, 10,  9,  8,  5,  1,  4 ],\n  [ 8, 10,  5,  3,  7,  4,  2,  9,  1,  6 ],\n  [ 8,  6,  1,  3, 10,  7,  5,  4,  9,  2 ],\n  [ 5,  4,  3,  1,  7,  9,  6, 10,  2,  8 ]\n]\n</code></pre> </li> <li> <p>Write a function <code>markov_game</code></p> <ul> <li>Input: <code>omega</code> which is an integer fixing the random seed</li> <li>Output: <code>final</code> which is a one dimensional array of size <code>10</code></li> </ul> <p>This function:</p> <p>a) generate a matrix <code>matrix</code> from <code>random_choice_matrix(omega)</code></p> <p>b) for each number of the first row of matrix, it moves forward in the matrix by the exact number of index of this number until it finishes and record the last number.</p> <p>For instance in the example above, if I start with <code>10</code> on the first row, I move from left to right and up to down by <code>10</code> to end at the number <code>9</code> in the second row, then I move from <code>9</code> to end up at the number <code>6</code> on the third row, etc. until you end up on a number on the last row where you can not go further.</p> <p>c) return the array for each terminal value starting from each number from the first row.</p> </li> <li> <p>what do you notice when you run the program for several seeds <code>omega</code>?</p> </li> <li> <p><code>%timeit</code> your function and see if you can improve the efficiency of the program by using numba.</p> </li> </ul>"},{"location":"material/final/#question-2-performance","title":"Question 2: Performance","text":"<ul> <li> <p>Write a function <code>mat_mult_slow</code>:</p> <ul> <li>Input: two matrices <code>A</code> of size <code>NxM</code> and <code>B</code> of size <code>MxK</code></li> <li>Output: matrix <code>C</code> of size <code>NxK</code></li> </ul> <p>The function returns the matrix multiplication <code>AB</code> using exclusively <code>for loop</code> and basic additions/multiplications.</p> </li> <li> <p>Write a function <code>mat_mult_numpy</code>:</p> <p>Same input and output as above but use numpy to compute the product</p> </li> <li> <p>With two random matrices that you generate of size <code>1000x10000</code> and <code>10000x5000</code> report the speed of each function using <code>%timeit</code>.</p> </li> <li> <p>Use <code>numba</code> with the decorator <code>@nb.njit</code> and copy the function <code>mat_mult_slow</code> to define a <code>mat_mult_fast</code> and compare the speed of each function.</p> </li> </ul>"},{"location":"material/final/#question-3-pandas","title":"Question 3: Pandas","text":"<p>We clean and analyse the breast cancer dataset and prepare the data in pandas first</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\n\nbreast = load_breast_cancer()\nprint(breast)\n</code></pre> <p>The data is a dictionary with keys * <code>data</code>: numpy array of size <code>Nxd</code> (values) * <code>target</code>: numpy array of size <code>N</code> (label <code>0</code> and <code>1</code> for not serious and serious cancer) * <code>feature_names</code>: numpy array of size <code>d</code> naming the nature of the columns in data</p> <ul> <li> <p>Create a panda dataframe with <code>d+1</code> columns and <code>N</code> rows where the first <code>d</code> columns have names <code>feature_names</code> and the last column name <code>label</code>. The content of the first <code>d</code> columns are data, the content of the <code>label</code> column is <code>target</code></p> </li> <li> <p>transform the dataframe of <code>d</code> columns by removing the mean from each column and dividing by the standard deviation.</p> </li> <li>Perform a PCA of these <code>d</code> columns and get the first two components <code>y1</code> and <code>y2</code> of dimension <code>d</code> each.</li> <li> <p>Generate a dataframe with three columns</p> <ul> <li><code>pc1</code>: matrix multiplication of the first component against the data</li> <li><code>pc2</code>: matrix multiplication of the second component against the data</li> <li><code>label</code></li> </ul> </li> <li> <p>provide a scatter plot <code>pc1</code> against <code>pc2</code> by setting a color blue when the label is <code>0</code> and a color red when the label is <code>1</code></p> </li> <li> <p>Provide mathematically what happened, and how from the results, the PCA in this case allows to classify the data.</p> </li> </ul>"},{"location":"material/final/#projects","title":"Projects","text":"<p>Out of the two following questions, choose one for your report.</p>"},{"location":"material/final/#project-1-ode","title":"Project 1: ODE","text":"<p>The following Oscillator</p> \\[ \\begin{equation*}   y^{\\prime\\prime} - \\mu(1-y^2)y^\\prime +y = 0  \\end{equation*} \\] <p>For large \\(\\mu\\) this equation exhibit rapid changes in speed and therefore is difficult to approximate. With the following variable change \\(y^\\prime = z\\) we get the first order ODE system</p> \\[ \\begin{equation*} \\begin{cases} y^{\\prime} = z\\\\ z^\\prime = \\mu(1-y^2)z - y \\end{cases} \\end{equation*} \\] <ul> <li> <p>Taking <code>mu = 1000</code> use your implementation of <code>euler_scheme</code> and <code>RK</code> for this equation with \\(y(0) =1\\), \\(z(0) = 0\\) starting from \\(t=0\\) to \\(t=10\\) and plot the numerical solution for different time steps \\(0.5\\), \\(0.1\\), \\(0.01\\), \\(0.001\\), ... \\(0.0001\\).</p> </li> <li> <p>Implement the implicit <code>euler_implicit_scheme</code> where</p> </li> </ul> \\[ \\begin{equation*} \\begin{cases} y(t+h) &amp;= y(t) + h z(t+h)\\\\ z(t+h) &amp;= z(t) + h(\\mu(1-y^2(t+h))z(t+h) - y(t+h)) \\end{cases} \\end{equation*} \\] <p>This involves solving a root finding at every step for which you can use <code>scipy.optimize.root</code></p> <ul> <li> <p>Compare the result of the implicit Euler Scheme with the previous scheme for each time step as well as the speed of each methods.</p> </li> <li> <p>Use <code>numba</code> to speed up your <code>euler_scheme</code> and <code>RK</code> scheme and see the speed improvement results.</p> </li> <li>Can you use <code>numba</code> to improve the <code>euler_implicit_scheme</code>?</li> </ul>"},{"location":"material/final/#project-2-systemic-risk-computation","title":"Project 2: Systemic Risk Computation","text":"<p>Given a \\(d\\) dimensional random variable \\(\\mathbf{X}\\) the goal is to compute the values \\(\\mathbf{m} = (m_1, \\ldots, m_d)\\) argmin in \\(\\mathbf{m}\\) of </p> \\[ \\begin{equation*}   F(\\mathbf{m}, \\mathbf{X})= E\\left[\\ell\\left(X_1 - m_1, \\ldots, X_d - m_d\\right)\\right] \\end{equation*} \\] <p>where</p> \\[ \\begin{equation*}   \\ell(z_1, \\ldots, z_d) = \\sum_{k,l} \\alpha \\left((x_k+x_l)^+\\right)^2 +(1-\\alpha)\\left((x_k + x_l)^-\\right)^2 \\end{equation*} \\] <p>where \\(x^+ = \\max\\{x, 0\\}\\) and \\(x^- = \\max\\{-x, 0\\}\\) are the positive and negative parts of \\(x\\) and \\(1/2 &lt; \\alpha &lt; 1\\) is a parameter.</p> <p>Note</p> <p>The result of this function is computed daily as to decide how much different financial institution have to pay in insurance to cover the systemic risk they provide to the financial system. If institution \\(k\\) is very risky for the overall system, it has to pay an amount \\(m_k\\) larger to the common insurance.</p> <p>Now the problem of this computation is that usually \\(d\\) is quite large (from 100 to thousands) and \\(\\mathbf{X}\\) which represents the returns of each institution changes every day.</p> <p>The expectation in \\(F\\) takes joint integrals which are quite expensive to compute while you search for the argmin.</p> <ul> <li> <p>Define a function <code>loss</code> that takes as input <code>alpha</code> a number and <code>z</code> a <code>d</code> dimensional array and returns \\(\\ell(\\mathbf{z})\\).</p> </li> <li> <p>Given </p> </li> <li> <p><code>N</code> samples <code>x_n</code> of dimension <code>d</code></p> </li> <li>A vector <code>m</code> of dimension <code>d</code></li> <li><code>alpha</code> number</li> </ul> <p>Provide a function that returns the Monte Carlo estimation of \\(F(m, X)\\)</p> <ul> <li>Implement the numerical gradient of the previous function</li> <li>Implement the gradient descent function (take a tolerance of <code>1e-4</code> and max iterations of <code>10000</code>.).</li> <li>Run tests using the following code to generate <code>N</code> samples of <code>d</code> dimensional normal distributed normal distribution (use <code>d = 3, 5, 10</code>)</li> </ul> <pre><code># fix dimension\nimport numpy as np\nd = 4\nomega0 = 10  # seed to generate the constants\nomega1 = 20  # seed to generate the sample.\n\n# create a random d*d matrix, a random eigenvalue one, get q from qr and generate Sigma\nrng0 = np.random.default_rng(omega0)\neigenval = np.diag(rng0.uniform(low=0.1, high=1, size=d))\nq, _ = np.linalg.qr(rng0.normal(size=(d, d)))\nSigma = q.dot(eigenval).dot(q.T)\n\n# generate N random samples from multivariate\nN = 100000\nrng1 = np.random.default_rng(omega1)\nx = rng1.multivariate_normal(mean=np.zeros(d), cov=Sigma, size=N)\n</code></pre> <ul> <li> <p>Check the accuracy of the results by changing the value of <code>omega1</code> (different samples) as well as the speed.</p> </li> <li> <p>improve the speed of your application using <code>numba</code></p> </li> <li> <p>implement the stochastic gradient descent on this example and compare the speed and accuracy.</p> </li> </ul>"},{"location":"material/final/#project-3-image-classification","title":"Project 3: Image Classification","text":"<p>We consider the Hello World problem of machine learning, namely classifying from images of handwritten digits the value of the digit from \\(0\\) to \\(9\\). We use a small set of ML procedures to decide given an image (input \\(\\mathbf{x}\\)) if is a \\(0\\) or \\(1\\) (output \\(y\\)), that is</p> \\[ \\begin{equation*}   y \\approx f(\\mathbf{x}) \\end{equation*} \\] <p>We will try</p> <ol> <li>Linear Regression</li> <li>Logistic (multivariate) regression</li> <li>Support Vector Machine</li> <li>(optional) Neural Network</li> </ol> <p>(you can also try PCA as for the cancer test problem)</p>"},{"location":"material/final/#data-preparation","title":"Data preparation","text":"<p>We use a small dataset provided by <code>sklearn</code> package: The data is a dictionary with keys * <code>data</code>: numpy array of size <code>Nxd</code> (values) \\(N\\) for the number of images \\(d=64 = 8x8\\) for the value of each pixel. * <code>target</code>: numpy array of size <code>N</code> (label <code>0</code> and <code>1</code>)</p> <p>We split the data into a training and testing set using a functionality of scikit learn.</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\n\n# load the data set\ndigits = load_digits()\n\n# We split the set (data and target) into a 50/50% train and test set\nX_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.5, shuffle=False)\n</code></pre>"},{"location":"material/final/#1-linear-regression","title":"1. Linear regression","text":"<ul> <li> <p>Implement and perform the linear regression on the training set such that</p> \\[ \\begin{equation*}   Y \\approx \\mathbf{w}\\cdot \\bar{\\mathbf{X}} \\end{equation*} \\] <p>in the square sense where \\(\\bar{\\mathbf{X}}\\) is augmented by one dimension with a constant \\(1\\).</p> </li> </ul> <p>An image is successfully classified as being a number \\(k\\) if \\(k-1/20&lt;\\mathbf{w}^\\ast \\cdot \\bar{\\mathbf{x}}&lt;k+1/20\\) (if \\(k=0\\) then no lower bound and if \\(k=9\\) no upper bound).</p> <ul> <li> <p>Create two dataframes:</p> <ul> <li><code>df_train</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_train</code> and <code>prediction</code> contains <code>prediction(x_train)</code></li> <li><code>df_test</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_test</code> and <code>prediction</code> contains <code>prediction(x_test)</code></li> </ul> </li> <li> <p>Compute the dataframes <code>conf_train</code> and <code>conf_test</code> with index and columns <code>0, 1, ..., 9</code> and with values <code>a[i,j]</code> equal to the ratio of the number of images <code>i</code> predicted as <code>j</code>.</p> </li> <li> <p>plot using <code>imxshow</code> the heatmap of this confusion matrix for the train and test set.</p> </li> </ul>"},{"location":"material/final/#2-multivariate-logistic-regression","title":"2. Multivariate logistic regression","text":"<p>Our problem is of categorical type and therefore approximating with a linear functional is not that adequate. We adopt another strategy where we try to approximate \\(y\\) in terms of probability.</p> <p>In other terms we intend to find a distribution depending on the input that approximate the probability that the output is equal to \\(k\\). For this we make a parametrized guess for the such a probability density \\(P[Y=k] \\approx p_k(\\mathbf{x}|\\mathbf{w}_1, \\ldots, \\mathbf{w}_9)\\) and given by</p> \\[ \\begin{equation*} \\begin{cases}   p_k(\\mathbf{x})&amp;= \\frac{e^{\\mathbf{w}_k\\cdot \\mathbf{x}}}{1+\\sum_{l=1}^9 e^{\\mathbf{w}_l\\cdot \\mathbf{x}}} &amp; k=1, \\ldots 9\\\\ p_0(\\mathbf{x}) &amp;=1-\\sum_{k=1}^9 P[Y=k] \\end{cases} \\end{equation*} \\] <p>We want to find \\(\\mathbf{w}_1, \\ldots, \\mathbf{w}_9\\) in \\(\\mathbb{R}^{64}\\) that matches the most the empirical observed probability. This corresponds to maximizing the (log) likelihood function</p> \\[ \\begin{equation*} \\ell(\\mathbf{w}_1, \\ldots, \\mathbf{w}_9) = \\sum_{n=1}^N \\sum_{k=0}^9 \\Delta(k, y_n)p_k(\\mathbf{x}_n) \\end{equation*} \\] <p>where \\(\\Delta(k, y_n)\\) is equal to \\(1\\) is \\(y_n = k\\) and \\(y_n = 0\\) otherwise.</p> <ul> <li>Implement the log likelhood function and its gradient.</li> <li>using gradient descent, find the vectors \\(\\mathbf{w}_1,\\ldots, \\mathbf{w}_9\\) that minimize \\(-\\ell\\).</li> </ul> <p>As for the prediction function, an image \\(y\\) is classified as being \\(k\\) if \\(p_k(\\mathbf{x}) &gt; p_l(x)\\) for any other \\(l\\).</p> <p>As above, </p> <ul> <li> <p>Create two dataframes:</p> <ul> <li><code>df_train</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_train</code> and <code>prediction</code> contains <code>prediction(x_train)</code></li> <li><code>df_test</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_test</code> and <code>prediction</code> contains <code>prediction(x_test)</code></li> </ul> </li> <li> <p>Compute the dataframes <code>conf_train</code> and <code>conf_test</code> with index and columns <code>0, 1, ..., 9</code> and with values <code>a[i,j]</code> equal to the ratio of the number of images <code>i</code> predicted as <code>j</code>.</p> </li> <li> <p>plot using <code>imxshow</code> the heatmap of this confusion matrix for the train and test set.</p> </li> </ul>"},{"location":"material/final/#3-support-vector-machine","title":"3. Support vector Machine","text":"<p>We won't see the implementation of support vector machine (though it is not difficult but involves constrained optimization problems that we didn't see), the idea is to separate group of points by an hyper plane to classify them into two or more categories.</p> <p>In a two classification framework with data points \\((\\mathbf{x}_n, y_n)\\) where \\(y_n = \\pm 1\\), we want to find and hyper plane \\(\\mathbf{w}\\cdot \\mathbf{x} - b\\) such that \\(\\mathbf{x}\\cdot \\mathbf{x}_n - b \\geq 0\\) if \\(y_n =1\\) and \\(\\mathbf{w}\\cdot \\mathbf{x}_n - b&lt;0\\) if \\(y_n = -1\\).</p> <p>It involves simple quadratic optimization problem with linear constraints that are quite efficient to solve even in high dimensions. Extensions are done in the multidimensional case.</p> <ul> <li>Follow the example from scikit learn to perform the svm clustering and compare the results with your previous implementations.</li> </ul> <p>Follow the </p>"},{"location":"material/hw01/","title":"Homework 01","text":"Overall Info Due date: 2024-03-25 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw01/#1-datatypes-control-flows-functions","title":"1. Datatypes, Control Flows, Functions","text":"<p>Note</p> <p>For the following short exercises, no use of <code>numpy</code>.</p> <p>1.1 Using conditional statements and loops, count the number of numbers between 0 and 10.000 which are divisible by 3 or 7 and print it.</p> <p>1.2 Write a program that print the following pattern</p> <pre><code>ooooooooooooooooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \noooo                                                                    \noooo                                                                    \noooo                                                                    \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \n             oooo                                                       \n             oooo                                                       \n             oooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo\n</code></pre> <p>1.3 Given a list <code>[\"apple\", \"orange\", \"cabage\", \"lemon\", \"potato\"]</code> extract the subarray containing cabage and potato, and return their indices in the original list. Furthermore, write a program that inverse the order of the list.</p> <p>1.5 Write a function that takes as input one of the name of the 12 month and return the number of days of this month (february is 28)</p> <p>1.6 Write a function that takes a list of numbers and return a ordered list. i.e. <code>[1, 4, 2] -&gt; [1, 2, 4]</code>. You can test this function by creating arbitraty list from numpy arrays <code>x = list(np.random.rand(N)</code>.</p>"},{"location":"material/hw01/#2-numpy","title":"2. Numpy","text":"<p>2.1 Using <code>numpy</code> and its functionalities redo the exercises 1.1 and 1.6</p> <p>2.2 Create two arrays of numbers between -1 and 1. The first one has consecutive numbers equally spaced by 0.01 while the second one has exactly 100 elements.</p> <p>2.3 Given natural numbers \\(n\\) and \\(d\\), create a \\(n\\times d\\) matrix of the form</p> <pre><code>[\n    [0, 1, ..., d-1],\n    [d, d+1, ..., 2d-1]\n    ...\n    [(n-1)d,...,(nd) -1 ]\n]\n</code></pre> <p>Note</p> <p>There are several ways to do it, but remember that loops are not efficient in python. Have a look at the shape manipulations in <code>numpy</code>.</p> <p>2.4 Create a 10x10 matrix where each line contains all the numbers 0 to 9 but shuffled uniformly randomly (check the random routines of numpy documentation)</p> <p>2.5 Normalize a random 5x5 matrix such that the smallest element is 0 and largest is 1</p> <p>2.6 Round a random array 5x5 with two digits after the coma</p> <p>2.7 Given a random array 100 find the position and value of the closest element to 0.6</p> <p>2.8 Write a function which given an array of size \\(N\\) of integers between 0 and 10 returns the histogram of the array by bins of 0.1 (that is number of elements between 0 and 0.1, number of elements between 0.1 and 0.2, ..., between 0.9 and 1</p>"},{"location":"material/hw01/#3-numpy-and-plotly-collatz-conjecture","title":"3. Numpy and Plotly: Collatz Conjecture","text":"<p>Collatz Conjecture</p> <p>Consider the following sequence \\(u = (u_i)\\) of natural numbers given by</p> \\[ \\begin{equation} u_{i+1} = \\begin{cases} u_i /2 &amp; \\text{if }u_i \\text{ is even}\\\\ 3u_i + 1 &amp; \\text{if }u_i \\text{ is odd} \\end{cases} \\end{equation} \\] <p>starting with a number \\(u_0 = n \\in \\mathbb{N}\\).</p> <p>The Collatz Conjecture states that whatever starting integer \\(n \\in \\mathbb{N}\\), the sequence will ultimately reach after some time \\(1\\). This Conjecture is still an open problem, some partial answer in this direction given recently by Terence Tao in 2019.</p> <p>For \\(n \\in \\mathbb{N}\\), denote by</p> \\[ \\tau(n) : = \\inf\\{i \\colon u_i = 1\\} \\] <p>which representes the first time where the sequence starting form \\(n\\) reaches \\(1\\). If this sequence never reaches \\(1\\) starting with \\(n\\), then \\(\\tau(n) = \\infty\\). Collatz conjecture states that \\(\\tau(n)&lt;\\infty\\) for every \\(n\\).</p> <p>There is strong confidence that this conjecture is true, and empirically, it holds for every natural number smaller than \\(2^{68}\\)</p> <p>3.1 Using the control flow <code>while</code>, given an integer \\(n\\) write a function that returns a <code>numpy</code> array \\((u_0, u_i, \\ldots, u_{\\tau(n)})\\). Mathematically, also write what is the domain and codomain of this function.</p> <p>3.2 Using <code>plotly</code>, provide a function where given a <code>numpy</code> array \\(x = (n_0, \\ldots, n_{d-1})\\) it plots \\(d\\) paths \\((u_0, \\ldots, u_{\\tau(n_k)})\\) where \\(u_0 = n_k\\) for \\(k=0, \\ldots, d-1\\).</p> <p>3.4 Write a third function where given a <code>numpy</code> array \\(x = (1, ldots, d)\\) it returns the array \\((\\tau(1), \\ldots, \\tau(d))\\).</p> <p>3.5 Using <code>bar</code> ploting functionality (<code>fig.add_bar(...)</code>) of <code>plotly</code>, write a function that plot the histogram of the previous function, that is \\((l_1, l_2, \\ldots)\\) where</p> \\[ \\begin{equation} l_k = \\text{Cardinality}\\{n\\colon \\tau(n) = k, \\quad 0\\leq n \\leq N\\} \\end{equation} \\] <p>for (depending on the performance of your computer) \\(N=1000, 10000, 100000\\).</p>"},{"location":"material/hw01/#4-scipy","title":"4. Scipy","text":"<p>4.1 Consider the function \\(x \\mapsto f(x) = x ** 2 + 10 * sin(x)\\) for \\(x \\in \\mathbb{R}\\)</p> <ul> <li>plot the function</li> <li>find the minimum</li> </ul> <p>4.2 For the following distributions:</p> <ul> <li>normal with std = 1, 2, 5</li> <li>student with degree of freedom 2, 3, 4, 6</li> </ul> <p>Plot the pdf and cdf of each class for different parameters and compare</p>"},{"location":"material/hw02/","title":"Homework 02","text":"Overall Info Due date: 2024-04-22 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw02/#1-monte-carlo-convergence","title":"1. Monte Carlo Convergence","text":"<p>We compute the following expectation</p> \\[ \\begin{equation} E[(X - K)^+] = \\int_{-\\infty}^{\\infty}(x-K)^+ dF_X(x) = \\int_{-\\infty}^{\\infty}(x-K)^+ f_X(x)dx \\end{equation} \\] <p>where \\(K\\) is a constant, \\(F_X\\) is the <code>cdf</code> of \\(X\\) and \\(f_X=dF_X/dx\\) is the <code>pdf</code> of \\(X\\).</p> <p>We assume throughout that \\(X\\sim \\mathcal{N}(\\mu, \\sigma^2)\\) is a guaussian distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Such a random variable is declared in <code>scipy</code> as follows</p> <pre><code>from scipy.stats import norm\n\nmu = 0.5\nsigma = 0.2\n\nRV = norm(loc = mu, scale = sigma)\n</code></pre> <p>1.1 Define a function <code>expectation</code> that takes as input the random variable <code>RV</code>, the constant <code>K</code> and return the value of the integral using <code>quad</code>.</p> <p>1.2 Define a function <code>mc_expectation</code> that takes as input the random variable <code>RV</code>, the constant <code>K</code> and the natural number <code>N</code> (the number of samples) that retuns a <code>numpy</code> vector <code>[I_0, ..., I_{N-1}]</code> where</p> \\[ \\begin{equation} I_k = \\frac{1}{k} \\sum_{l=0}^{k-1} (x_k-K)^+ \\end{equation} \\] <p>where <code>x = [x_0, \\ldots, x_{N-1}]</code> is a random sample from the distribution of \\(X\\).</p> <p>1.3 For \\(N = 100000\\), with a plotly graph, plot</p> <ul> <li>The constant function <code>expectation(RV, K)</code> for <code>n=0, ..., N-1</code></li> <li>10 functions <code>mc_expectation(RV, K, N)</code> (they already return a vector <code>I = [I_0, ..., I_{N-1}]</code>)</li> </ul> <p>Comment on the speed of convergence of monte carlo method (you can vary \\(N\\) as well as the number of monte carlo samples you compute).</p>"},{"location":"material/hw02/#2-quantile-exact-vs-mc-methods","title":"2. Quantile: exact vs MC methods","text":"<p>From the lecture we know</p> Value at Risk: The value at risk is defined as \\(V@R_{\\alpha}(X) = q_X(1-\\alpha) = F_X^{-1}(1-\\alpha)\\) where \\(q_X\\) is the quantile of \\(X\\). <p>Leads to three methods to compute it.</p> <ul> <li>You already have a <code>ppf</code> function at hand for the quantile</li> <li>You compute the inverse of the <code>cdf</code> using <code>root</code></li> <li>You have just random sample of the distribution and compute the empirical quantile.</li> </ul> <p>2.1 Define a <code>quantile00</code> function that takes as input a known <code>RV</code> and a number <code>0&lt;u&lt;1</code> and return the quantile with a root finding method to invert the <code>cdf</code></p> <p>2.2 Compare the speed of computation for different <code>RV</code> (normal, student, normal inverse guaussian from the <code>scipy.stats</code> library) of this function with respect to the <code>ppf</code> function of those random variable.</p> <p>2.3 Sometimes, you do not have access to the <code>ppf</code> or <code>cdf</code> explicitely but just have \\(N\\) random samples \\(x^N = (x_0^N, ..., x^N_{N-1})\\) of this random variable. Numpy has a functionality to return the quantile of a random sample (there are many ways to interpolate it, see documnetation). Given a random sample (as a numpy array) <code>x=[x_0, ..., x_{N-1}]</code> the quantile is given by <code>np.quantile(x, u)</code>. This empirical quantile converges to the normal quantile. Experiment with different random samples from a normal random variable (<code>rvs</code>) and plot the convergence as a function of \\(N\\) of the empirical quantile to the theoretical quantile.</p> Empirical Quantile <p>Note that the general definition of the (right) quantile is given by</p> \\[ \\begin{equation}     q_X(u) := \\inf \\left\\{ x \\in \\mathbb{R}\\colon P[X\\leq x] \\geq u \\right\\} = \\inf \\left\\{ x \\in \\mathbb{R}\\colon F_X(x) \\geq u \\right\\} \\end{equation} \\] <p>If you have a a random sample \\((x_0, \\ldots, x_{N-1})\\) of \\(X\\), denote by </p> \\[ \\begin{equation}     F^N(x) = \\frac{\\# \\{k \\colon x_k \\leq x\\}}{N} \\end{equation} \\] <p>It holds that \\(F^N \\to F_X\\) if \\(F_X\\) is continuous (is not easy to show, it holds in general gut in a distributional sense).</p> <p>Hence, the quantile \\(q^N\\) of \\(F^N\\) converges too to \\(q_X\\) as \\(N\\) is large.</p> <p>If you denote by \\((y_0, \\ldots, y_{N-1})\\) the reordering of \\((x_0, \\ldots, x_{N-1})\\) from the smallest to the largest value, then it holds</p> \\[     q^N(u) = y_{k_u} \\] <p>where </p> \\[     k_u =      \\begin{cases}         \\inf\\{k \\colon k\\geq Nu\\} &amp; \\text{if }Nu\\leq N-1\\\\         N-1 &amp; \\text{otherwize}     \\end{cases} \\]"},{"location":"material/hw02/#3-average-value-at-risk","title":"3. Average Value at Risk","text":"<p>We discussed in the lecture that the value at risk (which is a quantile) is not appropriate to estimate the risk. It has been replaced by the average value at risk which has different representations</p> \\[ \\begin{align} AV@R_{\\alpha}(X) &amp; = \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 q_X(u) du\\\\ &amp; = \\inf\\left\\{x + \\frac{1}{\\alpha}E\\left[(X - x)^+\\right]\\colon x \\in \\mathbb{R}\\right\\}\\\\ &amp; = q_X(1-\\alpha) + \\frac{1}{\\alpha}E\\left[ (X - q_X(1-\\alpha))^+ \\right] \\end{align} \\] <p>3.1 Implement the <code>AVaR0</code>, <code>AVaR1</code> and <code>AV@R2</code> functions with input <code>RV</code> and <code>alpha</code> and return with <code>quad</code> the result for the first, second and third representation using <code>ppf</code> and/or <code>minimize</code> depending on the representation</p> <p>3.2 Implement the <code>mc_AVaR0</code>, <code>mc_AVaR1</code> and <code>mc_AVaR2</code> functions with input <code>x = [x_0, \\ldots, x_{N-1}]</code> numpy random sample of \\(X\\) and <code>alpha</code> using Monte carlo and empirical quantile for each representations</p> <p>3.3 Compare numerically the speed and accuracy of each method.</p>"},{"location":"material/hw02/#4-multidimensional","title":"4. Multidimensional","text":"<p>Usually in risk managment, the random variable \\(X\\) is a combination of many random variables</p> \\[ \\begin{equation} X = \\sum_{k=1}^d w^k X^k \\end{equation} \\] <p>where the vector \\((X^1, \\ldots, X^d)\\) has a given <code>cdf</code> or random samples, and \\(w^1, \\ldots, w^d\\) are numbers representing the contribution of each factor \\(X^k\\) to the total risk \\(X\\).</p> <p>Throughout, we will consider that \\((X^1, \\ldots, X^d)\\) is a \\(d\\)-dimensional normal Gaussian random variable.</p> Multivariate Gaussian distribution <p>The multivariate Gaussian distribution is the multidimensional extension of a Gaussian distribution for a vector of random variables \\(X=(X^1, \\ldots, X^d)\\). The parameters are the mean \\(\\mathbf{\\mu} = (\\mu^1, \\ldots, \\mu^d)\\) and the covariance matrix (positive semi definite matrix) \\(\\mathbf{\\Sigma} \\in \\mathbb{R}^{d\\times d}\\).</p> <p>The <code>pdf</code> of this multidimensional random variable is given by</p> \\[ \\begin{equation} f(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2} \\sqrt{\\det(\\mathbf{\\Sigma})}} \\exp\\left(-\\frac{1}{2}\\left(\\mathbf{x} - \\mathbf{\\mu}\\right)^\\top \\mathbf{\\Sigma}\\left(\\mathbf{x} - \\mathbf{\\mu}\\right)\\right)  \\end{equation} \\] <p>Denoting by \\(\\sigma^k = \\sqrt{\\mathbf{\\Sigma}^{k,k}}\\) the square root of the diagonal of \\(\\mathbf{\\Sigma}\\), then each random variable \\(X^k\\) is a normal distribution \\(\\mathcal{N}(\\mu^k, (\\sigma^k)^2)\\).</p> <p>However, the different components of the random vector might be dependent as </p> \\[ \\begin{equation} E[(X^k - \\mu^k)(X^l - \\mu^l)] = \\mathbf{\\Sigma}^{k,l} \\end{equation} \\] <p>4.1 Extend the functions <code>mc_AVaR0</code>, <code>mc_AVaR1</code> and <code>mc_AVaR2</code> to multidimensional samples. Use the following two case scenarios to compare accuracy and execution time by varying \\(N\\) the number of samples </p> <pre><code># case of 2 dimensions\nimport numpy as np\nfrom scipy.stats import multivariate_normal\n\nmu = np.array([0.2, 0.5])\nSigma = np.array(\n    [\n        [ 1.        , -0.26315789],\n        [-0.26315789,  1.        ]\n    ]\n)\nw = np.array([2, 5])\n\nRV_2dim = multivariate_normal(mean = mu, cov = Sigma)\n\n# generate N random samples (you get a numpy array Nx2)\nN = 10\nsamples = RV_2dim.rvs(N)\n\n# case of 5 dimensions\nmu = np.array([0.2, 0.5, -0.1, 0, 0.6])\n\nSigma = np.array(\n    [\n        [1.        , 0.2688825 , 0.401427  , 0.19473116, 0.66256879],\n        [0.2688825 , 1.        , 0.3907619 , 0.43373298, 0.43199657],\n        [0.401427  , 0.3907619 , 1.        , 0.27893741, 0.61330745],\n        [0.19473116, 0.43373298, 0.27893741, 1.        , 0.46849892],\n        [0.66256879, 0.43199657, 0.61330745, 0.46849892, 1.        ]\n    ]\n)\nw = np.array([2, 5, -2, 3, 6])\n\nRV_5dim = multivariate_normal(mean = mu, cov = Sigma)\n\n# generate N random samples (you get a numpy array Nx5)\nN = 10\nsamples = RV_5dim.rvs(N)\n</code></pre> <p>Hint: Do not forget that numpy gives you access to the <code>dot</code> product to compute \\(\\sum w^k X^k\\).</p> <p>4.2 Optional: you can try for the two dimensional case to implement with <code>dblquad</code> the direct computation of the <code>AVaR1</code> to compare speed and accuracy.</p> Any dimensional multidimensional Gaussian distributions <p>To create a multidimensional guassian vector, you need to provide the mean vector \\(\\mathbf{\\mu} = (\\mu^1, \\ldots, \\mu^d)\\) as well as the covariance matrix \\(\\mathbf{\\Sigma}\\) which is usually calibrated to data. In our case we can generate some of these distribution using <code>numpy</code> and <code>scipy</code></p> <pre><code># we import the multivariate normal as well as a function to generate Sigma\nfrom scipy.stats import multivariate_normal, random_correlation\nimport numpy as np\n\n# create a random vector of positive eigenvalues and then random covariance\nd=4\neigenvalues = np.random.rand(d)\nSigma = random_correlation.rvs(eigenvalues) # covariance matrix\nmu = no.random.rand(d)                      # vector of mean\n\nRV = multivariate_normal(mean = mu, cov = Sigma)\n\n# generate random samples (N random vectors or dimension d each so Nxd numpy array)\nN = 1000\nsamples = RV.rvs(N)\nprint(samples)\n</code></pre>"},{"location":"material/hw03/","title":"Homework 03","text":"Overall Info Due date: 2024-05-24 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw03/#1-linear-regression-fake-data","title":"1. Linear Regression Fake Data","text":"<p>To illustrate the principle of linear regression we consider the following model</p> \\[ \\begin{equation*}     Y = a + b_1 X_1 +b_2 X_2 + \\varepsilon = \\mathbf{X}\\mathbf{b} + \\varepsilon \\end{equation*} \\] <p>where</p> \\[ \\begin{equation*}     \\mathbf{b} =     \\begin{bmatrix}         a\\\\         b_1\\\\         b_2     \\end{bmatrix}     \\quad     \\text{and}     \\quad     \\mathbf{X} =     \\begin{bmatrix}         1 &amp; X_1 &amp;  X_2     \\end{bmatrix} \\end{equation*} \\] <p>We assume that</p> \\[ \\begin{equation*}     \\begin{bmatrix}         X_1 \\\\         X_2     \\end{bmatrix}     \\sim     \\mathcal{N}\\left(     \\begin{bmatrix}         \\mu_1 \\\\         \\mu_2     \\end{bmatrix}     ,     \\begin{bmatrix}         \\sigma_1^2 &amp; \\sigma_1 \\sigma_2 \\rho\\\\         \\sigma_1 \\sigma_2 \\rho &amp; \\sigma_2^2     \\end{bmatrix}     \\right)     \\quad \\text{and}\\quad     \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2) \\end{equation*} \\] <p>with \\(\\varepsilon\\) independent of \\((X_1, X_2)\\).</p> <p>Consider the following specifications</p> <pre><code>import numpy as np\n\nb = np.array([1, 1, -0.5]).T\n\nmu = np.array([1, 0]).T\nsigma1 = 1\nsigma2 = 0.5\nrho = 0.4\nSigma = np.array(\n    [\n        [sigma1 ** 2, sigma1 * sigma2 * rho],\n        [sigma1 * sigma2 * rho, sigma2 ** 2]\n    ]\n)\n\nsigma = 2\n\n# We prepare the dataset\n\n# Fix random number generator and number of samples\nrng = np.random.default_rng(seed = 150)\nN = 1000\n\n# generate samples\nX = rng.multivariate_normal(mu, Sigma, size = N)        # size N x 2\nepsilon = rng.normal(0, sigma, size = N)                # size N\n\n# Add an axis of 1 to X\nX = np.append(np.ones((N, 1)), X, axis = 1)             # append Nx1 to Nx2 -&gt; Nx3\n\n# Generate Y\nY = X.dot(b) + epsilon                                  # size N\nY\n</code></pre>"},{"location":"material/hw03/#question-1","title":"Question 1:","text":"<ul> <li>Generate a scatter plot of \\(Y\\) against \\(X_1\\) and \\(X_2\\), as well as a scatter plot of \\(X_1\\) against \\(X_2\\).</li> <li>Implement the computation of \\(\\hat{\\mathbf{b}}(N)\\) from the \\(N\\) sample data and compare the obtained values with the true one.</li> <li>Return the residual error \\(\\hat{\\varepsilon}(N)=Y - \\hat{\\mathbf{b}}(N)\\cdot \\mathbf{X}\\) and plot its histogram.</li> </ul>"},{"location":"material/hw03/#question-2","title":"Question 2:","text":"<p>Since we fixed the random generator with <code>seed=150</code> you always get the same result for \\(\\hat{\\mathbf{b}}(N)\\) as well as \\(\\hat{\\varepsilon}(N)\\).</p> <p>Two source of error can come into the linear regression: The randomness in the sample (the seed) as well as the number of samples <code>N</code>.</p> <ul> <li> <p>Define a function <code>f(N, M)</code> where <code>N</code> is the number of samples, and \\(M\\) is the number of trials where you draw this sample. This function shall return</p> </li> <li> <p>an array \\(\\hat{\\mathbf{b}}(N)\\) of size <code>3xM</code> for each computation of the regression coefficient (in the random generator you set <code>seed = None</code>)</p> </li> <li> <p>an array \\(\\hat{\\varepsilon}(N)\\) of size <code>NxM</code> of the corresponding residual for each sample drawn.</p> </li> <li> <p>Fix <code>M=100</code> and for <code>N = 10, 100</code> and <code>1000</code> plot the histogram of</p> </li> <li> <p><code>a(N)</code>, <code>b_1(N)</code> and <code>b_2(N)</code> (they are arrays of <code>M=100</code> values)</p> </li> <li>mean and standard deviation in the direction of the <code>N</code> axis of \\(\\hat{\\varepsilon}(N)\\) (you get two arrays of <code>M=100</code> values)</li> </ul>"},{"location":"material/hw03/#2-linear-regression-real-data","title":"2. Linear Regression Real Data","text":"<p>As seen in the lecture, we are given a set of data in a dataframe <code>df</code> with</p> <ul> <li>a column <code>y</code> for the serie of outputs;</li> <li><code>d</code> columns <code>x_0</code>, ..., <code>x_d</code> for the series of outputs</li> </ul> <p>In the following example we consider a dataset about wine</p>"},{"location":"material/hw03/#question-1_1","title":"Question 1:","text":"<p>Proceed through the following:</p> <ul> <li>Load the dataset with pandas, check if the data are correct and provide some descriptive statistics.</li> </ul> <p>The output \\(\\mathbf{y}\\) is <code>quality</code>, the column <code>type</code> stands for the rows that are either <code>red</code> or <code>white</code>, all the other columns are characteristics of the wine.</p> <ul> <li> <p>Using plotly scatter plot, visualize for <code>red</code> and <code>white</code> the relation between each input dimension and output dimension.</p> </li> <li> <p>Implement using <code>statsmodels</code> the ols regression of <code>quality</code> against the inputs and show the results.</p> </li> </ul>"},{"location":"material/hw03/#question-2_1","title":"Question 2.","text":"<p>The number of features is quite large and it is not clear which feature is relevant or not in the linear regression. The goal is to reduce the number of features as to explain as much as possible the output.</p> <p>Without entering in feature selection overall, we just want to see which input is the most relevant. One indicator for the goodness of a linear regression is <code>rsquared</code> which can be obtained from the returned fitted model <code>est = sm.OLS(y, X).fit()</code> and then <code>est.rsquared</code>.</p> <p>We just try to get the two best features</p> <ul> <li>Loop through every single input feature, perform the linear regression, get the rsquared.</li> <li>take the feature with the largest rsquared.</li> <li>Loop through each other feature, perform the linear regression together with the previously selected and first feature</li> <li>select the feature with the largest rsquared.</li> </ul> <p>Note</p> <p>Normally you should also consider if the new feature collected is not strongly colinear with the first one. To do so you should double check the VIF factor, see <code>variance_inflation_factor</code>.</p>"},{"location":"material/hw03/#3-clustering","title":"3. Clustering","text":"<p>The principle of clustering is as follows. Given a set \\(X = \\{x_1, \\ldots, x_N\\}\\) of \\(N\\) points in \\(\\mathbb{R}^d\\), the goal is to find a partition (cluster) \\(C_1, \\ldots C_K \\subseteq X\\) which somehow group similar points.</p> <p>Similarity between points is defined in terms of some distance \\(d(x,y)\\). The clustering aims to find an optimal cluster \\(C_1^\\ast, \\ldots, C_K^\\ast\\) such that</p> \\[ \\begin{equation} \\sum_{k=1}^K \\frac{1}{\\# C^\\ast_k}\\sum_{x, y \\in C_k^\\ast} d(x, y) \\leq \\sum_{k=1}^K \\frac{1}{\\# C_k}\\sum_{x, y \\in C_k} d(x, y) \\end{equation} \\] <p>for any other cluster \\(C_1, \\ldots, C_K\\).</p> <p>We denote by \\(\\mathfrak{C}\\) the set of all clusters (or partitions) \\(\\mathcal{C} = \\{C_1, \\ldots, C_K\\}\\) of \\(X\\) in \\(K\\) elements and define</p> \\[ \\begin{equation*}     F(\\mathcal{C}) = \\sum_{C \\in \\mathcal{C}} \\frac{1}{\\# C}\\sum_{x, y \\in C} d(x, y) \\end{equation*} \\] <p>the problem can therefore be reformulated into an optimization problem</p> \\[ \\begin{equation*}     \\mathcal{C}^\\ast = (C_1^\\ast, \\ldots, C_K^\\ast) = \\mathrm{argmin}\\left\\{F(\\mathcal{C})\\colon \\mathcal{C} \\in \\mathfrak{C}\\right\\} \\end{equation*} \\] <p>Computing \\(F\\) for a given cluster \\(\\mathcal{C}\\) is relatively fast as long as the distance is quick to compute. However, the optimization problem itself is very difficult. Indeed, it is a minimization problem on a set \\(\\mathfrak{C}\\) which does not have a suitable topology to define derivatives for instance. Hence, the only way a priori would be a brute force optimization, that is running through every possible partition, which is however not suitable since the cardinality of \\(\\mathfrak{C}\\) is gigantic. It corresponds to the stirling number of the second kind \\({ N \\brace K}\\):</p> \\[ \\begin{equation*}     \\#\\mathfrak{C} := {N\\brace K} = \\sum_{k=0}^K \\frac{(-1)^{K-k} k^N}{(K-k)!k!} \\sim_{N\\to \\infty} \\frac{K^N}{K!} \\end{equation*} \\] <p>meaning that for a fixed number \\(K\\), the cardinality is growing exponentially in the size of the set. The problem can be refined and some better approximation can be found but in general this is NP-Hard.</p> <p>However, with some assumptions about the distance, and geometrical consideration, an honnest and fast algorithm can be designed to achieve some local optimum.</p> <p>We consider as ''distance''' the square of the euclidean norm, that is \\(d(x,y) = \\|x - y\\|^2\\).</p>"},{"location":"material/hw03/#question-1_2","title":"Question 1.","text":"<p>Show that</p> \\[ \\begin{equation*}     \\frac{1}{\\# C} \\sum_{x, y \\in C} \\| x - y \\|^2 = 2 \\sum_{x \\in c} \\|x - \\mu\\|^2 \\end{equation*} \\] <p>where \\(\\mu = \\frac{1}{\\# C} \\sum x\\) is the average/barycenter or centroid of \\(C\\).</p>"},{"location":"material/hw03/#question-2_2","title":"Question 2.","text":"<p>It follows that</p> \\[ \\begin{equation*}     F(\\mathcal{C}) = \\sum_{C \\in \\mathcal{C}} \\sum_{x \\in X} \\|x - \\mu_{C}\\|^2 \\end{equation*} \\] <p>With this reformulation in term of geometric center of \\(C\\) leads to the following idea for an algorithm to select a partition.</p> <ol> <li>Initialize \\(K\\) centers \\(\\mu_1(0), \\ldots, \\mu_K(0)\\) by choosing \\(K\\)-points in \\(X\\).</li> <li> <p>Recursively: While \\(\\mathcal{C}(n+1) \\neq \\mathcal{C}(n)\\) at the end of the following do:</p> </li> <li> <p>Given \\(K\\) \\(\\mu_1(n), \\ldots \\mu_K(n)\\) define \\(K\\) sets \\(C_1(n+1), \\ldots, C_K(n+1)\\):</p> <p>\\(C_k(n+1) = \\left\\{x \\in X\\colon \\|x - \\mu_K(k)\\|^2 \\leq \\|x - \\mu_K(j)\\|^2 \\text{ for any }j\\neq k\\right\\}\\)</p> <p>If some point is assigned to two or more then set it to a single one. The best way to do it, is to assign the points to the first cluster, then assign the remaining points to the second one, etc.</p> </li> <li> <p>update the new centers \\(\\mu_1(n+1), \\ldots, \\mu_K(n+1)\\):</p> <p>\\(\\mu_k(n+1) = \\frac{1}{\\# C_k(n+1)} \\sum_{x \\in C_k(n+1)} x\\)</p> </li> </ol> <ul> <li>Show that at each step \\(F(\\mathcal{C}(n+1))\\leq F(\\mathcal{C}(n)\\), hence we find a sequence along which the cost function is decreasing.</li> <li>Show that the algorythm finishes after a finite number of steps.</li> <li>implement the algorythm in numpy by choosing randomly \\(k\\) elements of the set \\(X\\). (the set \\(X\\) can be represented by a numpy array <code>Nxd</code>.)</li> </ul>"},{"location":"material/hw03/#question-2_3","title":"Question 2.","text":"<p>Consider the dataset California Housing which represents the housing data for California.</p> <ul> <li>Load the dataset and select the columns <code>longitude</code>, <code>lattitude</code> and <code>medianIncome</code> as final dataframe <code>df</code>.</li> <li>Install (using conda or pip) the package <code>scikit-learn</code> which is a standard machine learning library.</li> <li>Cluster the data with 4 clusters using Kmeans: <code>from sklearn.cluster import KMeans</code>.</li> <li>given a numpy array <code>X</code> of size <code>N x d</code>, computing the cluster with <code>Kmeans</code> is done as follows <code>result = KMeans(n_clusters = 4).fit(X)</code> and the labels for the cluster are given by <code>result.labels_</code> which is an array of size <code>N</code>.</li> <li>join the cluster values in the dataframe as a new column.</li> <li>plot using plotly express scatter the scatter plot latitude against longitude with a different color for each cluster.</li> </ul>"},{"location":"material/hw04/","title":"Homework 04","text":"Overall Info Due date: 2024-06-26 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw04/#1-ode-implementation","title":"1. ODE implementation","text":"<p>Harmonic Oscillator:</p> \\[ \\begin{equation*}   x^{\\prime\\prime} + \\omega^2 x = 0 \\end{equation*} \\] <ul> <li>setting \\(v = x^\\prime\\), convert this second order ode into a two dimensional first order ODE \\((x, v)\\).</li> <li>Use Euler scheme to compute the solution with \\(\\omega=1\\) with \\(x(0) = 1\\), \\(v(0) =1\\)</li> <li>plot the curve \\(t\\mapsto (x(t), v(t))\\) for \\(0\\leq t \\leq 10\\).</li> </ul> <p>Consider the Damped harmonic oscillator:</p> \\[ \\begin{equation*}   x^{\\prime\\prime} + 2\\gamma x^\\prime +  \\omega^2 x = 0 \\end{equation*} \\] <ul> <li>same notation convert this equation into first order ode in two dimensions.</li> <li>Use RK 4th order to compute the solution \\(\\omega = 1\\) and \\(\\gamma = 0.1\\) and \\(x(0) = v(0)=1\\).</li> <li>plot the solution and compare with the previous solution</li> </ul>"},{"location":"material/hw04/#2-forward-vs-backward-explicit-vs-implicit","title":"2. Forward vs Backward (explicit vs implicit).","text":"<p>Explicit Euler</p> \\[ \\begin{equation*}   y(t+h) = y(t) + h f(t, y(t)) \\end{equation*} \\] <p>Implicit Euler</p> \\[ y(t+h) = y(t) + h f(t+h, y(t+h)) \\] <p>This second method involves solving a root problem to get \\(y(t+h)\\).</p> <ul> <li>Using <code>root</code> from <code>scipy.minimize</code> implement the implicit Euler</li> </ul> <p>Consider the ODE</p> \\[ \\begin{equation*}   y^\\prime = -\\lambda y, \\quad y(0) = 1 \\end{equation*} \\] <p>with solution \\(y(t) = e^{-\\lambda t}\\)</p> <ul> <li>use explicit Euler, RK 4th to compare with implicit Euler (precision and speed)</li> </ul>"},{"location":"material/hw04/#3-gradient-descent","title":"3. Gradient Descent","text":"<p>We implement the gradient descent on the blurred \\(0\\) and \\(1\\) images from <code>sklearn</code> package.</p> <pre><code>import numpy as np\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\nimport sklearn.datasets as dt\nfrom sklearn.model_selection import train_test_split\n\n# load the images and their feature (if it is 0 or 1)\ndigits, target = dt.load_digits(n_class=2, return_X_y=True)\n\n\n# the shape of the dataset\nprint(digits.shape)\n\n# We plot a short sample \npx.imshow(digits.reshape(360, 8, 8)[:10, :, :], facet_col=0, binary_string=True)\n</code></pre> <p>The goal it to perform a simple linear regression but using gradient descent by minimizing among all \\(\\mathbf{w} = [w_0, \\ldots, w_{64}]^\\top\\) the objective function</p> \\[ \\frac{1}{N}\\sum (y_n - \\mathbf{w}^\\top \\bar{\\mathbf{x}}_n)^2 \\] <p>where \\(y_n\\) is either \\(0\\) or \\(1\\) for the label of the \\(n\\)-th image and \\(\\bar{\\mathbf{x}}_n = [1, \\mathbf{x}_n]\\) is the array of the image augmented with a \\(1\\).</p> <ul> <li>modify the objective function and gradient of which so that it takes as input \\(\\mathbf{w}\\) \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) and modify the gradient descent function.</li> </ul> <p>Since our goal is to find a correct specification to further classify data, we calibrate the model on a training set and evaluate its accuracy on a testing set. To split the two set of data we use <code>sklearn</code></p> <pre><code>x_train, x_test, y_train, y_test = train_test_split(\n  digits,\n  target,\n  test_size=0.2,\n  random_state=10\n)\n</code></pre> <ul> <li>Using the gradient descent calibrate on the training set <code>x_train</code>, <code>y_train</code> the optimal value of \\(\\mathbf{w}\\). Plot the value of <code>f_history</code> (choose a maximum number of iteration of 100 and 0.1 as threshold and tweak a little bit with momentum and learning rate until you reach a satisfactory convergence rate and error)</li> </ul> <p>Now we want to be able to classify the data. We proceed as follows</p> <p>If \\(\\mathbf{w}^\\top \\bar{\\mathbf{x}} \\geq 0.5\\) it is classified as \\(1\\) otherwise it is classified as \\(0\\).</p> <ul> <li> <p>Given \\(\\mathbf{w}\\), \\(N\\) samples \\((\\mathbf{x}_1, y_1), \\ldots,(\\mathbf{x}_N, y_N)\\), design a function <code>accuracy(w, x, y)</code> that returns the percentage of correctly classified values.</p> </li> <li> <p>Using this function, provide the accuracy of your solutions on the testing set <code>(x_train, y_train)</code> and on the test set <code>(x_test, y_test)</code>.</p> </li> <li> <p>Optional Question: compare the gradient descent method with the traditional OLS linear regression method.</p> </li> </ul>"},{"location":"material/material/","title":"Setup","text":"<p>Any normal computer with either Linux, Windows of MacOS will do it.</p> <p>What is primarily needed:</p> <ul> <li>Python</li> <li>A Code editor</li> </ul>"},{"location":"material/material/#python","title":"Python","text":"<p>Python can be installed in many different ways (In linux it is for instance most of the time already in the system). Several python (with different versions) can run under the same computer.</p> <p>However the most simple and best advice is to use Anaconda</p> <ol> <li>Step 1: Download Anaconda for your platform</li> <li>Step 2: Install on your computer</li> </ol> Miniconda <p>Anaconda comes with a GUI software to manage the environment and packages with point and click. It also installs a default set of packages such as <code>Jupyther</code>, <code>numpy</code>, etc. If you prefer to install a minimal version and install only the packages you need one after the other you can install Miniconda</p> <p>Anaconda usually comes with a python interpreter called <code>ipython</code> that allows to run code directly from a console or an editor.</p>"},{"location":"material/material/#code-editor","title":"Code Editor","text":"<p>Two write code you only need an editor, however dedicated editors allows you to program more efficiently.</p> <ul> <li>Jupyther Notebook:     Allows you to run on the browser so called notebook where you can input code, text, and run each cell.     Good for pure beginner.</li> <li>VSCode:     Is a multi platform open source editor maintained and released by Microsoft.     It is a great environment for development.     The principle is that it is a basic editor in which you can install so called plugins (mini apps like in wechat or allipay).     Download and install.     Then go to the plugins repository and install the <code>python</code> plugin from Microsoft.</li> </ul> <p>Good practice</p> <p>It is recommended to have a directory in your computer containing your code files (for organization purposes and also because python will run as environment in this directory).</p>"},{"location":"material/material/#installing-additional-libraries","title":"Installing additional libraries","text":"<p>Python can be extended with libraries this is one of the strength of it that will perform tasks for you. Installing a new library can be done in three ways with anaconda:</p> <ol> <li>Use the GUI and search for the library</li> <li>Open a terminal and type <code>conda install &lt;library&gt;</code></li> <li>Open a terminal and use pip with <code>pip install &lt;library&gt;</code></li> </ol> <p>Warning</p> <p>The first and second options are preferable usually. Indeed, libraries have a complex system of inter-dependence and since you are likely using Anaconda, the tool <code>conda</code> will manage the inter-dependence of each packages better. It is however slower.</p>"},{"location":"material/material/#which-libraries","title":"Which libraries","text":"<p>In the lecture we will use quite a lot of libraries and install them on the go. Fundamentally the following ones will be recurrent</p> <ul> <li><code>numpy</code>: multidimensional array library</li> <li><code>pandas</code>: data analysis (tabular) framework </li> <li><code>scipy</code>: scientific library</li> <li><code>pytorch</code>: AI and ML library with tensors</li> <li><code>plotly</code>: Data visualization</li> </ul>"},{"location":"material/project01/","title":"Project I","text":""},{"location":"material/project01/#equilibrium-price","title":"Equilibrium Price","text":"<p>In the lecture we assumed that the market is arbitrage free in the sense that Arbitrages makes the market ill defined. The main reason is that if an arbitrage suddenly exists, arbitrageurs would immediately size this opportunity driving the prices by law of offer and demand within the arbitrage free bounds.</p> <p>In the following we show that prices that are negociated between different agents on the market yields a price for the underlying assets that is arbitrage free.</p> <p>Since we are woriking in a one period model we will make some simplifying assumptions (no dividends).</p> <p>A company wants to go IPO by issuing \\(M\\) shares with an outcome \\(S_1 \\sim \\mathcal{N}(\\mu, \\sigma^2)\\).(1) In the market we have \\(N\\) potential buyers denoted by \\(i=1, \\ldots, N\\), that can aquire \\(\\eta^i\\) of this share for a price \\(S_0\\) to be negociated among each of them. We assume that every buyer does not hold assets or cash at the begining, hence start with \\(0\\).(2) We also assume that there is no interest rate, i.e. \\(r = 0\\).</p> <ol> <li> <p>This is already an irrealistic assumption since the share value at time \\(1\\) might be negative but we could carry similar argumentation with a log normal distribution or just a binomial model.</p> </li> <li> <p>You can see how the system change if those investors comes with some money, or if they have some radom endowment.</p> </li> </ol> <p>For a price of \\(S_0\\), and strategy \\(\\eta^i\\), the wealth of buyer \\(i\\) is given by</p> \\[ \\begin{equation*} W^i = \\eta^i \\Delta X_1 = \\eta^i S_1 - \\eta^i S_0  \\end{equation*} \\] <p>In order to make investors trading with each others we need to give them some objectives. In economic terms, it means that they evaluate the future outcomes \\(W\\) in terms of utility, that is </p> \\[ U^i(W) = E\\left[ u^i(W) \\right] \\] <p>where \\(u^i:\\mathbb{R} \\to \\mathbb{R}\\) is a convex function.(1) In our cases, we assume that \\(u^i(x) = -e^{-\\gamma^i x}/\\gamma^i\\) where \\(\\gamma^i &gt;0\\) is the risk aversion of investor \\(i\\).</p> <ol> <li>The utility function means first that for every two investment \\(W\\) and \\(\\tilde{W}\\), then \\(U(\\lambda W + (1-\\lambda)\\tilde{W})\\geq \\lambda U(W) + (1-\\lambda)U(\\tilde{W}) \\geq \\min\\{U(W), U(\\tilde{W})\\), meaning that the investor favors diversified outcome rather than concentrated ones. Furthermore since the function is increasing, better outcomes for sure yields better utility.</li> </ol> <p>A Radner Equilibrium is defined as follows</p> <p>Definition: Radner Equilibrium</p> <p>An equilibrium is characterised by the vector of investments \\((\\bar{\\eta}^1, \\ldots, \\bar{\\eta}^N)\\) of the \\(N\\) investors and an agreed price \\(\\bar{S}_0\\), such that</p> <ol> <li> <p>Individual optimality: Given the equilibrium price \\(\\bar{S}_0\\), no investor can get better than his own strategic purchase, that is</p> \\[   U^i(\\bar{\\eta}^i (S_1 - \\bar{S}_0)) \\geq U^i(\\eta^i (S_1 - \\bar{S}_0)) \\] <p>for any other possible allocation \\(\\eta^i\\) and for any investor \\(i\\).</p> </li> <li> <p>Market Clearing: There is so much to share as it is offered.     In other terms the total amount of shares held by the investors should equal (or at least be less than) the total amount of shares proposed.</p> \\[     \\sum \\eta^i =M \\] </li> </ol> <p>given this definition, your goal is to show that there exists and equilibrium and investigate it.</p> <ol> <li> <p>For a given investor \\(i\\) and a price \\(S_0\\), compute the optimal amount of shares it aquires by computing </p> \\[   \\eta^i(S_0) = \\mathrm{argmax}_{\\eta^i} U^i(W^i) \\] </li> <li> <p>For the optimal response solution of each agent \\(\\eta^i(S_0)\\) for a given price, solve for \\(S_0\\) using the market clearing condition, that is \\(\\bar{S}_0\\) solving</p> \\[   \\sum \\eta^i(S_0) = M \\] </li> <li> <p>Compute the amount of money raised by the IPO as a function of \\(\\mu\\) (the sure premises on returns) and \\(\\sigma\\) the volatility to which this company is subject to.</p> </li> </ol> <p>Warning</p> <p>If you want to make it simple at the begining, consider that each \\(\\gamma^i\\) are the same \\(\\gamma\\). Furthermore, check online what is the expectation of \\(E[e^{\\gamma^i Z}]\\) when \\(Z\\) is a normal distribution.</p> <p>Proof</p> <ol> <li> <p>We are given a price \\(S_0\\), and try to find the best strategy for agent \\(i\\) (since it is indepedent of \\(i\\) we drop the index \\(i\\) for the moment).</p> <p>We want to find \\(\\eta(S_0)\\) such that</p> \\[   U(\\eta(S_0)(S_1 - S_0)) \\geq U(\\eta (S_1 - S_0)) \\] <p>for any other buy decision \\(\\eta\\).</p> <p>Since \\(\\eta \\mapsto U(\\eta (S_1 -S_0))\\) is concave, we just need to compute the first order condition which yield (a mathematician would pay attention about the derivation under the expectation sign...)</p> \\[     \\begin{align*}       \\frac{d U(\\eta (S_1 - S_0))}{d\\eta} &amp; = -\\frac{1}{\\gamma}\\frac{d}{d\\eta}E\\left[ e^{-\\gamma(S_1 - S_0)} \\right]\\\\       &amp; = -\\frac{1}{\\gamma}E\\left[ \\frac{d}{d\\eta}e^{-\\gamma \\eta (S_1 - S_0)} \\right]\\\\       &amp; = E\\left[ (S_1 - S_0) e^{-\\gamma \\eta(S_1-S_0)} \\right]\\\\       &amp; = e^{\\gamma \\eta S_0}E\\left[ (S_1 - S_0) e^{-\\gamma \\eta S_1} \\right]     \\end{align*} \\] <p>Setting equal to \\(0\\) with \\(e^{\\gamma \\eta S_0} &gt;0\\), it follows that the first order condition reads as </p> \\[   E[S_1 e^{-\\gamma \\eta S_1}]=S_0E[e^{-\\gamma \\eta S_1}] \\] </li> </ol>"}]}