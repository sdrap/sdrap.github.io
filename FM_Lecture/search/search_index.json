{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Financial Mathematics: Lecture Notes","text":"<p>These lecture notes, still a work in progress, are for a course taught at Shanghai Advanced Institute for Finance, Shanghai Jiao Tong University, for graduate students.</p>"},{"location":"#course-objective","title":"Course Objective","text":"<p>Stochastics as a mathematical field evolved in parallel with the development of the finance industry, starting with insurance, followed by stock markets, derivatives, and more. This lecture serves as an introduction to the mathematical theory underpinning modern finance. The course aims to introduce mathematical concepts in finance through the following topics:</p> <ul> <li> <p>One-period financial markets: Financial assets, self-financing strategies, arbitrage, the fundamental theorem of asset pricing, and option pricing.   From a mathematical perspective, this introduces probability spaces, expectations, pricing measures, and measure changes.</p> </li> <li> <p>Modern risk management and quantification: Value at Risk (V@R), Expected Shortfall (ES), and systemic risk.   From a mathematical perspective, this introduces the concept of probability distribution (CDF, PDF, quantile), joint distributions and tail risk.</p> </li> <li> <p>Multi-period financial markets: Concepts of information, the CRR model, pricing and hedging, exotic options, stopping times, and American options.   This includes mathematical concepts such as filtrations, conditional expectations, martingales, and stopping times.</p> </li> <li> <p>Basics of ruin theory and default pricing.</p> </li> <li> <p>Continuous-time financial markets: Introduction to the Black-Scholes framework.</p> </li> </ul>"},{"location":"#concrete-approach","title":"Concrete Approach","text":"<p>The course combines blackboard lectures with practical applications in Python. Lecture notes will be provided and updated during the course. Simple homework exercises (not graded but corrected and discussed by the TA) will be assigned. Additionally, students will complete two group projects (5-6 members per group), alongside a midterm and final exam.</p> <p>For further reading, we recommend Shreve<sup>1</sup> for an introduction to mathematical finance in discrete time and F\u00f6llmer and Schied<sup>2</sup> for a more advanced treatment.</p>"},{"location":"#references","title":"References","text":"<ol> <li> <p>Steven E. Shreve. Stochastic Calculus for Finance. Volume I of Springer Finance. Springer-Verlag, New York, 2004. ISBN 0-387-40100-8. The binomial asset pricing model.\u00a0\u21a9</p> </li> <li> <p>Hans F\u00f6llmer and Alexander Schied. Stochastic Finance. An Introduction in Discrete Time. De Gruyter Studies in Mathematics. Walter de Gruyter, Berlin, New York, 3rd edition, 2011.\u00a0\u21a9</p> </li> </ol>"},{"location":"javascripts/node_modules/mathjax/","title":"MathJax","text":""},{"location":"javascripts/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"javascripts/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"javascripts/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"javascripts/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\n  loader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\n  const svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\n  console.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"javascripts/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"javascripts/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"},{"location":"lecture/00-Introduction/000-index/","title":"Introduction","text":""},{"location":"lecture/00-Introduction/000-index/#what-is-mathematical-finance","title":"What is Mathematical Finance?","text":"<p>Finance concerns the allocation and pricing of assets\u2014goods, stocks, etc.\u2014and liabilities\u2014debts, loans, bonds, etc.\u2014in the presence of uncertainty and risk. This definition raises several fundamental questions:</p> <ul> <li>What is trade, money, or pricing?  </li> <li>What are uncertainty and risk?  </li> <li>Which academic fields address these questions?  </li> <li>What role does mathematics\u2014particularly stochastics\u2014play in finance?  </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#a-brief-and-biased-history-of-trade-money-and-finance","title":"A Brief and Biased History of Trade, Money, and Finance","text":""},{"location":"lecture/00-Introduction/000-index/#trade-of-goods-and-the-emergence-of-money","title":"Trade of Goods and the Emergence of Money","text":"<ul> <li> <p>Exchange of goods (around 150,000 BC):</p> <ul> <li>Advantages: Better allocation of comparative advantages.  </li> <li>Question:  <ul> <li>How is exchange value determined (bilateral agreement)?  </li> <li>Need for intermediaries.  </li> </ul> </li> </ul> </li> <li> <p>Money as a medium of exchange (around 12,000 BC):  </p> <ul> <li>Advantages:  <ul> <li>Solves the double coincidence problem, enabling efficient allocation.  </li> <li>Serves as a unit of account (num\u00e9raire).  </li> <li>Stores value over time.  </li> </ul> </li> <li>Questions:  <ul> <li>How is value established (multilateral agreements between numerous goods)? Law of demand and supply.  </li> <li>How does money preserve value over time?  </li> <li>Introduces the concept of the time value of money.  </li> </ul> </li> </ul> </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#assessing-uncertainty-the-rise-of-financial-markets","title":"Assessing Uncertainty: The Rise of Financial Markets","text":"<ul> <li> <p>Commodity markets (4,000 BC):     Development of forward contracts to hedge against price fluctuations.  </p> <ul> <li>Question: How are prices determined?  </li> </ul> </li> <li> <p>Loans and banking systems (2,000 BC):     Facilitated leveraged investments.  </p> <ul> <li>Question: How to price future payments?  </li> </ul> </li> <li> <p>Insurance (1400s):     Emerged during overseas trading, with premiums exchanged for risk.  </p> <ul> <li>Sparked the beginnings of probability theory.  </li> </ul> </li> <li> <p>Stock markets (1600s):     Enabled capital raising and introduced challenges such as dividend payments and stock price modeling (e.g., Bachelier model, Brownian motion).  </p> </li> <li> <p>Options (1600s, standardized in 1973):     Put and call options provided bounded insurance against price movements.  </p> </li> <li> <p>Derivatives:     Broader contracts written on assets, indices, interest rates, etc.  </p> </li> </ul> <p>Pricing remains the central problem for all these financial instruments. While agreements between counterparties can set prices, mathematical models provide fair and robust valuations. A specialized subfield of mathematical finance also focuses on assessing financial risk.</p>"},{"location":"lecture/00-Introduction/000-index/#academic-fields-involved-in-finance","title":"Academic Fields Involved in Finance","text":"<ul> <li>Economics: Macroeconomics, microeconomics, decision theory.  </li> <li>Psychology: Behavioral finance.  </li> <li>Law.  </li> <li>Computer Science: Algorithmic trading, machine learning.  </li> <li>Mathematics:  <ul> <li>Stochastics (modeling).  </li> <li>Statistics (calibration, machine learning...).  </li> <li>Optimization.  </li> <li>Functional analysis and partial differential equations (e.g., Black-Scholes model).  </li> </ul> </li> </ul>"},{"location":"lecture/00-Introduction/001-notations/","title":"Notations","text":""},{"location":"lecture/00-Introduction/001-notations/#mathematical-notations","title":"Mathematical Notations","text":"<p>The following notations will be used throughout the course:</p> <ul> <li>Natural Numbers: \\(\\mathbb{N} = \\{1, 2, \\ldots\\}\\), \\(\\mathbb{N}_0 = \\{0, 1, 2, \\ldots\\}\\).</li> <li>Integers: \\(\\mathbb{Z} = \\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\)</li> <li>Rational Numbers: \\(\\mathbb{Q} = \\{ p/q\\colon p \\in \\mathbb{Z}, q \\in \\mathbb{N}\\}\\)</li> <li>Real Numbers: \\(\\mathbb{R}\\)</li> <li>Vectors in \\(\\mathbb{R}^d\\) are denoted in bold font, \\(\\boldsymbol{x} = (x^1, \\dots, x^d)\\), and are assumed to be column vectors.  </li> <li>Vectors with positive components \\(\\mathbb{R}^d_+ = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k \\geq 0, k=1,\\ldots,d\\}\\) and vectors with strictly positive components \\(\\mathbb{R}^d_{++} = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k &gt; 0, k=1,\\ldots,d\\}\\).  </li> <li>Scalar Product: \\(\\boldsymbol{x} \\cdot \\boldsymbol{y} := \\sum x_k y_k\\) denotes the scalar product of \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\) in \\(\\mathbb{R}^d\\).  </li> <li>\\(\\beta \\boldsymbol{x} := (\\beta x_1, \\ldots, \\beta x_d)\\) represents the multiplication of \\(\\boldsymbol{x}\\) in \\(\\mathbb{R}^d\\) by a scalar \\(\\beta \\in \\mathbb{R}\\).  </li> <li>\\(\\boldsymbol{x} + \\boldsymbol{y} := (x_1 + y_1, \\ldots, x_d + y_d)\\) represents vector addition in \\(\\mathbb{R}^d\\).  </li> <li>Component wise operations: \\(\\boldsymbol{x}\\boldsymbol{y}= (x_1 y_1, \\ldots, x_d y_d)\\), \\(\\boldsymbol{x}/ \\boldsymbol{y} = (x_1/ y_1, \\ldots, x_d/y_d)\\), \\(f(\\boldsymbol{x}) = (f(x_1), \\ldots, f(x_d))\\) for any function \\(f\\colon \\mathbb{R}\\to \\mathbb{R}\\).</li> <li> <p>For scalars \\(x, y \\in \\mathbb{R}\\), the following notations are used:  </p> \\[   x \\vee y = \\max\\{x, y\\}, \\quad x \\wedge y = \\min\\{x, y\\}, \\quad x^+ = \\max\\{x, 0\\}, \\quad x^- = \\max\\{-x, 0\\}. \\] <p>Notably, \\(x = x^+ - x^-\\) and \\(|x| = x^+ + x^-\\).  </p> </li> </ul>"},{"location":"lecture/00-Introduction/001-notations/#colorenvironment-conventions","title":"Color/Environment conventions","text":"<p>Definition</p> <p>For a ... we define</p> <p>Remark</p> <p>Note that  </p> <p>Example</p> <p>As an example we consider </p> <p>Theorem</p> <p>Let \\((\\Omega, \\mathcal{F}, P)\\) be a probability space...</p> <p>Proposition</p> <p>Assuming no-arbitrage for the financial market, the followign assertions holds...</p> <p>Corollary</p> <p>As a corrolary to the previous proposition, it holds</p> <p>Lemma</p> <p>In the case where \\(P^\\ast\\) is equivalent to \\(P\\), it holds...</p> <p>Proof</p> <p>In a first step we show that \\((i)\\) implies \\((ii)\\)...</p> <p>Exercise</p> <p>Solve in a a binomial financial market...</p>"},{"location":"lecture/01-One-Period/011-mathematical-model/","title":"Mathematical Model","text":"<p>In this section, we model a one-period financial market evolving between two points in time:</p> <ul> <li>Today: The current state of the world is known, including the prices of equities, commodities, and the overall economic condition.</li> <li>Tomorrow: Various possible states of the world may emerge, where changes in the economy or the prices of stocks and commodities occur based on these states.</li> </ul> <p>In this financial market, we have \\(d\\) risky assets available for investment and a bank account to store or borrow liquidity.</p> <ul> <li>At time \\(0\\): The prices of these \\(d\\) financial assets and the amount in the bank account are known.     Investors can decide on a strategy, specifying how much to invest in each asset by purchasing a certain number of shares. The bank account is used to finance these investments.</li> <li>At time \\(1\\): The portfolio's value is determined by:<ul> <li>The remaining balance in the bank account after buying the shares at time \\(0\\), including interest earned.</li> <li>The uncertain value of the financial assets at time \\(1\\), multiplied by the number of shares held.</li> </ul> </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#bank-account","title":"Bank Account","text":"<p>The bank account is denoted by \\(B\\), where \\(B_0 = 1\\) represents the price of one unit of currency at time \\(0\\). The bank offers an interest rate \\(r\\), announced at time \\(0\\) and applied at time \\(1\\). With one unit deposited at time \\(0\\), the amount in the account at time \\(1\\) becomes:</p> \\[ \\begin{equation*}   B_1 = B_0(1 + r) = 1 + r \\end{equation*} \\] <p>We assume \\(r &gt; -1\\), meaning the bank does not default. The bank account evolution is summarized as:</p> \\[ \\begin{equation*}   \\begin{cases}     B_0 = 1 \\\\     B_1 = 1 + r   \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#financial-assets","title":"Financial Assets","text":"<p>These assets are represented by the vector:</p> \\[ \\begin{equation*}   \\boldsymbol{S} = (S^1, \\ldots, S^d) \\end{equation*} \\] <p>Each \\(S^k\\) for \\(k = 1, \\ldots, d\\) describes the price evolution of financial asset \\(k\\) between time \\(0\\) and \\(1\\).</p> <ul> <li> <p>At time \\(0\\): The price of asset \\(k\\) is \\(S_0^k\\), which is strictly positive and known:</p> \\[ \\begin{equation*}   \\boldsymbol{S}_0 = (S_0^1, \\ldots, S_0^d) \\quad \\text{where} \\quad S_0^k &gt; 0 \\; \\text{for all }k \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The price of asset \\(k\\) is \\(S_1^k\\), which is uncertain but non-negative (if \\(S_1^k = 0\\), the asset \\(k\\) has defaulted):</p> \\[ \\begin{equation*}   \\boldsymbol{S}_1 = (S_1^1, \\ldots, S_1^d) \\quad \\text{where} \\quad S_1^k \\geq 0 \\; \\text{for all }k \\end{equation*} \\] </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#self-financing-portfolio","title":"Self-Financing Portfolio","text":"<p>A portfolio consists of holdings in each financial asset and the balance in the bank account. The portfolio's total value is denoted by \\(\\bar{V}\\).</p> <ul> <li> <p>At time \\(0\\): You observe the prices \\(S_0^k\\) for \\(k = 1, \\ldots, d\\) and decide on a strategy, holding \\(\\eta^k \\in \\mathbb{R}\\) shares of each asset. The cost of purchasing these assets is:</p> \\[ \\begin{equation*}   \\sum_{k=1}^d \\eta^k S_0^k = \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\end{equation*} \\] <p>where \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\) represents your holdings. The self-financing condition requires that this cost is fully covered by the bank account. Thus:</p> \\[ \\begin{equation*}   \\bar{V}_0 \\leadsto \\underbrace{\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Bank account value}} +  \\underbrace{\\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Asset holdings value}}= \\bar{V}_0 - \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 + \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 = \\bar{V}_0 \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The portfolio value evolves as asset prices change:</p> \\[ \\begin{align*}     \\bar{V}_1 &amp; = \\left(\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0\\right)(1+r) + \\sum_{k=1}^d \\eta^k S^k_1 \\\\               &amp; = \\left( \\bar{V}_0 - \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\right)(1+r) +\\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_1  \\\\               &amp; = \\bar{V}_0(1+r) +\\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r) \\right) \\end{align*} \\] </li> </ul> <p>Hence a portfolio over time is entirely determined by its start value \\(\\bar{V}_0\\) as well as the strategy \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\).</p> Remark: How realistic are those assumptions? <p>In this setting, we make somewhat restrictive assumptions that are disputable namely:</p> <ul> <li>No dividends.</li> <li>No transaction costs when buying assets: fixed fees, taxes, transaction fees, liquidity.</li> <li>The amount of shares in a financial asset is a real number.       Usually you are only allowed to buy/sell a round lot.       Furthermore, you are allowed to hold a negative amount of shares.       In other terms short selling is allowed and without particular transaction costs related to it.</li> <li>You can buy/sell unlimited amount of shares, in particular for very large amount you face no liquidity costs.</li> <li>The bank account provides the same rate \\(r\\) for deposit and lending which is very unlikely.     And this rate is independent of the amount.</li> <li>You can lend infinite amount of money from the bank.</li> </ul> <p>We consider the ideal scenario of a small investor operating in a frictionless financial market\u2014an assumption that closely approximates modern realities. Some aspects, such as taxes, transaction fees, dividends, and round lot restrictions, are either negligible or can be incorporated with minimal adjustments. However, factors like differing lending and deposit rates, liquidity costs, short-selling constraints, and price impacts are more complex and can significantly influence the results.    </p>"},{"location":"lecture/01-One-Period/011-mathematical-model/#discounting","title":"Discounting","text":"<p>It is often convenient to consider discounted values of financial assets and the portfolio to express their worth in terms of today's currency. Define the discounted prices \\(\\boldsymbol{X}=\\boldsymbol{S}/B\\) and portfolio value \\(V=\\bar{V}/B\\) as follows:</p> \\[ \\begin{align*}     X_0^k &amp; = \\frac{S^k_0}{B_0}=S^k_0         &amp; \\text{and} &amp;  &amp; X_1^k &amp; = \\frac{S_1^k}{B_1}=\\frac{S_1^k}{1+r}         \\\\     V_0   &amp; = \\frac{\\bar{V}_0}{B_0}=\\bar{V}_0 &amp; \\text{and} &amp;  &amp; V_1   &amp; = \\frac{\\bar{V}_1}{B_1}=\\frac{\\bar{V}_1}{1+r} \\end{align*} \\] <p>In particular, it follows that</p> \\[ \\begin{align*}     V_1     &amp; = \\frac{\\bar{V}_1}{1+r}\\\\             &amp; = \\frac{1}{1+r}\\left(\\bar{V}_0(1+r) +\\sum_{k=1}^d \\eta^k\\left( S^k_1  - (1+r)S_0^k\\right)\\right)\\\\             &amp; = \\bar{V}_0 +\\sum_{k=1}^d \\eta^k\\left( \\frac{S^k_1}{1+r}  - S_0^k\\right)\\\\                 &amp; = V_0 + \\sum_{k=1}^n \\eta^k\\left( X^k_1 - X^k_0 \\right)\\\\           &amp; = V_0 + \\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{X}_1 - \\boldsymbol{X}_0 \\right) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\end{align*} \\] <p>for which we get an interpretation of the evolution of the discounted value of the portfolio:</p> \\[ \\begin{equation*}   V_1 = \\underbrace{V_0}_{\\text{Initial Value}} + \\underbrace{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1}_{\\text{Incremental gain/loss of discounted prices}} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#uncertainty","title":"Uncertainty","text":"<p>So far, we have described a simple financial market and how investments can be made while adhering to self-financing principles. However, while we acknowledged that the prices of assets at time \\(1\\) are subject to uncertainty, we have not detailed how this uncertainty is modeled.  In other words, while we treated the financial assets at time \\(1\\) as a vector of prices, we have not specified how this vector reflects the uncertainty associated with its values.</p> <p>The price evolution depends on the \"state of the world\" that will be realized. If we denote by \\(\\omega\\) one such possible state, then \\(S_1^k(\\omega)\\) represents the price of asset \\(k\\) at time \\(1\\) in state \\(\\omega\\). If \\(\\Omega\\) denotes the collection of all possible states, the stock price \\(S_1^k\\) is a function:</p> \\[ \\begin{align*}   S_1^k\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_+\\\\   \\omega &amp; \\longmapsto \\underbrace{S_1^k(\\omega)}_{\\text{Price of financial asset $k$ at time $1$ in state $\\omega$}} \\end{align*} \\] <p>Combining all such functions, we obtain state-dependent price vectors:</p> \\[ \\begin{align*}   \\boldsymbol{S}_1\\colon \\Omega &amp; \\longrightarrow \\mathbb{R}_+^d\\\\   \\omega &amp; \\longmapsto \\boldsymbol{S}_1(\\omega) = (S_1^1(\\omega), \\ldots, S_1^d(\\omega)) \\end{align*} \\] <p>Similarly, the discounted self-financing portfolio value at time \\(1\\) and the discounted asset prices become state-dependent functions:</p> \\[ \\begin{align*}   \\boldsymbol{X}_1\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_{+}^d &amp; V_1 \\colon \\Omega &amp;\\longrightarrow \\mathbb{R} \\\\   \\omega &amp; \\longmapsto \\boldsymbol{X}_1(\\omega) = \\left( \\frac{S_1^1(\\omega)}{1+r}, \\ldots, \\frac{S_1^d(\\omega)}{1+r} \\right) &amp; \\omega &amp;\\longmapsto V_1(\\omega) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1(\\omega) \\end{align*} \\] <p>The objective of financial mathematics is to estimate or price these state-dependent portfolios. To achieve this, we need further assessments of how likely each event is to occur. This is where stochastic theory plays a crucial role.</p> <p>Definition: One Period Financial Market</p> <p>Given a probability space \\((\\Omega, \\mathcal{F}, P)\\), a financial market is defined as follows:</p> <ul> <li> <p>A bank account \\(B\\), where:</p> \\[ B_0 = 1 \\quad \\text{and} \\quad B_1 = 1 + r \\] <p>for \\(r&gt;-1\\)</p> </li> <li> <p>\\(d\\)-financial assets \\(\\boldsymbol{S} = (S^1, \\ldots, S^d)\\), where:</p> \\[   S_0^k &gt; 0 \\quad \\text{and} \\quad S_1^k : \\Omega \\to \\mathbb{R}_+ \\] <p>for \\(k = 1, \\ldots, d\\), with \\(S_1^k\\) being a measurable random variable.</p> </li> </ul> <p>A Portfolio \\(\\bar{V}\\) is given by a start value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and a holding strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). Self financing condition implies</p> \\[   \\bar{V}_1 = \\bar{V}_0(1+r) + \\sum \\eta^k \\left(S_1^k - S_0^k(1+r)\\right) = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\left(\\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r)\\right) \\] <p>The discounded portfolio \\(V = \\bar{V}/B\\) and financial assets \\(\\boldsymbol{X} = \\boldsymbol{S}/B\\) allows to write</p> \\[   V_1 = V_0 + \\sum \\eta^k \\left(X_1^k - X_0^k\\right) = V_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\] Warning: What about returns, portfolio weights? <p>Very often in finance, the exposition is done in terms of returns and portfolio weights. Talking in terms of returns and weights requires some particular care.</p> <p>It is possible to speak of returns for the financial market as the prices at time \\(0\\) are strictly positive. In other terms, if we define the interest rate \\(r\\) as:</p> \\[ r = \\frac{B_1 - B_0}{B_0}, \\quad \\text{then it holds} \\quad B_1 = B_0(1 + r) \\] <p>Similarly, for the return \\(R_1^k\\) of a financial asset \\(k\\), we define:</p> \\[ R_1^k = \\frac{S_1^k - S_0^k}{S_0^k}, \\quad \\text{then it holds} \\quad S_1^k = S_0^k(1 + R_1^k) \\] <p>Thus, the definition of a financial market as described earlier is equivalent to specifying:</p> <ul> <li>A vector \\(\\boldsymbol{S}_0\\) of strictly positive initial prices.</li> <li>An interest rate \\(r &gt; -1\\), with \\(r \\in \\mathbb{R}\\).</li> <li> <p>A vector \\(\\boldsymbol{R}_1 = (R_1^1, \\ldots, R_1^d)\\) of random returns, where:</p> \\[ R_1^k: \\Omega \\longrightarrow [-1, \\infty), \\quad \\omega \\longmapsto R_1^k(\\omega) \\] <p>for each \\(k = 1, \\ldots, d\\).</p> </li> </ul> <p>It is also possible for a portfolio to speak in terms of holding value rather than number of shares, that is \\(\\boldsymbol{h} = \\boldsymbol{\\eta}\\boldsymbol{S}_0 = (\\eta^1 S_0^1, \\ldots, \\eta^d S_0^d)\\). In this case we can write the portfolio evolution as</p> \\[ \\begin{align*}   \\bar{V_1} &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k\\left(S_1^k - S_0^k (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k S_0^k \\left(\\frac{S_1^k}{S_0^k} - (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum h^k \\left(R_1^k - r\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\boldsymbol{h}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>Now we would like to consider the returns of the portfolio \\((\\bar{V}_1 - \\bar{V}_0)/\\bar{V}_0\\) as well as the portfolio weight \\(\\boldsymbol{w} = \\boldsymbol{h}/\\bar{V_0}\\). Indeed, the portfolio weight in asset \\(k\\) is equal to the asset value holding divided by the portfolio value at time \\(0\\). Following on the previous computation we have</p> \\[ \\begin{align*}   \\frac{\\bar{V}_1 - \\bar{V}_0}{\\bar{V}_0} &amp; = r + \\sum \\frac{h^k}{\\bar{V}_0}\\left(R^k_1 - r\\right)\\\\       &amp; = r + \\boldsymbol{w}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>We get the classical interpretation that the portfolio returns is equal to the risk free rate plus the weighted excess returns in the financial assets. In particular if \\(\\sum w^k = 1\\), meaning that you hold your portfolio entirely in assets, the returns of the portfolio is equal to \\(\\boldsymbol{w}\\cdot \\boldsymbol{R}_1\\).</p> <p>This looks familar and used widely, it is however  mathematically not correct without further assumptions. Consider the following situations where \\(\\bar{V}_0 &lt;0\\) or \\(\\bar{V}_0 = 0\\), returns and weights do not make much sense isn't it?</p> <p>Furthermore, even if you assume that \\(\\bar{V}_0&gt;0\\) (usually \\(\\bar{V}_0 = 1\\)), suppose that you can short, then you may well end-up with a strictly negative or zero portfolio value at time \\(1\\). How would you then compute the portfolio returns between time \\(1\\) and time \\(2\\)?</p> <p>Such a way to look at portfolio returns are consistent mathematically if some strong assumptions are made to garantee that \\(\\bar{V}_0\\) and \\(\\bar{V}_1\\) remain strictly positive (no shorting plus budget constraint for instance). This is the reason why we do not consider during this lecture this kind of approach (portfolio returns or portfolio weights).</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/","title":"Arbitrage and Pricing","text":"<p>A fundamental concept in financial market is the notion of Arbitrage. Consider the following example</p> <p>Example: Arbitrage in a coint toss model</p> <p>Consider the example of a simple coin toss model. Formally:</p> <ul> <li>\\(\\Omega = \\{-1, 1\\}\\)</li> <li>\\(\\mathcal{F} = \\{\\emptyset, \\{1\\}, \\{-1\\}, \\{-1, 1\\}\\}\\)</li> <li> <p>Given \\(0&lt;p&lt;1\\)</p> \\[ P[\\{\\omega\\}] = \\begin{cases}     p &amp; \\text{if } \\omega = 1, \\\\     1-p &amp; \\text{if } \\omega = -1 \\end{cases} \\] </li> </ul> <p>We define for our bank account \\(B_0 = 1\\) and \\(B_1 = 1 + r\\) where \\(r &gt; -1\\). We also consider a single stock with:</p> \\[ S_0 &gt; 0, \\quad S_1(\\omega) = S_0(1 + R(\\omega)) \\] <p>where the return \\(R\\) is given by:</p> \\[ R(\\omega) = \\begin{cases}     u &amp; \\text{if } \\omega = 1, \\\\     d &amp; \\text{if } \\omega = -1 \\end{cases} \\] <p>with \\(d &lt; u\\). We assume that \\(S_1\\) is strictly positive, so \\(d &gt; -1\\).</p> <p>Suppose I enter the market with no money and observe that \\(r \\leq d\\). I borrow \\(\\eta S_0\\) from the bank to buy \\(\\eta&gt;0\\) shares of the stock. At time \\(1\\), the value of my portfolio is:</p> \\[     \\bar{V}_1(\\omega) = -\\eta S_0(1 + r) + \\eta S_1(\\omega) =     \\begin{cases}         \\eta S_0(u - r) &amp; \\text{if } \\omega = 1, \\\\         \\eta S_0(d - r) &amp; \\text{if } \\omega = -1     \\end{cases} \\] <p>Since \\(r \\leq d &lt; u\\), my strategy does not lose money in any cases and I always make a strictly positive gain with probability \\(p&gt;0\\). By scaling this strategy, I could generate unlimited wealth without risk. A similar scenario arises if \\(d &lt; u \\leq r\\), where I could short-sell the stock infinitely.</p> <p>As this example shows, such a market would be dysfunctional. Economically, arbitrageurs would exploit this situation, driving the stock price back within boundaries to eliminate these opportunities. Hence, we require the concept of an arbitrage-free market.</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#arbitrage","title":"Arbitrage","text":"<p>Definition Arbitrage and Arbitrage Free Market</p> <p>A portfolio \\(\\bar{V}\\) with initial value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) is called an arbitrage if</p> \\[ \\begin{equation*}         \\underbrace{P\\left[\\bar{V}_1(\\omega) \\geq \\bar{V}_0(1 + r)\\right] = 1}_{\\text{No downside risk}}\\quad \\text{and}\\quad \\underbrace{P\\left[\\bar{V}_1(\\omega) &gt; \\bar{V}_0(1 + r)\\right] &gt;0}_{\\text{Strict positive gains with strict positive probability}} \\end{equation*} \\] <p>A financial market is call arbitrage free, if there exists no arbitrage.</p> <p>In other words, a self-financing strategy is an arbitrage if it guarantees a net gain at time \\(1\\) in every possible state and a strictly positive gain with nonzero probability.</p> <p>There exists several equivalent way to express arbitrage as the following proposition states</p> <p>Proposition Arbitrage Equivalence</p> <p>The following statements are equivalent:</p> <ol> <li>The financial market admits an arbitrage portfolio.</li> <li> <p>There exists a discounted portfolio \\(V\\) such that:</p> \\[ P\\left[V_1 \\geq V_0\\right] = 1 \\quad \\text{and} \\quad P\\left[V_1 &gt; V_0\\right] &gt; 0 \\] </li> <li> <p>There exists a strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\right] = 1 \\quad \\text{and} \\quad P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0\\right] &gt; 0 \\] </li> </ol> Proof <ol> <li> <p>Equivalence of (i) and (ii):     For a portfolio \\(\\bar{V}\\), \\(\\bar{V}_1 \\geq (1 + r)\\bar{V}_0\\) is equivalent to \\(V_1 \\geq V_0\\) by dividing the inequality by \\(1 + r &gt; 0\\). The same holds for the strict inequality.</p> </li> <li> <p>Equivalence of (ii) and (iii):     For a discounted portfolio \\(V\\), \\(V_1 = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq V_0\\) is equivalent to \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\) by subtracting \\(V_0\\).</p> </li> </ol> Exercise <p>Recall that the returns vector \\(\\boldsymbol{R}_1\\) are defined as</p> \\[     R^k_1 = \\frac{S_1^k - S_0^k}{S_0^k}\\quad \\text{for }k=1, \\ldots, d \\] <p>Show that the following assertions are equivalent:</p> <ol> <li> <p>The financial market admits and arbitrage.</p> </li> <li> <p>There exists \\(\\boldsymbol{h} \\in \\mathbb{R}^d\\) such that:</p> \\[     P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\geq 0 \\right] = 1      \\quad \\text{and} \\quad      P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) &gt; 0 \\right] = 1  \\] </li> </ol>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#pricing-measure","title":"Pricing Measure","text":"<p>As we will consequently see in the Fundamental Theorem of Asset Pricing, another central concept in financial market are pricing measures</p> <p>Definition: Pricing Measure</p> <p>A probability measure \\(P^\\ast\\) is called a pricing measure(1) if:</p> <ol> <li> Also known as a pricing kernel in financial engineering or martingale measure in mathematics.</li> </ol> \\[     E^{P^\\ast}\\left[\\frac{S_1^k}{1 + r}\\right] = S_0^k, \\quad \\text{for } k = 1, \\ldots, d \\] <p>In other words, under a pricing measure the discounted expected value of each asset equals its present price.</p> <p>Remark: Vector notation and equivalent formulations</p> <p>For a vector of random variables \\(\\boldsymbol{Z} = (Z^1, \\ldots, Z^d)\\) and a probability measure \\(Q\\), we denote:</p> \\[ E^Q[\\boldsymbol{Z}] := \\left(E^Q[Z^1], \\ldots, E^Q[Z^d]\\right) \\] <p>In particular, \\(P^\\ast\\) is a pricing measure if:</p> \\[ E^{P^\\ast}\\left[\\frac{\\boldsymbol{S}_1}{1 + r}\\right] = \\boldsymbol{S}_0, \\quad \\text{or equivalently}\\quad E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0 \\] <p>This implies that under a pricing measure, the average return of each financial asset equals the bank's interest rate:</p> \\[ E^{P^\\ast}[R_1^k] = r, \\quad \\text{for every } k = 1, \\ldots, d \\] <p>Lemma</p> <p>Suppose that the financial market admits a pricing measure \\(P^\\ast\\). Then</p> <ol> <li> <p>for every portfolio \\(\\bar{V}\\), it holds</p> \\[     \\bar{V}_0 = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right] \\] </li> <li> <p>for every (discounted) portfolio \\(V\\), it holds</p> \\[     V_0 = E^{P^\\ast}\\left[ V_1 \\right] \\] </li> <li> <p>for every strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\), it holds</p> \\[     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0 \\] </li> </ol> Proof <p>We just show the last assertion, the other two follows directly. Let \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) and \\(P^\\ast\\) be a pricing measure. By definition of \\(P^\\ast\\) and the properties of the expectation, it follows that</p> \\[ \\begin{equation*}     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right]  = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right]= \\sum \\eta^k E^{P^\\ast}\\left[ \\Delta X_1^k  \\right] = \\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right] = 0 \\end{equation*} \\] <p>In the following, we will consider those pricing measures \\(P^\\ast\\) that are equivalent to \\(P\\)(1). By the very definition, it follows in particular that if \\(P^\\ast\\sim P\\) and \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, then </p> <ol> <li> <p>See appendix on probability theory for details and consequence in terms of Radon-Nykodym derivative.</p> <p>Just recalling the definition, a probability measure \\(Q\\) is equivalent to \\(P\\) and denoted by \\(Q\\sim P\\) if</p> \\[P[A] = 0 \\quad \\text{if and only if} \\quad Q[A]=0\\] <p>In other terms the two measures agrees on negligible events.</p> <p>This is however equivalent to</p> \\[P[A] = 1 \\quad \\text{if and only if} \\quad Q[A]=1\\] <p>or</p> \\[P[A] &gt; 0 \\quad \\text{if and only if} \\quad Q[A]&gt;0\\] </li> </ol> \\[ \\begin{equation*} \\begin{cases}   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\quad \\text{is equivalent to } \\quad \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#fundamental-theorem-of-asset-pricing","title":"Fundamental Theorem of Asset Pricing","text":"<p>Fundamental Theorem of Asset Pricing (FTAP)</p> <p>In a financial market, the following conditions are equivalent:</p> <ol> <li>The market is arbitrage-free.</li> <li>There exists at least one pricing measure \\(P^\\ast \\sim P\\) with bounded density \\(dP^\\ast/dP\\).</li> </ol> Proof: (sketch) <ol> <li> <p>Step 1 (easy direction): condition 2. implies 1..     By contradiction, assume that there exists a pricing measure \\(P^\\ast \\sim P\\) and an arbitrage strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). We show that this is not possible.</p> <p>On one hand, having a pricing measure \\(P^\\ast\\) implies that \\(E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0\\). It follows that for the arbitrage strategy \\(\\boldsymbol{\\eta}\\), we have:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right] = 0 \\] <p>On the other hand, since \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, it holds that:</p> \\[ \\begin{cases}   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>Since \\(P^\\ast \\sim P\\), this is equivalent to:</p> \\[ \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>The first line implies that the random variable \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\) is positive \\(P^\\ast\\)-almost surely. The second line indicates that this variable is strictly positive somewhere. Taking the expectation of this strictly positive random variable results in a strictly positive expectation:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 \\] <p>However, this contradicts the earlier result that \\(E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0\\). This shows that 2. implies 1..</p> </li> <li> <p>Step 2 (difficult direction): condition 1. implies 2.. </p> <p>Here, we show that if 1.$ does not hold (i.e., there exists no pricing measure \\(P^\\ast\\) with bounded density), then there exists an arbitrage. To state that there exists no pricing measure \\(P^\\ast\\) with bounded density, consider the set:</p> \\[   \\mathcal{C} = \\left\\{ E^Q[\\Delta \\boldsymbol{X}_1] : Q \\sim P \\text{ and } \\frac{dQ}{dP} \\text{ is bounded} \\right\\} \\] <p>This set includes all vectors of expectations of discounted gains under pricing measures with bounded density \\(Q\\). There exists a pricing measure \\(P^\\ast \\sim P\\) with bounded density if and only if the vector \\(0\\) is in \\(\\mathcal{C}\\). Hence, the condition that 2. does not hold is equivalent to \\(0 \\notin \\mathcal{C}\\).</p> <p>We show that the set \\(\\mathcal{C} \\subseteq \\mathbb{R}^d\\) has the following properties:</p> <ul> <li> <p>Non-emptiness: \\(\\mathcal{C} \\neq \\emptyset\\). Since \\(P \\sim P\\) and \\(\\frac{dP}{dP} = 1\\), it follows that \\(E^P[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C}\\)(1).</p> </li> <li> <p>Note: We never assumed \\(\\boldsymbol{X}_1\\) is integrable under \\(P\\). This can be addressed in the appendix.</p> </li> <li> <p>Convexity: \\(\\mathcal{C}\\) is convex(1).</p> <ol> <li>That is, for any two points \\(\\boldsymbol{x}, \\boldsymbol{y} \\in \\mathcal{C}\\) and any \\(\\lambda \\in [0, 1]\\), the interval \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y}\\) is also in \\(\\mathcal{C}\\).  </li> </ol> <p>By definition, there exist \\(Q^{\\boldsymbol{x}}\\) and \\(Q^{\\boldsymbol{y}}\\) equivalent to \\(P\\) with bounded density such that \\(E^{Q^{\\boldsymbol{x}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{x}\\) and \\(E^{Q^{\\boldsymbol{y}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{y}\\). By the Radon-Nikodym theorem, define:</p> \\[   \\frac{dQ}{dP} = \\lambda \\frac{dQ^{\\boldsymbol{x}}}{dP} + (1 - \\lambda) \\frac{dQ^{\\boldsymbol{y}}}{dP} \\] <p>This \\(dQ/dP\\) is a strictly positive bounded random variable (since \\(dQ^{\\boldsymbol{x}}/dP\\) and \\(dQ^{\\boldsymbol{y}}/dP\\) are) with expectation equal to \\(1\\):</p> \\[   E^P\\left[ \\frac{dQ}{dP} \\right] = \\lambda E^P\\left[ \\frac{dQ^{\\boldsymbol{x}}}{dP} \\right] + (1 - \\lambda) E^P\\left[ \\frac{dQ^{\\boldsymbol{y}}}{dP} \\right] = \\lambda + (1 - \\lambda) = 1 \\] <p>Hence, \\(dQ/dP\\) defines a probability measure \\(Q \\sim P\\) with bounded density, and:</p> \\[   \\boldsymbol{z} = E^Q[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C} \\] <p>Moreover:</p> \\[   \\boldsymbol{z} = \\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\] <p>showing that \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\in \\mathcal{C}\\).</p> </li> </ul> <p>The fact that \\(0 \\notin \\mathcal{C}\\), where \\(\\mathcal{C}\\) is not a convex set, the Hahn-Banach theorem allows to separate with a line (an hyperplane) the point from the convex set.</p> <p> </p> <p>It translates mathematicaly into the existence of a vector \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ \\begin{cases}    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x} \\geq 0 &amp; \\text{for all } \\boldsymbol{x} \\in \\mathcal{C}, \\\\    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x}_0 &gt; 0 &amp; \\text{for some } \\boldsymbol{x}_0 \\in \\mathcal{C}. \\end{cases} \\] <p>By definition of \\(\\mathcal{C}\\), this translates to:</p> \\[ \\begin{cases}    E^Q\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] \\geq 0 &amp; \\text{for all } Q \\sim P \\text{ with bounded } \\frac{dQ}{dP}, \\\\    E^{Q_0}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 &amp; \\text{for some } Q_0 \\sim P \\text{ with bounded } \\frac{dQ_0}{dP}. \\end{cases} \\] <p>The last condition implies that \\(Q_0[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\), and since \\(Q_0\\) is equivalent to \\(P\\), it also implies that </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\] <p>As for the first condition, we claim that it implies </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\] <p>showing then that \\(\\boldsymbol{\\eta}\\) is an arbitrage.</p> <p>To this end, define \\(A = \\{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &lt; 0\\}\\) and consider the sequence of strict positive random variables:</p> \\[   Y_n := \\left( 1 - \\frac{1}{n} \\right)1_A + \\frac{1}{n}1_{A^c} \\] <p>which is bounded by \\(1\\) and satisfies \\(Y_n \\to 1_A\\) \\(P\\)-almost surely. Since \\(Y_n &gt; 0\\), it generates a sequence of probability measures \\(Q_n\\) equivalent to \\(P\\) with bounded densities:</p> \\[   \\frac{dQ_n}{dP} = \\frac{Y_n}{E[Y_n]} \\] <p>Hence</p> \\[   0 \\leq E^{Q_n}\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\right] = \\frac{1}{E[Y_n]} E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right]. \\] <p>Taking the limit (1), it follows that:</p> <ol> <li>To be rigorous you invoke the dominated convergence theorem applied to \\(Y_n\\).</li> </ol> \\[   0 \\leq E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right] \\to E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 1_A\\right] \\] <p>which, by the definition of \\(A\\), shows that \\(P[A] = 0\\). In other words, \\(P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\). Hence, \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, contradicting the assumption of an arbitrage-free market.  </p> <p>Thus, there exists a pricing measure equivalent to \\(P\\) with bounded density, which concludes the proof.</p> </li> </ol> <p>This Theorem is called a theorem and fundamental because it states an if and only if assertion between a somehow economical concept (no arbitrage) and a mathematical concept (the existence of a pricing measure). This statement will have many consequences that will unfold while studying derivative pricing.</p> <p>However, an immediate consequence of which is the so called Law of One Price, often stated as given in finance, yet is a consequence of the FTAP.</p> <p>Theorem: Law of One Price</p> <p>If the market is arbitrage free, then for any two portfolios \\(\\bar{V}\\) and \\(\\tilde{V}\\) with exact same outcome tomorrow, that is</p> \\[   P\\left[ \\bar{V}_1 = \\tilde{V}_1\\right] = 1 \\] <p>the value of each portfolio at time \\(0\\) is the same, that is \\(\\bar{V}_0 = \\tilde{V}_0\\)</p> Proof <p>By the fundamental theorem of asset pricing, no arbitrage is equivalent to the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Let further \\(\\bar{V}\\) and \\(\\tilde{V}\\) be two portfolio such that</p> \\[   P\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>Since \\(P^\\ast \\sim P\\), it follows that</p> \\[   P^\\ast\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>showing that \\(E^{P^\\ast}\\left[ \\bar{V}_1 \\right] = E^{P^\\ast}\\left[ \\tilde{V}_1 \\right]\\).</p> <p>Furthermore, it holds that</p> \\[   \\frac{\\bar{V}_1}{1+r} = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\quad \\text{and}\\quad \\frac{\\tilde{V}_1}{1+r} = \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1 \\] <p>for some \\(\\boldsymbol{\\eta}\\) and \\(\\tilde{\\boldsymbol{\\eta}}\\) in \\(\\mathbb{R}^d\\).</p> <p>Taking expectation under the pricing measure, it follows that</p> \\[ \\begin{align*}   \\bar{V}_0 &amp; = \\bar{V}_0 + \\underbrace{\\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right]}_{=0\\text{ since }P^\\ast \\text{ is a pricing measure}}\\\\   &amp; = E^{P^\\ast}\\left[  \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\tilde{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[  \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = \\tilde{V}_0 \\end{align*} \\] <p>This statement stipulates that if a market is arbitrage free, regardless the portfolio you have in the market, if those deliver the same outcome, then their financing costs has to be the same.</p> <p>The statement of the FTAP seems to be quite abstract, but is has a very easy interpretation in terms of linear algebra when the set of possible states is finite. Indeed, consider the following financial market where </p> <ul> <li>\\(\\Omega = \\{\\omega_1, \\ldots, \\omega_N\\}\\)</li> <li>\\(\\mathcal{F} = 2^\\Omega\\).  </li> <li>\\(P\\) is a probability measure specified by the vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N)\\) where \\(p_i = P[\\{\\omega_i\\}] &gt;0\\) and \\(\\sum p_i =1\\).</li> </ul> <p>We have a bank account with:</p> \\[ B_0 = 1, \\quad B_1 = 1 + r \\] <p>for some \\(r&gt;-1\\).</p> <p>As for the finanical asset, suppose that we have a single one:</p> \\[ S_0 &gt; 0 \\quad \\text{and} \\quad S_1(\\omega_i) = s_i &gt; 0. \\] <p>Up to reordering, we assume that \\(0 &lt; s_1 &lt; s_2 &lt; \\ldots &lt; s_N\\), and denote \\(\\boldsymbol{s} = (s_1, \\ldots, s_N)\\) as the vector of payoffs for \\(S^1\\) at time \\(1\\). </p> <p>Since the state space is finite, any expectation of the asset price can be written as</p> \\[ \\begin{equation*}   E^{Q}\\left[ S_1 \\right] = \\boldsymbol{s}\\cdot \\boldsymbol{q} \\end{equation*} \\] <p>where \\(\\boldsymbol{q} = (q_1, \\ldots, q_N)\\) represent a probability equivalent to \\(P\\) if and only if \\(q_i&gt;0\\) for every \\(i\\).</p> <p>Hence the  market is arbitrage-free if and only if</p> \\[ (1 + r)S_0 \\in \\left\\{\\boldsymbol{s} \\cdot \\boldsymbol{q} \\colon \\boldsymbol{q} \\in \\mathbb{R}^d, \\sum q_i =1 , \\; q_i &gt; 0 \\text{ for every } i\\right\\} = (s_1, s_N) \\] <p>This means the market is arbitrage-free if and only if the following system of equations:</p> \\[ \\begin{cases}     q_1 s_1 + \\cdots + q_n s_n = (1 + r)S_0 \\\\     q_1 + \\cdots + q_n = 1 \\\\     q_i &gt; 0 &amp; \\text{for all } i \\end{cases} \\] <p>admits at least one solution.  </p> <p>If a solution exists, it is unique if and only if \\(N = 2\\).</p> <p>If you extend to several assets \\(d\\), then you will end up with \\(d+1\\) equations in the system.  If a solution exists then it is unique if and only if \\(N = d+1\\)</p>"},{"location":"lecture/01-One-Period/013-derivative-securities/","title":"Derivative Securities","text":"<p>A contingent claim is a contract between a seller and a buyer where the seller agrees to deliver a certain payoff at a future time. A contingent claim is called a derivative if this contract is written as a payoff depending on some underlying, such as stocks, bonds, indices, portfolios, or funds. Options are specific derivatives characterized by parameters like strike price and expiration date. While definitions may vary, the mathematical interpretation remains consistent.</p> <p>Examples of Derivatives</p> <p>In the presentation of the different derivatives we consider a financial market with a generic asset \\(S\\).</p> <ul> <li> <p>Forward/Future Contract</p> <p>A forward contract is an agreement between two parties to buy or sell an asset \\(S\\) at a future time for a price \\(K\\) fixed today. The payoff for the contract owner is determined by the difference between the asset price and the agreed price:  </p> \\[     C^{fw} = S - K \\] </li> <li> <p>Forward Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>European Put/Call Option</p> <p>A European Call or Put option grants the right, but not the obligation, to buy or sell an asset \\(S\\) at a future time for a strike price \\(K\\) fixed today.       The payoff is</p> \\[     \\begin{align*}       C^{call} &amp; = (S - K)^+                 =     \\begin{cases}       S - K &amp; \\text{if } S \\geq K, \\\\       0 &amp; \\text{otherwise}.     \\end{cases}\\\\     C^{put} &amp; = (K - S)^+              =     \\begin{cases}       K - S &amp; \\text{if } K \\geq S, \\\\       0 &amp; \\text{otherwise}.     \\end{cases}     \\end{align*} \\] <p>European call and put options are related by the formula </p> \\[   C^{call} - C^{put} = S - K \\] </li> <li> <p>European Call/Put Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>Straddle Option</p> <p>The goal of a straddle option is to profit from significant price movements of the underlying asset, regardless of the direction. It grants the right to get the price deviation (positive or negative) of the underlying asset with respect to a strike \\(K\\).</p> <p>The payoff is:</p> \\[   C^{straddle} = |S - K| =   \\begin{cases}     S-K &amp; \\text{ if } S\\geq K\\\\     K-S &amp; \\text{ if } S &lt;K   \\end{cases} \\] <p>Note that a straddle option is equivalent to holding a call and a put option with the same strike.</p> \\[   C^{straddle}(K) = C^{call}(K) + C^{put}(K) \\] </li> <li> <p>Straddle Option Payoff</p> <p> </p> </li> </ul> <ul> <li> <p>Butterfly Option</p> <p>A butterfly option has somehow the counter effect to a straddle option in the sense that it is designed to profit from price movement around a given target \\(K\\) within an interval \\(\\underline{K} &lt; K &lt;\\overline{K}\\).</p> <p>The payoff is:</p> \\[   C^{butterfly} =    \\begin{cases}     0 &amp; \\text{if }S&lt;\\underline{K} \\text{ or }S&gt;\\overline{K}\\\\     S-\\underline{K} &amp; \\text{if } \\underline{K}\\leq S\\leq K\\\\     \\overline{K} - S &amp; \\text{if } K&lt;S \\leq \\overline{K}   \\end{cases} \\] <p>Note that such a straddle option can also be written as a combination of put and call options strikes</p> \\[   C^{butterfly}(\\underline{K}, K, \\overline{K}) = C^{call}(\\underline{K}) + C^{call}(\\overline{K}) - 2 C^{call}(K) \\] <p>Usually, the strike \\(K\\) is at the mid point between \\(\\underline{K}\\) and \\(\\overline{K}\\).</p> </li> <li> <p>Butterfly Option Payoff</p> <p> </p> </li> </ul> <p>Note that each of these options can be expressed as \\(f(S)\\), where \\(S\\) is the underlying asset, and \\(f: \\mathbb{R} \\to \\mathbb{R}\\) is some continuous function.</p> <p>Definition: Contingent Claim</p> <ul> <li> <p>A contingent claim \\(C\\) is a positive random variable.(1)</p> <ol> <li>In a strictly more general sense it does not need to be strictly positive but usually bounded from below. See for instance forward contracts.</li> </ol> </li> <li> <p>A derivative \\(C\\) is a contingent claim that depends only on the information provided by the underlying on which it is written.     In other terms, \\(C = f(\\boldsymbol{S}_1)\\) for some continuous function \\(f:\\mathbb{R}^d \\to [0, \\infty)\\).(1)</p> <ol> <li>In a more general fashion, it means that \\(C\\) is \\(\\sigma(\\boldsymbol{S}_1)\\)-measurable, which with some proof work can be shown to be equivalent to \\(C = f(\\boldsymbol{S}_1)\\) for some measurable function \\(f\\).</li> </ol> </li> </ul>"},{"location":"lecture/01-One-Period/013-derivative-securities/#pricing-a-contingent-claim","title":"Pricing a Contingent Claim","text":"<p>Given a contingent claim \\(C\\), the goal is to determine a fair price \\(\\pi(C)\\) at which it can be sold. To do this, we analyze the situation from the seller's perspective:</p> <ol> <li> <p>Time 0:      The seller receives \\(\\pi(C)\\) and deposits it into their bank account. This amount is used to invest in a strategy \\(\\boldsymbol{\\eta}\\) in \\(\\mathbb{R}^d\\).     The holdings in the bank account become \\(\\pi(C) - \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0\\) and the golding in assets becomes \\(\\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0\\).     The initial portfolio value is \\(\\bar{V}_0(\\boldsymbol{\\eta}) = \\pi(C)\\).</p> </li> <li> <p>Time 1:     The seller delivers the payoff \\(C\\) to the buyer while benefiting from their investment strategy \\(\\boldsymbol{\\eta}\\).     The discounted portfolio value minus the discounted payoff is:</p> \\[   V_1(\\boldsymbol{\\eta}) - \\frac{C}{1 + r} = \\pi(C) + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 - \\frac{C}{1 + r} \\] </li> </ol> <p>In an ideal situation, the seller of the option would like to get out with gains without downside risk, that is, fully hedge the position. Hence, the seller aims to ensure:</p> \\[ \\pi(C) + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}  \\] <p>Such a price \\(\\pi(C)\\) together with the smart strategy \\(\\boldsymbol{\\eta}\\) means that the seller super hedge his position. Considering all the possible prices and smart strategies that super hedge the position allows to define the lowest price at which the seller is willing to sell the option without taking risk, the super-hedging price</p> \\[ \\bar{\\pi}(C) = \\inf \\left\\{ x \\in \\mathbb{R} : x + \\boldsymbol{\\eta} \\cdot \\Delta\\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}, \\; \\text{for some } \\boldsymbol{\\eta} \\in \\mathbb{R}^d \\right\\}. \\] <p>Conversely, the buyer's perspective leads to the sub-hedging price, \\(\\underline{\\pi}(C)\\):</p> \\[ \\underline{\\pi}(C) = \\sup \\left\\{ y \\in \\mathbb{R} : y + \\boldsymbol{\\nu} \\cdot \\Delta\\boldsymbol{X}_1 \\leq \\frac{C}{1 + r}, \\; \\text{for some } \\boldsymbol{\\nu} \\in \\mathbb{R}^d \\right\\}. \\] <p>It seems economically reasonable that prices \\(y\\) from the buyer sub-hedging their position should be lower than the prices \\(x\\) of the seller super-hedging their positions. This is however true if the market is arbitrage free as seen in the subsequent proposition.</p> <p>To simplify our exposition, let us provide the notation for pricing measures</p> \\[ \\mathcal{P}^\\ast := \\left\\{ P^\\ast \\sim P \\colon E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right] = 0 \\text{ and } dP^\\ast/dP \\text{ is bounded}\\right\\} \\] <p>In particular, the FTAP can be formulated as \"The market is arbitrage free if and only if \\(\\mathcal{P}^\\ast\\) is not empty\".</p> Remark: Geometric Interpretation I <p>Define \\(I\\) and \\(J\\) as the set of super- and sub-hedging prices, respectively:</p> \\[ \\begin{align*}     I &amp; := \\left\\{ x \\in \\mathbb{R}\\colon x+\\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}\\text{ for some smart strategy }\\boldsymbol{\\eta} \\in \\mathbb{R}^d \\right\\}\\\\     J &amp; := \\left\\{ y \\in \\mathbb{R}\\colon y+\\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r}\\text{ for some smart strategy }\\boldsymbol{\\nu} \\in \\mathbb{R}^d \\right\\}\\\\ \\end{align*} \\] <p>For which holds \\(\\bar{\\pi}(C) = \\inf I\\) and \\(\\underline{\\pi}(C) = \\sup J\\).</p> <p>These two sets, \\(I\\) and \\(J\\), are eventually intervals</p> <p>Lemma</p> <ul> <li>\\(I\\) is either an interval of the form \\([\\bar{\\pi}(C), \\infty)\\) or \\((\\bar{\\pi}(C), \\infty)\\)</li> <li>\\(J\\) is either an interval of the form \\((-\\infty, \\underline{\\pi}(C)]\\) or \\((-\\infty, \\underline{\\pi}(C))\\)</li> </ul> <p>Proof</p> <p>We show only the first assertion, the second follows the same argumentation. Clearly \\(\\bar{\\pi}(C)\\) is the lower bound of the set \\(I\\), whether or not it is a minimum or an infimum. We just have to show that for any \\(x\\) in \\(I\\), if \\(m&gt;0\\), then \\(x+m\\) is also in \\(I\\). This follows however from the definition, as for a smart strategy \\(\\boldsymbol{\\eta}\\) such that</p> \\[x + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}\\] <p>It follows immediately that </p> \\[x +m + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\geq m +\\frac{C}{1+r} \\geq \\frac{C}{1+r}\\] <p>showing that \\(x+m\\) is in \\(I\\).</p> <p>We are now in position to show the first proposition regarding the super- and sub-hedging price</p> <p>Proposition</p> <p>If the market is arbitrage free, then for any super-hedging price \\(x\\), sub-hedging price \\(y\\) and any pricing measure \\(P^\\ast\\) it holds</p> \\[     y \\leq E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] \\leq x \\] <p>In particular, we get</p> \\[     \\underline{\\pi}(C) \\leq \\inf_{P^\\ast \\in \\mathcal{P}^\\ast} E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right]\\leq \\sup_{P^\\ast \\in \\mathcal{P}^\\ast} E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right]\\leq \\bar{\\pi}(C) \\] Proof <p>Let \\(x\\) be a super-hedging price and \\(y\\) be a sub-hedging price. By definition, there exists smart strategies \\(\\boldsymbol{\\eta}\\) and \\(\\boldsymbol{\\nu}\\) in \\(\\mathbb{R}^d\\) such that</p> \\[     y + \\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\leq x + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\] <p>Now, since the market is arbitrage free, according to the FTAP, for any pricing measure \\(P^\\ast\\) in \\(\\mathcal{P}^\\ast\\) which is not empty, by taking expectation of this inequality, it holds</p> \\[     y + \\underbrace{E^{P^\\ast}\\left[\\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1\\right]}_{=0} \\leq E^{P^\\ast}\\left[\\frac{C}{1+r} \\right]\\leq x + \\underbrace{E^{P^\\ast}\\left[\\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1\\right]}_{=0} \\] <p>showing the first assertion.</p> <p>Since this inequality holds for any super hedging price \\(x\\), any sub hedging price \\(y\\) and any pricing measure \\(P^\\ast\\), by the definition of \\(\\bar{\\pi}(C)\\) and \\(\\underline{\\pi}(C)\\) the second assertion follows.</p> <p>We however still need to define the notion of of a fair price for a contingent claim and how it relates to the super-/sub-hedging price.</p> <p>Definition: Fair Price of Contingent Claims</p> <p>Given a contingent claim \\(C\\), a price \\(\\pi(C)\\) is called a fair price if the original financial market extended with the new financial instrument \\(S^{d+1}\\) given by</p> \\[   S^{d+1}_0 = \\pi(C) \\quad \\text{and}\\quad S^{d+1}_1 = C \\] <p>is arbitrage free.</p> <p>We denote by \\(\\Pi(C)\\) the set of all possible fair prices for the contingent claim \\(C\\).</p> <p>In other terms, if the financial market considers the new financial instrument \\(C\\) traded at price \\(\\pi(C)\\) it remains arbitrage free. As pendant to the super- and sub-hedging price, with the help of the FTAP we can connect arbitrage free prices to pricing measures as follows.</p> <p>Proposition</p> <p>Let \\(C\\) be a contingent claim on an arbitrage-free financial market. Then the set of fair prices for the contingent claim \\(C\\) is non-empty and given by:</p> \\[   \\Pi(C) := \\left\\{ E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] : P^\\ast \\sim P \\text{ pricing measure with bounded density}  \\right\\}. \\] Proof <p>A price \\(\\pi(C)\\) for \\(C\\) is fair if the extended financial market is arbitrage-free. By the FTAP, it follows that there exists a pricing measure \\(\\hat{P}\\) equivalent to \\(P\\) with bounded density such that:</p> \\[     E^{\\hat{P}}\\left[\\frac{\\boldsymbol{S}_1}{1+r}\\right] = \\boldsymbol{S}_0, \\quad \\text{and} \\quad E^{\\hat{P}}\\left[\\frac{C}{1+r}\\right] = \\pi(C). \\] <p>In particular, \\(\\hat{P}\\) is a pricing measure equivalent to \\(P\\) for the smaller market \\(\\boldsymbol{S}\\), that is, an element of \\(\\mathcal{P}^\\ast\\), showing that:</p> \\[     \\Pi(C) \\subseteq \\{ E^{P^\\ast}[C/(1+r)] : P^\\ast \\in \\mathcal{P}^\\ast \\}. \\] <p>Reciprocally, let \\(\\pi(C)\\) be an element of \\(\\{ E^{P^\\ast}[C/(1+r)] : P^\\ast \\in \\mathcal{P}^\\ast \\}\\). It follows that \\(\\pi(C) = E^{P^\\ast}[C/(1+r)]\\) for some \\(P^\\ast \\sim P\\) with bounded density. Hence, \\(P^\\ast\\) is a pricing measure equivalent to \\(P\\) for the extended market, showing by the FTAP that the extended market is arbitrage-free. Hence, \\(\\pi(C) \\in \\Pi(C)\\), proving the reverse inclusion.(1)</p> <ol> <li> <p>The proof is not fully complete unless we can show that we can show that \\(\\Pi(C)\\) is non-empty.     As done previously, we pick a probability measure \\(\\tilde{P}\\) equivalent to \\(P\\) such that \\(E^{\\tilde{P}}[C] &lt; \\infty\\). Under \\(\\tilde{P}\\), the market is arbitrage-free.     The FTAP guarantees the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\) with bounded density.      In particular, \\(E^{P^\\ast}[C] &lt; \\infty\\), and therefore:</p> \\[     \\pi(C) = E^{P^\\ast}[C/(1+r)] \\in \\Pi(C). \\] </li> </ol> <p>We are now in place to show the relation ship between super- sub-hedging prices, pricing measures and fair prices. In a nuttshell that the following illustration holds</p> <p> </p> <p>Theorem: Super/Sub Hedging and Fair Prices</p> <p>Let \\(C\\) be a contingent claim. For</p> \\[     \\begin{align*}         J &amp; = \\left\\{ y\\in \\mathbb{R}\\colon y + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\text{ for some }\\boldsymbol{\\eta}\\in \\mathbb{R}^d \\right\\} &amp;&amp; \\text{Risk free subhedging prices}\\\\         \\underline{\\pi}(C) &amp; = \\sup J &amp;&amp; \\text{Sub-hedging price}\\\\         I &amp; = \\left\\{ x\\in \\mathbb{R}\\colon x + \\boldsymbol{\\nu}\\cdot \\Delta \\boldsymbol{X}_1 \\leq \\frac{C}{1+r} \\text{ for some }\\boldsymbol{\\nu}\\in \\mathbb{R}^d \\right\\} &amp;&amp; \\text{Risk free superhedging prices}\\\\         \\underline{\\pi}(C) &amp; = \\inf I &amp;&amp; \\text{Super-hedging price}\\\\         \\Pi(C) &amp; = \\left\\{ \\pi(C)\\colon \\text{fair prices} \\right\\} &amp;&amp; \\text{Fair prices}\\\\         \\mathcal{P}^\\ast &amp; = \\left\\{ P^\\ast \\sim P \\colon P^\\ast \\text{ is a pricing measure} \\right\\} &amp;&amp; \\text{Pricing measures}     \\end{align*} \\] <p>If the market is arbitrage free, then it holds that \\(J\\), \\(I\\), and \\(\\Pi(C)\\) are intervals such that \\(J\\leq \\Pi(C) \\leq I\\). Furthermore </p> \\[     \\begin{align*}         J &amp; = (-\\infty, \\underline{\\pi}(C)] &amp;         \\Pi(C) &amp; = \\left\\{ E^{P^\\ast}\\left[ \\frac{C}{1+r} \\right] \\colon P^\\ast \\in \\mathcal{P}^\\ast \\right\\} &amp;         I &amp; = [\\overline{\\pi}(C), \\infty )      \\end{align*} \\] <p>and</p> \\[     \\begin{align*}         \\underline{\\pi}(C) &amp; = \\inf \\Pi(C) &amp; \\overline{\\pi}(C) &amp; = \\sup \\Pi(C)     \\end{align*} \\] Proof <p>We already saw that \\(J\\) and \\(I\\) are intervals (see geometric interpretation remark above). We also say that \\(\\Pi(C) = \\{E^{P^\\ast}[C/(1+r)]\\colon P^\\ast \\in \\mathcal{P}^\\ast\\}\\) and that \\(J \\leq \\Pi(C) \\leq I\\). The fact that \\(\\Pi(C)\\) is also an interval follows directly from \\(\\mathcal{P}^\\ast\\) is a convex set, same argumentation as for \\(\\mathcal{C}\\) in the proof of the FTAP.</p> <p>We are left to show that \\(\\underline{\\pi}(C) \\in J\\) and \\(\\overline{\\pi}(C) \\in I\\) and that \\(\\underline{\\pi}(C) = \\inf \\Pi(C)\\) as well as \\(\\overline{\\pi}(C)  = \\sup \\Pi(C)\\).</p> <p>Let us proove that \\(\\overline{\\pi}(C) = \\sup \\Pi(C)\\). We already know that \\(\\overline{\\pi}(C) \\geq \\sup \\Pi(C)\\) Suppose \\(\\sup \\Pi(C) &lt; \\infty\\), otherwise the equality is trivial. Let \\(m &gt; \\sup \\Pi(C)\\). By definition, the market extended with \\((m, C)\\) admits an arbitrage opportunity. That is, there exist \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) and \\(\\mu \\in \\mathbb{R}\\) such that:</p> \\[     \\begin{cases}         P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right) \\geq 0\\right] = 1, \\\\         P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right) &gt; 0\\right] &gt; 0.     \\end{cases} \\] <p>Since the original market is arbitrage-free, it follows that \\(\\mu \\neq 0\\). Taking the expectation of the positive random variable \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 + \\mu \\left(\\frac{C}{1+r} - m\\right)\\) with respect to \\(P^\\ast \\in \\mathcal{P}^\\ast\\) yields:</p> \\[     \\mu E^{P^\\ast}\\left[\\frac{C}{1+r} - m\\right] \\geq 0. \\] <p>By definition of \\(m\\), this implies \\(\\mu &lt; 0\\). Defining \\(\\boldsymbol{\\nu} = -\\boldsymbol{\\eta}/\\mu \\in \\mathbb{R}^d\\) yields:</p> \\[     m + \\boldsymbol{\\nu} \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}, \\] <p>showing that \\(m\\) is in \\(I\\), and therefore \\(m \\geq \\bar{\\pi}(C)\\). Consequently:</p> \\[     \\sup \\Pi(C) \\geq \\bar{\\pi}(C). \\] <p>The same argumentation shows that \\(\\overline{\\pi}(C) = \\inf \\Pi(C)\\).</p> Warning, the last part of the assertion calls for compactness arguments <p>We are left to show that \\(\\overline{\\pi}(C)\\) is in \\(I\\). Without loss of generality, due to the law of one price, we may assume that there is no redundancy; that is, \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 = 0\\) implies \\(\\boldsymbol{\\eta} = 0\\).  </p> <p>Pick a sequence \\((m_n)\\) of elements in \\(I\\) such that \\(m_n \\downarrow \\overline{\\pi}(C)\\) and denote by \\(\\boldsymbol{\\eta}^n\\) the corresponding sequence of strategies such that:</p> \\[     m_n + \\boldsymbol{\\eta}^n \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1 + r}. \\] <p>If \\((\\boldsymbol{\\eta}^n)\\) is bounded, up to a subsequence, we may assume that \\(\\boldsymbol{\\eta}^n \\to \\boldsymbol{\\eta} \\in \\mathbb{R}^d\\), for which it holds:</p> \\[     \\frac{C}{1 + r} \\leq m_n + \\boldsymbol{\\eta}^n \\cdot \\Delta \\boldsymbol{X}_1 \\to \\bar{\\pi}(C) + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1, \\] <p>showing that \\(\\bar{\\pi}(C)\\) is in I.</p> <p>If \\(\\lim \\|\\boldsymbol{\\eta}^n\\| = \\infty\\), up to a subsequence, it follows that \\(\\boldsymbol{\\eta}^n / \\|\\boldsymbol{\\eta}^n\\| \\to \\boldsymbol{\\mu}\\) with \\(\\|\\boldsymbol{\\mu}\\| = 1\\).</p> <p>However, it follows that:</p> \\[     0 \\leq \\lim \\frac{C}{\\|\\boldsymbol{\\eta}^n\\|(1 + r)} = \\lim \\frac{\\boldsymbol{\\eta}^n}{\\|\\boldsymbol{\\eta}^n\\|} \\cdot \\Delta \\boldsymbol{X}_1 + \\frac{m_n}{\\|\\boldsymbol{\\eta}^n\\|} = \\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_1 \\] <p>Since the market is arbitrage-free, it must follow that \\(\\boldsymbol{\\mu} \\cdot \\Delta \\boldsymbol{X}_1 = 0\\), which by the non-redundancy assumption implies \\(\\boldsymbol{\\mu} = 0\\), leading to a contradiction since \\(\\|\\boldsymbol{\\mu}\\| = 1\\).</p> <p>Definition</p> <p>A contingent claim \\(C\\) is called replicable \u2014 attainable, hedgeable, or redundant \u2014 if there exists a portfolio with start value \\(\\bar{V}_0\\) and strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[     C = \\bar{V}_1 = \\bar{V}_0 + \\boldsymbol{\\eta} \\cdot \\left(\\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r)\\right). \\] <p>In other term, a contingent claim is replicable if its outcome can be fully attained by a self financing portfolio.</p> <p>Proposition</p> <p>Let \\(C\\) be a contingent claim in an arbitrage-free market. Then:</p> <ul> <li> <p>\\(C\\) is replicable if and only if \\(\\overline{\\pi}(C) = \\underline{\\pi}(C)\\) which is the unique price of the contingent claim</p> </li> <li> <p>If \\(C\\) is not replicable, then \\(\\overline{\\pi}(C) &gt; \\underline{\\pi}(C)\\), and:</p> </li> </ul> \\[     \\Pi(C) = \\left(\\overline{\\pi}(C), \\underline{\\pi}(C)\\right). \\] Proof <p>Clearly, if \\(C\\) is replicable, it follows that \\(\\underline{\\pi}(C) = \\overline{\\pi}(C)\\) by the definition of \\(\\underline{\\pi}\\) and \\(\\overline{\\pi}\\). The reciprocal follows from the second assertion. To prove the second assertion:</p> <ol> <li>\\(\\Pi(C)\\) is an interval</li> <li> <p>Non-replicability implies that \\(\\bar{\\pi}(C) \\not\\in \\Pi(C)\\):     Indeed, by the previous theorem, there exists a strategy \\(\\boldsymbol{\\eta}\\) such that:</p> \\[     \\bar{\\pi}(C) + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq \\frac{C}{1+r}. \\] <p>Since \\(C\\) is not replicable, this inequality cannot hold with equality \\(P\\)-almost surely. This demonstrates \\(\\bar{\\pi}(C) \\not\\in \\Pi(C)\\).</p> </li> </ol> <p>Since \\(\\overline{\\pi}(C) = \\sup \\Pi(C)\\), it follows that \\(\\Pi(C)\\) forms an open interval:</p> \\[     \\Pi(C) = \\left(\\underline{\\pi}(C), \\overline{\\pi}(C)\\right) \\] <p>A condition that garantees that every contingent claim is replicable and henceforth with a unique price is when \\(\\mathcal{P}^\\ast\\) contains a unique pricing measure. In such a market every contingent claim is uniquely priced and hedgable. In other terms every contingent claim in a complete financial market is redundant since they can all be achieved by a portfolio. A market with a unique pricing measure is called a complete market</p> <p>On the other hand, the proposition shows that unless the claim is attainable, then fair prices of a contingent claim are not unique. The choice of a fair price (and therefore a deal) for such a contingent claim is henceforth due to an agreement between the buyer and the seller to choose a price within the interval \\(\\Pi(C)\\). Therefore, they both have to accept some downside risk since neither will have a price in their confort risk free zone.</p> <p>Example: Forward Contract</p> <p>Recall that forward contract are contingent claims of the form(1)</p> <ol> <li>Note first that forward contract are not necessarily positive random variable, but usually for contingent claims we can assume that they are greater than some constant.</li> </ol> \\[   C^{fw}(K) = S_1 - K  \\] <p>Suppose that our market is arbitrage free and choose any pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Taking expectation of the the discounted value of the contingent claim yields</p> \\[   E^{P^\\ast}\\left[ \\frac{C^{fw}}{1+r} \\right] = E^{P^\\ast}\\left[ \\frac{S_1}{1+r} \\right] - \\frac{K}{1+r} = S_0 - \\frac{K}{1+r} \\] <p>showing that the fair price of the forward contract is unique. It is not surpising as the payoff can be immediately replicated by a portfolio.</p> <p>However in financial markets, people speaks and quote the so called forward price. The definition of a forward price \\(F\\) is the value of the strike \\(K\\) such that the fair price of the forward contract is equal to \\(0\\). In other term, the forward price \\(F\\) is given by</p> \\[   F = (1+r) S_0 \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#european-call-and-put-options","title":"European Call and Put Options","text":"<p>The European call and put options are ubiquitous in finance as the most simple types of options.</p> <p>Recall the payoff of such options</p> \\[ \\begin{align*}   C^{call}(K) &amp; = (S_1-K)^+ &amp;    C^{put}(K) &amp; = (K-S_1)^+ \\end{align*} \\] <p>We suppose that the market is arbitrage free and denote with \\(\\pi^{call}(K)\\) and \\(\\pi^{put}(K)\\) the fair prices for each option.</p> <p>Since both prices are fair, there exists a pricing measure \\(P^\\ast \\sim P\\) in the extended market where those two options are traded together with the underlying. It holds in particular that</p> \\[ \\pi^{call}(K) = E^{P^\\ast}\\left[ \\frac{(S_1 - K)^+}{1+r} \\right] \\quad \\text{and}\\quad \\pi^{put}(K) = E^{P^\\ast}\\left[ \\frac{(K - S_1)^+}{1+r} \\right] \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#put-call-parity","title":"Put Call Parity","text":"<p>Using the fact that \\((S_1-K)^+ - (K-S_1)^- = S_1-K\\) we can derive the so called put/call parity by taking expectation under \\(P^\\ast\\):</p> \\[ \\pi^{call}(K) - \\pi^{put}(K) =  E^{P^\\ast}\\left[\\frac{(S_1-K)^+ - (K-S_1)^+}{1+r}\\right] = E^{P^\\ast}\\left[ \\frac{S_1-K}{1+r} \\right] = S_0 - \\frac{K}{1+r} \\] <p>Put Call Parity</p> \\[   \\pi^{call}(K) - \\pi^{put}(K) = S_0 - \\frac{K}{1+r} \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#universal-price-bounds","title":"Universal Price Bounds","text":"<p>In an arbitrage free market, let \\(\\pi^{call} = E^{P^\\ast}[C^{call}/(1+r)]\\) be any fair price for this call option. We are interested at providing bounds for the fair price of this call option.</p> <p>On the one hand, it holds that \\(S-K \\leq (S-K)^+\\). Taking the expectation under \\(P\\) of the discounted value of this inequality together with the fact that \\(\\pi^{call} \\geq 0\\) yields</p> \\[   \\left(S_0 - \\frac{K}{1+r}\\right)^+ \\leq \\pi \\] <p>On the other hand, it holds that \\((S_1-K)^+ \\leq S_1\\), taking expectation of the discounted value of this inequality yields</p> \\[     \\pi^{call} \\leq S_0 \\] <p>showing the universal bounds for call options \\((S_0 - K/(1+r))^+ \\leq \\pi{call}\\leq S_0\\) for any fair price for the call.</p> <p>Using put call parity, for any fair price for the put \\(\\pi^{put}\\) it holds that \\(K/{1+r}\\geq \\pi^{put}\\geq (S_0-K/(1+r))^+ + K/(1+r) - S_0 = (K/(1+r) - S_0)^+\\).</p> <p>Universal Price Bounds</p> \\[   \\begin{equation*}   \\begin{cases}      \\left( S_0 -\\frac{K}{1+r} \\right)^+ \\leq \\underline{\\pi}\\left( C^{call}(K) \\right) \\leq \\overline{\\pi}\\left( C^{call}(K) \\right)\\leq S_0\\\\       \\\\       \\frac{K}{1+r} \\leq \\underline{\\pi}\\left( C^{put}(K) \\right) \\leq \\overline{\\pi}\\left( C^{put}(K) \\right)\\leq \\left( \\frac{K}{1+r} - S_0 \\right)^+   \\end{cases}   \\end{equation*} \\]"},{"location":"lecture/01-One-Period/013-derivative-securities/#jargon","title":"Jargon","text":"<p>A lot of jargon is connected to these options.</p> <ul> <li> <p>Intrinsic Value: The intrinsic value of the option is the value if it were executed now, that is</p> \\[IV^{call} = (S_0-K)^+ \\quad \\text{and}\\quad IV^{put} = (K-S_0)^+\\] </li> <li> <p>In/At/Out of the Money: An option is called in the money if its intrinsic value is strictly positive, at the money if the underlying price equal the strike, out of the money if the intrinsic value is \\(0\\) and the underlying price is not equal to the strike.</p> </li> <li> <p>Moneyness: Moneyness is a concept that has no rigorous definition but stems from a particular property of the call/put option, the positive homogeneity of their payoff, that it \\((\\lambda x)^+ = \\lambda x^+\\) for any \\(\\lambda &gt;0\\).</p> <p>We can therefore normalize the payoff of options by either \\(K\\), \\(S_0\\) or \\(K/(1+r)\\), etc. Most of those normalizations are brought in connection with the resulting Black-Scholes-Merton formula, but let us stress some aspects of this definition. The simple version of moneyness is related to the intrinsic value of the option. In the case of a call, we can normalize by the strike where the simple spot moneyness is defined as \\(S_0/K\\). Indeed, it holds</p> \\[   \\pi^{call}(K) = K E^{P^\\ast}\\left[ \\frac{1}{1+r}\\left( \\frac{S_1}{K} - 1 \\right)^+ \\right]  \\] <p>The intrinsic value of the normalize option in the inner part of the expectation is \\((S_0/K-1)^+\\) and therefore is in the money iff the simple (call) spot moneyness is greater than one and out of the money otherwise.</p> <p>In the case of the put option we normalize by the current underlying price \\(S_0\\), that is, the simple spot moneyness is defined as \\(K/S_0\\):</p> \\[   \\pi^{put}(K) = S_0 E^{P^\\ast}\\left[ \\frac{1}{1+r}\\left(\\frac{K}{S_0}- \\frac{S_1}{S_0} \\right)^+ \\right]  \\] <p>The intrinsic value of this normalized option in the inner part of the expectation is \\((K/S_0 -1)^+\\) which is positive iff the simple (put) spot moneyness is greater than one and out of the money otherwise.</p> <p>Since those definition is rather confusing, always rely on your mathematical knowledge about what each should mean.</p> </li> </ul>"},{"location":"lecture/02-risk-management/021-what-is-risk/","title":"What is Risk","text":"<p>Even if the notion of risk is colloquial and everyone intuitively understands it, it is far from clear what it is the exact definition.</p> <p>We saw in the previous chapter how to price contingent claims in a \"risk-neutral way\" ensured by an arbitrage-free financial market. However, such pricing does not tell us much about the amount of \"risk\" one undertakes when investing in one product or another.</p> <p>Let us consider the following example.</p> <p>Example</p> <p>Let \\(\\Omega=\\{\\omega_1,\\omega_2,\\omega_3\\}\\), \\(\\mathcal{F}=2^\\Omega\\), and the \"objective probability\" measure \\(P\\) given by \\(P[\\{\\omega_1\\}]=0.1\\), \\(P[\\{\\omega_2\\}]=0.85\\), and \\(P[\\{\\omega_3\\}]=0.05\\). Our bank account \\(B_0=1\\) and \\(B_1=(1+r)\\). We have two stocks with the same start price \\(S_0^1=S_0^2=100\\) and prices tomorrow:</p> \\[ S_1^1(\\omega)= \\begin{cases}     110 &amp; \\text{if } \\omega = \\omega_1 \\\\     105 &amp; \\text{if } \\omega = \\omega_2 \\\\     100 &amp; \\text{if } \\omega = \\omega_3 \\end{cases} \\quad \\text{and} \\quad S_1^2(\\omega)= \\begin{cases}     160 &amp; \\text{if } \\omega = \\omega_1 \\\\     110 &amp; \\text{if } \\omega = \\omega_2 \\\\     0   &amp; \\text{if } \\omega = \\omega_3 \\end{cases} \\] <p>Simple computation shows that for \\(r=\\frac{1}{15} \\approx 6.66\\%\\), there exists a unique risk-neutral pricing measure \\(P^\\ast\\) given by:</p> \\[ P^\\ast[\\{\\omega_1\\}] = p_1^\\ast = \\frac{2}{3}, \\quad P^\\ast[\\{\\omega_3\\}] = p_3^\\ast = \\frac{1}{3}, \\quad \\text{and} \\quad P^\\ast[\\{\\omega_2\\}] = p_2^\\ast = 0 \\] <p>Now, as a portfolio manager, you face the dilemma of which stock you would choose or what proportion you would allocate to one or the other. If the only rationale underlying your decision process is given in terms of the risk-neutral pricing, there is no difference between the two stocks, and you are indifferent.</p> <p>However, you intuitively see that the first stock is a blue chip, whereas the second one is rather the hot but \"risky\" kid on the playground\u2014a startup or so. Your decision process would likely be driven by a \"risk/reward\" analysis in the face of \"uncertainty,\" whatever that means.</p> <p>We make the analysis even simpler with the following second example.</p> <p>Example</p> <p>You own 1,000 RMB and have the choice between the following games:</p> <ol> <li> <p>Pay 1,000 and get immediately:</p> \\[ \\begin{cases}     2,000 &amp; \\text{with probability } 50\\% \\\\     0     &amp; \\text{otherwise} \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,200 &amp; \\text{with probability } \\frac{5}{6} \\approx 83.33\\% \\\\      0     &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,300 &amp; \\text{with probability } 25\\% \\\\      900   &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Pay 1,000 and get immediately:</p> \\[  \\begin{cases}      1,100 &amp; \\text{with probability } 50\\% \\\\      900   &amp; \\text{otherwise}  \\end{cases} \\] </li> <li> <p>Do nothing and keep your 1,000.</p> </li> </ol> <p>All these games have an expected return of 0. However, you would likely have a preference regarding which one is the best. Considering their standard deviations\u2014that is, \\(E[(X - E[X])^2]^{1/2}\\)\u2014it holds:</p> \\[   \\begin{aligned}       \\mathrm{STD}(\\text{game 1}) &amp; \\approx 1,000, \\\\       \\mathrm{STD}(\\text{game 2}) &amp; \\approx 447.21, \\\\       \\mathrm{STD}(\\text{game 3}) &amp; \\approx 173.21, \\\\       \\mathrm{STD}(\\text{game 4}) &amp; \\approx 100, \\\\       \\mathrm{STD}(\\text{game 5}) &amp; \\approx 0.   \\end{aligned} \\] <p>Remark</p> <p>Risk perception is a subjective view of how you assess uncertain prospective outcomes. This may differ from one person to another as well as from one context to another. How can we model this fact mathematically?</p>"},{"location":"lecture/02-risk-management/021-what-is-risk/#two-examples-for-risk-assessment-instruments","title":"Two Examples for Risk Assessment Instruments","text":""},{"location":"lecture/02-risk-management/021-what-is-risk/#markowitz-mean-variance","title":"Markowitz Mean Variance","text":"<p>The deviation from the mean appears to be a good indicator of our aversion to uncertainty. This is why Markowitz introduced the following criterion to assess the trade-off between risk and rewards in terms of variance and means.</p> <p>Definition</p> <p>Given a square integrable random variable \\( X \\)\u2014modeling some payoff such as a portfolio strategy, industrial projects, or any management decision\u2014the Markowitz mean/variance measure is defined as:</p> \\[ MV_{\\alpha}(X) = E[X] - \\frac{\\alpha}{2} \\text{VAR}(X) \\] <p>where:</p> \\[ \\text{VAR}(X) = E\\left[(X - E[X])^2\\right] \\] <p>is the variance of the random variable, and \\( \\alpha \\) is a positive number.</p> <p>For any value of \\( \\alpha \\), you can check that assessing previous games in terms of mean and variance will rank them, with the largest standard deviation corresponding to the worst game and the smallest standard deviation corresponding to the best game. </p> <p>The Markowitz mean-variance approach was a highly successful instrument for finding optimal portfolio strategies. It can also be used as a risk assessment measure. However, since we are more interested in the downside risks, we consider risk measures defined for the random variable \\( L = -X \\), where \\( X \\) represents returns.</p> <p>Definition</p> <p>The Markowitz risk measure is defined as:</p> \\[   RMV_{\\alpha}(L) = E[L] + \\frac{\\alpha}{2} \\text{VAR}(L) \\] <p>where \\( L \\) is a square integrable loss profile.</p> <p>Proposition</p> <p>The Markowitz risk measure satisfies the following properties:</p> <ol> <li> <p>Cash-invariance: For every loss profile \\( L \\) and \\( m \\in \\mathbb{R} \\),</p> \\[   RMV_{\\alpha}(L - m) = RMV_{\\alpha}(L) - m. \\] </li> <li> <p>Convexity: For any two loss profiles \\( L_1, L_2 \\) and \\( \\lambda \\in [0, 1] \\),</p> \\[   RMV_{\\alpha}(\\lambda L_1 + (1 - \\lambda)L_2) \\leq \\lambda RMV_{\\alpha}(L_1) + (1 - \\lambda)RMV_{\\alpha}(L_2) \\leq \\max \\left\\{ RMV_{\\alpha}(L_1), RMV_{\\alpha}(L_2)\\right\\}. \\] </li> <li> <p>Law Invariance: If two loss profiles \\( L_1 \\) and \\( L_2 \\) have the same CDF, then:</p> \\[   RMV_{\\alpha}(L_1) = RMV_{\\alpha}(L_2). \\] </li> </ol> Proof <ol> <li> <p>Cash-invariance: For every \\( m \\in \\mathbb{R} \\), and loss \\( L \\), it holds:</p> \\[   \\begin{align*}      RMV_{\\alpha}(L-m) &amp; = E[L-m] + \\frac{\\alpha}{2} E\\left[\\left(L-m-E[L-m]\\right)^2\\right]\\\\                        &amp; = E[L] + \\frac{\\alpha}{2} E\\left[\\left(L - E[L]\\right)^2\\right] - m = RMV_{\\alpha}(L) - m   \\end{align*} \\] </li> <li> <p>Convexity: Let \\( 0 \\leq \\lambda \\leq 1 \\) and \\( L_1 \\) and \\( L_2 \\) be two loss profiles. </p> <p>Since the function \\( x \\mapsto x^2 \\) is convex, it follows that:</p> \\[   \\begin{align*}      \\left(\\lambda L_1 + (1-\\lambda)L_2 - E[\\lambda L_1 + (1-\\lambda)L_2]\\right)^2        &amp;=\\left(\\lambda(L_1 - E[L_1]) + (1-\\lambda)(L_2 - E[L_2])\\right)^2\\\\       &amp;\\leq \\lambda \\left(L_1 - E[L_1]\\right)^2 + (1-\\lambda)\\left(L_2 - E[L_2]\\right)^2   \\end{align*} \\] <p>Taking expectation, it follows that:</p> \\[   \\text{VAR}(\\lambda L_1 + (1-\\lambda)L_2) \\leq \\lambda \\text{VAR}(L_1) + (1-\\lambda) \\text{VAR}(L_2) \\] <p>showing that:</p> \\[   \\begin{align*}      RMV_{\\alpha}(\\lambda L_1 + (1-\\lambda)L_2) &amp; = \\lambda E[L_1] + (1-\\lambda)E[L_2] + \\frac{\\alpha}{2} \\text{VAR}(\\lambda L_1 + (1-\\lambda)L_2)\\\\       &amp;\\leq \\lambda\\left(E[L_1] + \\frac{\\alpha}{2} \\text{VAR}(L_1)\\right) + (1-\\lambda)\\left(E[L_2] + \\frac{\\alpha}{2} \\text{VAR}(L_2)\\right)\\\\       &amp; = \\lambda RMV_{\\alpha}(L_1) + (1-\\lambda)RMV_{\\alpha}(L_2)\\\\       &amp; \\leq \\max \\left\\{ RMV_{\\alpha}(L_1), RMV_{\\alpha}(L_2) \\right\\}   \\end{align*} \\] </li> <li> <p>Law Invariance: For the last assertion, let \\( L_1 \\) and \\( L_2 \\) be such that \\( F_{L_1} = F_{L_2} \\).   It follows that:</p> \\[ \\begin{align*}    RMV_{\\alpha}(L_1) &amp; = \\int_{\\mathbb{R}} x dF_{L_1}(x) + \\frac{\\alpha}{2}\\int_{\\mathbb{R}} \\left[x - \\int_{\\mathbb{R}}x dF_{L_1}(x)\\right]^2 dF_{L_1}(x) \\\\       &amp; = \\int_{\\mathbb{R}} x dF_{L_2}(x) + \\frac{\\alpha}{2}\\int_{\\mathbb{R}} \\left[x - \\int_{\\mathbb{R}}x dF_{L_2}(x)\\right]^2 dF_{L_2}(x) \\\\       &amp; = RMV_{\\alpha}(L_2) \\end{align*} \\] </li> </ol>"},{"location":"lecture/02-risk-management/021-what-is-risk/#value-at-risk-vr","title":"Value at Risk (V@R)","text":"<p>The value at risk (V@R) is a widely used risk assessment measure introduced in the finance industry by JP Morgan around 1995. However as an instrument for measuring risk, it has been used for centuries in insurrance industry and turns out to be a very well known mathematical concept. It measures downside risk as follows:</p> <p>Definition</p> <p>Let \\( L \\) be a loss profile. The value at risk (\\( V@R_{\\alpha} \\)) with parameter \\( 0 &lt; \\alpha &lt; 1 \\) is defined as:</p> \\[   V@R_{\\alpha}(L) = \\inf\\{m \\in \\mathbb{R} : P[L &gt; m] \\leq \\alpha\\}. \\] <p>This can also be expressed as:</p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf\\{m \\in \\mathbb{R} : P[L &gt; m] \\leq \\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : 1-P[L\\leq m] \\leq \\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : F_L(m) \\geq 1-\\alpha\\}   \\end{align*} \\] <p>where \\( F_L(m):= P[L\\leq m] \\) is the cumulative distribution function (CDF) of \\( L \\).</p> <p> </p> <p>Note: Quantile Function</p> <p>Note that the CDF \\(F_L\\) is an increasing function from \\(0\\) to \\(1\\). Furthermore, it is right continuous meaning that \\(F_L(m_n)\\downarrow F_L(m)\\) for any sequence \\(m_n \\downarrow m\\). Indeed, let \\(A_n = \\{L \\leq m_n\\}\\) and \\(A =\\{L\\leq m\\}\\), it follows that \\(A_1\\supseteq A_2 \\ldots \\supseteq A_n \\supseteq \\ldots\\) with \\(\\cap A_n =A\\). As a consequence of the \\(\\sigma\\)-additivity of the probability measure, it follows that \\(P[A_n]\\downarrow P[A]\\).</p> <p>Now, if \\(F_L\\) is strictly increasing and continuous, it has an inverse \\(F_L^{-1}\\colon (0, 1)\\to \\mathbb{R}\\) which is also strictly increasing and continuous. Such an inverse is called the quantile of \\(L\\) and denoted by \\(q_L\\colon (0,1)\\to \\mathbb{R}\\). It follows that we can write the value at risk in terms of quantile:</p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf\\{m \\in \\mathbb{R} : F_L(m) \\geq 1-\\alpha\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : F^{-1}_L(F_L(m)) \\geq F^{-1}_L(1-\\alpha)\\}\\\\                     &amp; = \\inf\\{m \\in \\mathbb{R} : m \\geq F^{-1}_L(1-\\alpha)\\}\\\\                     &amp; = F^{-1}_L(1-\\alpha)   \\end{align*} \\] <p>In other terms, \\(V@R_{\\alpha}(L)=q_L(1-\\alpha)\\) is the \\(1-\\alpha\\) quantile of the distribution.</p> <p>In the case where \\(F_L\\) is not strictly increasing and continuous, we can still define the so called (left) pseudo-inverse or quantile as</p> <p>Definition: Quantile</p> <p>The quantile of the random variable \\(L\\) is defined as</p> \\[ \\begin{equation*}   \\begin{split}     q_L \\colon (0,1) &amp; \\longrightarrow \\mathbb{R}\\\\                 s &amp; \\longmapsto q_L(\\alpha) = \\inf\\left\\{ m \\in \\mathbb{R}\\colon P\\left[ L\\leq m \\right] \\geq s\\right\\}   \\end{split} \\end{equation*} \\] <p>The quantile is an increasing and left continuous function for which holds</p> \\[   F_L(q_L(s)-) \\leq s\\leq F_L(q_L(s))   \\] <p>The value at risk indicates the amount of cash or liquidity needed to reduce the loss size so that the probability of making losses exceeds \\( \\alpha \\) is small. Typical values for \\( \\alpha \\) are 5%, 1%, or 0.5%, depending on the horizon.</p> <p>Example</p> <p>Let \\( \\Omega = \\{\\omega_1, \\omega_2, \\omega_3, \\omega_4\\} \\) with probabilities \\( p = (0.7\\%, 3.3\\%, 46\\%, 50\\%) \\), and let \\( L \\) be a loss profile defined as:</p> \\[ L(\\omega) = \\begin{cases} 10,000 &amp; \\text{if } \\omega = \\omega_1, \\\\ -50    &amp; \\text{if } \\omega = \\omega_2, \\\\ -200   &amp; \\text{if } \\omega = \\omega_3, \\\\ -1,000 &amp; \\text{if } \\omega = \\omega_4. \\end{cases} \\] <p>The corresponding CDF \\( F_L(m) \\) is:</p> \\[ F_L(m) = \\begin{cases} 0       &amp; \\text{if } m &lt; -1,000, \\\\ 50\\%    &amp; \\text{if } -1,000 \\leq m &lt; -200, \\\\ 96\\%    &amp; \\text{if } -200 \\leq m &lt; -50, \\\\ 99.3\\%  &amp; \\text{if } -50 \\leq m &lt; 10,000, \\\\ 1       &amp; \\text{if } m \\geq 10,000. \\end{cases} \\] <p>From this, the quantile function is:</p> \\[ q_L(x) = \\begin{cases} -1,000 &amp; \\text{if } 0 &lt; x \\leq 50\\%, \\\\ -200   &amp; \\text{if } 50\\% &lt; x \\leq 96\\%, \\\\ -50    &amp; \\text{if } 96\\% &lt; x \\leq 99.3\\%, \\\\ 10,000 &amp; \\text{if } 99.3\\% &lt; x \\leq 1. \\end{cases} \\] <p>Thus: [ V@R_{5\\%} = q_L(95\\%) = -200, \\quad V@R_{1\\%} = q_L(99\\%) = -50, \\quad V@R_{0.5\\%} = q_L(99.5\\%) = 10,000. ]</p> <p>Note: Practical Computation of Value at Risk</p> <p>Unlike mean-variance risk measures, which involve computing expectations (analytical or via Monte Carlo methods, for instance), the computation of Value at Risk (VaR) is slightly more complex.  Even when a random variable has a probability density function, there is generally no analytical form for its quantile function. In cases where the cumulative distribution function (CDF) is strictly increasing and continuous, computing VaR requires inverting the function \\( m \\mapsto F_L(m) \\). This involves solving the equation:</p> \\[   F_L(m^\\ast) = s \\] <p>where \\( m^\\ast \\) is the quantile we are seeking. This is a classical root-finding problem.</p> <p>Most scientific libraries provide methods for root finding, such as Newton's method, the secant method, or more advanced mixed approaches like Brent's method.  It is important to note, however, that VaR often focuses on high quantiles (e.g., 0.99 or 0.999) of the CDF, which lie near the boundary of the inverse. This makes the problem particularly challenging, as the derivative of the CDF approaches zero near these limits, testing the bounds of numerical precision.  Fortunately, most scientific libraries with statistical functions provide predefined and highly optimized methods for quantile computation. </p> <p>Below, we illustrate this using Python, specifically with <code>scipy.optimize</code> and <code>scipy.stats</code>.</p> <p>Computation of value at risk<pre><code># import libraries\nimport numpy as np\nfrom scipy.stats import norm, t             # Normal and Student distribution\nfrom scipy.optimize import root, brentq     # root-&gt;newton method, brentq-&gt;bissecant flavor\nimport plotly.graph_objs as go              # professional but easy plotting\n\n# Straightforward quantile computation implementation\ndef quantile(cdf, s):\n  # definition of the root function(1) \n  def fun(m):\n    result = cdf(m) - s\n    return result\n\n  # return the root(2)\n  result = root(fun, 0)\n  return result.x[0]\n\n# Define two random variables\nX = norm()      # standard normal\nY = t(df = 2)   # student with 2 as degree of freedom\n\n# plot the cdf of both\n\nx = np.linespace(-4, 4, 100)\ny1 = X.cdf(x)\ny2 = Y.cdf(x)\n\nfig = go.Figure()\nfig.add_scatter(x=x, y=y1, name=\"normal distribution\")\nfig.add_scatter(x=x, y=y2, name=\"student distribution\")\nfig.update_layout(title = 'CDF of normal and student')\nfig.show()\n\n# compute the var 0.01 and 0.01 for each\n\nprint(f\"\"\"\n1% V@R for Normal:\\t{quantile(X.cdf, 0.99)}\n0.01% V@R for Normal:\\t{quantile(X.cdf, 0.999)}\n1% V@R for Student:\\t{quantile(Y.cdf, 0.99)}\n0.01% V@R for Student:\\t{quantile(Y.cdf, 0.999)}\n\"\"\")\n\n\n# using the pre programmed `ppf` functions\nprint(f\"\"\"\n1% V@R for Normal:\\t{X.ppf(0.99)}\n0.01% V@R for Normal:\\t{X.ppf(0.999)}\n1% V@R for Student:\\t{Y.ppf(0.99)}\n0.01% V@R for Student:\\t{Y.ppf(0.999)}\n\"\"\")\n\n# You can compare the speed between your implementation and the pre programmed using %timeit\n</code></pre></p> <ol> <li>Find <code>m</code> such that <code>F(m) = s</code> is equivalent to finding <code>m</code> such that <code>F(m) - s = 0</code> which is the usual implementation.</li> <li>We use here the Newton variant of root optimization problem. It only requires a start point and is usually fast.      However it might not converge if the derivative is quite close to <code>0</code> so it might not always be adequate.     Using <code>brentq</code>, as a bissecant type, requires to provide two bounds <code>a&lt;b</code> within which that root shall be found. In particular it should hold that <code>fun(a)</code> has a different sign as <code>fun(b)</code>.     Both have advantages and inconvenience.</li> </ol> <p>As for mean-variance, value at risk also fulfills some properties</p> <p>Proposition</p> <p>The Value at Risk V@R satisfies the following properties:</p> <ol> <li> <p>Cash-invariance: For every loss profile \\( L \\) and \\( m \\in \\mathbb{R} \\),</p> \\[   V@R_{\\alpha}(L - m) = V@R_{\\alpha}(L) - m. \\] </li> <li> <p>Monotonicity: For any two loss profiles \\( L_1, L_2 \\) with \\(L_1(\\omega) \\leq L_2(\\omega)\\) it holds,</p> \\[   V@R_{\\alpha}(L_1) \\leq V@R_{\\alpha}(L_2). \\] </li> <li> <p>Law Invariance: If two loss profiles \\( L_1 \\) and \\( L_2 \\) have the same CDF, then:</p> \\[   V@R_{\\alpha}(L_1) = V@R_{\\alpha}(L_2). \\] </li> </ol> Proof <ol> <li> <p>Cash-invariance: For every \\( m \\in \\mathbb{R} \\), and loss \\( L \\), it holds with variable change \\(\\hat{m} = \\tilde{m} - m\\):</p> \\[   \\begin{align*}      V@R_{\\alpha}(L-m) &amp; = \\inf\\left\\{ \\tilde{m} \\in \\mathbb{R} \\colon P[L-m&gt;\\tilde{m}] \\leq \\alpha \\right\\}\\\\                     &amp; = \\inf \\left\\{ \\hat{m} - m \\colon P[L&gt;\\hat{m}] \\leq \\alpha  \\right\\}\\\\                     &amp; = \\inf \\left\\{ \\hat{m} \\colon P[L&gt;\\hat{m}] \\leq \\alpha  \\right\\} - m = V@R_{\\alpha}(L) - m   \\end{align*} \\] </li> <li> <p>Monotonicity: Let \\( L_1 \\leq L_2 \\) be two loss profiles.</p> <p>For any \\(m\\), it holds</p> \\[     \\left\\{ \\omega \\colon L_1(\\omega)\\leq m \\right\\} \\supseteq \\left\\{ \\omega \\colon L_2(\\omega)\\leq m \\right\\} \\] <p>showing that for every \\(m\\) we have \\(P[L_1\\leq m] \\geq P[L_2 \\leq m]\\). Hence, we have</p> \\[     \\left\\{ m \\in \\mathbb{R} \\colon P\\left[ L_1\\leq m \\right]\\geq 1-\\alpha \\right\\} \\subseteq  \\left\\{ m \\in \\mathbb{R} \\colon P\\left[ L_2\\leq m \\right]\\geq 1-\\alpha \\right\\} \\] <p>showing that the infimum of the the left handside is smaller than the infimum of the right hand side, that is \\(V@R_{\\alpha}(L_1)\\leq V@R_{\\alpha}(L_2)\\). </p> </li> <li> <p>Law Invariance: This follows immediately since the value at risk depends only on the CDF.</p> </li> </ol>"},{"location":"lecture/02-risk-management/021-what-is-risk/#sound-properties","title":"Sound Properties?","text":"<p>Both risk assessments make sense and have a certain appeal. Let us discuss some of the properties they fulfill:</p> <ul> <li> <p>Cash Invariance: Given a risk assessment instrument \\( L \\mapsto R(L) \\), being cash invariant means that \\( R(L - m) = R(L) - m \\).     This property is appreciated by economists and regulators as it confers a clear monetary interpretation to risk assessment.     Regulators typically require financial institutions to maintain their total risk below zero.     For a financial institution with a loss exposure \\( L \\), the question is how much liquidity (or cash) must be held to reduce the overall risk to below zero.     With cash \\( m \\) and risky exposure \\( L \\), the resulting loss profile is \\( L - m \\), with a risk equal to \\( R(L - m) \\).     A risk assessment below zero implies that \\( m \\geq R(L) \\). In other words, the minimal cash requirement to make the risky exposure acceptable is \\( m = R(L) \\).</p> </li> <li> <p>Law Invariance: Law invariance is important because, even though we work with random variables, in practice we observe only their realizations and approximate their CDF.     Hence, a risk assessment instrument should depend solely on the CDF of the loss profile.</p> </li> <li> <p>Monotonicity: Monotonicity means that if the loss profile of one position is always greater than another, i.e., it results in higher losses in all scenarios, then its risk should also be higher.</p> </li> <li> <p>Diversification (Convexity): Diversification implies that combining two risky assets (a convex combination) should result in a risk lower than the worst of the two individual risks.</p> </li> </ul> Property \\( MVR_{\\alpha} \\) \\( V@R_{\\alpha} \\) Cash Invariance Law Invariance Monotonicity Diversification <p>Warning: Value at Risk might lead to Concentration</p> <p>Value at Risk (VaR) can, in some cases, counteract diversification. The primary reason is that the quantile is just a single point on the CDF of the loss distribution and does not account for the full risk in the tail. The following example illustrates this concentration issue:</p> <p>In the first scenario, you lend \\( 1000 \\) RMB to a friend, expecting repayment in one year with \\( 4\\% \\) interest. - If the friend repays the loan, you gain \\( 40 \\) RMB. - If the friend defaults, you lose \\( 1000 \\) RMB. - Assume the probability of default is \\( 4\\% \\).  </p> <p>The loss profile can be represented as:  </p> \\[     L =      \\begin{cases}         -40 &amp; \\text{with probability } 96\\% \\\\         1000 &amp; \\text{with probability } 4\\%     \\end{cases} \\] <p>This results in the following CDF and quantile function:  </p> \\[     \\begin{align*}         F_L(m) &amp; = \\begin{cases}             0 &amp; \\text{for } m &lt; -40 \\\\             96\\% &amp; \\text{for } -40 \\leq m &lt; 1000 \\\\             100\\% &amp; \\text{for } m \\geq 1000         \\end{cases} \\\\         q_L(s) &amp; = \\begin{cases}             -40 &amp; \\text{for } 0 &lt; s \\leq 96\\% \\\\             1000 &amp; \\text{for } s &gt; 96\\%         \\end{cases}     \\end{align*} \\] <p>The Value at Risk at the \\( 5\\% \\) level is:  </p> \\[     V@R_{5\\%}(L) = q_L(95\\%) = -40 \\] <p>Now, consider diversifying your exposure by lending \\( 500 \\) RMB to two independent friends:  </p> \\[     L =      \\begin{cases}         -40 &amp; \\text{with probability } 92.16\\% \\\\         480 &amp; \\text{with probability } 7.68\\% \\\\         1000 &amp; \\text{with probability } 0.16\\%     \\end{cases} \\] <p>This diversification reduces the probability of large losses to \\( 0.16\\% \\), but introduces a medium loss of \\( 480 \\) RMB with a \\( 7.68\\% \\) probability.  </p> <p>The CDF and quantile function for this case are:  </p> \\[     \\begin{align*}         F_L(m) &amp; = \\begin{cases}             0 &amp; \\text{for } m &lt; -40 \\\\             92.16\\% &amp; \\text{for } -40 \\leq m &lt; 480 \\\\             99.84\\% &amp; \\text{for } 480 \\leq m &lt; 1000 \\\\             100\\% &amp; \\text{for } m \\geq 1000         \\end{cases} \\\\         q_L(s) &amp; = \\begin{cases}             -40 &amp; \\text{for } 0 &lt; s \\leq 92.16\\% \\\\             480 &amp; \\text{for } 92.16\\% &lt; s \\leq 99.84\\% \\\\             1000 &amp; \\text{for } s &gt; 99.84\\%         \\end{cases}     \\end{align*} \\] <p>The Value at Risk at the \\( 5\\% \\) level is:  </p> \\[     V@R_{5\\%}(L) = q_L(95\\%) = 480 \\] <p>In this case, the Value at Risk increases from \\( -40 \\) to \\( 480 \\), contradicting the expectation that diversification reduces risk. The primary reason is that, in the non-diversified scenario, all potential losses are concentrated in the tail of the distribution beyond the chosen quantile. In other words, Value at Risk is blind to the magnitude of losses beyond the selected quantile level.</p> <p>Even though both instruments (mean-variance risk and Value at Risk) have intuitive appeal and practical applications, closer scrutiny reveals that each violates one or more fundamental properties expected of a robust risk measure.</p>"},{"location":"lecture/02-risk-management/022-risk-preferences/","title":"Risk Preferences and Measures","text":"<p>So far, we have introduced potential examples of risk measures and discussed their shortcomings regarding properties deemed sound for risk assessment. Additionally, the selection of these measures might appear arbitrary. In the following, we aim to formalize the concepts of risk and uncertainty.</p> <p>On the one hand, uncertainty refers to the possibility of multiple outcomes. In other words, it considers the set \\( \\Omega \\) within a probability space. This concept is inherently an objective matter, tied to the nature of the world.</p> <p>On the other hand, risk represents a subjective or personal perception of uncertainty. It depends on an individual's viewpoint and can be understood as a cautious response to uncertainty. To model this consistently within a mathematical framework, we rely on decision theory, which captures preferences among various choices. The set of possible choices is denoted by \\( \\mathcal{X} \\). In this context, uncertain outcomes are modeled as random variables, meaning we work with a vector space \\( \\mathcal{X} \\) of random variables (primarily bounded for mathematical convenience).</p> <p>Definition: Preference Order and Numerical Representation</p> <p>A preference order \\( \\preccurlyeq \\) on \\( \\mathcal{X} \\) is a binary relation \\( x \\preccurlyeq y \\) indicating that choice \\( y \\) is preferred to choice \\( x \\). We assume this relation satisfies the following normative properties:</p> <ul> <li>Transitivity: \\( x \\preccurlyeq y \\) and \\( y \\preccurlyeq z \\) imply \\( x \\preccurlyeq z \\);</li> <li>Completeness: For any two possible choices \\( x \\) and \\( y \\), either \\( x \\preccurlyeq y \\) or \\( y \\preccurlyeq x \\).</li> </ul> <p>A function \\( U\\colon \\mathcal{X} \\to \\mathbb{R} \\) is called a numerical representation (or utility) of a preference order \\( \\preccurlyeq \\) if:</p> \\[     x \\preccurlyeq y \\quad \\text{if and only if} \\quad U(x) \\leq U(y) \\] <p>Preference orders are a generic way to represent subjective views on outcomes. The first property, transitivity, ensures consistency: if \\( y \\) is preferred to \\( x \\), and \\( z \\) is preferred to \\( y \\), then \\( z \\) must also be preferred to \\( x \\). This property appears quite intuitive. The second property, completeness, requires that, for any two elements, one must always express a preference between them. This is a strong assumption, as it mandates the ability to decide between any two elements in a potentially infinite set \\( \\mathcal{X} \\).  </p> <p>These two rational (or normative, as decision theorists would say) assumptions often fail in empirical decision-making. However, they are intended to model fully rational behavior in decision-making processes involving prospective outcomes.  </p> <p>A numerical representation maps the preference ranking into \\( \\mathbb{R} \\), providing a quantitative measure of preferences.</p> Note <p>Note first that if we have a numerical representation \\( U \\) for a preference order \\( \\preccurlyeq \\), it is not unique. Any strictly increasing function \\( \\phi \\colon \\mathbb{R} \\to \\mathbb{R} \\) defines another numerical representation \\( \\tilde{U} = \\phi \\circ U \\). Indeed, \\( x \\preccurlyeq y \\) is equivalent to \\( U(x) \\leq U(y) \\), which is equivalent to \\( \\phi(U(x)) = \\tilde{U}(x) \\leq \\tilde{U}(y) = \\phi(U(y)) \\).</p> <p>Second, starting directly with a function \\( U \\colon \\mathcal{X} \\to \\mathbb{R} \\), it defines a preference order \\( \\preccurlyeq \\) by:</p> \\[     x \\preccurlyeq y \\Leftrightarrow U(x) \\leq U(y) \\] <p>As an exercise, show that \\( \\preccurlyeq \\), so defined through a function \\( U \\), is a preference order, satisfying transitivity and completeness.</p> <p>Third, even if a numerical function defines a preference order, the reciprocal is not necessarily true. Additional assumptions are required to ensure that, for a given preference order, a numerical representation \\( U \\) exists. However, under reasonable assumptions, this is often the case.</p> <p>Proposition</p> <p>If the set \\( \\mathcal{X} \\) is countable (1), then any preference order \\( \\preccurlyeq \\) on \\( \\mathcal{X} \\) admits a numerical representation.</p> <ol> <li>Meaning that \\( \\mathcal{X} \\) can be enumerated as a subset of \\( \\mathbb{N} \\).</li> </ol> <p>Proof</p> <p>Without loss of generality, assume \\( \\mathcal{X} = \\{x_1, x_2, \\ldots\\} \\). On \\( \\mathbb{N} \\), define a probability measure \\( P[\\{n\\}] = p_n = 1 / 2^n \\), since \\( \\sum p_n = 1 \\). For each \\( x_n \\), define \\( A_n = \\{k \\colon x_k \\preccurlyeq x_n\\} \\), the set of indices \\( k \\) for elements in \\( \\mathcal{X} \\) that are less preferred than \\( x_n \\). By definition, \\( x_n \\preccurlyeq x_m \\) if and only if \\( A_n \\subseteq A_m \\). The function:</p> \\[     \\begin{equation*}         \\begin{split}             U \\colon \\mathcal{X} &amp;\\longrightarrow \\mathbb{R}\\\\                 x_n &amp; \\longmapsto U(x_n) = P[A_n] = \\sum_{\\{k \\colon x_k \\preccurlyeq x_n\\}} p_k         \\end{split}     \\end{equation*} \\] <p>defines a numerical representation of \\( \\preccurlyeq \\). Indeed, \\( x_n \\preccurlyeq x_m \\) if and only if \\( A_n \\subseteq A_m \\). Since \\( P \\) assigns a unique probability to each element of \\( \\mathbb{N} \\), it follows that \\( A_n \\subseteq A_m \\) if and only if \\( U(x_n) = P[A_n] \\leq P[A_m] = U(x_m) \\). This completes the proof.</p> <p>This proposition uses probability measures to define a numerical representation. The argument extends to more general sets, provided you can relate sublevel sets \\( \\{\\tilde{x} \\colon \\tilde{x} \\preccurlyeq x\\} \\) using topological arguments like smoothness. If such smoothness is absent, preference orders may exist without a numerical representation.</p> <p>The Lexicographical Order Does Not Admit a Numerical Representation</p> <p>Consider \\( \\mathcal{X} = [0, 1] \\times [0, 1] \\) and define the lexicographical order as:</p> \\[     x = (x_1, x_2) \\preccurlyeq y = (y_1, y_2) \\quad \\text{if and only if} \\quad      \\begin{cases}       \\text{either } &amp; x_1 &lt; y_1, \\\\       \\text{or } &amp; x_1 = y_1 \\text{ and } x_2 \\leq y_2.     \\end{cases} \\] <p>This is a preference order (similar to library book ordering). However, since \\( \\mathcal{X} \\) is uncountable and the preference order lacks smoothness, it can be shown that no numerical representation exists. Try this as an exercise: assume a numerical representation exists and derive a contradiction.</p> <p>Decision theory typically frames preferences and utilities (where higher values are better). However, when discussing risk, we consider possible loss profiles \\( \\mathcal{L} \\)\u2014random variables representing losses. For simplicity, we consider complete binary relations \\( \\preccurlyeq \\), where \\( L_1 \\preccurlyeq L_2 \\) means \"\\( L_1 \\) is less risky than \\( L_2 \\).\" Thus, loss profiles are ranked by \\( \\preccurlyeq \\) based on perceived risk. However, the basic properties of a preference order \\( \\preccurlyeq \\) on \\( \\mathcal{L} \\) do not inherently convey insights about risk perception.</p> <p>Definition: Risk Order and Risk Measures</p> <p>A preference order \\( \\succcurlyeq \\) on \\( \\mathcal{L} \\) is called a risk order if the following two additional assumptions are satisfied:</p> <ul> <li> <p>Diversification: If \\( L_1 \\) is more risky than \\( L_2 \\), then any diversified position between the two is less risky than the worse one:</p> \\[     \\text{if } L_1 \\succcurlyeq L_2, \\quad \\text{then}\\quad L_1 \\succcurlyeq \\lambda L_1 + (1-\\lambda) L_2, \\quad \\text{for every } 0 \\leq \\lambda \\leq 1. \\] </li> <li> <p>Monotonicity (worse for sure is more risky): If the losses of \\( L_1 \\) are worse than those of \\( L_2 \\) in every state of the world, then \\( L_1 \\) is more risky than \\( L_2 \\):</p> \\[     \\text{if } L_1(\\omega) \\geq L_2(\\omega) \\text{ for every } \\omega, \\quad \\text{then } L_1 \\succcurlyeq L_2. \\] </li> </ul> <p>A numerical representation \\( R \\colon \\mathcal{L} \\to \\mathbb{R} \\) of a risk order is called a risk measure.</p> <p>These two additional properties express reasonable and intuitive features of risk perception. They also have implications for the properties of risk measures.</p> <p>Proposition</p> <p>Let \\( R \\) be a numerical representation of a preference order \\( \\succcurlyeq \\) on \\( \\mathcal{L} \\). Then the following assertions are equivalent:</p> <ul> <li>\\( \\succcurlyeq \\) is a risk order;</li> <li>\\( R \\) satisfies:<ul> <li>Quasi-convexity: \\( \\max\\{R(L_1), R(L_2)\\} \\geq R(\\lambda L_1 + (1-\\lambda) L_2) \\) for every \\( 0 \\leq \\lambda \\leq 1 \\);</li> <li>Monotonicity: If \\( L_1(\\omega) \\geq L_2(\\omega) \\) for every \\( \\omega \\), then \\( R(L_1) \\geq R(L_2) \\).</li> </ul> </li> </ul> Proof <p>Let \\( L_1 \\) and \\( L_2 \\) be two loss profiles. Assume that \\( \\succcurlyeq \\) is a risk order.  </p> <p>For quasi-convexity, due to the completeness of the relation, assume without loss of generality that \\( L_1 \\succcurlyeq L_2 \\), which is equivalent to \\( R(L_1) = \\max\\{R(L_1), R(L_2)\\} \\). For any \\( 0 \\leq \\lambda \\leq 1 \\), the diversification property implies \\( L_1 \\succcurlyeq \\lambda L_1 + (1-\\lambda) L_2 \\), which gives:</p> \\[     \\max\\{R(L_1), R(L_2)\\} = R(L_1) \\geq R(\\lambda L_1 + (1-\\lambda) L_2), \\] <p>showing quasi-convexity of \\( R \\).</p> <p>For monotonicity, assume \\( L_1(\\omega) \\geq L_2(\\omega) \\) for every \\( \\omega \\). By the monotonicity assumption, \\( L_1 \\succcurlyeq L_2 \\), which implies \\( R(L_1) \\geq R(L_2) \\).  </p> <p>The reverse implication\u2014that a numerical representation being quasi-convex and monotone implies \\( \\succcurlyeq \\) is a risk order\u2014is straightforward to verify.</p> <p>This proposition shows that neither the mean-variance risk measure nor the Value at Risk represents a risk order. Additional properties may be required of a risk measure, but they might not always align with the underlying risk order.</p> <p>Definition</p> <p>A risk measure \\( R \\) is called:</p> <ul> <li>Cash-Invariant: if \\( R(L-m) = R(L) - m \\) for every \\( m \\in \\mathbb{R} \\);</li> <li>Positive-Homogeneous: if \\( R(\\lambda L) = \\lambda R(L) \\) for every \\( \\lambda &gt; 0 \\);</li> <li>Law-Invariant: if \\( R(L) = R(\\tilde{L}) \\) whenever the CDFs of \\( L \\) and \\( \\tilde{L} \\) coincide.</li> </ul> <p>Aside from law invariance, the other two properties do not hold if the risk measure is transformed by a strictly increasing function. Nevertheless, they are commonly used and practical.</p> <p>Cash-Invariance</p> <p>Cash-invariance is typically required from regulatory or financial perspectives. For instance, consider a financial institution with a risky position \\( X \\). The question is how much liquidity \\( m \\) is needed in the bank account to ensure the overall position (cash plus risky assets) has acceptable risk. The threshold is that the total risk must be below zero. The total loss profile is \\( L - m \\), where \\( L = -X \\). By cash-invariance:</p> \\[     0 \\geq R(L - m) = R(L) - m \\implies m \\geq R(L). \\] <p>Thus, the minimal liquidity required to make the risky position acceptable is \\( m = R(L) \\). This interpretation ties the risk measure to capital requirements.</p> <p>Moreover, cash-invariance, combined with quasi-convexity, implies convexity.</p> <p>Lemma</p> <p>If \\( R \\) is a cash-invariant risk measure, then \\( R \\) is convex.</p> Proof <p>Let \\( R \\) be a cash-invariant risk measure, \\( 0 \\leq \\lambda \\leq 1 \\), and \\( L_1, L_2 \\) be loss profiles. To prove \\( R(\\lambda L_1 + (1-\\lambda) L_2) \\leq \\lambda R(L_1) + (1-\\lambda) R(L_2) \\), define \\( m_1 = R(L_1) \\) and \\( m_2 = R(L_2) \\). By cash-invariance and quasi-convexity:</p> \\[     \\begin{align*}         R(\\lambda L_1 + (1-\\lambda) L_2) - \\lambda m_1 - (1-\\lambda)m_2 &amp; = R\\left( \\lambda L_1 + (1-\\lambda) L_2 - \\lambda m_1 - (1-\\lambda)m_2 \\right) \\\\         &amp; = R\\left( \\lambda (L_1 - m_1) + (1-\\lambda)(L_2 - m_2) \\right) \\\\         &amp; \\leq \\max\\{R(L_1 - m_1), R(L_2 - m_2)\\} \\\\         &amp; = \\max\\{0, 0\\} = 0.     \\end{align*} \\] <p>Positive Homogeneity</p> <p>Positive homogeneity has a financial interpretation: if \\( L \\) represents the loss exposure of an investment with risk \\( R(L) \\), scaling the investment by \\( \\lambda &gt; 0 \\) scales the corresponding risk by \\( \\lambda \\). While desirable for mathematical reasons, super-linear scaling might be expected in some contexts. Positive homogeneity also implies sub-additivity, ensuring that risk is not exacerbated by combining positions.</p> <p>Lemma</p> <p>Let \\( R \\) be a cash-invariant risk measure. If \\( R \\) is positive homogeneous, then:</p> \\[     R(L_1 + L_2) \\leq R(L_1) + R(L_2). \\] Proof <p>Let \\( R \\) be a cash-invariant and positive-homogeneous risk measure. By convexity:</p> \\[     \\begin{align*}         R(L_1 + L_2) &amp; = R\\left( 2 \\cdot \\frac{1}{2}(L_1 + L_2) \\right) \\\\         &amp; = 2 R\\left(\\frac{1}{2}L_1 + \\frac{1}{2}L_2 \\right) \\quad \\text{(Positive Homogeneity)} \\\\         &amp; \\leq 2 \\left( \\frac{1}{2}R(L_1) + \\frac{1}{2}R(L_2) \\right) \\quad \\text{(Convexity)} \\\\         &amp; = R(L_1) + R(L_2).     \\end{align*} \\]"},{"location":"lecture/02-risk-management/023-oce/","title":"Expected Shortfall","text":"<p>We have thus far explored the fundamentals of risk assessment, focusing on the key principles it must satisfy to achieve sound quantification: monotonicity, diversification, and, for financial purposes, cash-invariance. This foundation has enabled us to highlight the fundamental flaws of mean-variance analysis and value at risk (VaR) in meeting these criteria. However, from a practical standpoint, we are still far from identifying a fully satisfactory approach.</p> <p>When considering a risk quantification instrument \\( R \\), the following points are crucial:</p> <ol> <li>Soundness: The instrument \\( R \\) must satisfy the properties of diversification and monotonicity to ensure robust risk quantification.</li> <li>Understandability: \\( R \\) should be intuitively comprehensible from a financial perspective, even for individuals not deeply versed in the intricacies of mathematics. Ultimately, you need to convince your boss, the regulator, and the public that the methodology you employ is sensible and reliable.</li> <li>Implementability: The computation of \\( R \\) must be feasible. At the end of the day, you need to produce a quantifiable result. This means it should be possible to create a programmatic function, based on available data, to compute the value of your risk measure (prototyping).</li> <li>Efficiency and Robustness: The implementation of \\( R \\) should meet industry standards\u2014being fast, reliable, and free of bugs. Risk computations are not a one-time experiment; they need to be conducted daily. Large financial institutions, by regulatory requirement, must aggregate and assess vast and complex positions to provide timely results on a daily basis.</li> </ol> <p>As for now, our focus has been primarily on the first point\u2014establishing the groundwork for soundness. However, the other points are equally vital in practice. Since the 2008 financial crisis, the shortcomings of value at risk (VaR) have been widely acknowledged. While these shortcomings (particularly related to soundness) were long known to academics, addressing the other points took time before a new industry standard could emerge. This standard is the expected shortfall (also known under equivalent terms such as average value at risk or conditional value at risk).</p>"},{"location":"lecture/02-risk-management/023-oce/#expected-shortfall_1","title":"Expected Shortfall","text":"<p>As the main issue of value at risk being the fact that it only provides information at one point of the CDF and being blind beyond it, the idea is to consider the tail beyond value at risk</p> <p>Definition: Expected Shortfall</p> <p>The expected shortfall of a random variable (integrable) at level \\(\\alpha\\) is defined as</p> \\[     ES_{\\alpha}(L) = \\frac{1}{\\alpha}\\int_0^\\alpha V@R_{s}(L) ds = \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 q_L(s) ds \\] <p>Note</p> <p>The Expected Shortfall (ES) was introduced by Artzner, Delbaen, Eber, and Heath in 1999 to address the shortcomings of Value at Risk (V@R). Expected Shortfall is known by several other names (with equivalent definitions, modulo some subtleties), including:  </p> <ul> <li>Average Value at Risk (AV@R),  </li> <li>Conditional Value at Risk (CV@R),  </li> <li>Expected Tail Loss (ETL), and  </li> <li>Superquantile.</li> </ul> <p> </p> <p>As shown in the figure, the expected shortfall (ES) addresses the shortcomings of value at risk (V@R) by considering the loss area beyond V@R. Specifically, if two loss distributions, \\( \\tilde{L} \\) and \\( L \\), share the same V@R but \\( \\tilde{L} \\) exhibits larger losses beyond the V@R (i.e., has fatter tails than \\( L \\)), then\u2014even with identical V@R values\u2014the expected shortfall (the area beyond V@R) of \\( \\tilde{L} \\) will exceed that of \\( L \\).</p> <p>This observation addresses the second point on our wish list, as ES naturally rectifies V@R's limitations regarding tail risk. However, it does not resolve the first issue on our list. Specifically, while it is clear that V@R fails to satisfy diversification, it remains puzzling why ES should satisfy this property. The desirable properties of V@R\u2014monotonicity, law invariance, cash-invariance, and positive homogeneity\u2014extend to ES through its integral formulation. However, since V@R is not convex, it is unclear why ES should exhibit convexity based on this representation.</p> <p>Furthermore, while this formulation satisfies the third point (as ES is computed as an integral of a quantifiable object), doubts remain about its efficiency. Calculating the integral of the quantile involves evaluating numerous quantiles between \\( 1-\\alpha \\) and \\( 1 \\), which is computationally intensive and prone to error. This challenge is especially pronounced for extreme quantiles (e.g., \\( 99.999\\% \\) or \\( 99.99999\\% \\)), where sampling the distribution in highly unlikely regions becomes unstable.</p> <p>To address these issues, we now explore another class of risk assessment instruments introduced by operations research scientists Ben-Tal and Teboulle: the optimized certainty equivalent.</p>"},{"location":"lecture/02-risk-management/023-oce/#optimized-certainty-equivalent","title":"Optimized Certainty Equivalent","text":"<p>At the core of the definition of the optimized certainty equivalent is a special penalization function called loss function.</p> <ul> <li> <p>Definition: Loss Function</p> <p>A function \\(\\ell \\colon \\mathbb{R} \\to \\mathbb{R}\\) is called a loss function if</p> <ul> <li>\\(\\ell\\) is convex</li> <li>\\(\\ell\\) is increasing    </li> <li> <p>\\(\\ell(0) = 0\\) and \\(\\ell^\\prime(0) = 1\\)(1)</p> <ol> <li>Note that \\(\\ell\\) does not necessarily need to be differentiable such as \\(\\ell(x) = x^+/\\alpha\\) for \\(0&lt; \\alpha &lt;1\\). It just needs to have \\(\\ell^{\\prime}_-(0) \\leq 1 \\leq \\ell^\\prime_+(0)\\) where \\(\\ell_-^\\prime\\) and \\(\\ell^\\prime_+\\) are the left and right derivative that always exists for convex functions.</li> </ol> </li> <li> <p>\\(\\lim_{x \\to \\infty}\\ell(x)/x &gt;1\\) and \\(\\lim_{x \\to -\\infty} \\ell(x)/x &lt;1\\).</p> </li> </ul> <p>Classical examples following this definition</p> <ul> <li>piecewise linear: \\(\\ell(x)= x^+/ \\alpha\\) with \\(0&lt; \\alpha &lt;1\\);</li> <li>quadratic: \\(\\ell(x)=x^++(x^+)^2/2\\);</li> <li>exponential: \\(\\ell(x)=e^x-1\\)</li> </ul> </li> </ul> <p> </p> <p>The loss function penalizes a loss (losses are considered positive in our case) \\( x \\geq 0 \\) by assigning a value \\( \\ell(x) \\geq x \\). For gains (negative values), it also penalizes by assigning an amount smaller than the gain itself.</p> <p>Thus, given a loss profile \\( L \\), you compute \\( E[\\ell(L)] \\geq E[L] \\), which represents the penalized loss estimation of the loss profile. The idea introduced by Ben-Tal and Teboulle is to reduce the value of these penalized losses by allocating some cash \\( m \\), transitioning from \\( E[\\ell(L)] \\) to \\( E[\\ell(L-m)] \\). However, in terms of total costs, you must account for the cash allocated, leading to the total cost valuation:</p> \\[ m + E[\\ell(L-m)]. \\] <p>With the decision variable being the amount of cash allocated, minimizing the total cost gives rise to the definition of the optimized certainty equivalent.</p> <p>Definition: Optimized Certainty Equivalent</p> <p>Given a loss function \\( \\ell \\), the optimized certainty equivalent \\( R \\) of a bounded random variable (under appropriate integrability conditions) is defined as:</p> \\[   R(L) = \\inf \\left\\{ m + E\\left[ \\ell(L - m) \\right] \\colon m \\in \\mathbb{R} \\right\\}. \\] <p>Proposition</p> <p>Given a loss function \\( \\ell \\), the optimized certainty equivalent \\( R \\) is a cash-invariant and law-invariant risk measure.</p> <p>Furthermore, it holds that:</p> \\[   R(L) = m^\\ast + E\\left[ \\ell(L - m^\\ast) \\right], \\] <p>where: (1)</p> <ol> <li> <p>If \\( \\ell \\) is not differentiable at \\( 0 \\), the condition changes to:</p> \\[ E[\\ell^\\prime_-(L-m^\\ast)] \\leq 1 \\leq E\\left[ \\ell^\\prime_+(L-m^\\ast) \\right], \\] </li> </ol> \\[     E[\\ell^\\prime(L - m^\\ast)] = 1. \\] Proof <p>We show that \\( R \\), as defined, is monotone, cash-invariant, and convex.</p> <ul> <li> <p>Monotonicity:      Suppose \\( L_1(\\omega) \\geq L_2(\\omega) \\) for all \\( \\omega \\).     Since \\( \\ell \\) is increasing:</p> \\[     m + \\ell\\left( L_1 - m \\right) \\geq m + \\ell\\left( L_2 - m \\right). \\] <p>Taking the expectation:</p> \\[     m + E\\left[\\ell\\left( L_1 - m \\right)\\right] \\geq m + E\\left[\\ell\\left( L_2 - m \\right)\\right]. \\] <p>Since \\( m + E[\\ell(L_2 - m)] \\geq R(L_2) \\), it follows that:</p> \\[     m + E\\left[\\ell\\left( L_1 - m \\right)\\right] \\geq R(L_2). \\] <p>Taking the infimum over \\( m \\) yields:</p> \\[     R(L_1) = \\inf\\left\\{ m + E\\left[\\ell\\left( L_1 - m \\right)\\right] \\colon m \\in \\mathbb{R} \\right\\} \\geq R(L_2). \\] </li> <li> <p>Cash-Invariance:     Let \\( m \\in \\mathbb{R} \\).     Then:</p> \\[     \\begin{align*}         R(L - m) &amp; = \\inf\\left\\{ \\tilde{m} + E\\left[\\ell\\left( L - m - \\tilde{m} \\right)\\right] \\colon \\tilde{m} \\in \\mathbb{R} \\right\\} \\\\             &amp; = \\inf\\left\\{ \\hat{m} - m + E\\left[\\ell\\left( L - \\hat{m} \\right)\\right] \\colon \\hat{m} \\in \\mathbb{R} \\right\\} \\quad \\text{(change of variable \\( \\hat{m} = m + \\tilde{m} \\))} \\\\             &amp; = R(L) - m.     \\end{align*} \\] </li> <li> <p>Convexity:   Let \\( L_1 \\) and \\( L_2 \\) be two loss profiles, and \\( 0 \\leq \\lambda \\leq 1 \\).     For \\( m_1, m_2 \\in \\mathbb{R} \\), define \\( m = \\lambda m_1 + (1-\\lambda)m_2 \\) and \\( L = \\lambda L_1 + (1-\\lambda)L_2 \\).     Since \\( \\ell \\) is convex:</p> \\[     m + \\ell(L - m) \\leq \\lambda\\left( m_1 + E\\left[ \\ell(L_1 - m_1) \\right] \\right) + (1-\\lambda)\\left( m_2 + E[\\ell(L_2 - m_2)] \\right). \\] <p>Since \\( R(L) \\leq m + E[\\ell(L - m)] \\), taking the infimum over \\( m_1 \\) and \\( m_2 \\) sequentially yields:</p> \\[     R(\\lambda L_1 + (1-\\lambda)L_2) = R(L) \\leq \\lambda R(L_1) + (1-\\lambda)R(L_2). \\] </li> <li> <p>Law-Invariance:   Law-invariance follows directly, as \\( R \\) depends only on the expectation \\( E[\\ell(\\cdot)] \\), which depends on the CDF of \\( L \\).</p> </li> </ul> <p>To show the final assertion: Define:</p> \\[     g(m) = m + E\\left[ \\ell(L - m) \\right], \\] <p>for which \\( R(L) = \\inf g(m) \\). Since \\( \\ell \\) is convex, \\( g \\) is also convex. It follows from \\(\\ell\\) being increasing and the asymptotic assumptions on \\(\\ell\\) that \\(\\ell(x) \\geq a_1 x -c_1\\) for \\(x\\) positively large enough with \\(a_1&gt;1\\) and \\(\\ell(x)\\geq a_2 x -c_2\\) for \\(x\\) negatively large enough and \\(a_2&lt;1\\). Since \\(L\\) is bounded, it follows that for \\(m\\) positively large enough (more than the bounds of \\(L\\) at least) we have</p> \\[     g(m) = m + E[\\ell(L-m)] \\geq m + a_2E\\left[ L -m \\right] - c_2 = \\underbrace{(1-a_2)}_{&gt;0} \\underbrace{m}_{&gt;0} + a_2 E[L] - c_2 \\xrightarrow[m \\to \\infty]{} \\infty \\] <p>The same argumentation for large enough negative values of \\(m\\) yields</p> \\[     g(m) = m + E[\\ell(L-m)] \\geq m + a_1E\\left[ L -m \\right] - c_1 = \\underbrace{(1-a_1)}_{&lt;0} \\underbrace{m}_{&lt;0} + a_1 E[L] - c_1 \\xrightarrow[m \\to -\\infty]{} \\infty \\] <p>All together, it shows that \\(g(m) \\to \\infty\\) for \\(m\\to \\pm \\infty\\), that is, in mathematical terms, \\(g\\) is coercive.</p> <p> </p> <p>This ensures that \\( g \\) attains its minimum at \\( m^\\ast \\), satisfying the first-order condition:</p> \\[     E\\left[ \\ell^\\prime_-(L-m^\\ast) \\right] \\leq 1 \\leq E\\left[ \\ell^\\prime_+(L-m^\\ast) \\right]. \\] <p>If \\( \\ell \\) is differentiable, this simplifies to:</p> \\[     E\\left[ \\ell^\\prime(L - m^\\ast) \\right] = 1. \\] <p>This completes the proof.</p> <p>This proposition provides several key takeaways:</p> <ol> <li>The optimized certainty equivalent (OCE) is a risk measure independent of the specific definition of \\( \\ell \\), as long as \\( \\ell \\) is a valid loss function.  </li> <li>By its definition and the convexity of the problem, the computation of OCE is straightforward, reducing to a one-dimensional unconstrained convex optimization problem. This allows for the application of efficient, state-of-the-art algorithms.  </li> <li>The simplicity of this optimization problem allows for circumventing classical gradient descent by providing an explicit expression for the first-order condition.</li> </ol> <p>The Exponential Function: Entropic Risk Measure</p> <p>Consider the loss function \\( \\ell(x) = (e^{\\gamma x} - 1)/\\gamma \\). By the first-order condition:</p> \\[   1 = E[\\ell^\\prime(L-m^\\ast)] = E[e^{\\gamma (L - m^\\ast)}] = e^{-\\gamma m^\\ast}E\\left[ e^{\\gamma L} \\right]. \\] <p>Solving for \\( m^\\ast \\):</p> \\[   m^\\ast = \\frac{\\ln\\left(E[e^{\\gamma L}]\\right)}{\\gamma}. \\] <p>Substituting \\( m^\\ast \\) back into \\( R \\) yields:</p> \\[   R(L) = \\frac{1}{\\gamma} \\ln \\left( E\\left[ e^{\\gamma L} \\right] \\right). \\] <p>Hence, for the exponential loss function, the OCE can be computed explicitly, and the resulting risk measure is known as the entropic risk measure.  </p> <p>While this measure is prevalent in other domains (e.g., statistical mechanics, physics, and machine learning) and is computationally efficient, it is unsuitable as a financial risk measure. The exponential penalization assigns extremely high values to large losses, making it impractical for scenarios with rare but severe losses.  </p> <p>For example, consider the loss profile:</p> \\[   \\begin{cases}       1,000,000,000 &amp; \\text{with probability } 0.00001, \\\\       -10,000 &amp; \\text{otherwise}.   \\end{cases} \\] <p>Despite the low probability of the extreme loss, the exponential penalization makes the risk computation infeasible due to numerical instability and even with exact values, the resulting risk would be stratospherical.</p> <p>The Piecewise Linear Function</p> <p>The exponential function example demonstrates how a strong penalization can lead to explicit representations but may not be practical for financial risk measures. Let us now consider the opposite extreme: a function that penalizes less, specifically a piecewise linear loss function:</p> \\[     \\ell(x) = \\frac{1}{\\alpha}x^+, \\] <p>where \\( 0 &lt; \\alpha &lt; 1 \\).  </p> <p>Since \\( \\ell \\) is not differentiable, the characterization uses the left and right derivatives:</p> \\[   \\ell_-^\\prime(x) = \\frac{1}{\\alpha} 1_{(0, \\infty)}(x) =        \\begin{cases}         \\frac{1}{\\alpha} &amp; x &gt; 0, \\\\         0 &amp; \\text{otherwise}.       \\end{cases}   \\quad \\text{and} \\quad   \\ell_+^\\prime(x) = \\frac{1}{\\alpha} 1_{[0, \\infty)}(x) =        \\begin{cases}         \\frac{1}{\\alpha} &amp; x \\geq 0, \\\\         0 &amp; \\text{otherwise}.       \\end{cases} \\] <p>Applying the first-order condition:</p> \\[   E[\\ell^\\prime_-(L-m^\\ast)] \\leq 1 \\leq E[\\ell^\\prime_+(L-m^\\ast)]. \\] <p>Substituting the derivatives:</p> \\[   \\frac{1}{\\alpha}P[L &gt; m^\\ast] \\leq 1 \\leq \\frac{1}{\\alpha}P[L \\geq m^\\ast]. \\] <p>This simplifies to:</p> \\[   P[L &lt; m^\\ast] \\leq 1-\\alpha \\leq P[L \\leq m^\\ast]. \\] <p>Thus, \\( m^\\ast \\) is the \\( 1-\\alpha \\) quantile of \\( L \\):</p> \\[   m^\\ast = q_L(1-\\alpha) = V@R_{\\alpha}(L). \\] <p>Therefore, for the piecewise linear loss function:</p> \\[     R(L) = \\inf\\left\\{ m + \\frac{1}{\\alpha}E\\left[ (L-m)^+ \\right] \\right\\} = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E\\left[ (L-V@R_{\\alpha}(L))^+ \\right]. \\]"},{"location":"lecture/02-risk-management/023-oce/#expected-shortfall-and-optimized-certainty-equivalent","title":"Expected Shortfall and Optimized Certainty Equivalent","text":"<p>On one hand, we previously noted that it is not entirely clear how to show that Expected Shortfall (ES) is a risk measure when derived as the integral of V@R. On the other hand, the optimized certainty equivalent (OCE) with a piecewise linear loss function shows some structural similarities to V@R. It turns out that these two concepts are strongly connected, as demonstrated by the following proposition:</p> <p>Proposition</p> <p>For bounded loss profiles (or even integrable ones), the Expected Shortfall with confidence level \\( 0 &lt; \\alpha &lt; 1 \\) coincides with the optimized certainty equivalent using a piecewise linear loss function with a factor of \\( 1/\\alpha \\).  </p> <p>In other words:</p> \\[   ES_{\\alpha}(L) = \\frac{1}{\\alpha}\\int_{0}^\\alpha V@R_{s}(L)ds = \\inf \\left\\{ m +\\frac{1}{\\alpha}E[(L-m)^+] \\colon m \\in \\mathbb{R} \\right\\} = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E\\left[ \\left( L-V@R_{\\alpha}(L) \\right)^+ \\right]. \\] <p>In particular, Expected Shortfall is a cash-invariant and law-invariant risk measure.</p> <p>This remarkable result addresses the key questions about ES: it confirms that ES is a sound risk measure and provides a computationally efficient approach. Instead of directly computing the integral of the quantile (which can be computationally intensive and error-prone), ES can be expressed as the sum of V@R (already an industry standard) and the expected loss beyond V@R, which can be computed easily either using the PDF of \\( L \\) or Monte Carlo methods with importance sampling.</p> Proof <p>The connection between ES and OCE arises from the fact that the quantile function \\( q_L(s) \\) of \\( L \\) shares the same CDF as \\( L \\) itself. Formally, given a loss profile (random variable) \\( L \\) with CDF \\( F_L(m) = P[L \\leq m] \\) and quantile function \\( q_L(s) = \\inf\\{m \\colon F_L(m)\\geq s\\} \\), the quantile \\( q_L(s) \\) can be viewed as a random variable defined on the probability space \\( (\\tilde{\\Omega}, \\tilde{\\mathcal{F}}, \\tilde{P}) \\), where:</p> <ul> <li>\\( \\tilde{\\Omega} = (0,1) \\),  </li> <li>\\( \\tilde{\\mathcal{F}} \\) is the \\( \\sigma \\)-algebra generated by intervals of \\((0,1)\\), and  </li> <li>\\( \\tilde{P} \\) is the Lebesgue measure \\( dx \\) (the measure of interval lengths).</li> </ul> <p>It can be shown that \\( q_L(s) \\) has the same CDF as \\( L \\), i.e., \\( F_{q_L}(m) = F_L(m) \\). Indeed, by the definition of \\( q_L(s) \\):</p> \\[ (0, F_L(m)) \\subseteq \\{s \\colon q_L(s) \\leq m\\} \\subseteq (0, F_L(m)], \\] <p>and under \\( \\tilde{P} \\), these sets yield:</p> \\[     F_L(m) = \\tilde{P}[(0, F_L(m))] \\leq \\tilde{P}[q_L \\leq m] \\leq \\tilde{P}[(0, F_L(m)]] = F_L(m). \\] <p>Therefore, \\( F_{q_L}(m) = F_L(m) \\).</p> <p>Using this fact, and noting that \\( q_L(s) \\geq q_L(1-\\alpha) \\) for \\( s \\geq 1-\\alpha \\):</p> \\[ \\begin{align*}   ES_{\\alpha}(L) &amp; = \\frac{1}{\\alpha} \\int_{0}^\\alpha V@R_{s}ds \\\\     &amp; = \\frac{1}{\\alpha} \\int_{1-\\alpha}^1 q_L(s) ds \\\\     &amp; = q_L(1-\\alpha) + \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 \\left( q_L(s) - q_{L}(1-\\alpha) \\right)ds \\\\     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}\\int_{\\mathbb{R}} \\left( m - V@R_{\\alpha}(L) \\right)^+ dF_{q_L}(m) \\\\     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}\\int_{\\mathbb{R}} \\left( m - V@R_{\\alpha}(L) \\right)^+ dF_{L}(m) \\\\     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E \\left[ \\left( L - V@R_{\\alpha}(L) \\right)^+ \\right]. \\end{align*} \\] <p>Remark on the Distribution of the Quantile and Random Sampling</p> <p>This kind of magic trick to show the relationship between the piecewise linear optimized certainty equivalent and the expected shortfall relies on the fundamental fact that the distribution of a random variable \\(X\\) on some probability space \\((\\Omega, \\mathcal{F}, P)\\) is the same as the distribution of its quantile \\(q_X\\) on \\((\\tilde{\\Omega}, \\tilde{\\mathcal{F}}, \\tilde{P})\\) where \\(\\tilde{\\Omega} = (0,1)\\), \\(\\tilde{F} = \\mathcal{B}((0,1))\\) the \\(\\sigma\\)-algebra generated by intervals and \\(\\tilde{P}\\) is the lebesgue measure \\(dx\\) that measure interval length, that it \\(\\tilde{P}[(a, b]] = b-a\\).</p> <p>This result is widely known and extensively used, particularly for random sampling. Suppose you want to sample \\( x_1, \\ldots, x_N \\) from the distribution of a random variable \\( X \\) (e.g., normal, Student's t, gamma). A computer, however, generates (quasi-)random numbers \\( u_1, \\ldots, u_N \\) uniformly distributed between \\( 0 \\) and \\( 1 \\). By the equivalence between the distributions of \\( X \\) and \\( q_X \\), defining \\( x_n = q_X(u_n) \\) for \\( n = 1, \\ldots, N \\) produces a random sample \\( x_1, \\ldots, x_N \\) from the distribution of \\( X \\).</p> <pre><code>import numpy as np\nfrom scipy.stats import norm      # (1)\nimport plotly.graph_objs as go    # (2)\n\nN = 10000\nu = np.random.rand(N)             # uniform sample\nx0 = norm.ppf(u)                  # quantile of normal distribution of u\nx1 = norm.rvs(size=N)             # sample from normal\n\n# Plot the two histograms\nfig = go.Figure()\nfig.add_histogram(\n    x=x0,\n    histnorm='probability',\n    name='Quantile of Uniform Sample',\n)\nfig.add_histogram(\n    x=x1,\n    histnorm='probability',\n    name='Standard Normal Sample',\n)\nfig.show()\n</code></pre> <ol> <li>The <code>scipy.stats</code> library provides access to many distributions, including their <code>cdf</code>, <code>pdf</code>, and <code>ppf</code> (quantile function).  </li> <li><code>plotly</code> is used here for plotting; alternatively, <code>matplotlib</code> can be used.</li> </ol> <p>This principle underpins Monte Carlo integration, where the goal is to compute \\( E[f(X)] \\). By the law of large numbers and the central limit theorem, it holds that:</p> \\[     \\frac{1}{N}\\sum_{n=1}^N f(x_n) \\xrightarrow[N \\to \\infty]{} E[f(X)], \\] <p>where \\( x_1, \\ldots, x_N \\) is a random sample from the distribution of \\( X \\). In practice, a random sample \\( u_1, \\ldots, u_N \\) is drawn from a uniform distribution on \\( (0, 1) \\), and then \\( x_n = q_X(u_n) \\) is computed and used in the arithmetic mean of \\( f(x_n) \\) for \\( n = 1, \\ldots, N \\).</p> <p>As of now, we know that Expected Shortfall (ES) is a sound risk measure: it is understandable, implementable, and, due to its representation, efficient to compute. Prior to the introduction of ES, financial institutions commonly computed \\( V@R \\). To transition to ES, they only need to compute the additional term \\( E[(L-V@R_{\\alpha}(L))^+]/\\alpha \\), which is computationally efficient (either analytically or via Monte Carlo methods).</p> <p>The computation of ES in simple cases is demonstrated below:</p> <pre><code>import numpy as np\nfrom scipy.stats import norm, t       # Normal and Student's t distributions\nfrom scipy.optimize import root       # Root finding\nfrom scipy.integrate import quad      # One-dimensional integration\nimport plotly.graph_objs as go        # Plotting library\n\n# Define the basic computation of the quantile (X is a random variable)\ndef quantile(X, s):\n    def fun(m):\n        return X.cdf(m) - s\n    result = root(fun, 0)  # Find the root\n    return result.x[0]\n\n# Compute ES using the integral of quantile representation\ndef ES1(X, alpha):\n    def fun(s):\n        return quantile(X, s)\n    result, err = quad(fun, 1 - alpha, 1)  # Integrate quantile between 1-alpha and 1\n    return result / alpha\n\n# Compute ES using the OCE representation\ndef ES2(X, alpha):\n    var = quantile(X, 1 - alpha)\n    def fun(x):\n        return (x - var) * X.pdf(x)\n    result, err = quad(fun, var, np.Inf)  # Integrate beyond V@R\n    return var + result / alpha\n\n# Define distributions\nX1 = norm\nX2 = t(df=2)  # Student's t distribution with df=2 (variance = 1)\n\nalpha = 0.01  # Confidence level (1%)\n\n# Display results\nprint(f\"\"\"\nV@R (Normal):\\t{quantile(X1, 1 - alpha)}\nES (slow, Normal):\\t{ES1(X1, alpha)}\nES (fast, Normal):\\t{ES2(X1, alpha)}\n\nV@R (Student):\\t{quantile(X2, 1 - alpha)}\nES (slow, Student):\\t{ES1(X2, alpha)}\nES (fast, Student):\\t{ES2(X2, alpha)}\n\"\"\")\n\n# Exercise:\n# Compare and plot the differences between V@R and ES for Normal and Student's t distributions for 0.0001 &lt; alpha &lt; 0.05.\n# Use %timeit to compare the computation times of ES1 and ES2.\n</code></pre> <p>We saw that the expected shortfall has multiple representations, and simple transformations can yield additional formulations.</p> <p>The expected shortfall has the following representations</p> \\[   \\begin{align*}     ES_{\\alpha}(L)  &amp; = \\frac{1}{\\alpha}\\int_0^\\alpha V@R_{s}(L)ds &amp;&amp; \\text{Quantile representation}\\\\                     &amp; = \\inf\\{m + \\frac{1}{\\alpha}E[(L-m)^+]\\colon m \\in \\mathbb{R}\\} &amp;&amp; \\text{OCE representation}\\\\                     &amp; = V@R_{\\alpha}(L) + \\frac{1}{\\alpha}E\\left[ \\left( L - V@R_{\\alpha}(L) \\right)^+ \\right] \\\\                     &amp; = \\frac{1}{\\alpha}\\int_{V@R_{\\alpha}(L)}^\\infty x dF_L(x)   \\end{align*} \\] <p>Furthermore, the expected shortfall is positive homogeneous, that is</p> \\[ ES_{\\alpha}(\\lambda L) = \\lambda ES_{\\alpha}(L)\\] <p>for every \\(\\lambda&gt;0\\). In particular \\(ES_{\\alpha}(L_1 + L_2)\\leq ES_{\\alpha}(L_1) + ES_{\\alpha}(L_2)\\).</p>"},{"location":"material/ex01/","title":"Exercise: One Period Financial Market","text":"<p>Exercise</p> <p>We consider the following two financial market models with state space \\( \\Omega=\\{\\omega_1,\\omega_2, \\omega_3\\} \\) and a probability measure \\( P \\) with</p> \\[     P\\left[ \\{\\omega_i\\} \\right] = p_i \\quad \\text{for} \\quad          \\begin{cases}             p_i  &gt; 0 &amp; \\text{for every } i=1,2,3, \\\\             p_1 + p_2 + p_3 = 1         \\end{cases} \\] <ol> <li> <p>Financial Market I: \\( B_0 = 1 \\) and \\( B_1 = 2 \\) as bank account and three stocks given by</p> \\[     \\begin{align*}         \\boldsymbol{S}_0 &amp; = (S_0^1, S_0^2, S_0^3) = (7, 31, 62)\\\\         \\boldsymbol{S}_1 &amp; =          \\begin{bmatrix}             S^1_1(\\omega_1) &amp; S^2_1(\\omega_1) &amp; S^3_1(\\omega_1) \\\\             S^1_1(\\omega_2) &amp; S^2_1(\\omega_2) &amp; S^3_1(\\omega_2) \\\\             S^1_1(\\omega_3) &amp; S^2_1(\\omega_3) &amp; S^3_1(\\omega_3)         \\end{bmatrix} =          \\begin{bmatrix}             40 &amp; 60 &amp; 120 \\\\             0 &amp; 40 &amp; 80 \\\\             20 &amp; 100 &amp; 200         \\end{bmatrix}     \\end{align*} \\] </li> <li> <p>Financial Market I: \\( B_0 = 1 \\) and \\( B_1 = 1 \\) as bank account and two stocks given by</p> \\[     \\begin{align*}         \\boldsymbol{S}_0 &amp; = (S_0^1, S_0^2) = (8, 10)\\\\         \\boldsymbol{S}_1  &amp;=             \\begin{bmatrix}                 S^1_1(\\omega_1) &amp; S^2_1(\\omega_1) \\\\                 S^1_1(\\omega_2) &amp; S^2_1(\\omega_2) \\\\                 S^1_1(\\omega_3) &amp; S^2_1(\\omega_3)             \\end{bmatrix} =              \\begin{bmatrix}             6 &amp; 11 \\\\             5 &amp; 11 \\\\             12 &amp; 9             \\end{bmatrix}     \\end{align*} \\] </li> </ol> <p>Are these models arbitrage-free? If yes, give all risk-neutral pricing measures. Otherwise, provide an arbitrage strategy.</p> <p>Exercise</p> <p>Given a generic financial market as in the lecture on some probability space \\( (\\Omega, \\mathcal{F},P) \\). Recall that the vector of returns of the financial assets is the random variable given by</p> \\[ \\boldsymbol{R}_1 = \\left( \\frac{S_1^1-S_0^1}{S_0^1}, \\ldots, \\frac{S_1^d-S_0^d}{S_0^d} \\right) \\] <p>Show that the following assertions are equivalent:</p> <ol> <li>The financial market is arbitrage-free;</li> <li> <p>There exists no \\( \\boldsymbol{\\eta}\\) in \\(\\mathbb{R}^d \\) such that</p> \\[     P\\left[ \\boldsymbol{\\eta} \\cdot \\boldsymbol{R}_1 \\geq r \\sum_{k=1}^d \\eta^k \\right]=1 \\quad \\text{and} \\quad P\\left[ \\boldsymbol{\\eta} \\cdot \\boldsymbol{R}_1 &gt; r \\sum_{k=1}^d \\eta^k \\right]&gt;0 \\] </li> <li> <p>For any strategy \\( \\boldsymbol{\\eta}\\) in \\(\\mathbb{R}^d \\), it holds that</p> \\[     P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right]=1 \\quad \\text{implies} \\quad P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 = 0 \\right]=1 \\] </li> </ol> <p>Exercise</p> <p>We consider a binomial financial market model with interest rate \\( r \\geq 0 \\),</p> \\[     \\Omega=\\{\\omega^+,\\omega^-\\}, \\quad p:=P(\\{\\omega^+\\})=\\frac{1}{2} \\] <p>and one risky asset with initial value \\( S_0=100 \\) and at time 1,</p> \\[     S_1(\\omega) =          \\begin{cases}             120 &amp; \\text{if } \\omega = \\omega^+ \\\\             90 &amp; \\text{if } \\omega = \\omega^-         \\end{cases} \\] <p>Let \\( C=(S_1-K)^+ \\) be a call option on \\( S \\) with strike price \\( K=100 \\).</p> <ol> <li>For which \\( r \\) is the model arbitrage-free?     For those \\( r \\) for which the model is arbitrage-free, give the risk-neutral pricing measure \\( P^* \\) by finding \\( p^*=P^*(\\{\\omega^+\\}) \\).</li> <li> <p>If you compute the call option's price as the expectation \\( E\\left[\\frac{C}{1+r}\\right] \\) under the objective measure \\( P \\), then there exists an arbitrage in the model.     Show that the risk-free arbitrage gain equals the difference</p> \\[     E\\left[\\frac{C}{1+r}\\right] - E^*\\left[\\frac{C}{1+r}\\right]. \\] </li> <li> <p>For the call option, find a portfolio with start value \\( V_0 \\) and hedging strategy \\( \\eta \\) in \\(\\mathbb{R}\\) such that</p> \\[     \\frac{C}{1+r}=V_0 + \\eta \\Delta X_1 \\] <p>Show that the necessary amount of money to finance this strategy is the risk-neutral price \\( V_0=E^*\\left[\\frac{C}{1+r}\\right] \\).</p> </li> </ol> <p>Exercise: Put/Call Parity</p> <p>On an arbitrage-free financial market, we consider a call and a put</p> \\[ C^{call}=(S_1-K)^+, \\quad \\text{and} \\quad C^{put}=(K-S_1)^+ \\] <p>on the same financial asset \\( S^1 \\) and with the same strike \\( K \\). Show that if \\( \\pi(C^{call}) \\) and \\( \\pi(C^{put}) \\) are fair prices for the call and put respectively, then it has to hold</p> \\[ \\pi(C^{call})=\\pi(C^{put})+S_0-\\frac{K}{1+r} \\] <p>Exercise</p> <p>We consider a financial market with bank account \\( B_0 = 1 \\) and \\( B_1 = 1 + r \\) for some \\( r &gt; -1 \\). We have a single financial asset \\( S \\). We suppose that the financial market is arbitrage-free, and that on this market every call option \\( C(K) = (S_1 - K)^+ \\) is traded for a fair price \\( \\pi(K) \\). Using the \"law of one price,\" compute the prices of the following derivatives:</p> <ol> <li>\\( \\min(S_1, K) \\).</li> <li> <p>\"Butterfly spread\" with payoff \\( f(S_1) \\), whereby \\( f \\) is given by</p> \\[ f(x) =     \\begin{cases}         x-a &amp; \\text{if } a \\leq x \\leq \\frac{a+b}{2}, \\\\         b-x &amp; \\text{if } \\frac{a+b}{2} \\leq x \\leq b, \\\\         0 &amp; \\text{otherwise}     \\end{cases} \\] <p>for some \\( 0 \\leq a \\leq b \\).</p> </li> </ol> <p>Exercise</p> <p>On an arbitrage-free market, we consider a financial asset \\( S \\). A \\( S^2 \\)MART certificate with loss barrier \\( 0 &lt; K_1 \\), strike price \\( K &gt; K_1 \\), and participation rate \\( \\alpha \\) is a certificate given by:</p> <ul> <li>If the financial asset falls below the loss barrier \\( K_1 \\), the certificate pays \\( \\frac{K}{K_1} \\) times the price of the asset at this point.</li> <li>If the financial asset falls between \\( K_1 \\) and \\( K \\), the certificate pays \\( K \\).</li> <li>If the financial asset is above \\( K \\), the certificate pays a portion \\( \\alpha \\) of the asset plus a portion \\( (1-\\alpha) \\) of the strike price.</li> </ul> <p>Given this certificate:</p> <ol> <li>Write the index as a function of \\( S, K_1, K, \\) and \\( \\alpha \\).</li> <li>Show that this certificate can be written as a linear combination of the financial asset and adequate call options.</li> <li>Given \\( K_1, K \\), and the fair price of the call options, determine what should be the participation rate \\( \\alpha \\) such that the fair price of the certificate equals the price of the financial asset.</li> </ol>"},{"location":"material/ex02/","title":"Exercise: Risk Management","text":"<p>Exercise</p> <p>A random variable \\( L \\) is called normally distributed with mean \\( \\mu \\) in \\(\\mathbb{R} \\) and variance \\( \\sigma &gt; 0 \\) if it has a probability density given by</p> \\[   f_{\\mu,\\sigma}(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right) \\] <p>and we use the notation \\( L \\sim \\mathcal{N}(\\mu, \\sigma^2) \\). We denote by</p> \\[ F_{\\mu,\\sigma}(m) = P[L \\leq m] = \\int_{-\\infty}^{m} f_{\\mu,\\sigma}(y) \\, dy, \\quad x \\in \\mathbb{R} \\quad \\text{and} \\quad q_{\\mu,\\sigma}(s) = F^{-1}_{\\mu,\\sigma}(s), \\quad s \\in (0,1) \\] <p>the CDF and quantile of the normal distribution with mean \\( \\mu \\) and variance \\( \\sigma \\). We use the simplified notations for the standard normal:</p> \\[ f = f_{0,1}, \\quad F = F_{0,1}, \\quad q = q_{0,1}. \\] <ol> <li>Show that if \\( L \\sim \\mathcal{N}(0,1) \\), it holds \\( \\mu + \\sigma L \\sim \\mathcal{N}(\\mu, \\sigma^2) \\).</li> <li>Show that if \\( L \\sim \\mathcal{N}(\\mu, \\sigma^2) \\), it holds \\( -L \\sim \\mathcal{N}(-\\mu, \\sigma^2) \\).</li> <li> <p>Show that</p> \\[ f_{\\mu,\\sigma}(x) = \\frac{1}{\\sigma} f\\left( \\frac{x-\\mu}{\\sigma} \\right), \\quad \\sigma^2 f^\\prime_{\\mu,\\sigma} (x) = (\\mu-x)f_{\\mu,\\sigma}(x) \\] \\[ F_{\\mu,\\sigma}(x) = F\\left( \\frac{x-\\mu}{\\sigma} \\right), \\quad q_{\\mu,\\sigma}(s) = \\mu + \\sigma q(s). \\] </li> </ol> <p>Recall that </p> \\[   \\begin{align*}     V@R_{\\alpha}(L) &amp; = \\inf \\{m \\colon P[L&gt;m]\\geq \\alpha\\} = q_L(1-\\alpha)\\\\     ES_{\\alpha}(L) &amp; = \\frac{1}{\\alpha}\\int_0^\\alpha V@R_{\\alpha}(s) ds = \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 q_L(s)ds   \\end{align*} \\] <p>and that both functionals are positive homogoneous.</p> <p>Show that for \\(L\\sim \\mathcal{N}(\\mu, \\sigma^2)\\)</p> \\[     V@R_{\\alpha}(L) = \\mu + \\sigma V@R_{\\alpha}(\\bar{L}) \\quad \\text{and} \\quad ES_{\\alpha}(L) = \\mu + \\sigma ES_{\\alpha}(\\bar{L}) \\] <p>where \\(\\bar{L} \\sim \\mathcal{N}(0, 1)\\) (in other terms, to compute the value at risk or expected shortfal of normal distribution, you just need the V@R and ES of the standard normal distribution).</p> <p>Deduce that for normally distributed random variable \\(L\\) with zero mean, \\(V@R\\) and \\(ES\\) are related through</p> \\[     ES_{\\alpha}(L) = C V@R_{\\alpha}(L) \\] <p>for some constant \\(C\\) which you provide explicitely.</p> <p>Dual Representation</p> <p>We already know that the expected shortfall has two possible representations:</p> \\[   \\begin{align*}      ES_\\alpha(L) &amp; = \\frac{1}{\\alpha} \\int_{1-\\alpha}^{1} q_L(s) ds\\\\                   &amp; = \\inf\\left\\{ m + \\frac{1}{\\alpha} E\\left[ (L-m)^+ \\right] \\right\\}\\\\                   &amp; = q_L(1-\\alpha) + \\frac{1}{\\alpha} E\\left[ \\left( L - q_L(1-\\alpha) \\right)^+ \\right]   \\end{align*} \\] <p>We derive an alternative formulation in terms of duality, namely:</p> \\[ ES_{\\alpha}(L) = \\sup\\left\\{ E^Q[L] \\colon 0 \\leq \\frac{dQ}{dP} \\leq \\frac{1}{\\alpha} \\right\\} \\] <p>This general statement says that the expected shortfall accounts for computing the expected loss under any alternative probability model \\( Q \\) such that \\( Q \\) is not \"too\" far away from \\( P \\) in the sense that the density is bounded by \\( 1/\\alpha \\).</p> <ol> <li> <p>Show that for every \\( x \\) and every \\( y \\) with \\( 0 \\leq y \\leq 1/\\alpha \\) it holds:</p> \\[ \\frac{1}{\\alpha} x^+ \\geq xy \\] <p>In other terms, \\( x^+ / \\alpha = \\sup\\{ xy \\colon 0 \\leq y \\leq 1/\\alpha \\} \\), which is called Fenchel-Moreau duality.</p> </li> <li> <p>Using the fact that \\( E[dQ/dP] = 1 \\), show that if \\( 0 \\leq dQ/dP \\leq 1/\\alpha \\), then it holds:</p> \\[ m + \\frac{1}{\\alpha} E\\left[ (L-m)^+ \\right] \\geq E^Q[L] \\] <p>and deduce that:</p> \\[ ES_{\\alpha}(L) \\geq \\sup\\left\\{ E^Q[L] \\colon 0 \\leq \\frac{dQ}{dP} \\leq \\frac{1}{\\alpha} \\right\\} \\] </li> <li> <p>Assuming that \\( F_L \\) is continuous and strictly increasing, show that if we define the random variable:</p> \\[ \\frac{dQ^\\ast}{dP} = \\frac{1}{\\alpha} 1_{\\{L \\geq q_L(1-\\alpha)\\}} \\] <p>then it defines a probability measure \\( Q^\\ast \\) such that \\( 0 \\leq dQ^\\ast/dP \\leq 1/\\alpha \\) and for which it holds:</p> \\[ ES_{\\alpha}(L) = E^{Q^\\ast}[L] \\] <p>and deduce the duality formula \u2014 for which you now have an explicit \\( Q^\\ast \\) that depends on \\( L \\).</p> </li> </ol>"},{"location":"material/ex_math/","title":"Exercises: Probability and Stochastic Processes","text":"<p>Remark</p> <p>For the Radon Nykodym theorem, the notion of absolute continuity and equivalence between probability measure is central.</p> <p>Definition</p> <p>Given two probability measure \\(P\\) and \\(Q\\) we say that</p> <ol> <li> <p>\\(Q\\) is absolutely continuous with repext to \\(P\\) and denote \\(Q\\ll P\\) if </p> \\[ P[A] = 0 \\quad \\text{implies} \\quad Q[A] = 0\\] </li> <li> <p>\\(Q\\) is equivalent to \\(P\\) and denote \\(Q\\sim P\\) if both \\(Q\\ll P\\) and \\(P\\ll Q\\).     That is</p> \\[ P[A] = 0 \\quad \\text{if and only if} \\quad Q[A] = 0\\] </li> </ol> <p>By definition it clearly holds that</p> \\[     Q \\ll P \\quad \\text{if and only if} \\quad P[A] = 1 \\, \\text{implies}\\, Q[A] = 1 \\] <p>or</p> \\[     Q \\ll P \\quad \\text{if and only if} \\quad Q[A] &gt; 0 \\, \\text{implies}\\, P[A] &gt; 0 \\] <p>and in the equivalent case</p> \\[     Q \\sim P \\quad \\text{if and only if} \\quad P[A] = 1 \\, \\text{if and only if}\\, Q[A] = 1 \\] <p>or</p> \\[     Q \\sim P \\quad \\text{if and only if} \\quad P[A] &gt; 0 \\, \\text{if and only if}\\, Q[A] &gt; 0 \\] <p>Exercise</p> <p>The Radon-Nykodym theorem states that if a probability measure \\( Q \\ll P \\), then there exists a (\\( P \\)-almost surely) unique random variable \\(Z\\) such that</p> \\[   \\begin{equation*}     \\begin{cases}       Z &amp; \\geq 0 \\\\       E^P[Z] &amp; = 1 \\\\       E^Q[X] &amp; = E^P[Z X] \\quad \\text{ for any positive bounded random variable }X     \\end{cases}   \\end{equation*} \\] <p>This unique random variable is called the density of \\(Q\\) with respect to \\(P\\) and denoted by \\(dQ/dP\\).</p> <p>This density allows to compute expectation of random variable under \\(Q\\) in terms of expectation under \\(P\\). If \\(Q\\sim P\\) then \\(dQ/dP\\) is strictly positive and \\(dP/dQ = (dQ/dP)^{-1}\\).</p> <p>This fundamental theorem is complex to prove in the general case, relying on other fundamental theorems of functional analysis. However, you can prove it easily in the finite state setting.</p> <p>Let \\( \\Omega=\\{\\omega_1,\\ldots,\\omega_n\\} \\) be a finite state space with \\( \\sigma \\)-algebra \\( \\mathcal{F}=2^\\Omega \\) and probability measure \\( P \\) given by the vector \\( \\boldsymbol{p}=(p_1,\\ldots,p_n) \\) where \\( P[\\{\\omega_i\\}]=p_i&gt;0 \\) for every \\( i \\) and \\( \\sum p_i=1 \\).</p> <p>Let now \\( Q \\) be another probability measure on \\( (\\Omega,\\mathcal{F}) \\) given by the vector \\( \\boldsymbol{q}=(q_1,\\ldots,q_n) \\) where \\( Q[\\{\\omega_i\\}]=q_i\\geq 0 \\) and \\( \\sum q_i=1 \\). Since \\( P[A]=0 \\) implies \\( A=\\emptyset \\), it follows that \\( Q[A]=Q[\\emptyset]=0 \\). Hence, \\( Q \\) is absolutely continuous with respect to \\( P \\).</p> <p>Find a random variable \\( \\frac{dQ}{dP}:\\Omega \\to \\mathbb{R} \\) such that \\( \\frac{dQ}{dP}\\geq 0 \\), \\( E_P[\\frac{dQ}{dP}]=1 \\), and </p> \\[ E_Q[X]=E_P\\left[ \\frac{dQ}{dP}X \\right] \\] <p>for every random variable \\( X:\\Omega\\to \\mathbb{R} \\). Show that \\( \\frac{dQ}{dP} \\) is also unique.</p> <p>Note that since it is a finite setting, the random variable \\(dQ/dP\\) can be represented by an \\( n \\)-dimensional vector \\(\\boldsymbol{z} = (z_1, \\ldots, z_n)\\) with \\(z_i = dQ/dP(\\omega_i)\\). The conditions therefore translate into finding such a vector \\(\\boldsymbol{z}\\) with \\(z_i \\geq 0\\), \\(\\sum z_i p_i = 1\\) and such that for every vector \\(\\boldsymbol{x}=(x_1, \\ldots, x_n)\\) it holds</p> \\[   \\sum x_i q_i =E^Q[X] = E\\left[ \\frac{dQ}{dP}X \\right] = \\sum x_i z_i p_i \\] <p>Exercise</p> <p>Let \\( (\\Omega, \\mathcal{F}, P) \\) be a probability space. Given a positive random variable \\( X \\), we define </p> \\[ A = \\left\\{ X &gt; 0 \\right\\} := \\left\\{ \\omega \\colon X(\\omega) &gt; 0 \\right\\} \\quad \\text{and} \\quad A_n = \\left\\{ X &gt; \\frac{1}{n} \\right\\}, \\quad n \\in \\mathbb{N}. \\] <p>Show that:</p> <ol> <li>\\( A_n \\subseteq A_{n+1} \\) and \\( \\cup_{k \\leq n} A_k = A_n \\nearrow A \\).</li> <li> <p>\\( P[A_n] \\nearrow P[A] \\).</p> <p>Hint: Show that the sequence of events \\( B_1 = A_1 \\), \\( B_2 = A_2 \\setminus A_1 \\), \\( B_3 = A_3 \\setminus A_2 \\), \\( \\ldots \\) is such that:</p> \\[ B_k \\cap B_j = \\emptyset \\text{ for } k \\neq j, \\quad \\cup_{k=1}^n B_k = A_n, \\quad \\text{and} \\quad \\cup_{k=1}^\\infty B_k = A, \\] <p>and conclude with the property of a probability measure which implies:</p> \\[ P\\left[ \\cup_{k=1}^n B_k \\right] = \\sum_{k=1}^{n} P\\left[ B_k \\right] \\nearrow \\sum_{k=1}^\\infty P[B_k] = P\\left[\\cup_{k=1}^\\infty B_k \\right]. \\] </li> <li> <p>Show that \\( X \\leq Y \\) implies \\( E[X] \\leq E[Y] \\), and deduce:</p> \\[ \\frac{1}{n} P\\left[ A_n \\right] \\leq E\\left[ X 1_{A_n} \\right] \\leq E\\left[ X \\right]. \\] </li> <li> <p>Deduce that if \\( X \\geq 0 \\) and \\( E[X] = 0 \\), then \\( P[X &gt; 0] = 0 \\).</p> </li> <li>Deduce that if \\( X \\geq 0 \\) and \\( P\\left[ X &gt; 0 \\right] &gt; 0 \\), then \\( E\\left[ X \\right] &gt; 0 \\).</li> </ol> <p>Exercise</p> <p>Let \\( (\\Omega, \\mathcal{F}, P) \\) be a probability space. Let further \\( (A_n) \\) be a sequence of pairwise disjoint elements\\footnote{That is \\( A_n \\cap A_m = \\emptyset \\) for every \\( n \\neq m \\).} of \\( \\mathcal{F} \\) such that \\( P[A_n] &gt; 0 \\) for every \\( n \\). Define \\( \\mathcal{G} = \\sigma(A_n \\colon n) \\), the \\( \\sigma \\)-algebra generated by the sequence \\( (A_n) \\). That is,</p> \\[ A \\in \\mathcal{G} \\quad \\text{if and only if} \\quad A = \\cup_{i \\in I} A_i, \\quad I \\subseteq \\mathbb{N}. \\] <p>Show that:</p> <ol> <li> <p>For every \\( B \\in \\mathcal{F} \\), it holds</p> \\[ P\\left[ B|\\mathcal{G} \\right] := E\\left[ 1_B |\\mathcal{G} \\right] = \\sum P\\left[ B | A_n \\right] 1_{A_n} \\] <p>where \\( P[B|A_n] := \\frac{P[B \\cap A_n]}{P[A_n]} \\).</p> </li> <li> <p>For every \\( X \\), a bounded random variable, it holds</p> \\[ E\\left[ X|\\mathcal{G} \\right] = \\sum \\frac{E\\left[ 1_{A_n} X \\right]}{P[A_n]} 1_{A_n}. \\] </li> </ol> <p>Exercise</p> <ol> <li> <p>Let \\( X \\) and \\( Y \\) be two identically distributed random variables. Show that</p> \\[ E\\left[ X \\big| \\sigma(X+Y) \\right] = \\frac{X+Y}{2}. \\] <p>Hint: Note that \\( E[X+Y | \\sigma(X+Y)] = X+Y \\).</p> </li> <li> <p>Let \\( X = (X_t)_{0 \\leq t \\leq T} \\) be a martingale on a probability space \\( (\\Omega, \\mathcal{F}, P) \\) with a filtration \\( \\mathbb{F} = (\\mathcal{F}_t)_{0 \\leq t \\leq T} \\). Show that \\( E[X_s|\\mathcal{F}_t]=X_t \\) for every \\( 0 \\leq t \\leq s \\leq T \\).</p> </li> <li> <p>Let \\( Y_1, \\ldots, Y_T \\) be independent random variables on a probability space \\( (\\Omega, \\mathcal{F}, P) \\) with \\( Y_t &gt; 0 \\) \\( P \\)-almost surely and \\( E[Y_t]=1 \\) for every \\( t \\). Show that</p> \\[ X_0 = 1, \\quad X_t = \\prod_{s=1}^t Y_s, \\quad t = 1, \\ldots, T \\] <p>is a martingale with respect to the filtration \\( \\mathcal{F}_0 = \\{\\emptyset, \\Omega\\} \\) and \\( \\mathcal{F}_t = \\sigma(Y_1, \\ldots, Y_t) \\).</p> </li> <li> <p>Let \\( Y_1, \\ldots, Y_t \\) be independent random variables such that \\( Y_t \\sim \\mathcal{N}(0,1) \\) on some probability space \\( (\\Omega, \\mathcal{F}, P) \\). Consider the filtration \\( \\mathcal{F}_0 = \\{\\emptyset, \\Omega\\} \\) and \\( \\mathcal{F}_t = \\sigma(Y_1, \\ldots, Y_t) \\). We consider the price process</p> \\[ S_0 &gt; 0, \\quad S_t = S_0 \\exp\\left( \\sum_{s=1}^t \\left(\\sigma Y_s + \\mu\\right) \\right) \\] <p>where \\( \\sigma, \\mu \\) are constants such that \\( \\sigma &gt; 0 \\). Let further the bank account be</p> \\[ B_t = (1 + r)^t. \\] <p>For which values of \\( \\mu \\) is the discounted price process</p> \\[ X_t = \\frac{S_t}{B_t} \\] <p>a martingale?</p> <p>Hint: Note that if \\( Z \\sim \\mathcal{N}(0, \\sigma^2) \\), then it holds that \\( E[e^Z] = e^{\\sigma^2 / 2} \\).</p> </li> </ol> <p>Exercise: Measure Change</p> <p>Consider a probability space \\( (\\Omega, \\mathcal{F}, P) \\) and a filtration \\( \\{\\emptyset, \\Omega\\} = \\mathcal{F}_0 \\subseteq \\mathcal{F}_1 \\subseteq \\cdots \\subseteq \\mathcal{F}_T \\).</p> <p>Let \\( Q \\) be a probability measure equivalent to \\( P \\), and we denote by \\( Z = dQ / dP \\) its density, that is, the unique positive integrable random variable with expectation \\( 1 \\) such that for any \\( Q \\)-integrable random variable \\( H \\) it holds</p> \\[ E^Q\\left[ H \\right] = E\\left[ Z H \\right] \\] <p>We further denote by</p> \\[ Z_t = E\\left[ Z \\, | \\, \\mathcal{F}_t \\right], \\quad t = T, T-1, \\ldots, 0 \\] <p>the conditional density.</p> <p>Show that:</p> <ul> <li>\\( Z_t \\) is a positive random variable with expectation \\( 1 \\). It defines therefore a probability measure \\( Q_t \\sim P \\) on \\( \\mathcal{F}_t \\).</li> <li>Show that the stochastic process \\( Z = Z_0, Z_1, \\ldots \\) is a \\( P \\)-martingale.</li> <li> <p>Show that for any \\( Q \\)-integrable random variable \\( H \\) it holds</p> \\[ E^Q\\left[ H \\big| \\mathcal{F}_t \\right] = \\frac{1}{Z_t} E^P\\left[ Z H \\big| \\mathcal{F}_t \\right] \\] </li> <li> <p>Let \\( M = M_0, M_1, \\ldots \\) be an adapted and \\( Q \\)-integrable stochastic process. Show that \\( M \\) is a \\( Q \\)-martingale if and only if \\( Z M \\) is a \\( P \\)-martingale.</p> </li> </ul>"},{"location":"material/probability/","title":"Probability","text":""},{"location":"material/probability/#probability-space","title":"Probability Space","text":"<p>In probability, we consider:</p> <ul> <li>A state space \\( \\Omega \\) of states \\( \\omega \\in \\Omega \\):      Description of possible states of an outcome for which there is uncertainty.</li> <li>Events \\( A \\subseteq \\Omega \\) as a collection of states that can happen.     The family of all considered events \\( A \\subseteq \\Omega \\) is denoted by \\( \\mathcal{F} \\).</li> </ul> <p>Examples</p> <ol> <li> <p>Coin Flipping:</p> <ul> <li> <p>State space: \\( \\Omega = \\{H, T\\} \\), where \\( H \\) and \\( T \\) denote the states \"Head occurs\" and \"Tail occurs\" as the possible outcomes of throwing a coin.</p> </li> <li> <p>Events: \\( A = \\{H\\} \\) is the event that head will occur.</p> </li> </ul> </li> <li> <p>Temperature tomorrow:</p> <ul> <li> <p>State space: \\( \\Omega = \\mathbb{R} \\), where \\( x \\in \\Omega \\) represents the possible temperature at 8:00 am tomorrow.</p> </li> <li> <p>Events: \\( A = [13,19] \\) is the event that tomorrow at 8:00 am, the temperature will lie between \\( 13 \\) and \\( 19 \\) degrees.</p> </li> </ul> </li> <li> <p>Financial decision: </p> <ul> <li> <p>State space: \\( \\Omega = [-1,10]^2 \\), where for \\( (x, y) \\in \\Omega \\), \\( x \\) and \\( y \\) represent the interest rates that the central banks of the USA and EU, respectively, will fix next month.</p> </li> <li> <p>Events: \\( A = [0.25,0.75] \\times [0.9,1.8] \\cup \\{1\\} \\times [1.7,2.1] \\) is the event that next month the USA fixes an interest rate between \\( 0.25\\% \\) and \\( 0.75\\% \\) while the EU fixes one between \\( 0.9\\% \\) and \\( 1.8\\% \\), OR the USA fixes an interest rate of \\( 1\\% \\) while the EU fixes one between \\( 1.7\\% \\) and \\( 2.1\\% \\).</p> </li> </ul> </li> <li> <p>Texas Holdem:</p> <p>For Texas Holdem, we have 52 cards deck \\(D\\) with cards  ,  ,  , ...</p> <p>After pre-flop, flop, turn and river (if you're still there), you have to choose 5 best cards out of the best combinations you can get from the 5 on the table and the two in your hand.</p> <ul> <li> <p>State space: \\( \\Omega = \\{\\{c_1, c_2, c_3, c_4, c_5\\} \\colon c_i \\in D, \\text{ and } c_i \\neq c_j\\} \\).   Note here the notation in terms of set, since the order does not count. Furthermore, each card is different since distributing occurs without replacement.</p> </li> <li> <p>Event: The event \\(A\\) that I have a royal flush corresponds to \\(A\\) containing the elements \\(\\{\\) , , , , \\(\\}\\), \\(\\{\\) , , , , \\(\\}\\), \\(\\{\\) , , , , \\(\\}\\), \\(\\{\\) , , , , \\(\\}\\).</p> </li> </ul> </li> </ol> <p>Events are supposed to be measured afterwards, however we require some structure among events. We want to speak about the occurence of one or the other event, two events happening coincidentally, or an event not happening. Therefore, the definition of measurable space</p> <p>Measurable Space</p> <p>A measurable space is a tuple \\( (\\Omega, \\mathcal{F}) \\), where </p> <ul> <li>\\(\\Omega\\) is a set (state space)</li> <li>\\(\\mathcal{F}\\) is an algebra of subsets of \\(\\Omega\\) (Events)</li> </ul> <p>An algebra is a collection of sets satisfying the following properties</p> <ul> <li>\\( \\emptyset \\) (nothing happens) and \\( \\Omega \\) (anything can happen) are events.</li> <li>If \\(A\\) is an event, then so is \\(A^c\\);</li> <li>If \\(A\\) and \\(B\\) are events, then \\(A\\cup B\\) is an event (the event that \\(A\\) or \\(B\\) happen is itself an event)</li> </ul> <p>Warning</p> <p>Note that this is the intuitive definition of a measurable space, but for mathematical reason, we require the algebra of events \\(\\mathcal{F}\\) to be \\(\\sigma\\)-stable, that is instead of requiring union of two or finitely many events to be an events, we also require </p> <p>If the state space \\(\\Omega\\) is finite or countable, the classical assumption is to consider as algebra of events the power set \\(2^{\\Omega}\\) which is the collection of any subsets. If the state space is infinite, such as \\(\\mathbb{R}\\), the power set would be truly large and leading to mathematical issues. In the case of \\(\\mathbb{R}\\) for instance, the measurable sets are those generated by intervals.</p> <p>Proposition</p> <p>The third assumption for an algebra is equivalent to replace by </p> <ul> <li>If \\(A\\) and \\(B\\) are events, then \\(A\\cap B\\) is an event.</li> </ul> <p>Proof</p> <p>Let \\(A\\) and \\(B\\) be event, from the second assumption it follows follows that \\(A^c\\). Now the equivalence between the two assertion (intersection vs union) follows from Morgan's rule</p> \\[     A\\cap B = (A^c \\cup B^c)^c \\quad \\text{and}\\quad A\\cup B = (A^c \\cap B^c)^c \\] <p>Examples</p> <p>Here are some classical exmaples we will see throughout the lecture.</p> <ul> <li> <p>Coin toss:</p> <ul> <li>State Space: \\(\\Omega = \\{-1, 1\\}\\) two states for head and tail</li> <li>Events: \\(\\mathcal{F} = 2^\\Omega = \\{\\emptyset, \\Omega, \\{1\\}, \\{-1\\}\\}\\)</li> </ul> <p>There are here exactly \\(2^2 =4\\) events.</p> </li> <li> <p>Finite state space:</p> <ul> <li>State Space: \\(\\Omega = \\{\\omega_1, \\ldots, \\omega_N\\}\\)</li> <li>Events: \\(\\mathcal{F} = 2^\\Omega\\)</li> </ul> <p>There are here exactly \\(2^{\\#\\Omega} = 2^N\\) events (already with \\(N\\) beyond 100 this is more than a computer can take).</p> </li> <li> <p>Random Walk:</p> <p>The random walk consists to draw a coin several times in a row, recording every single result.</p> <ul> <li>State Sapce: \\(\\Omega = \\{\\omega = (\\omega_1, \\ldots, \\omega_T)\\colon \\omega_i = \\pm 1\\}\\) where each state is the sequence of results of the coin toss.</li> <li>Events: \\(\\mathcal{F}=2^\\Omega\\).</li> </ul> <p>As above, the cardinality of \\(\\mathcal{F}\\) is equal to \\(2^{\\# \\Omega}\\). However there are \\(2^N\\) possible sequences, and so the cardinality of events is equal to \\(2^{2^N}\\). You can imagine that for small \\(N\\) this size is already gigantic.</p> </li> </ul>"},{"location":"material/probability/#random-variables","title":"Random Variables","text":"<p>Aside from being able to measure events, we also want to know how to measure the events that a function of this state satisfies. For instance, in the case of the coin toss, suppose that you play a game where if head you win 100 and if tail you lose everything. As a function of the state it writes as \\(X \\colon \\Omega \\to \\mathbb{R}\\) where \\(X(\\omega) = 100\\) if \\(\\omega = 1\\) and \\(X(\\omega) = 0\\) otherwize. We want to be able to speak about the event \\(A\\) you strictly win something which clearly if \\(\\{1\\}\\). In the general case we define random variables as such functions where you can measure this function to reach some certain level.</p> <p>Definition</p> <p>Let \\( (\\Omega, \\mathcal{F}) \\) be a measurable space. A function</p> \\[   \\begin{equation*}     \\begin{split}       X\\colon \\Omega \\longrightarrow \\mathbb{R}\\\\           \\omega &amp; \\longmapsto X(\\omega)     \\end{split}   \\end{equation*} \\] <p>is called a random variable if for every level \\(x\\), the set</p> \\[     A = \\left\\{ \\omega \\in \\Omega \\colon X(\\omega)\\leq x \\right\\}:= \\{X\\leq x\\} \\] <p>is an event, that is \\(A \\in \\mathcal{F}\\).</p> <p>The fact that we require the event smaller than some value seems arbitrary, however, since we have a (\\(\\sigma\\))-algebra this is quite general</p> <p>Proposition</p> <p>It is equivalent for \\( X: \\Omega \\to \\mathbb{R} \\) to be a random variable to require:</p> <ol> <li>\\( \\{X &gt; x\\} \\in \\mathcal{F} \\) for any \\( x \\).</li> <li>\\( \\{X &lt; x\\} \\in \\mathcal{F} \\) for any \\( x \\).</li> <li>\\( \\{X \\geq x\\} \\in \\mathcal{F} \\) for any \\( x \\).</li> <li>\\( \\{x \\leq(&lt;) X \\leq(&lt;) y\\} \\in \\mathcal{F} \\) for any \\( x \\leq y \\).</li> </ol> Proof <ol> <li>Follows from \\( \\{X &gt; x\\} = \\{X \\leq x\\}^c \\), and \\( \\mathcal{F} \\) is closed under complementation.</li> <li>\\( \\{X &lt; x\\} = \\cap_{n} \\{X \\leq x +1/n\\} \\), and \\( \\mathcal{F} \\) is closed under countable union.</li> </ol> <p>The other assertions follows similar argumentations.</p> <p>This definition is compatible with many of the standard operations. In other terms the sum, product, composition with continuous function of random variables remain random variables.</p> <p>Proposition</p> <p>Let \\( X \\) be a random variable and \\( f:\\mathbb{R}\\to \\mathbb{R} \\) be a continuous function. Then</p> \\[   \\begin{equation*}     \\begin{split}       Y\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}\\\\       \\omega &amp; \\longmapsto Y(\\omega) = f(X(\\omega))     \\end{split}   \\end{equation*} \\] <p>is a random variable denoted \\( Y = f(X) \\).</p> <p>Let \\( X, Y \\) be random variables as well as \\( (X_n) \\) be a converging sequence of random variables. The following are random variables:</p> <ul> <li>\\( aX + bY \\) for every \\( a, b \\in \\mathbb{R} \\);</li> <li>\\( XY \\);</li> <li>\\( \\max(X, Y) \\) and \\( \\min(X, Y) \\);</li> <li>\\( \\sup X_n \\) and \\( \\inf X_n \\);</li> <li>\\( \\lim X_n \\).</li> </ul> Proof <p>The first part of the proof is not trivial and has to do with topology as well as the definition of continuous functions. The argument goes as follows, for \\(y\\) in \\(\\mathbb{R}\\), the set \\(F = \\{x \\in \\mathbb{R}\\colon f(x) \\leq y\\}\\) is a close set since \\(f\\) is continuous (lower semi-continuous would be enought). Now it is possible to show following the previous proposition that if \\(X\\) is a random variable, then \\(\\{X \\in F\\}\\) is an event since \\(F\\) is closed. It follows that</p> \\[   \\begin{align*}     \\{Y \\leq y\\} &amp; = \\left\\{\\omega \\in \\Omega\\colon f(X(\\omega))\\leq y\\right\\}\\\\                   &amp; = \\left\\{ \\omega \\in \\Omega \\colon X(\\omega) \\in \\{x \\in \\mathbb{R}\\colon f(x)\\leq y\\} \\right\\}\\\\                   &amp; = \\left\\{ X \\in F \\right\\} &amp;&amp; \\text{which is an event.}   \\end{align*} \\] <p>For the other three points, it follows from the continuity of functions. For the \\(\\sup\\) and \\(\\inf\\), it follows from \\(\\{\\sup X_n \\leq x\\} = \\cap \\{X_n \\leq x\\}\\) and \\(\\{\\inf X_n &lt;x\\} = \\cup \\{X_n &lt;x\\}\\), with similar argumentation of the limit of converging sequence of random variables.</p> <p>If you are interested, you can ask for lecture notes on probability.</p> <p>Example: Indicator and Simple Random Variables</p> <p>We turn to the most simple yet one of the most important example of random variable in probability.</p> <ul> <li> <p>Indicator Function</p> <p>Definition</p> <p>Let \\( (\\Omega, \\mathcal{F}) \\) be a measurable space and let \\( A \\in \\mathcal{F} \\) be an event. The function</p> \\[ \\begin{equation*} \\begin{split}   1_A \\colon &amp; \\Omega \\longrightarrow \\mathbb{R}\\\\   \\omega &amp; \\longmapsto 1_A(\\omega) =       \\begin{cases}        1 &amp; \\text{if } \\omega \\in A, \\\\        0 &amp; \\text{if } \\omega \\notin A      \\end{cases} \\end{split} \\end{equation*} \\] <p>is called the indicator function of \\( A \\).</p> <p>Exercise</p> <p>The indicator function \\(1_A\\) of an event \\(A\\) is a random variable. Indeed, let \\(x\\) be in \\(\\mathbb{R}\\). It follows that</p> \\[   \\{1_A \\leq x\\} =    \\begin{cases}   \\emptyset &amp; \\text{if } x&lt;0\\\\   A^c &amp; \\text{if }0\\leq x &lt;1 \\\\   \\Omega &amp; \\text{if }x \\geq 1   \\end{cases} \\] </li> <li> <p>Plot</p> <p> </p> </li> </ul> <p>This definition is strongly related to a table of truth: \\( 1 \\) for true, \\( 0 \\) for false. Clearly \\( 1_{\\emptyset} = 0 \\) and \\( 1_{\\Omega} = 1 \\). Show that:</p> <ol> <li>If \\( A \\) and \\( B \\) are events such that \\( A \\cap B = \\emptyset \\), then \\( 1_{A \\cup B} = 1_A + 1_B \\).</li> <li>If \\( A \\) and \\( B \\) are events, then \\( 1_{A \\cap B} = 1_A 1_B \\).</li> <li>If \\( A \\subseteq B \\) are events, then \\( 1_A \\leq 1_B \\).</li> </ol> <ul> <li> <p>Simple Random Variable</p> <p>Definition: Simple Random Variables</p> <p>For a family \\( A_1, A_2, \\ldots, A_n \\) of disjoint events and numbers \\( \\alpha_1, \\ldots, \\alpha_n \\), we can define the simple random variable</p> \\[   X(\\omega) = \\sum_{k=1}^n \\alpha_k 1_{A_k}(\\omega) =      \\begin{cases}       \\alpha_k &amp; \\text{if } \\omega \\in A_k, \\\\       0 &amp; \\text{otherwize}     \\end{cases} \\] <p>According to the previous proposition, it follows that \\( X \\) is also a random variable.</p> <p>Note that intuitively, multiplication and addition of simple random variables remain simple random variables, however one has to be careful to show it on the events where both random variable coincide.</p> </li> <li> <p>Plot</p> <p> </p> </li> </ul> <p>Example: Random Variable on Finite State Space</p> <p>Let \\( \\Omega = \\{\\omega_1, \\omega_2, \\ldots, \\omega_N\\} \\) be a finite state space and \\( \\sigma \\)-algebra \\( \\mathcal{F} = 2^\\Omega \\). We consider a financial market with one stock \\( S \\) where \\( S_0 &gt; 0 \\) denotes the price today and \\( S_1 \\) represents the possible price of the stock tomorrow. The possible evolution for the stock is given as a function:</p> \\[   \\begin{equation*}     \\begin{split}       S_1\\colon \\Omega &amp; \\longrightarrow [0, \\infty)\\\\           \\omega_n &amp;\\longmapsto S_1(\\omega_n) = s_n     \\end{split}   \\end{equation*} \\] <p>We can also write the stock price function as a simple random variable (showing therefore that it is a random variable):</p> \\[ S_1 = \\sum_{n=1}^N s_n 1_{A_n} \\] <p>where \\( A_n = \\{\\omega_n\\} \\). In other terms, the stock price is entirely given by the vector \\( (s_1, \\ldots, s_N) \\). Without any loss of generality, since we have one stock, we may assume that \\( s_1 &lt; s_2 &lt; \\ldots &lt; s_N \\). Also, since the stock price is positive, we also have \\( 0 \\leq s_1 \\). The returns \\( R_1 = \\frac{S_1 - S_0}{S_0} \\) are also a random variable that can be described as a vector \\( (r_1, \\ldots, r_N) \\), where</p> \\[ r_n = \\frac{s_n - S_0}{S_0} \\]"},{"location":"material/probability/#probability-measure","title":"Probability Measure","text":"<p>Definition: Probability Measure</p> <p>A probability measure \\( P \\) on the measurable space \\( (\\Omega, \\mathcal{F}) \\) is a function \\( P: \\mathcal{F} \\to [0,1] \\) that associate to each event \\(A\\) the likelyhood of this event.</p> <p>It has the following basic properties:</p> <ul> <li> <p>\\( P[\\emptyset] = 0 \\) and \\( P[\\Omega] = 1 \\)(1)</p> <ol> <li>Clearly, the probability that nothing or anything can happen is \\(0\\) or \\(1\\).</li> </ol> </li> <li> <p>\\(P[A \\cup B] = P[A] + P[B]\\) if \\(A\\) and \\(B\\) are two disjoint events.(1)</p> <ol> <li>The countable property is however assumed, that is \\( P[\\cup A_n] = \\sum P[A_n] \\) for every sequence of pairwise disjoint(1) events \\( (A_n) \\subseteq \\mathcal{F} \\).</li> </ol> </li> </ul> <p>The triple \\( (\\Omega, \\mathcal{F}, P) \\) is called a probability space.</p> <p>The assumptions for a probability measure are few, however together with the definition of the algebra we can rapidly derive classical properties that are common knowledge.</p> <p>Lemma</p> <p>Let \\( P \\) be a probability measure. For any events \\( A \\), \\( B \\), or sequence \\( (A_n) \\) of events, the following hold:</p> <ul> <li>\\( P[B] = P[A] + P[B \\setminus A] \\geq P[A] \\) whenever \\( A \\subseteq B \\);</li> <li>\\( P[A^c] = 1 - P[A] \\);</li> <li>\\( P[A \\cup B] + P[A \\cap B] = P[A] + P[B] \\);</li> <li> <p>If \\( A_1 \\subseteq A_2 \\subseteq \\ldots \\subseteq A_n \\subseteq \\ldots \\), then:</p> \\[   P\\left[ \\cup A_n \\right] = \\lim P[A_n] \\] </li> <li> <p>If \\( A_1 \\supseteq A_2 \\supseteq \\ldots \\supseteq A_n \\supseteq \\ldots \\), then:</p> \\[   P\\left[ \\cap A_n \\right] = \\lim P[A_n] \\] <p>In particular, it equals \\( 0 \\) if \\( \\cap A_n = \\emptyset \\).</p> </li> </ul> Proof <p>We prove some of the points, leaving the others as an exercise.</p> <p>For the first point, let \\( A \\subseteq B \\). We have \\( B = A \\cup (B \\setminus A) \\), where this union is disjoint. By the second property of a probability measure and the positivity of probability:</p> \\[ P[B] = P[A \\cup (B \\setminus A)] = P[A] + P[B \\setminus A] \\geq P[A] \\] <p>Taking \\( B = \\Omega \\), and using \\( P[\\Omega] = 1 \\), the second point follows.</p> <p>Using similar arguments, prove the third point.</p> <p>For the fourth point, construct the sequence of disjoint sets:</p> \\[     B_1 = A_1, \\quad B_2 = A_2 \\setminus A_1, \\quad \\ldots, \\quad B_n = A_n \\setminus A_{n-1} \\] <p>By induction, it is easy to show:</p> \\[ A_n = \\cup_{k=1}^n A_k = \\cup_{k=1}^n B_k, \\quad \\text{and} \\quad \\cup_n A_n = \\cup_n B_n \\] <p>By additivity of the probability measure:</p> \\[   P[A_n] = P\\left[ \\cup_{k=1}^n A_k \\right] = P\\left[ \\cup_{k=1}^n B_k \\right] = \\sum_{k=1}^n P[B_k] \\nearrow \\sum_{k=1}^\\infty P[B_k] \\] <p>Thus:</p> \\[   \\lim P[A_n] = \\sum_{k=1}^\\infty P[B_k] \\] <p>By the second property of a probability measure:</p> \\[ P\\left[ \\cup_{k=1}^\\infty A_k \\right] = P\\left[ \\cup_{k=1}^\\infty B_k \\right] = \\sum_{k=1}^\\infty P[B_k] \\] <p>Combining these equations shows \\( \\lim P[A_n] = P[\\cup A_n] \\).</p> <p>Follow similar reasoning to prove the last point.</p> <p>Note: Shorthand Notations in Probability</p> <p>In probability theory, the following shorthand notations are commonly used:</p> \\[ P[X \\in B] := P[\\{\\omega \\in \\Omega : X(\\omega) \\in B\\}], \\quad  P[X = x] := P[\\{\\omega \\in \\Omega : X(\\omega) = x\\}] \\] \\[ P[X \\leq x] := P[\\{\\omega \\in \\Omega : X(\\omega) \\leq x\\}], \\quad \\ldots \\] <p>Examples</p> <ol> <li> <p>Probability on Finite Sets:     Suppose \\( \\Omega = \\{\\omega_1, \\ldots, \\omega_N\\} \\) is finite.     Each probability measure \\( P \\) on \\( \\mathcal{F} = 2^\\Omega \\) is entirely determined by the values \\( p_n = P[\\{\\omega_n\\}] \\) for \\( n = 1, \\ldots, N \\).     Indeed, for every event \\(A\\) is of the form \\(A=\\{\\omega_n\\colon n \\in I\\}\\) for some \\(I\\subseteq \\{1, \\ldots, N\\}\\).     It follows that</p> \\[   P[A] = \\sum_{\\omega \\in A} P[\\{\\omega\\}] = \\sum_{n \\in I} p_n \\] <p>This vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N) \\) has the property that \\(p_n = P[\\{\\omega_n\\}]\\geq 0\\) and \\(\\sum p_n =P[\\Omega] = 1\\).</p> <p>Reciprocally, if you give yourself a vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N)\\) with \\(p_n \\geq 0\\) and \\(\\sum p_n\\), it defines a probability \\(P\\) on \\(\\mathcal{F}\\) with the definition</p> \\[   P[A]:=\\sum_{n \\in I} p_n \\] <p>where \\(A = \\{\\omega_n \\colon n \\in I\\}\\). As an exercise, verify that this defines a probability measure.</p> <p>The set of such vectors is denoted by</p> \\[   \\Delta := \\left\\{ \\boldsymbol{p} \\in \\mathbb{R}^N \\colon : p_n \\geq 0, \\, \\sum p_n = 1 \\right\\} \\] <p>An important case is when \\( p_n = 1/N \\) for all \\( n \\). This is called the uniform probability distribution.</p> </li> <li> <p>Probability on the Coin Toss Space:     Let \\( \\Omega = \\{\\omega = (\\omega_1, \\ldots, \\omega_T) : \\omega_t = \\pm 1\\} \\), a finite state space.     Assuming the probability of heads is \\( p \\) and coin tosses are independent, the probability is:</p> \\[   P[\\{\\omega = (\\omega_1, \\ldots, \\omega_T)\\}] = p^l q^{T-l} \\] <p>where \\( l \\) is the number of times \\( \\omega_t = 1 \\) for \\( t = 1, \\ldots, T \\).</p> </li> <li> <p>Normal Distribution:     For \\( \\Omega = \\mathbb{R} \\) and \\( \\mathcal{F} \\) the \\( \\sigma \\)-algebra of \\( \\mathbb{R} \\) generated by intervals, define for any event \\(A\\) the probability</p> \\[   P[A] = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\int_A e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\lambda(dx) \\] <p>where \\( \\lambda \\) is the Lebesgue measure on \\( \\mathbb{R} \\), the one measuring intervals. This is the normal distribution. For example, temperatures in Shanghai at this time of year may follow a normal distribution around 24\u00b0C with variance 1.</p> </li> </ol>"},{"location":"material/probability/#integration","title":"Integration","text":"<p>The historical idea behind integration was to measure areas below a function. The expectation in probability brings exactly the same intuition to this more abstract level.</p> <p>Consider the simple example of the indicator function \\(1_A\\), it represents a rectangle of height \\(1\\) and width represented by the measure of \\(A\\), that is \\(P[A]\\). Hence, the area of the rectangle, or expectation of the indicator function, is given by \\(E[1_A]=1 \\times P[A]\\).</p> <p>Extending this concept is straightforward for any positive simple random variable.</p> <ul> <li> <p>Integration of Simple Random Variable</p> <p>Definition: Expectation 1.0</p> <p>Let \\((\\Omega,\\mathcal{F},P)\\) be a probability space. Given a simple random variable  </p> \\[   X = \\sum_{k\\leq n} \\alpha_k 1_{A_k} \\] <p>we define the expectation of \\(X\\) with respect to \\(P\\) as  </p> \\[   E[X]:=\\sum_{k\\leq n} \\alpha_k P[A_k] \\] </li> <li> <p>Plot</p> <p> </p> </li> </ul> <p>Warning</p> <p>One needs to be careful that this definition is independent of the representation of the simple random variable. Indeed, we have \\(X= 1_A + 1_B = 1_{A\\cup B}\\) if \\(A\\) and \\(B\\) are disjoint for instance. Luckily, by the properties of the probability measure, this random variable has the same expectation for the two representations.</p> <p>Proposition</p> <p>The two following important properties of the expectation on simple random variables can be rapidely checked.</p> <ul> <li>Monotony: \\(E[X]\\leq E[Y]\\) whenever \\(X\\leq Y\\).  </li> <li>Linearity: \\(E[aX+bY]=aE[X]+bE[Y]\\).  </li> </ul> <p>The proof of which is easy and left to you.</p> <p>Exercise</p> <p>Given a simple random variable \\(X\\) show that</p> <ol> <li>If \\(X\\) is positive, then \\(E[X]&gt;0\\) if and only if \\(P[X&gt;0] &gt;0\\).  </li> <li>If \\(X\\) is positive, then \\(E[X] = 0\\) if and only if \\(P[X = 0]=1\\).  </li> </ol> <p>We can now define the expectation of general random positive random variables as follows</p> <p>Definition: Expectation 1.5</p> <p>Given a positive random variable, the expectation of which is defined as</p> \\[   E[X] := \\sup \\left\\{ E[Y] \\colon Y\\text{ simple random variable and } Y\\leq X \\right\\} \\] <p>This is well defined but eventually equal to \\(\\infty\\). For this is also holds that for two positive random variable \\(X\\) and \\(Y\\) with positive numbers \\(a\\) and \\(b\\) then \\(E[aX + bY] = aE[X] + b E[Y]\\) as well as \\(E[X]\\leq E[Y]\\) if \\(X\\leq Y\\).</p> <p>To consider general random variable, we need to assume integrability.</p> <p>Definition: Expectation 2.0</p> <p>A random variable is called integrable if \\(E[X^+]&lt;\\infty\\) and \\(E[X^-]&lt;\\infty\\). The expectation of an integrable random variable is then defined as</p> \\[E[X] = E[X^+]-E[X^-]\\] <p>On the set of integrable random variables, which is a vector space, the expectation is also linear and monotone.</p> <p>The following fundamental theorem is due to Lebesgue. It tells under which conditions it is possible to swap limit and expectation.</p> <p>Theorem</p> <p>Let \\((X_n)\\) be a sequence of random variables.  The following holds true</p> <ol> <li> <p>Monotone Convergence: If \\((X_n)\\) are positive and increasing, that is, X_1\\leq X_2 \\leq \\cdots$  it holds that</p> \\[     \\sup E[X_n] = \\lim E[X_n] = E[\\sup X_n] = E[\\lim X_n] \\] </li> <li> <p>Fatou's Lemma: If \\((X_n)\\) are positive then it holds</p> \\[     E\\left[ \\liminf X_n \\right]:=E\\left[ \\sup_n \\inf_{k\\geq n} X_k\\right] \\leq \\liminf E[X_n] \\] </li> <li> <p>Lebesgue's Dominated Convergence: If \\(X_n(\\omega) \\to X(\\omega)\\) for all (at least in probability) and \\(|X_n|\\leq Y\\) for some integrable random variable \\(Y\\), then it holds</p> \\[   \\lim E[X_n] = E[\\lim X_n] = E[X] \\] </li> </ol> Proof <p>We start by the monotone convergence.</p> <p>By monotonicity, we clearly have \\(E[X_n]\\leq E[X]\\) for every \\(n\\), therefore \\(\\sup E[X_n]\\leq E[X]\\).</p> <p>Reciprocally, suppose that \\(E[X]&lt;\\infty\\) and pick \\(\\varepsilon&gt;0\\) and a positive simple random variable \\(Y \\) such that \\(Y\\leq X\\) and \\(E[X]-\\varepsilon\\leq E[Y]\\). For \\(0&lt;c&lt;1\\), define the sets \\(A_n=\\{X_n\\geq cY\\}\\). Since \\(X^n\\) is increasing to \\(X\\), it follows that \\(A_n\\) is an increasing sequence of events. Furthermore, since \\(cY\\leq Y\\leq X\\) and \\(cY&lt;X\\) on \\(\\{X&gt;0\\}\\), it follows that \\(\\cup A_n=\\Omega\\). By non-negativity of \\(X_n\\) and monotonicity, it follows that</p> \\[     cE[1_{A_n}Y]\\leq E[1_{A_n}X_n]\\leq E[X_n] \\] <p>and so</p> \\[     c\\sup E[1_{A_n}Y]\\leq \\sup E[X_n] \\] <p>Since \\(Y=\\sum_{l\\leq k} \\alpha_l 1_{B_l}\\) for positive numbers \\(\\alpha_1,\\ldots,\\alpha_k\\) and events \\(B_1,\\ldots, B_k\\), it follows that  </p> \\[     E\\left[ 1_{A_n}Y \\right]=\\sum_{l\\leq k}\\alpha_l P[A_n\\cap B_l]. \\] <p>However, since \\(P\\) is a probability measure, and \\(A_n\\) is increasing to \\(\\Omega\\), it follows from the lower semi-continuity of probability measures, that \\(P[A_n\\cap B_l]\\nearrow P[\\Omega\\cap B_l]=P[B_l]\\), and so  </p> \\[     \\sup E[1_{A_n}Y]=\\sum_{l\\leq k}\\alpha_l \\sup P[A_n\\cap B_l]=\\sum \\alpha_l P[B_l]=E[Y]. \\] <p>Consequently</p> \\[     E[X]\\geq \\lim E[X_n]=\\sup E[X_n]\\geq cE[Y] \\geq cE[X]-c\\varepsilon \\] <p>which, by letting \\(c\\) converge to \\(1\\) and \\(\\varepsilon\\) to \\(0\\), yields the result.  </p> <p>The case where \\(E[X]=\\infty\\) is similar and left to the reader.</p> <p>As for Fatou's lemma, define \\(Y_n =\\inf_{k\\geq n} X_k\\) which defines by assumption an increasing sequence of positive random variables. It follows from monotone convergence that</p> \\[     \\sup_n E\\left[ Y_n  \\right] = E[\\sup_n Y_n] = E[\\sup_n \\sup_{k\\geq n}X_n] = E[\\liminf X_n] \\] <p>On the other hand, it clearly holds that \\(X_k \\geq Y_n\\) for every \\(k\\geq n\\) and therefore \\(\\inf_{k\\geq n} E[X_k] \\geq E[Y_n]\\). Combined with the previous inequality we get</p> \\[   E[\\liminf X_n] = \\sup_n E[Y_n]\\leq \\sup_n \\inf_{k\\geq n}E[X_k] = \\liminf E[X_n] \\] <p>As for the dominated convergence of Lebesgue, we have by assumption that \\(X_n+Y\\) is a sequence of positive random variables, which by Fatou's lemma yields</p> \\[   E[X+Y] =E[\\liminf X_n +Y ] \\leq \\liminf E[X_n] +E[Y] \\] <p>Reciprovally \\(Y = X_n\\) is a sequence of positive random variable for which also holds</p> \\[   E[Y-X] = E[\\liminf Y - X_n] \\leq E[Y] +\\liminf -E[X_n] = E[Y] - \\limsup E[X_n] \\] <p>Combining both inequality yields</p> \\[   \\limsup E[X_n] \\leq E[X] \\leq \\liminf E[X_n] \\] <p>Since $\\liminf \\leq \\limsup $ if and only if there exists a limit we deduce that \\(E[X] = \\lim E[X_n]\\).</p> <p>Example</p> <ul> <li> <p>Integration for the simple coin toss:     Let \\(\\Omega =\\{\\omega_1,\\omega_2\\}\\) and \\(p=P[\\{\\omega_1\\}]\\) and \\(q=(1-p)\\).     Every random variable \\(X:\\Omega \\to \\mathbb{R}\\) is entirely determined by the values \\(X(\\omega_1) = x_1\\) and \\(X(\\omega_2)=x_2\\).     It follows that  </p> \\[     E[X]=pX(\\omega_1)+qX(\\omega_2) = p x_1 + (1-p)x_2 \\] </li> <li> <p>Integration in the finite state case:     Let \\(\\Omega=\\{\\omega_1,\\ldots,\\omega_N\\}\\) be a finite state space.     The probability measure is entirely given by the vector \\(\\boldsymbol{p}=(p_1,\\ldots,p_N)\\in \\mathbb{R}^N\\), where \\(p_n=P[\\{\\omega_n\\}]\\geq 0\\) and \\(\\sum p_n=1\\).     Every random variable \\(X:\\Omega \\to \\mathbb{R}\\) can be seen as a vector \\(\\boldsymbol{x} \\in \\mathbb{R}^N\\), where \\(x_n=X(\\omega_n)\\).     It follows that the expectation of \\(X\\) under \\(P\\) is given by</p> \\[     E[X]=\\sum p_n X(\\omega_n)=\\sum p_n x_n=\\boldsymbol{p}\\cdot \\boldsymbol{x} \\] <p>In other terms, the expectation of \\(X\\) boils down to the scalar product of the probability vector \\(\\boldsymbol{p}\\) with the vector of values \\(\\boldsymbol{x}\\) of the random variable.</p> </li> </ul>"}]}