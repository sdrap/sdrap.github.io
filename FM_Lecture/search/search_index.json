{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Financial Mathematics: Lecture Notes","text":"<p>These lecture notes, still a work in progress, are for a course taught at Shanghai Advanced Institute for Finance, Shanghai Jiao Tong University, for graduate students.</p>"},{"location":"#course-objective","title":"Course Objective","text":"<p>Stochastics as a mathematical field evolved in parallel with the development of the finance industry, starting with insurance, followed by stock markets, derivatives, and more. This lecture serves as an introduction to the mathematical theory underpinning modern finance. The course aims to introduce mathematical concepts in finance through the following topics:</p> <ul> <li> <p>One-period financial markets: Financial assets, self-financing strategies, arbitrage, the fundamental theorem of asset pricing, and option pricing.   From a mathematical perspective, this introduces probability spaces, expectations, pricing measures, and measure changes.</p> </li> <li> <p>Modern risk management and quantification: Value at Risk (V@R), Expected Shortfall (ES), and systemic risk.   From a mathematical perspective, this introduces the concept of probability distribution (CDF, PDF, quantile), joint distributions and tail risk.</p> </li> <li> <p>Multi-period financial markets: Concepts of information, the CRR model, pricing and hedging, exotic options, stopping times, and American options.   This includes mathematical concepts such as filtrations, conditional expectations, martingales, and stopping times.</p> </li> <li> <p>Basics of ruin theory and default pricing.</p> </li> <li> <p>Continuous-time financial markets: Introduction to the Black-Scholes framework.</p> </li> </ul>"},{"location":"#concrete-approach","title":"Concrete Approach","text":"<p>The course combines blackboard lectures with practical applications in Python. Lecture notes will be provided and updated during the course. Simple homework exercises (not graded but corrected and discussed by the TA) will be assigned. Additionally, students will complete two group projects (5-6 members per group), alongside a midterm and final exam.</p> <p>For further reading, we recommend Shreve<sup>1</sup> for an introduction to mathematical finance in discrete time and F\u00f6llmer and Schied<sup>2</sup> for a more advanced treatment.</p>"},{"location":"#references","title":"References","text":"<ol> <li> <p>Steven E. Shreve. Stochastic Calculus for Finance. Volume I of Springer Finance. Springer-Verlag, New York, 2004. ISBN 0-387-40100-8. The binomial asset pricing model.\u00a0\u21a9</p> </li> <li> <p>Hans F\u00f6llmer and Alexander Schied. Stochastic Finance. An Introduction in Discrete Time. De Gruyter Studies in Mathematics. Walter de Gruyter, Berlin, New York, 3rd edition, 2011.\u00a0\u21a9</p> </li> </ol>"},{"location":"javascripts/node_modules/mathjax/","title":"MathJax","text":""},{"location":"javascripts/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"javascripts/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"javascripts/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"javascripts/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\n  loader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\n  const svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\n  console.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"javascripts/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"javascripts/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"},{"location":"lecture/00-Introduction/000-index/","title":"Introduction","text":""},{"location":"lecture/00-Introduction/000-index/#what-is-mathematical-finance","title":"What is Mathematical Finance?","text":"<p>Finance concerns the allocation and pricing of assets\u2014goods, stocks, etc.\u2014and liabilities\u2014debts, loans, bonds, etc.\u2014in the presence of uncertainty and risk. This definition raises several fundamental questions:</p> <ul> <li>What is trade, money, or pricing?  </li> <li>What are uncertainty and risk?  </li> <li>Which academic fields address these questions?  </li> <li>What role does mathematics\u2014particularly stochastics\u2014play in finance?  </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#a-brief-and-biased-history-of-trade-money-and-finance","title":"A Brief and Biased History of Trade, Money, and Finance","text":""},{"location":"lecture/00-Introduction/000-index/#trade-of-goods-and-the-emergence-of-money","title":"Trade of Goods and the Emergence of Money","text":"<ul> <li>Exchange of goods (around 150,000 BC):</li> <li>Advantages:  <ul> <li>Better allocation of comparative advantages.  </li> </ul> </li> <li> <p>Question:  </p> <ul> <li>How is exchange value determined (bilateral agreement)?  </li> <li>Need for intermediaries.  </li> </ul> </li> <li> <p>Money as a medium of exchange (around 12,000 BC):  </p> </li> <li>Advantages:  <ul> <li>Solves the double coincidence problem, enabling efficient allocation.  </li> <li>Serves as a unit of account (num\u00e9raire).  </li> <li>Stores value over time.  </li> </ul> </li> <li>Questions:  <ul> <li>How is value established (multilateral agreements between numerous goods)?  </li> <li>Answer: Law of demand and supply.  </li> <li>How does money preserve value over time?  </li> <li>Introduces the concept of the time value of money.  </li> </ul> </li> </ul>"},{"location":"lecture/00-Introduction/000-index/#assessing-uncertainty-the-rise-of-financial-markets","title":"Assessing Uncertainty: The Rise of Financial Markets","text":"<ul> <li>Commodity markets (4,000 BC):   Development of forward contracts to hedge against price fluctuations.  </li> <li> <p>Question: How are prices determined?  </p> </li> <li> <p>Loans and banking systems (2,000 BC):   Facilitated leveraged investments.  </p> </li> <li> <p>Question: How to price future payments?  </p> </li> <li> <p>Insurance (1400s):   Emerged during overseas trading, with premiums exchanged for risk.  </p> </li> <li> <p>Sparked the beginnings of probability theory.  </p> </li> <li> <p>Stock markets (1600s):   Enabled capital raising and introduced challenges such as dividend payments and stock price modeling (e.g., Bachelier model, Brownian motion).  </p> </li> <li> <p>Options (1600s, standardized in 1973):   Put and call options provided bounded insurance against price movements.  </p> </li> <li> <p>Derivatives:   Broader contracts written on assets, indices, interest rates, etc.  </p> </li> </ul> <p>Pricing remains the central problem for all these financial instruments. While agreements between counterparties can set prices, mathematical models provide fair and robust valuations. A specialized subfield of mathematical finance also focuses on assessing financial risk.</p>"},{"location":"lecture/00-Introduction/000-index/#academic-fields-involved-in-finance","title":"Academic Fields Involved in Finance","text":"<ul> <li>Economics: Macroeconomics, microeconomics, decision theory.  </li> <li>Psychology: Behavioral finance.  </li> <li>Law.  </li> <li>Computer Science: Algorithmic trading, machine learning.  </li> <li>Mathematics:  </li> <li>Stochastics (modeling).  </li> <li>Statistics (calibration).  </li> <li>Optimization.  </li> <li>Functional analysis and partial differential equations (e.g., Black-Scholes model).  </li> </ul>"},{"location":"lecture/00-Introduction/001-notations/","title":"Notations","text":"<p>The following notations will be used throughout the course:</p> <ul> <li>Natural Numbers: \\(\\mathbb{N} = \\{1, 2, \\ldots\\}\\), \\(\\mathbb{N}_0 = \\{0, 1, 2, \\ldots\\}\\).</li> <li>Integers: \\(\\mathbb{Z} = \\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\)</li> <li>Rational Numbers: \\(\\mathbb{Q} = \\{ p/q\\colon p \\in \\mathbb{Z}, q \\in \\mathbb{N}\\}\\)</li> <li>Real Numbers: \\(\\mathbb{R}\\)</li> <li>Vectors in \\(\\mathbb{R}^d\\) are denoted in bold font, \\(\\boldsymbol{x} = (x^1, \\dots, x^d)\\), and are assumed to be column vectors.  </li> <li>Vectors with positive components \\(\\mathbb{R}^d_+ = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k \\geq 0, k=1,\\ldots,d\\}\\) and vectors with strictly positive components \\(\\mathbb{R}^d_{++} = \\{\\boldsymbol{x} \\in \\mathbb{R}^d : x^k &gt; 0, k=1,\\ldots,d\\}\\).  </li> <li>Scalar Product: \\(\\boldsymbol{x} \\cdot \\boldsymbol{y} := \\sum x_k y_k\\) denotes the scalar product of \\(\\boldsymbol{x}\\) and \\(\\boldsymbol{y}\\) in \\(\\mathbb{R}^d\\).  </li> <li>\\(\\beta \\boldsymbol{x} := (\\beta x_1, \\ldots, \\beta x_d)\\) represents the multiplication of \\(\\boldsymbol{x}\\) in \\(\\mathbb{R}^d\\) by a scalar \\(\\beta \\in \\mathbb{R}\\).  </li> <li>\\(\\boldsymbol{x} + \\boldsymbol{y} := (x_1 + y_1, \\ldots, x_d + y_d)\\) represents vector addition in \\(\\mathbb{R}^d\\).  </li> <li> <p>For scalars \\(x, y \\in \\mathbb{R}\\), the following notations are used:  </p> \\[   x \\vee y = \\max\\{x, y\\}, \\quad x \\wedge y = \\min\\{x, y\\}, \\quad x^+ = \\max\\{x, 0\\}, \\quad x^- = \\max\\{-x, 0\\}. \\] <p>Notably, \\(x = x^+ - x^-\\) and \\(|x| = x^+ + x^-\\).  </p> </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/","title":"Mathematical Model","text":"<p>In this section, we model a one-period financial market evolving between two points in time:</p> <ul> <li>Today: The current state of the world is known, including the prices of equities, commodities, and the overall economic condition.</li> <li>Tomorrow: Various possible states of the world may emerge, where changes in the economy or the prices of stocks and commodities occur based on these states.</li> </ul> <p>In this financial market, we have \\(d\\) risky assets available for investment and a bank account to store or borrow liquidity.</p> <ul> <li>At time \\(0\\): The prices of these \\(d\\) financial assets and the amount in the bank account are known.     Investors can decide on a strategy, specifying how much to invest in each asset by purchasing a certain number of shares. The bank account is used to finance these investments.</li> <li>At time \\(1\\): The portfolio's value is determined by:<ul> <li>The remaining balance in the bank account after buying the shares at time \\(0\\), including interest earned.</li> <li>The uncertain value of the financial assets at time \\(1\\), multiplied by the number of shares held.</li> </ul> </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#bank-account","title":"Bank Account","text":"<p>The bank account is denoted by \\(B\\), where \\(B_0 = 1\\) represents the price of one unit of currency at time \\(0\\). The bank offers an interest rate \\(r\\), announced at time \\(0\\) and applied at time \\(1\\). With one unit deposited at time \\(0\\), the amount in the account at time \\(1\\) becomes:</p> \\[ \\begin{equation*}   B_1 = B_0(1 + r) = 1 + r \\end{equation*} \\] <p>We assume \\(r &gt; -1\\), meaning the bank does not default. The bank account evolution is summarized as:</p> \\[ \\begin{equation*}   \\begin{cases}     B_0 = 1 \\\\     B_1 = 1 + r   \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#financial-assets","title":"Financial Assets","text":"<p>These assets are represented by the vector:</p> \\[ \\begin{equation*}   \\boldsymbol{S} = (S^1, \\ldots, S^d) \\end{equation*} \\] <p>Each \\(S^k\\) for \\(k = 1, \\ldots, d\\) describes the price evolution of financial asset \\(k\\) between time \\(0\\) and time \\(1\\).</p> <ul> <li> <p>At time \\(0\\): The price of asset \\(k\\) is \\(S_0^k\\), which is strictly positive and known:</p> \\[ \\begin{equation*}   \\boldsymbol{S}_0 = (S_0^1, \\ldots, S_0^d) \\quad \\text{where} \\quad S_0^k &gt; 0 \\; \\text{for all }k \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The price of asset \\(k\\) is \\(S_1^k\\), which is uncertain but non-negative (if \\(S_1^k = 0\\), the asset \\(k\\) has defaulted):</p> \\[ \\begin{equation*}   \\boldsymbol{S}_1 = (S_1^1, \\ldots, S_1^d) \\quad \\text{where} \\quad S_1^k \\geq 0 \\; \\text{for all }k \\end{equation*} \\] </li> </ul>"},{"location":"lecture/01-One-Period/011-mathematical-model/#self-financing-portfolio","title":"Self-Financing Portfolio","text":"<p>A portfolio consists of holdings in each financial asset and the balance in the bank account. The portfolio's total value is denoted by \\(\\bar{V}\\).</p> <ul> <li> <p>At time \\(0\\): You observe the prices \\(S_0^k\\) for \\(k = 1, \\ldots, d\\) and decide on a strategy, holding \\(\\eta^k \\in \\mathbb{R}\\) shares of each asset. The cost of purchasing these assets is:</p> \\[ \\begin{equation*}   \\sum_{k=1}^d \\eta^k S_0^k = \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\end{equation*} \\] <p>where \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\) represents your holdings. The self-financing condition requires that this cost is fully covered by the bank account. Thus:</p> \\[ \\begin{equation*}   \\bar{V}_0 \\leadsto \\underbrace{\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Bank account value}} +  \\underbrace{\\sum_{k=1}^d \\eta^k S^k_0}_{\\text{Asset holdings value}}= \\bar{V}_0 - \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 + \\boldsymbol{\\eta}\\cdot \\boldsymbol{S}_0 = \\bar{V}_0 \\end{equation*} \\] </li> <li> <p>At time \\(1\\): The portfolio value evolves as asset prices change:</p> \\[ \\begin{align*}     \\bar{V}_1 &amp; = \\left(\\bar{V}_0 - \\sum_{k=1}^d \\eta^k S^k_0\\right)(1+r) + \\sum_{k=1}^d \\eta^k S^k_1 \\\\               &amp; = \\left( \\bar{V}_0 - \\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_0 \\right)(1+r) +\\boldsymbol{\\eta} \\cdot \\boldsymbol{S}_1  \\\\               &amp; = \\bar{V}_0(1+r) +\\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r) \\right) \\end{align*} \\] </li> </ul> <p>Hence a portfolio over time is entirely determined by its start value \\(\\bar{V}_0\\) as well as the strategy \\(\\boldsymbol{\\eta} = (\\eta^1, \\ldots, \\eta^d)\\).</p> How realistic are those assumptions? <p>In this setting, we make somewhat restrictive assumptions that are disputable namely:</p> <ul> <li>No dividends.</li> <li>No transaction costs when buying assets: fixed fees, taxes, transaction fees, liquidity.</li> <li>The amount of shares in a financial asset is a real number.       Usually you are only allowed to buy/sell a round lot.       Furthermore, you are allowed to hold a negative amount of shares.       In other terms short selling is allowed and without particular transaction costs related to it.</li> <li>You can buy/sell unlimited amount of shares, in particular for very large amount you face no liquidity costs.</li> <li>The bank account provides the same rate \\(r\\) for deposit and lending which is very unlikely.     And this rate is independent of the amount.</li> <li>You can lend infinite amount of money from the bank.</li> </ul> <p>We consider the ideal scenario of a small investor operating in a frictionless financial market\u2014an assumption that closely approximates modern realities. Some aspects, such as taxes, transaction fees, dividends, and round lot restrictions, are either negligible or can be incorporated with minimal adjustments. However, factors like differing lending and deposit rates, liquidity costs, short-selling constraints, and price impacts are more complex and can significantly influence the results.    </p>"},{"location":"lecture/01-One-Period/011-mathematical-model/#discounting","title":"Discounting","text":"<p>It is often convenient to consider discounted values of financial assets and the portfolio to express their worth in terms of today's currency. Define the discounted prices \\(\\boldsymbol{X}=\\boldsymbol{S}/B\\) and portfolio value \\(V=\\bar{V}/B\\) as follows:</p> \\[ \\begin{align*}     X_0^k &amp; = \\frac{S^k_0}{B_0}=S^k_0         &amp; \\text{and} &amp;  &amp; X_1^k &amp; = \\frac{S_1^k}{B_1}=\\frac{S_1^k}{1+r}         \\\\     V_0   &amp; = \\frac{\\bar{V}_0}{B_0}=\\bar{V}_0 &amp; \\text{and} &amp;  &amp; V_1   &amp; = \\frac{\\bar{V}_1}{B_1}=\\frac{\\bar{V}_1}{1+r} \\end{align*} \\] <p>In particular, it follows that</p> \\[ \\begin{align*}     V_1     &amp; = \\frac{\\bar{V}_1}{1+r}\\\\             &amp; = \\frac{1}{1+r}\\left(\\bar{V}_0(1+r) +\\sum_{k=1}^d \\eta^k\\left( S^k_1  - (1+r)S_0^k\\right)\\right)\\\\             &amp; = \\bar{V}_0(1+r) +\\sum_{k=1}^d \\eta^k\\left( \\frac{S^k_1}{1+r}  - S_0^k\\right)\\\\                 &amp; = V_0 + \\sum_{k=1}^n \\eta_k\\left( X^k_1 - X^k_0 \\right)\\\\           &amp; = V_0 + \\boldsymbol{\\eta} \\cdot \\left( \\boldsymbol{X}_1 - \\boldsymbol{X}_0 \\right) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\end{align*} \\] <p>for which we get an interpretation of the evolution of the discounted value of the portfolio:</p> \\[ \\begin{equation*}   V_1 = \\underbrace{V_0}_{\\text{Initial Value}} + \\underbrace{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1}_{\\text{Incremental gain/loss of discounted prices}} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/011-mathematical-model/#uncertainty","title":"Uncertainty","text":"<p>So far, we have described a simple financial market and how investments can be made while adhering to self-financing principles. However, while we acknowledged that the prices of assets at time \\(1\\) are subject to uncertainty, we have not detailed how this uncertainty is modeled.  In other words, while we treated the financial assets at time \\(1\\) as a vector of prices, we have not specified how this vector reflects the uncertainty associated with its values.</p> <p>The price evolution depends on the \"state of the world\" that will be realized. If we denote by \\(\\omega\\) one such possible state, then \\(S_1^k(\\omega)\\) represents the price of asset \\(k\\) at time \\(1\\) in state \\(\\omega\\). If \\(\\Omega\\) denotes the collection of all possible states, the stock price \\(S_1^k\\) is a function:</p> \\[ \\begin{align*}   S_1^k\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_+\\\\   \\omega &amp; \\longmapsto \\underbrace{S_1^k(\\omega)}_{\\text{Price of financial asset $k$ at time $1$ in state $\\omega$}} \\end{align*} \\] <p>Combining all such functions, we obtain state-dependent price vectors:</p> \\[ \\begin{align*}   \\boldsymbol{S}_1\\colon \\Omega &amp; \\longrightarrow \\mathbb{R}_+^d\\\\   \\omega &amp; \\longmapsto \\boldsymbol{S}_1(\\omega) = (S_1^1(\\omega), \\ldots, S_1^d(\\omega)) \\end{align*} \\] <p>Similarly, the discounted self-financing portfolio value at time \\(1\\) and the discounted asset prices become state-dependent functions:</p> \\[ \\begin{align*}   \\boldsymbol{X}_1\\colon \\Omega &amp;\\longrightarrow \\mathbb{R}_{++}^d &amp; V_1 \\colon \\Omega &amp;\\longrightarrow \\mathbb{R} \\\\   \\omega &amp; \\longmapsto \\boldsymbol{X}_1(\\omega) = \\left( \\frac{S_1^1(\\omega)}{1+r}, \\ldots, \\frac{S_1^d(\\omega)}{1+r} \\right) &amp; \\omega &amp;\\longmapsto V_1(\\omega) = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1(\\omega) \\end{align*} \\] <p>The objective of financial mathematics is to estimate or price these state-dependent portfolios. To achieve this, we need further assessments of how likely each event is to occur. This is where stochastic theory plays a crucial role.</p> <p>Definition: One period financial market</p> <p>Given a probability space \\((\\Omega, \\mathcal{F}, P)\\), a financial market is defined as follows:</p> <ul> <li> <p>A bank account \\(B\\), where:</p> \\[ B_0 = 1 \\quad \\text{and} \\quad B_1 = 1 + r \\] <p>for \\(r&gt;-1\\)</p> </li> <li> <p>\\(d\\)-financial assets \\(\\boldsymbol{S} = (S^1, \\ldots, S^d)\\), where:</p> \\[   S_0^k &gt; 0 \\quad \\text{and} \\quad S_1^k : \\Omega \\to \\mathbb{R}_+ \\] <p>for \\(k = 1, \\ldots, d\\), with \\(S_1^k\\) being a measurable random variable.</p> </li> </ul> <p>A Portfolio \\(\\bar{V}\\) is given by a start value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and a holding strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). Self financing condition implies</p> \\[   \\bar{V}_1 = \\bar{V}_0(1+r) + \\sum \\eta^k \\left(S_1^k - S_0^k(1+r)\\right) = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\left(\\boldsymbol{S}_1 - \\boldsymbol{S}_0(1+r)\\right) \\] <p>The discounded portfolio \\(V = \\bar{V}/B\\) and financial assets \\(\\boldsymbol{X} = \\boldsymbol{S}/B\\) allows to write</p> \\[   V_1 = V_0 + \\sum \\eta^k \\left(X_1^k - X_0^k\\right) = V_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\] What about returns, portfolio weights? <p>Very often in finance, the exposition is done in terms of returns and portfolio weights. Talking in terms of returns and weights requires some particular care.</p> <p>It is possible to speak of returns for the financial market as the prices at time \\(0\\) are strictly positive. In other terms, if we define the interest rate \\(r\\) as:</p> \\[ r = \\frac{B_1 - B_0}{B_0}, \\quad \\text{then it holds} \\quad B_1 = B_0(1 + r) \\] <p>Similarly, for the return \\(R_1^k\\) of a financial asset \\(k\\), we define:</p> \\[ R_1^k = \\frac{S_1^k - S_0^k}{S_0^k}, \\quad \\text{then it holds} \\quad S_1^k = S_0^k(1 + R_1^k) \\] <p>Thus, the definition of a financial market as described earlier is equivalent to specifying:</p> <ul> <li>A vector \\(\\boldsymbol{S}_0\\) of strictly positive initial prices.</li> <li>An interest rate \\(r &gt; -1\\), with \\(r \\in \\mathbb{R}\\).</li> <li> <p>A vector \\(\\boldsymbol{R}_1 = (R_1^1, \\ldots, R_1^d)\\) of random returns, where:</p> \\[ R_1^k: \\Omega \\longrightarrow [-1, \\infty), \\quad \\omega \\longmapsto R_1^k(\\omega) \\] <p>for each \\(k = 1, \\ldots, d\\).</p> </li> </ul> <p>It is also possible for a portfolio to speak in terms of holding value rather than number of shares, that is \\(\\boldsymbol{h} = \\boldsymbol{\\eta}\\boldsymbol{S}_0 = (\\eta^1 S_0^1, \\ldots, \\eta^d S_0^d)\\). In this case we can write the portfolio evolution as</p> \\[ \\begin{align*}   \\bar{V_1} &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k\\left(S_1^k - S_0^k (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum \\eta^k S_0^k \\left(\\frac{S_1^k}{S_0^k} - (1+r)\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\sum h^k \\left(R_1^k - r\\right)\\\\             &amp; = \\bar{V}_0(1+r) + \\boldsymbol{h}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>Now we would like to consider the returns of the portfolio \\((\\bar{V}_1 - \\bar{V}_0)/\\bar{V}_0\\) as well as the portfolio weight \\(\\boldsymbol{w} = \\boldsymbol{h}/\\bar{V_0}\\). Indeed, the portfolio weight in asset \\(k\\) is equal to the asset value holding divided by the portfolio value at time \\(0\\). Following on the previous computation we have</p> \\[ \\begin{align*}   \\frac{\\bar{V}_1 - \\bar{V}_0}{\\bar{V}_0} &amp; = r + \\sum \\frac{h^k}{\\bar{V}_0}\\left(R^k_1 - r\\right)\\\\       &amp; = r + \\boldsymbol{w}\\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\end{align*} \\] <p>We get the classical interpretation that the portfolio returns is equal to the risk free rate plus the weighted excess returns in the financial assets. In particular if \\(\\sum w^k = 1\\), meaning that you hold your portfolio entirely in assets, the returns of the portfolio is equal to \\(\\boldsymbol{w}\\cdot \\boldsymbol{R}_1\\).</p> <p>This looks familar and used widely, it is however  mathematically not correct without further assumptions. Consider the following situations where \\(\\bar{V}_0 &lt;0\\) or \\(\\bar{V}_0 = 0\\), returns and weights do not make much sense isn't it?</p> <p>Furthermore, even if you assume that \\(\\bar{V}_0&gt;0\\) (usually \\(\\bar{V}_0 = 1\\)), suppose that you can short, then you may well end-up with a strictly negative or zero portfolio value at time \\(1\\). How would you then compute the portfolio returns between time \\(1\\) and time \\(2\\)?</p> <p>Such a way to look at portfolio returns are consistent mathematically if some strong assumptions are made to garantee that \\(\\bar{V}_0\\) and \\(\\bar{V}_1\\) remain strictly positive (no shorting plus budget constraint for instance). This is the reason why we do not consider during this lecture this kind of approach (portfolio returns or portfolio weights).</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/","title":"Arbitrage and Pricing","text":"<p>A fundamental concept in financial market is the notion of Arbitrage. Consider the following example</p> <p>Arbitrage in a coint toss model</p> <p>Consider the example of a simple coin toss model. Formally:</p> <ul> <li>\\(\\Omega = \\{-1, 1\\}\\)</li> <li>\\(\\mathcal{F} = \\{\\emptyset, \\{1\\}, \\{-1\\}, \\{-1, 1\\}\\}\\)</li> <li> <p>Given \\(0&lt;p&lt;1\\)</p> \\[ P[\\{\\omega\\}] = \\begin{cases}     p &amp; \\text{if } \\omega = 1, \\\\     1-p &amp; \\text{if } \\omega = -1 \\end{cases} \\] </li> </ul> <p>We define for our bank account \\(B_0 = 1\\) and \\(B_1 = 1 + r\\) where \\(r &gt; -1\\). We also consider a single stock with:</p> \\[ S_0 &gt; 0, \\quad S_1(\\omega) = S_0(1 + R(\\omega)) \\] <p>where the return \\(R\\) is given by:</p> \\[ R(\\omega) = \\begin{cases}     u &amp; \\text{if } \\omega = 1, \\\\     d &amp; \\text{if } \\omega = -1 \\end{cases} \\] <p>with \\(d &lt; u\\). We assume that \\(S_1\\) is strictly positive, so \\(d &gt; -1\\).</p> <p>Suppose I enter the market with no money and observe that \\(r \\leq d\\). I borrow \\(\\eta S_0\\) from the bank to buy \\(\\eta&gt;0\\) shares of the stock. At time \\(1\\), the value of my portfolio is:</p> \\[     \\bar{V}_1(\\omega) = -\\eta S_0(1 + r) + \\eta S_1(\\omega) =     \\begin{cases}         \\eta S_0(u - r) &amp; \\text{if } \\omega = 1, \\\\         \\eta S_0(d - r) &amp; \\text{if } \\omega = -1     \\end{cases} \\] <p>Since \\(r \\leq d &lt; u\\), my strategy does not lose money in any cases and I always make a strictly positive gain with probability \\(p&gt;0\\). By scaling this strategy, I could generate unlimited wealth without risk. A similar scenario arises if \\(d &lt; u \\leq r\\), where I could short-sell the stock infinitely.</p> <p>As this example shows, such a market would be dysfunctional. Economically, arbitrageurs would exploit this situation, driving the stock price back within boundaries to eliminate these opportunities. Hence, we require the concept of an arbitrage-free market.</p>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#arbitrage","title":"Arbitrage","text":"<p>Definition Arbitrage and Arbitrage Free Market</p> <p>A portfolio \\(\\bar{V}\\) with initial value \\(\\bar{V}_0 \\in \\mathbb{R}\\) and strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) is called an arbitrage if</p> \\[ \\begin{equation*}         \\underbrace{P\\left[\\bar{V}_1(\\omega) \\geq \\bar{V}_0(1 + r)\\right] = 1}_{\\text{No downside risk}}\\quad \\text{and}\\quad \\underbrace{P\\left[\\bar{V}_1(\\omega) &gt; \\bar{V}_0(1 + r)\\right] &gt;0}_{\\text{Strict positive gains with strict positive probability}} \\end{equation*} \\] <p>A financial market is call arbitrage free, if there exists no arbitrage.</p> <p>In other words, a self-financing strategy is an arbitrage if it guarantees a net gain at time \\(1\\) in every possible state and a strictly positive gain with nonzero probability.</p> <p>There exists several equivalent way to express arbitrage as the following proposition states</p> <p>Proposition Arbitrage Equivalence</p> <p>The following statements are equivalent:</p> <ol> <li>The financial market admits an arbitrage portfolio.</li> <li> <p>There exists a discounted portfolio \\(V\\) such that:</p> \\[ P\\left[V_1 \\geq V_0\\right] = 1 \\quad \\text{and} \\quad P\\left[V_1 &gt; V_0\\right] &gt; 0 \\] </li> <li> <p>There exists a strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\right] = 1 \\quad \\text{and} \\quad P\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0\\right] &gt; 0 \\] </li> </ol> Proof <ol> <li> <p>Equivalence of (i) and (ii):     For a portfolio \\(\\bar{V}\\), \\(\\bar{V}_1 \\geq (1 + r)\\bar{V}_0\\) is equivalent to \\(V_1 \\geq V_0\\) by dividing the inequality by \\(1 + r &gt; 0\\). The same holds for the strict inequality.</p> </li> <li> <p>Equivalence of (ii) and (iii):     For a discounted portfolio \\(V\\), \\(V_1 = V_0 + \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq V_0\\) is equivalent to \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0\\) by subtracting \\(V_0\\).</p> </li> </ol> Exercise <p>Recall that the returns vector \\(\\boldsymbol{R}_1\\) are defined as</p> \\[     R^k_1 = \\frac{S_1^k - S_0^k}{S_0^k}\\quad \\text{for }k=1, \\ldots, d \\] <p>Show that the following assertions are equivalent:</p> <ol> <li> <p>The financial market admits and arbitrage.</p> </li> <li> <p>There exists \\(\\boldsymbol{h} \\in \\mathbb{R}^d\\) such that:</p> \\[     P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) \\geq 0 \\right] = 1      \\quad \\text{and} \\quad      P\\left[ \\boldsymbol{h} \\cdot \\left(\\boldsymbol{R}_1 - r\\right) &gt; 0 \\right] = 1  \\] </li> </ol>"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#pricing-measure","title":"Pricing Measure","text":"<p>As we will consequently see in the Fundamental Theorem of Asset Pricing, another central concept in financial market are pricing measures</p> <p>Pricing Measure</p> <p>A probability measure \\(P^\\ast\\) is called a pricing measure(1) if:</p> <ol> <li> Also known as a pricing kernel in financial engineering or martingale measure in mathematics.</li> </ol> \\[     E^{P^\\ast}\\left[\\frac{S_1^k}{1 + r}\\right] = S_0^k, \\quad \\text{for } k = 1, \\ldots, d \\] <p>In other words, under a pricing measure the discounted expected value of each asset equals its present price.</p> <p>Vector notation and equivalent formulations</p> <p>For a vector of random variables \\(\\boldsymbol{Z} = (Z^1, \\ldots, Z^d)\\) and a probability measure \\(Q\\), we denote:</p> \\[ E^Q[\\boldsymbol{Z}] := \\left(E^Q[Z^1], \\ldots, E^Q[Z^d]\\right) \\] <p>In particular, \\(P^\\ast\\) is a pricing measure if:</p> \\[ E^{P^\\ast}\\left[\\frac{\\boldsymbol{S}_1}{1 + r}\\right] = \\boldsymbol{S}_0, \\quad \\text{or equivalently}\\quad E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0 \\] <p>This implies that under a pricing measure, the average return of each financial asset equals the bank's interest rate:</p> \\[ E^{P^\\ast}[R_1^k] = r, \\quad \\text{for every } k = 1, \\ldots, d \\] <p>Lemma</p> <p>Suppose that the financial market admits a pricing measure \\(P^\\ast\\). Then</p> <ol> <li> <p>for every portfolio \\(\\bar{V}\\), it holds</p> \\[     \\bar{V}_0 = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right] \\] </li> <li> <p>for every (discounted) portfolio \\(V\\), it holds</p> \\[     V_0 = E^{P^\\ast}\\left[ V_1 \\right] \\] </li> <li> <p>for every strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\), it holds</p> \\[     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0 \\] </li> </ol> Proof <p>We just show the last assertion, the other two follows directly. Let \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) and \\(P^\\ast\\) be a pricing measure. By definition of \\(P^\\ast\\) and the properties of the expectation, it follows that</p> \\[ \\begin{equation*}     E^{P^\\ast}\\left[ \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\right]  = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right]= \\sum \\eta^k E^{P^\\ast}\\left[ \\Delta X_1^k  \\right] = \\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right] = 0 \\end{equation*} \\] <p>In the following, we will consider those pricing measures \\(P^\\ast\\) that are equivalent to \\(P\\).(1) By the very definition, it follows in particular that if \\(P^\\ast\\sim P\\) and \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, then </p> <ol> <li> <p>See appendix on probability theory for details and consequence in terms of Radon-Nykodym derivative.</p> <p>Just recalling the definition, a probability measure \\(Q\\) is equivalent to \\(P\\) and denoted by \\(Q\\sim P\\) if</p> \\[P[A] = 0 \\quad \\text{if and only if} \\quad Q[A]=0\\] <p>In other terms the two measures agrees on negligible events.</p> <p>This is however equivalent to</p> \\[P[A] = 1 \\quad \\text{if and only if} \\quad Q[A]=1\\] <p>or</p> \\[P[A] &gt; 0 \\quad \\text{if and only if} \\quad Q[A]&gt;0\\] </li> </ol> \\[ \\begin{equation*} \\begin{cases}   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\quad \\text{is equivalent to } \\quad \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  \\geq 0\\right] &amp;= 1\\\\   P^\\ast\\left[ \\boldsymbol{\\eta}\\cdot \\Delta\\boldsymbol{X}_1  &gt; 0\\right] &amp;&gt;0 \\end{cases} \\end{equation*} \\]"},{"location":"lecture/01-One-Period/012-arbitrage-pricing/#fundamental-theorem-of-asset-pricing","title":"Fundamental Theorem of Asset Pricing","text":"<p>Fundamental Theorem of Asset Pricing (FTAP)</p> <p>In a financial market, the following conditions are equivalent:</p> <ol> <li>The market is arbitrage-free.</li> <li>There exists at least one pricing measure \\(P^\\ast \\sim P\\) with bounded density \\(dP^\\ast/dP\\).</li> </ol> Proof sketch <ol> <li> <p>Step 1 (easy direction): condition 2. implies 1..     By contradiction, assume that there exists a pricing measure \\(P^\\ast \\sim P\\) and an arbitrage strategy \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\). We show that this is not possible.</p> <p>On one hand, having a pricing measure \\(P^\\ast\\) implies that \\(E^{P^\\ast}[\\Delta \\boldsymbol{X}_1] = 0\\). It follows that for the arbitrage strategy \\(\\boldsymbol{\\eta}\\), we have:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = E^{P^\\ast}\\left[ \\sum \\eta^k \\Delta X_1^k \\right] = 0 \\] <p>On the other hand, since \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, it holds that:</p> \\[ \\begin{cases}   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>Since \\(P^\\ast \\sim P\\), this is equivalent to:</p> \\[ \\begin{cases}   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0 \\right] = 1, \\\\   P^\\ast\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0 \\right] &gt; 0 \\end{cases} \\] <p>The first line implies that the random variable \\(\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\) is positive \\(P^\\ast\\)-almost surely. The second line indicates that this variable is strictly positive somewhere. Taking the expectation of this strictly positive random variable results in a strictly positive expectation:</p> \\[   E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 \\] <p>However, this contradicts the earlier result that \\(E^{P^\\ast}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] = 0\\). This shows that 2. implies 1..</p> </li> <li> <p>Step 2 (difficult direction): condition 1. implies 2.. </p> <p>Here, we show that if 1.$ does not hold (i.e., there exists no pricing measure \\(P^\\ast\\) with bounded density), then there exists an arbitrage. To state that there exists no pricing measure \\(P^\\ast\\) with bounded density, consider the set:</p> \\[   \\mathcal{C} = \\left\\{ E^Q[\\Delta \\boldsymbol{X}_1] : Q \\sim P \\text{ and } \\frac{dQ}{dP} \\text{ is bounded} \\right\\} \\] <p>This set includes all vectors of expectations of discounted gains under pricing measures with bounded density \\(Q\\). There exists a pricing measure \\(P^\\ast \\sim P\\) with bounded density if and only if the vector \\(0\\) is in \\(\\mathcal{C}\\). Hence, the condition that 2. does not hold is equivalent to \\(0 \\notin \\mathcal{C}\\).</p> <p>We show that the set \\(\\mathcal{C} \\subseteq \\mathbb{R}^d\\) has the following properties:</p> <ul> <li> <p>Non-emptiness: \\(\\mathcal{C} \\neq \\emptyset\\). Since \\(P \\sim P\\) and \\(\\frac{dP}{dP} = 1\\), it follows that \\(E^P[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C}\\)(1).</p> </li> <li> <p>Note: We never assumed \\(\\boldsymbol{X}_1\\) is integrable under \\(P\\). This can be addressed in the appendix.</p> </li> <li> <p>Convexity: \\(\\mathcal{C}\\) is convex(1).</p> <ol> <li>That is, for any two points \\(\\boldsymbol{x}, \\boldsymbol{y} \\in \\mathcal{C}\\) and any \\(\\lambda \\in [0, 1]\\), the interval \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y}\\) is also in \\(\\mathcal{C}\\).  </li> </ol> <p>By definition, there exist \\(Q^{\\boldsymbol{x}}\\) and \\(Q^{\\boldsymbol{y}}\\) equivalent to \\(P\\) with bounded density such that \\(E^{Q^{\\boldsymbol{x}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{x}\\) and \\(E^{Q^{\\boldsymbol{y}}}[\\Delta \\boldsymbol{X}_1] = \\boldsymbol{y}\\). By the Radon-Nikodym theorem, define:</p> \\[   \\frac{dQ}{dP} = \\lambda \\frac{dQ^{\\boldsymbol{x}}}{dP} + (1 - \\lambda) \\frac{dQ^{\\boldsymbol{y}}}{dP} \\] <p>This \\(dQ/dP\\) is a strictly positive bounded random variable (since \\(dQ^{\\boldsymbol{x}}/dP\\) and \\(dQ^{\\boldsymbol{y}}/dP\\) are) with expectation equal to \\(1\\):</p> \\[   E^P\\left[ \\frac{dQ}{dP} \\right] = \\lambda E^P\\left[ \\frac{dQ^{\\boldsymbol{x}}}{dP} \\right] + (1 - \\lambda) E^P\\left[ \\frac{dQ^{\\boldsymbol{y}}}{dP} \\right] = \\lambda + (1 - \\lambda) = 1 \\] <p>Hence, \\(dQ/dP\\) defines a probability measure \\(Q \\sim P\\) with bounded density, and:</p> \\[   \\boldsymbol{z} = E^Q[\\Delta \\boldsymbol{X}_1] \\in \\mathcal{C} \\] <p>Moreover:</p> \\[   \\boldsymbol{z} = \\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\] <p>showing that \\(\\lambda \\boldsymbol{x} + (1 - \\lambda) \\boldsymbol{y} \\in \\mathcal{C}\\).</p> </li> </ul> <p>If \\(0 \\notin \\mathcal{C}\\), the Hahn-Banach separation theorem implies that there exists a vector \\(\\boldsymbol{\\eta} \\in \\mathbb{R}^d\\) such that:</p> \\[ \\begin{cases}    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x} \\geq 0 &amp; \\text{for all } \\boldsymbol{x} \\in \\mathcal{C}, \\\\    \\boldsymbol{\\eta} \\cdot \\boldsymbol{x}_0 &gt; 0 &amp; \\text{for some } \\boldsymbol{x}_0 \\in \\mathcal{C}. \\end{cases} \\] <p>By definition of \\(\\mathcal{C}\\), this translates to:</p> \\[ \\begin{cases}    E^Q\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] \\geq 0 &amp; \\text{for all } Q \\sim P \\text{ with bounded } \\frac{dQ}{dP}, \\\\    E^{Q_0}\\left[ \\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\right] &gt; 0 &amp; \\text{for some } Q_0 \\sim P \\text{ with bounded } \\frac{dQ_0}{dP}. \\end{cases} \\] <p>The last condition implies that \\(Q_0[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\), and since \\(Q_0\\) is equivalent to \\(P\\), it also implies that </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &gt; 0] &gt; 0\\] <p>As for the first condition, we claim that it implies </p> \\[P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\] <p>showing then that \\(\\boldsymbol{\\eta}\\) is an arbitrage.</p> <p>To this end, define \\(A = \\{\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 &lt; 0\\}\\) and consider the sequence of strict positive random variables:</p> \\[   Y_n := \\left( 1 - \\frac{1}{n} \\right)1_A + \\frac{1}{n}1_{A^c} \\] <p>which is bounded by \\(1\\) and satisfies \\(Y_n \\to 1_A\\) \\(P\\)-almost surely. Since \\(Y_n &gt; 0\\), it generates a sequence of probability measures \\(Q_n\\) equivalent to \\(P\\) with bounded densities:</p> \\[   \\frac{dQ_n}{dP} = \\frac{Y_n}{E[Y_n]} \\] <p>Hence</p> \\[   0 \\leq E^{Q_n}\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1\\right] = \\frac{1}{E[Y_n]} E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right]. \\] <p>Taking the limit (1), it follows that:</p> <ol> <li>To be rigorous you invoke the dominated convergence theorem applied to \\(Y_n\\).</li> </ol> \\[   0 \\leq E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 Y_n\\right] \\to E\\left[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 1_A\\right] \\] <p>which, by the definition of \\(A\\), shows that \\(P[A] = 0\\). In other words, \\(P[\\boldsymbol{\\eta} \\cdot \\Delta \\boldsymbol{X}_1 \\geq 0] = 1\\). Hence, \\(\\boldsymbol{\\eta}\\) is an arbitrage strategy, contradicting the assumption of an arbitrage-free market.  </p> <p>Thus, there exists a pricing measure equivalent to \\(P\\) with bounded density, which concludes the proof.</p> </li> </ol> <p>This Theorem is called a theorem and fundamental because it states an if and only if assertion between a somehow economical concept (no arbitrage) and a mathematical concept (the existence of a pricing measure). This statement will have many consequences that will unfold while studying derivative pricing.</p> <p>However an immediate consequence of which is the so called Law of One Price which is often stated as given in finance, which however is a consequence of the FTAP.</p> <p>Law of One Price</p> <p>If the market is arbitrage free, then for any two portfolios \\(\\bar{V}\\) and \\(\\tilde{V}\\) with exact same outcome tomorrow, that is</p> <pre><code>$$\n  P\\left[ \\bar{V}_1 = \\tilde{V}_1\\right] = 1\n$$\n</code></pre> <p>the value of each portfolio at time \\(0\\) is the same, that is \\(\\bar{V}_0 = \\tilde{V}_0\\)</p> Proof <p>By the fundamental theorem of asset pricing, no arbitrage is equivalent to the existence of a pricing measure \\(P^\\ast\\) equivalent to \\(P\\). Let further \\(\\bar{V}\\) and \\(\\tilde{V}\\) be two portfolio such that</p> \\[   P\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>Since \\(P^\\ast \\sim P\\), it follows that</p> \\[   P^\\ast\\left[ \\bar{V}_1 =\\tilde{V}_1\\right]=1 \\] <p>showing that \\(E^{P^\\ast}\\left[ \\bar{V}_1 \\right] = E^{P^\\ast}\\left[ \\tilde{V}_1 \\right]\\).</p> <p>Furthermore, it holds that</p> \\[   \\frac{\\bar{V}_1}{1+r} = \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1 \\quad \\text{and}\\quad \\frac{\\tilde{V}_1}{1+r} = \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1 \\] <p>for some \\(\\boldsymbol{\\eta}\\) and \\(\\tilde{\\boldsymbol{\\eta}}\\) in \\(\\mathbb{R}^d\\).</p> <p>Taking expectation under the pricing measure, it follows that</p> \\[ \\begin{align*}   \\bar{V}_0 &amp; = \\bar{V}_0 + \\underbrace{\\boldsymbol{\\eta}\\cdot E^{P^\\ast}\\left[ \\Delta \\boldsymbol{X}_1 \\right]}_{=0\\text{ since }P^\\ast \\text{ is a pricing measure}}\\\\   &amp; = E^{P^\\ast}\\left[  \\bar{V}_0 + \\boldsymbol{\\eta}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\bar{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[ \\frac{\\tilde{V}_1}{1+r} \\right]\\\\   &amp; = E^{P^\\ast}\\left[  \\tilde{V}_0 + \\tilde{\\boldsymbol{\\eta}}\\cdot \\Delta \\boldsymbol{X}_1\\right]\\\\   &amp; = \\tilde{V}_1 \\end{align*} \\] <p>This statement stipulates that if a market is arbitrage free, regardless the portfolio you have in the market, if those deliver the same outcome, then their financing costs has to be the same.</p> <p>The statement of the FTAP seems to be quite abstract, but is has a very easy interpretation in terms of linear algebra when the set of possible states is finite. Indeed, consider the following financial market where </p> <ul> <li>\\(\\Omega = \\{\\omega_1, \\ldots, \\omega_N\\}\\)</li> <li>\\(\\mathcal{F} = 2^\\Omega\\).  </li> <li>\\(P\\) is a probability measure specified by the vector \\(\\boldsymbol{p}=(p_1, \\ldots, p_N)\\) where \\(p_i = P[\\{\\omega_i\\}] &gt;0\\) and \\(\\sum p_i =1\\).</li> </ul> <p>We have a bank account with:</p> \\[ B_0 = 1, \\quad B_1 = 1 + r \\] <p>for some \\(r&gt;-1\\).</p> <p>As for the finanical asset, suppose that we have a single one:</p> \\[ S_0 &gt; 0 \\quad \\text{and} \\quad S_1(\\omega_i) = s_i &gt; 0. \\] <p>Up to reordering, we assume that \\(0 &lt; s_1 &lt; s_2 &lt; \\ldots &lt; s_N\\), and denote \\(s = (s_1, \\ldots, s_N)\\) as the vector of payoffs for \\(S^1\\) at time \\(1\\).  </p> <p>The market is arbitrage-free if:</p> \\[ (1 + r)S_0 \\in \\left\\{E^Q[S_1] = q \\cdot s \\colon Q = (q_1, \\ldots, q_N) \\in \\mathbb{R}^d, \\sum q_i =1 , \\; q_i &gt; 0 \\text{ for every } i\\right\\} = ]s_1, s_n[ \\] <p>This means the market is arbitrage-free if and only if the following system of equations:</p> \\[ \\begin{cases}     q_1 s_1 + \\cdots + q_n s_n = (1 + r)S_0 \\\\     q_1 + \\cdots + q_n = 1 \\\\     q_i &gt; 0 &amp; \\text{for all } i \\end{cases} \\] <p>admits at least one solution.  </p> <p>If a solution exists, it is unique if and only if \\(N = 2\\).</p> <p>If you extend to several assets \\(d\\), then you will end up with \\(d+1\\) equations in the system.  If a solution exists then it is unique if and only if \\(N = d+1\\)</p>"},{"location":"material/ex01/","title":"Simple exercises","text":"<p>This is a subsample of the 100 exercises on Python that can be found here. Exists also in Chinese</p> <p>100+ Python challenging programming exercises</p> <ul> <li>Question 1</li> <li>Level 1</li> </ul> Question: Write a program which will find all such numbers which are divisible by 7 but are not a multiple of 5, between 2000 and 3200 (both included). The numbers obtained should be printed in a comma-separated sequence on a single line. Hints: Consider use <code>range(#begin, #end)</code> method Solution <pre><code>l=[]\nfor i in range(2000, 3201):\n    if (i%7==0) and (i%5!=0):\n        l.append(str(i))\n\nprint ','.join(l)\n</code></pre> <ul> <li>Question 2</li> <li>Level 1</li> </ul> Question: Write a program which can compute the factorial of a given numbers. The results should be printed in a comma-separated sequence on a single line. Suppose the following input is supplied to the program: 8 Then, the output should be: 40320 Hints: In case of input data being supplied to the question, it should be assumed to be a console input. Solution <pre><code>def fact(x):\n    if x == 0:\n        return 1\n    return x * fact(x - 1)\n\nraw_input = 10\nx=int(raw_input)\nprint fact(x)\n</code></pre> <ul> <li>Question 3</li> <li>Level 1</li> </ul> Question: With a given integral number n, write a program to generate a dictionary that contains (i, i*i) such that is an integral number between 1 and n (both included). and then the program should print the dictionary. Suppose the following input is supplied to the program: 8 Then, the output should be: <code>{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64}</code> Hints: In case of input data being supplied to the question, it should be assumed to be a console input. Consider use <code>dict()</code> Solution <pre><code>n=20\nd=dict()\nfor i in range(1,n+1):\n    d[i]=i*i\n\nprint d\n</code></pre>"},{"location":"material/final/","title":"Final Report","text":"Overall Info Due date: 2024-06-23 Returns in terms of a <code>*.py</code> file with comments for the code One report per person"},{"location":"material/final/#question-1-numpy","title":"Question 1: Numpy","text":"<ul> <li> <p>Write a function <code>random_choice_matrix</code>:</p> <ul> <li>Input: <code>omega</code> which will be an integer fixing the random seed</li> <li>Output: <code>10x10</code> numpy array</li> </ul> <p>This function:</p> <p>a) fixes a seed using <code>np.random.default_rng</code>.</p> <p>b) create a random matrix with this seed where each row is an independent shuffeling of numbers between <code>1</code> and <code>10</code></p> <p>For instance</p> <pre><code>[\n  [ 8, 10,  2,  7,  4,  5,  6,  3,  9,  1 ],\n  [ 7,  9,  3,  4,  1,  5,  6,  2,  8, 10 ],\n  [ 6,  4,  9,  7,  2,  5, 10,  8,  3,  1 ],\n  [ 6,  1,  8,  5,  7, 10,  9,  3,  2,  4 ],\n  [ 1,  2,  6,  9, 10,  5,  8,  4,  7,  3 ],\n  [ 7,  1,  4,  9, 10,  6,  8,  5,  3,  2 ],\n  [ 6,  7,  2,  3, 10,  9,  8,  5,  1,  4 ],\n  [ 8, 10,  5,  3,  7,  4,  2,  9,  1,  6 ],\n  [ 8,  6,  1,  3, 10,  7,  5,  4,  9,  2 ],\n  [ 5,  4,  3,  1,  7,  9,  6, 10,  2,  8 ]\n]\n</code></pre> </li> <li> <p>Write a function <code>markov_game</code></p> <ul> <li>Input: <code>omega</code> which is an integer fixing the random seed</li> <li>Output: <code>final</code> which is a one dimensional array of size <code>10</code></li> </ul> <p>This function:</p> <p>a) generate a matrix <code>matrix</code> from <code>random_choice_matrix(omega)</code></p> <p>b) for each number of the first row of matrix, it moves forward in the matrix by the exact number of index of this number until it finishes and record the last number.</p> <p>For instance in the example above, if I start with <code>10</code> on the first row, I move from left to right and up to down by <code>10</code> to end at the number <code>9</code> in the second row, then I move from <code>9</code> to end up at the number <code>6</code> on the third row, etc. until you end up on a number on the last row where you can not go further.</p> <p>c) return the array for each terminal value starting from each number from the first row.</p> </li> <li> <p>what do you notice when you run the program for several seeds <code>omega</code>?</p> </li> <li> <p><code>%timeit</code> your function and see if you can improve the efficiency of the program by using numba.</p> </li> </ul>"},{"location":"material/final/#question-2-performance","title":"Question 2: Performance","text":"<ul> <li> <p>Write a function <code>mat_mult_slow</code>:</p> <ul> <li>Input: two matrices <code>A</code> of size <code>NxM</code> and <code>B</code> of size <code>MxK</code></li> <li>Output: matrix <code>C</code> of size <code>NxK</code></li> </ul> <p>The function returns the matrix multiplication <code>AB</code> using exclusively <code>for loop</code> and basic additions/multiplications.</p> </li> <li> <p>Write a function <code>mat_mult_numpy</code>:</p> <p>Same input and output as above but use numpy to compute the product</p> </li> <li> <p>With two random matrices that you generate of size <code>1000x10000</code> and <code>10000x5000</code> report the speed of each function using <code>%timeit</code>.</p> </li> <li> <p>Use <code>numba</code> with the decorator <code>@nb.njit</code> and copy the function <code>mat_mult_slow</code> to define a <code>mat_mult_fast</code> and compare the speed of each function.</p> </li> </ul>"},{"location":"material/final/#question-3-pandas","title":"Question 3: Pandas","text":"<p>We clean and analyse the breast cancer dataset and prepare the data in pandas first</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\n\nbreast = load_breast_cancer()\nprint(breast)\n</code></pre> <p>The data is a dictionary with keys * <code>data</code>: numpy array of size <code>Nxd</code> (values) * <code>target</code>: numpy array of size <code>N</code> (label <code>0</code> and <code>1</code> for not serious and serious cancer) * <code>feature_names</code>: numpy array of size <code>d</code> naming the nature of the columns in data</p> <ul> <li> <p>Create a panda dataframe with <code>d+1</code> columns and <code>N</code> rows where the first <code>d</code> columns have names <code>feature_names</code> and the last column name <code>label</code>. The content of the first <code>d</code> columns are data, the content of the <code>label</code> column is <code>target</code></p> </li> <li> <p>transform the dataframe of <code>d</code> columns by removing the mean from each column and dividing by the standard deviation.</p> </li> <li>Perform a PCA of these <code>d</code> columns and get the first two components <code>y1</code> and <code>y2</code> of dimension <code>d</code> each.</li> <li> <p>Generate a dataframe with three columns</p> <ul> <li><code>pc1</code>: matrix multiplication of the first component against the data</li> <li><code>pc2</code>: matrix multiplication of the second component against the data</li> <li><code>label</code></li> </ul> </li> <li> <p>provide a scatter plot <code>pc1</code> against <code>pc2</code> by setting a color blue when the label is <code>0</code> and a color red when the label is <code>1</code></p> </li> <li> <p>Provide mathematically what happened, and how from the results, the PCA in this case allows to classify the data.</p> </li> </ul>"},{"location":"material/final/#projects","title":"Projects","text":"<p>Out of the two following questions, choose one for your report.</p>"},{"location":"material/final/#project-1-ode","title":"Project 1: ODE","text":"<p>The following Oscillator</p> \\[ \\begin{equation*}   y^{\\prime\\prime} - \\mu(1-y^2)y^\\prime +y = 0  \\end{equation*} \\] <p>For large \\(\\mu\\) this equation exhibit rapid changes in speed and therefore is difficult to approximate. With the following variable change \\(y^\\prime = z\\) we get the first order ODE system</p> \\[ \\begin{equation*} \\begin{cases} y^{\\prime} = z\\\\ z^\\prime = \\mu(1-y^2)z - y \\end{cases} \\end{equation*} \\] <ul> <li> <p>Taking <code>mu = 1000</code> use your implementation of <code>euler_scheme</code> and <code>RK</code> for this equation with \\(y(0) =1\\), \\(z(0) = 0\\) starting from \\(t=0\\) to \\(t=10\\) and plot the numerical solution for different time steps \\(0.5\\), \\(0.1\\), \\(0.01\\), \\(0.001\\), ... \\(0.0001\\).</p> </li> <li> <p>Implement the implicit <code>euler_implicit_scheme</code> where</p> </li> </ul> \\[ \\begin{equation*} \\begin{cases} y(t+h) &amp;= y(t) + h z(t+h)\\\\ z(t+h) &amp;= z(t) + h(\\mu(1-y^2(t+h))z(t+h) - y(t+h)) \\end{cases} \\end{equation*} \\] <p>This involves solving a root finding at every step for which you can use <code>scipy.optimize.root</code></p> <ul> <li> <p>Compare the result of the implicit Euler Scheme with the previous scheme for each time step as well as the speed of each methods.</p> </li> <li> <p>Use <code>numba</code> to speed up your <code>euler_scheme</code> and <code>RK</code> scheme and see the speed improvement results.</p> </li> <li>Can you use <code>numba</code> to improve the <code>euler_implicit_scheme</code>?</li> </ul>"},{"location":"material/final/#project-2-systemic-risk-computation","title":"Project 2: Systemic Risk Computation","text":"<p>Given a \\(d\\) dimensional random variable \\(\\mathbf{X}\\) the goal is to compute the values \\(\\mathbf{m} = (m_1, \\ldots, m_d)\\) argmin in \\(\\mathbf{m}\\) of </p> \\[ \\begin{equation*}   F(\\mathbf{m}, \\mathbf{X})= E\\left[\\ell\\left(X_1 - m_1, \\ldots, X_d - m_d\\right)\\right] \\end{equation*} \\] <p>where</p> \\[ \\begin{equation*}   \\ell(z_1, \\ldots, z_d) = \\sum_{k,l} \\alpha \\left((x_k+x_l)^+\\right)^2 +(1-\\alpha)\\left((x_k + x_l)^-\\right)^2 \\end{equation*} \\] <p>where \\(x^+ = \\max\\{x, 0\\}\\) and \\(x^- = \\max\\{-x, 0\\}\\) are the positive and negative parts of \\(x\\) and \\(1/2 &lt; \\alpha &lt; 1\\) is a parameter.</p> <p>Note</p> <p>The result of this function is computed daily as to decide how much different financial institution have to pay in insurance to cover the systemic risk they provide to the financial system. If institution \\(k\\) is very risky for the overall system, it has to pay an amount \\(m_k\\) larger to the common insurance.</p> <p>Now the problem of this computation is that usually \\(d\\) is quite large (from 100 to thousands) and \\(\\mathbf{X}\\) which represents the returns of each institution changes every day.</p> <p>The expectation in \\(F\\) takes joint integrals which are quite expensive to compute while you search for the argmin.</p> <ul> <li> <p>Define a function <code>loss</code> that takes as input <code>alpha</code> a number and <code>z</code> a <code>d</code> dimensional array and returns \\(\\ell(\\mathbf{z})\\).</p> </li> <li> <p>Given </p> </li> <li> <p><code>N</code> samples <code>x_n</code> of dimension <code>d</code></p> </li> <li>A vector <code>m</code> of dimension <code>d</code></li> <li><code>alpha</code> number</li> </ul> <p>Provide a function that returns the Monte Carlo estimation of \\(F(m, X)\\)</p> <ul> <li>Implement the numerical gradient of the previous function</li> <li>Implement the gradient descent function (take a tolerance of <code>1e-4</code> and max iterations of <code>10000</code>.).</li> <li>Run tests using the following code to generate <code>N</code> samples of <code>d</code> dimensional normal distributed normal distribution (use <code>d = 3, 5, 10</code>)</li> </ul> <pre><code># fix dimension\nimport numpy as np\nd = 4\nomega0 = 10  # seed to generate the constants\nomega1 = 20  # seed to generate the sample.\n\n# create a random d*d matrix, a random eigenvalue one, get q from qr and generate Sigma\nrng0 = np.random.default_rng(omega0)\neigenval = np.diag(rng0.uniform(low=0.1, high=1, size=d))\nq, _ = np.linalg.qr(rng0.normal(size=(d, d)))\nSigma = q.dot(eigenval).dot(q.T)\n\n# generate N random samples from multivariate\nN = 100000\nrng1 = np.random.default_rng(omega1)\nx = rng1.multivariate_normal(mean=np.zeros(d), cov=Sigma, size=N)\n</code></pre> <ul> <li> <p>Check the accuracy of the results by changing the value of <code>omega1</code> (different samples) as well as the speed.</p> </li> <li> <p>improve the speed of your application using <code>numba</code></p> </li> <li> <p>implement the stochastic gradient descent on this example and compare the speed and accuracy.</p> </li> </ul>"},{"location":"material/final/#project-3-image-classification","title":"Project 3: Image Classification","text":"<p>We consider the Hello World problem of machine learning, namely classifying from images of handwritten digits the value of the digit from \\(0\\) to \\(9\\). We use a small set of ML procedures to decide given an image (input \\(\\mathbf{x}\\)) if is a \\(0\\) or \\(1\\) (output \\(y\\)), that is</p> \\[ \\begin{equation*}   y \\approx f(\\mathbf{x}) \\end{equation*} \\] <p>We will try</p> <ol> <li>Linear Regression</li> <li>Logistic (multivariate) regression</li> <li>Support Vector Machine</li> <li>(optional) Neural Network</li> </ol> <p>(you can also try PCA as for the cancer test problem)</p>"},{"location":"material/final/#data-preparation","title":"Data preparation","text":"<p>We use a small dataset provided by <code>sklearn</code> package: The data is a dictionary with keys * <code>data</code>: numpy array of size <code>Nxd</code> (values) \\(N\\) for the number of images \\(d=64 = 8x8\\) for the value of each pixel. * <code>target</code>: numpy array of size <code>N</code> (label <code>0</code> and <code>1</code>)</p> <p>We split the data into a training and testing set using a functionality of scikit learn.</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\n\n# load the data set\ndigits = load_digits()\n\n# We split the set (data and target) into a 50/50% train and test set\nX_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.5, shuffle=False)\n</code></pre>"},{"location":"material/final/#1-linear-regression","title":"1. Linear regression","text":"<ul> <li> <p>Implement and perform the linear regression on the training set such that</p> \\[ \\begin{equation*}   Y \\approx \\mathbf{w}\\cdot \\bar{\\mathbf{X}} \\end{equation*} \\] <p>in the square sense where \\(\\bar{\\mathbf{X}}\\) is augmented by one dimension with a constant \\(1\\).</p> </li> </ul> <p>An image is successfully classified as being a number \\(k\\) if \\(k-1/20&lt;\\mathbf{w}^\\ast \\cdot \\bar{\\mathbf{x}}&lt;k+1/20\\) (if \\(k=0\\) then no lower bound and if \\(k=9\\) no upper bound).</p> <ul> <li> <p>Create two dataframes:</p> <ul> <li><code>df_train</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_train</code> and <code>prediction</code> contains <code>prediction(x_train)</code></li> <li><code>df_test</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_test</code> and <code>prediction</code> contains <code>prediction(x_test)</code></li> </ul> </li> <li> <p>Compute the dataframes <code>conf_train</code> and <code>conf_test</code> with index and columns <code>0, 1, ..., 9</code> and with values <code>a[i,j]</code> equal to the ratio of the number of images <code>i</code> predicted as <code>j</code>.</p> </li> <li> <p>plot using <code>imxshow</code> the heatmap of this confusion matrix for the train and test set.</p> </li> </ul>"},{"location":"material/final/#2-multivariate-logistic-regression","title":"2. Multivariate logistic regression","text":"<p>Our problem is of categorical type and therefore approximating with a linear functional is not that adequate. We adopt another strategy where we try to approximate \\(y\\) in terms of probability.</p> <p>In other terms we intend to find a distribution depending on the input that approximate the probability that the output is equal to \\(k\\). For this we make a parametrized guess for the such a probability density \\(P[Y=k] \\approx p_k(\\mathbf{x}|\\mathbf{w}_1, \\ldots, \\mathbf{w}_9)\\) and given by</p> \\[ \\begin{equation*} \\begin{cases}   p_k(\\mathbf{x})&amp;= \\frac{e^{\\mathbf{w}_k\\cdot \\mathbf{x}}}{1+\\sum_{l=1}^9 e^{\\mathbf{w}_l\\cdot \\mathbf{x}}} &amp; k=1, \\ldots 9\\\\ p_0(\\mathbf{x}) &amp;=1-\\sum_{k=1}^9 P[Y=k] \\end{cases} \\end{equation*} \\] <p>We want to find \\(\\mathbf{w}_1, \\ldots, \\mathbf{w}_9\\) in \\(\\mathbb{R}^{64}\\) that matches the most the empirical observed probability. This corresponds to maximizing the (log) likelihood function</p> \\[ \\begin{equation*} \\ell(\\mathbf{w}_1, \\ldots, \\mathbf{w}_9) = \\sum_{n=1}^N \\sum_{k=0}^9 \\Delta(k, y_n)p_k(\\mathbf{x}_n) \\end{equation*} \\] <p>where \\(\\Delta(k, y_n)\\) is equal to \\(1\\) is \\(y_n = k\\) and \\(y_n = 0\\) otherwise.</p> <ul> <li>Implement the log likelhood function and its gradient.</li> <li>using gradient descent, find the vectors \\(\\mathbf{w}_1,\\ldots, \\mathbf{w}_9\\) that minimize \\(-\\ell\\).</li> </ul> <p>As for the prediction function, an image \\(y\\) is classified as being \\(k\\) if \\(p_k(\\mathbf{x}) &gt; p_l(x)\\) for any other \\(l\\).</p> <p>As above, </p> <ul> <li> <p>Create two dataframes:</p> <ul> <li><code>df_train</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_train</code> and <code>prediction</code> contains <code>prediction(x_train)</code></li> <li><code>df_test</code>: with two columns <code>label</code> and <code>prediction</code> where <code>label</code> contains the values of <code>y_test</code> and <code>prediction</code> contains <code>prediction(x_test)</code></li> </ul> </li> <li> <p>Compute the dataframes <code>conf_train</code> and <code>conf_test</code> with index and columns <code>0, 1, ..., 9</code> and with values <code>a[i,j]</code> equal to the ratio of the number of images <code>i</code> predicted as <code>j</code>.</p> </li> <li> <p>plot using <code>imxshow</code> the heatmap of this confusion matrix for the train and test set.</p> </li> </ul>"},{"location":"material/final/#3-support-vector-machine","title":"3. Support vector Machine","text":"<p>We won't see the implementation of support vector machine (though it is not difficult but involves constrained optimization problems that we didn't see), the idea is to separate group of points by an hyper plane to classify them into two or more categories.</p> <p>In a two classification framework with data points \\((\\mathbf{x}_n, y_n)\\) where \\(y_n = \\pm 1\\), we want to find and hyper plane \\(\\mathbf{w}\\cdot \\mathbf{x} - b\\) such that \\(\\mathbf{x}\\cdot \\mathbf{x}_n - b \\geq 0\\) if \\(y_n =1\\) and \\(\\mathbf{w}\\cdot \\mathbf{x}_n - b&lt;0\\) if \\(y_n = -1\\).</p> <p>It involves simple quadratic optimization problem with linear constraints that are quite efficient to solve even in high dimensions. Extensions are done in the multidimensional case.</p> <ul> <li>Follow the example from scikit learn to perform the svm clustering and compare the results with your previous implementations.</li> </ul> <p>Follow the </p>"},{"location":"material/hw01/","title":"Homework 01","text":"Overall Info Due date: 2024-03-25 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw01/#1-datatypes-control-flows-functions","title":"1. Datatypes, Control Flows, Functions","text":"<p>Note</p> <p>For the following short exercises, no use of <code>numpy</code>.</p> <p>1.1 Using conditional statements and loops, count the number of numbers between 0 and 10.000 which are divisible by 3 or 7 and print it.</p> <p>1.2 Write a program that print the following pattern</p> <pre><code>ooooooooooooooooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \noooo                                                                    \noooo                                                                    \noooo                                                                    \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \n             oooo                                                       \n             oooo                                                       \n             oooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo                                                       \nooooooooooooooooo\n</code></pre> <p>1.3 Given a list <code>[\"apple\", \"orange\", \"cabage\", \"lemon\", \"potato\"]</code> extract the subarray containing cabage and potato, and return their indices in the original list. Furthermore, write a program that inverse the order of the list.</p> <p>1.5 Write a function that takes as input one of the name of the 12 month and return the number of days of this month (february is 28)</p> <p>1.6 Write a function that takes a list of numbers and return a ordered list. i.e. <code>[1, 4, 2] -&gt; [1, 2, 4]</code>. You can test this function by creating arbitraty list from numpy arrays <code>x = list(np.random.rand(N)</code>.</p>"},{"location":"material/hw01/#2-numpy","title":"2. Numpy","text":"<p>2.1 Using <code>numpy</code> and its functionalities redo the exercises 1.1 and 1.6</p> <p>2.2 Create two arrays of numbers between -1 and 1. The first one has consecutive numbers equally spaced by 0.01 while the second one has exactly 100 elements.</p> <p>2.3 Given natural numbers \\(n\\) and \\(d\\), create a \\(n\\times d\\) matrix of the form</p> <pre><code>[\n    [0, 1, ..., d-1],\n    [d, d+1, ..., 2d-1]\n    ...\n    [(n-1)d,...,(nd) -1 ]\n]\n</code></pre> <p>Note</p> <p>There are several ways to do it, but remember that loops are not efficient in python. Have a look at the shape manipulations in <code>numpy</code>.</p> <p>2.4 Create a 10x10 matrix where each line contains all the numbers 0 to 9 but shuffled uniformly randomly (check the random routines of numpy documentation)</p> <p>2.5 Normalize a random 5x5 matrix such that the smallest element is 0 and largest is 1</p> <p>2.6 Round a random array 5x5 with two digits after the coma</p> <p>2.7 Given a random array 100 find the position and value of the closest element to 0.6</p> <p>2.8 Write a function which given an array of size \\(N\\) of integers between 0 and 10 returns the histogram of the array by bins of 0.1 (that is number of elements between 0 and 0.1, number of elements between 0.1 and 0.2, ..., between 0.9 and 1</p>"},{"location":"material/hw01/#3-numpy-and-plotly-collatz-conjecture","title":"3. Numpy and Plotly: Collatz Conjecture","text":"<p>Collatz Conjecture</p> <p>Consider the following sequence \\(u = (u_i)\\) of natural numbers given by</p> \\[ \\begin{equation} u_{i+1} = \\begin{cases} u_i /2 &amp; \\text{if }u_i \\text{ is even}\\\\ 3u_i + 1 &amp; \\text{if }u_i \\text{ is odd} \\end{cases} \\end{equation} \\] <p>starting with a number \\(u_0 = n \\in \\mathbb{N}\\).</p> <p>The Collatz Conjecture states that whatever starting integer \\(n \\in \\mathbb{N}\\), the sequence will ultimately reach after some time \\(1\\). This Conjecture is still an open problem, some partial answer in this direction given recently by Terence Tao in 2019.</p> <p>For \\(n \\in \\mathbb{N}\\), denote by</p> \\[ \\tau(n) : = \\inf\\{i \\colon u_i = 1\\} \\] <p>which representes the first time where the sequence starting form \\(n\\) reaches \\(1\\). If this sequence never reaches \\(1\\) starting with \\(n\\), then \\(\\tau(n) = \\infty\\). Collatz conjecture states that \\(\\tau(n)&lt;\\infty\\) for every \\(n\\).</p> <p>There is strong confidence that this conjecture is true, and empirically, it holds for every natural number smaller than \\(2^{68}\\)</p> <p>3.1 Using the control flow <code>while</code>, given an integer \\(n\\) write a function that returns a <code>numpy</code> array \\((u_0, u_i, \\ldots, u_{\\tau(n)})\\). Mathematically, also write what is the domain and codomain of this function.</p> <p>3.2 Using <code>plotly</code>, provide a function where given a <code>numpy</code> array \\(x = (n_0, \\ldots, n_{d-1})\\) it plots \\(d\\) paths \\((u_0, \\ldots, u_{\\tau(n_k)})\\) where \\(u_0 = n_k\\) for \\(k=0, \\ldots, d-1\\).</p> <p>3.4 Write a third function where given a <code>numpy</code> array \\(x = (1, ldots, d)\\) it returns the array \\((\\tau(1), \\ldots, \\tau(d))\\).</p> <p>3.5 Using <code>bar</code> ploting functionality (<code>fig.add_bar(...)</code>) of <code>plotly</code>, write a function that plot the histogram of the previous function, that is \\((l_1, l_2, \\ldots)\\) where</p> \\[ \\begin{equation} l_k = \\text{Cardinality}\\{n\\colon \\tau(n) = k, \\quad 0\\leq n \\leq N\\} \\end{equation} \\] <p>for (depending on the performance of your computer) \\(N=1000, 10000, 100000\\).</p>"},{"location":"material/hw01/#4-scipy","title":"4. Scipy","text":"<p>4.1 Consider the function \\(x \\mapsto f(x) = x ** 2 + 10 * sin(x)\\) for \\(x \\in \\mathbb{R}\\)</p> <ul> <li>plot the function</li> <li>find the minimum</li> </ul> <p>4.2 For the following distributions:</p> <ul> <li>normal with std = 1, 2, 5</li> <li>student with degree of freedom 2, 3, 4, 6</li> </ul> <p>Plot the pdf and cdf of each class for different parameters and compare</p>"},{"location":"material/hw02/","title":"Homework 02","text":"Overall Info Due date: 2024-04-22 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw02/#1-monte-carlo-convergence","title":"1. Monte Carlo Convergence","text":"<p>We compute the following expectation</p> \\[ \\begin{equation} E[(X - K)^+] = \\int_{-\\infty}^{\\infty}(x-K)^+ dF_X(x) = \\int_{-\\infty}^{\\infty}(x-K)^+ f_X(x)dx \\end{equation} \\] <p>where \\(K\\) is a constant, \\(F_X\\) is the <code>cdf</code> of \\(X\\) and \\(f_X=dF_X/dx\\) is the <code>pdf</code> of \\(X\\).</p> <p>We assume throughout that \\(X\\sim \\mathcal{N}(\\mu, \\sigma^2)\\) is a guaussian distribution with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Such a random variable is declared in <code>scipy</code> as follows</p> <pre><code>from scipy.stats import norm\n\nmu = 0.5\nsigma = 0.2\n\nRV = norm(loc = mu, scale = sigma)\n</code></pre> <p>1.1 Define a function <code>expectation</code> that takes as input the random variable <code>RV</code>, the constant <code>K</code> and return the value of the integral using <code>quad</code>.</p> <p>1.2 Define a function <code>mc_expectation</code> that takes as input the random variable <code>RV</code>, the constant <code>K</code> and the natural number <code>N</code> (the number of samples) that retuns a <code>numpy</code> vector <code>[I_0, ..., I_{N-1}]</code> where</p> \\[ \\begin{equation} I_k = \\frac{1}{k} \\sum_{l=0}^{k-1} (x_k-K)^+ \\end{equation} \\] <p>where <code>x = [x_0, \\ldots, x_{N-1}]</code> is a random sample from the distribution of \\(X\\).</p> <p>1.3 For \\(N = 100000\\), with a plotly graph, plot</p> <ul> <li>The constant function <code>expectation(RV, K)</code> for <code>n=0, ..., N-1</code></li> <li>10 functions <code>mc_expectation(RV, K, N)</code> (they already return a vector <code>I = [I_0, ..., I_{N-1}]</code>)</li> </ul> <p>Comment on the speed of convergence of monte carlo method (you can vary \\(N\\) as well as the number of monte carlo samples you compute).</p>"},{"location":"material/hw02/#2-quantile-exact-vs-mc-methods","title":"2. Quantile: exact vs MC methods","text":"<p>From the lecture we know</p> Value at Risk: The value at risk is defined as \\(V@R_{\\alpha}(X) = q_X(1-\\alpha) = F_X^{-1}(1-\\alpha)\\) where \\(q_X\\) is the quantile of \\(X\\). <p>Leads to three methods to compute it.</p> <ul> <li>You already have a <code>ppf</code> function at hand for the quantile</li> <li>You compute the inverse of the <code>cdf</code> using <code>root</code></li> <li>You have just random sample of the distribution and compute the empirical quantile.</li> </ul> <p>2.1 Define a <code>quantile00</code> function that takes as input a known <code>RV</code> and a number <code>0&lt;u&lt;1</code> and return the quantile with a root finding method to invert the <code>cdf</code></p> <p>2.2 Compare the speed of computation for different <code>RV</code> (normal, student, normal inverse guaussian from the <code>scipy.stats</code> library) of this function with respect to the <code>ppf</code> function of those random variable.</p> <p>2.3 Sometimes, you do not have access to the <code>ppf</code> or <code>cdf</code> explicitely but just have \\(N\\) random samples \\(x^N = (x_0^N, ..., x^N_{N-1})\\) of this random variable. Numpy has a functionality to return the quantile of a random sample (there are many ways to interpolate it, see documnetation). Given a random sample (as a numpy array) <code>x=[x_0, ..., x_{N-1}]</code> the quantile is given by <code>np.quantile(x, u)</code>. This empirical quantile converges to the normal quantile. Experiment with different random samples from a normal random variable (<code>rvs</code>) and plot the convergence as a function of \\(N\\) of the empirical quantile to the theoretical quantile.</p> Empirical Quantile <p>Note that the general definition of the (right) quantile is given by</p> \\[ \\begin{equation}     q_X(u) := \\inf \\left\\{ x \\in \\mathbb{R}\\colon P[X\\leq x] \\geq u \\right\\} = \\inf \\left\\{ x \\in \\mathbb{R}\\colon F_X(x) \\geq u \\right\\} \\end{equation} \\] <p>If you have a a random sample \\((x_0, \\ldots, x_{N-1})\\) of \\(X\\), denote by </p> \\[ \\begin{equation}     F^N(x) = \\frac{\\# \\{k \\colon x_k \\leq x\\}}{N} \\end{equation} \\] <p>It holds that \\(F^N \\to F_X\\) if \\(F_X\\) is continuous (is not easy to show, it holds in general gut in a distributional sense).</p> <p>Hence, the quantile \\(q^N\\) of \\(F^N\\) converges too to \\(q_X\\) as \\(N\\) is large.</p> <p>If you denote by \\((y_0, \\ldots, y_{N-1})\\) the reordering of \\((x_0, \\ldots, x_{N-1})\\) from the smallest to the largest value, then it holds</p> \\[     q^N(u) = y_{k_u} \\] <p>where </p> \\[     k_u =      \\begin{cases}         \\inf\\{k \\colon k\\geq Nu\\} &amp; \\text{if }Nu\\leq N-1\\\\         N-1 &amp; \\text{otherwize}     \\end{cases} \\]"},{"location":"material/hw02/#3-average-value-at-risk","title":"3. Average Value at Risk","text":"<p>We discussed in the lecture that the value at risk (which is a quantile) is not appropriate to estimate the risk. It has been replaced by the average value at risk which has different representations</p> \\[ \\begin{align} AV@R_{\\alpha}(X) &amp; = \\frac{1}{\\alpha}\\int_{1-\\alpha}^1 q_X(u) du\\\\ &amp; = \\inf\\left\\{x + \\frac{1}{\\alpha}E\\left[(X - x)^+\\right]\\colon x \\in \\mathbb{R}\\right\\}\\\\ &amp; = q_X(1-\\alpha) + \\frac{1}{\\alpha}E\\left[ (X - q_X(1-\\alpha))^+ \\right] \\end{align} \\] <p>3.1 Implement the <code>AVaR0</code>, <code>AVaR1</code> and <code>AV@R2</code> functions with input <code>RV</code> and <code>alpha</code> and return with <code>quad</code> the result for the first, second and third representation using <code>ppf</code> and/or <code>minimize</code> depending on the representation</p> <p>3.2 Implement the <code>mc_AVaR0</code>, <code>mc_AVaR1</code> and <code>mc_AVaR2</code> functions with input <code>x = [x_0, \\ldots, x_{N-1}]</code> numpy random sample of \\(X\\) and <code>alpha</code> using Monte carlo and empirical quantile for each representations</p> <p>3.3 Compare numerically the speed and accuracy of each method.</p>"},{"location":"material/hw02/#4-multidimensional","title":"4. Multidimensional","text":"<p>Usually in risk managment, the random variable \\(X\\) is a combination of many random variables</p> \\[ \\begin{equation} X = \\sum_{k=1}^d w^k X^k \\end{equation} \\] <p>where the vector \\((X^1, \\ldots, X^d)\\) has a given <code>cdf</code> or random samples, and \\(w^1, \\ldots, w^d\\) are numbers representing the contribution of each factor \\(X^k\\) to the total risk \\(X\\).</p> <p>Throughout, we will consider that \\((X^1, \\ldots, X^d)\\) is a \\(d\\)-dimensional normal Gaussian random variable.</p> Multivariate Gaussian distribution <p>The multivariate Gaussian distribution is the multidimensional extension of a Gaussian distribution for a vector of random variables \\(X=(X^1, \\ldots, X^d)\\). The parameters are the mean \\(\\mathbf{\\mu} = (\\mu^1, \\ldots, \\mu^d)\\) and the covariance matrix (positive semi definite matrix) \\(\\mathbf{\\Sigma} \\in \\mathbb{R}^{d\\times d}\\).</p> <p>The <code>pdf</code> of this multidimensional random variable is given by</p> \\[ \\begin{equation} f(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2} \\sqrt{\\det(\\mathbf{\\Sigma})}} \\exp\\left(-\\frac{1}{2}\\left(\\mathbf{x} - \\mathbf{\\mu}\\right)^\\top \\mathbf{\\Sigma}\\left(\\mathbf{x} - \\mathbf{\\mu}\\right)\\right)  \\end{equation} \\] <p>Denoting by \\(\\sigma^k = \\sqrt{\\mathbf{\\Sigma}^{k,k}}\\) the square root of the diagonal of \\(\\mathbf{\\Sigma}\\), then each random variable \\(X^k\\) is a normal distribution \\(\\mathcal{N}(\\mu^k, (\\sigma^k)^2)\\).</p> <p>However, the different components of the random vector might be dependent as </p> \\[ \\begin{equation} E[(X^k - \\mu^k)(X^l - \\mu^l)] = \\mathbf{\\Sigma}^{k,l} \\end{equation} \\] <p>4.1 Extend the functions <code>mc_AVaR0</code>, <code>mc_AVaR1</code> and <code>mc_AVaR2</code> to multidimensional samples. Use the following two case scenarios to compare accuracy and execution time by varying \\(N\\) the number of samples </p> <pre><code># case of 2 dimensions\nimport numpy as np\nfrom scipy.stats import multivariate_normal\n\nmu = np.array([0.2, 0.5])\nSigma = np.array(\n    [\n        [ 1.        , -0.26315789],\n        [-0.26315789,  1.        ]\n    ]\n)\nw = np.array([2, 5])\n\nRV_2dim = multivariate_normal(mean = mu, cov = Sigma)\n\n# generate N random samples (you get a numpy array Nx2)\nN = 10\nsamples = RV_2dim.rvs(N)\n\n# case of 5 dimensions\nmu = np.array([0.2, 0.5, -0.1, 0, 0.6])\n\nSigma = np.array(\n    [\n        [1.        , 0.2688825 , 0.401427  , 0.19473116, 0.66256879],\n        [0.2688825 , 1.        , 0.3907619 , 0.43373298, 0.43199657],\n        [0.401427  , 0.3907619 , 1.        , 0.27893741, 0.61330745],\n        [0.19473116, 0.43373298, 0.27893741, 1.        , 0.46849892],\n        [0.66256879, 0.43199657, 0.61330745, 0.46849892, 1.        ]\n    ]\n)\nw = np.array([2, 5, -2, 3, 6])\n\nRV_5dim = multivariate_normal(mean = mu, cov = Sigma)\n\n# generate N random samples (you get a numpy array Nx5)\nN = 10\nsamples = RV_5dim.rvs(N)\n</code></pre> <p>Hint: Do not forget that numpy gives you access to the <code>dot</code> product to compute \\(\\sum w^k X^k\\).</p> <p>4.2 Optional: you can try for the two dimensional case to implement with <code>dblquad</code> the direct computation of the <code>AVaR1</code> to compare speed and accuracy.</p> Any dimensional multidimensional Gaussian distributions <p>To create a multidimensional guassian vector, you need to provide the mean vector \\(\\mathbf{\\mu} = (\\mu^1, \\ldots, \\mu^d)\\) as well as the covariance matrix \\(\\mathbf{\\Sigma}\\) which is usually calibrated to data. In our case we can generate some of these distribution using <code>numpy</code> and <code>scipy</code></p> <pre><code># we import the multivariate normal as well as a function to generate Sigma\nfrom scipy.stats import multivariate_normal, random_correlation\nimport numpy as np\n\n# create a random vector of positive eigenvalues and then random covariance\nd=4\neigenvalues = np.random.rand(d)\nSigma = random_correlation.rvs(eigenvalues) # covariance matrix\nmu = no.random.rand(d)                      # vector of mean\n\nRV = multivariate_normal(mean = mu, cov = Sigma)\n\n# generate random samples (N random vectors or dimension d each so Nxd numpy array)\nN = 1000\nsamples = RV.rvs(N)\nprint(samples)\n</code></pre>"},{"location":"material/hw03/","title":"Homework 03","text":"Overall Info Due date: 2024-05-24 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw03/#1-linear-regression-fake-data","title":"1. Linear Regression Fake Data","text":"<p>To illustrate the principle of linear regression we consider the following model</p> \\[ \\begin{equation*}     Y = a + b_1 X_1 +b_2 X_2 + \\varepsilon = \\mathbf{X}\\mathbf{b} + \\varepsilon \\end{equation*} \\] <p>where</p> \\[ \\begin{equation*}     \\mathbf{b} =     \\begin{bmatrix}         a\\\\         b_1\\\\         b_2     \\end{bmatrix}     \\quad     \\text{and}     \\quad     \\mathbf{X} =     \\begin{bmatrix}         1 &amp; X_1 &amp;  X_2     \\end{bmatrix} \\end{equation*} \\] <p>We assume that</p> \\[ \\begin{equation*}     \\begin{bmatrix}         X_1 \\\\         X_2     \\end{bmatrix}     \\sim     \\mathcal{N}\\left(     \\begin{bmatrix}         \\mu_1 \\\\         \\mu_2     \\end{bmatrix}     ,     \\begin{bmatrix}         \\sigma_1^2 &amp; \\sigma_1 \\sigma_2 \\rho\\\\         \\sigma_1 \\sigma_2 \\rho &amp; \\sigma_2^2     \\end{bmatrix}     \\right)     \\quad \\text{and}\\quad     \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2) \\end{equation*} \\] <p>with \\(\\varepsilon\\) independent of \\((X_1, X_2)\\).</p> <p>Consider the following specifications</p> <pre><code>import numpy as np\n\nb = np.array([1, 1, -0.5]).T\n\nmu = np.array([1, 0]).T\nsigma1 = 1\nsigma2 = 0.5\nrho = 0.4\nSigma = np.array(\n    [\n        [sigma1 ** 2, sigma1 * sigma2 * rho],\n        [sigma1 * sigma2 * rho, sigma2 ** 2]\n    ]\n)\n\nsigma = 2\n\n# We prepare the dataset\n\n# Fix random number generator and number of samples\nrng = np.random.default_rng(seed = 150)\nN = 1000\n\n# generate samples\nX = rng.multivariate_normal(mu, Sigma, size = N)        # size N x 2\nepsilon = rng.normal(0, sigma, size = N)                # size N\n\n# Add an axis of 1 to X\nX = np.append(np.ones((N, 1)), X, axis = 1)             # append Nx1 to Nx2 -&gt; Nx3\n\n# Generate Y\nY = X.dot(b) + epsilon                                  # size N\nY\n</code></pre>"},{"location":"material/hw03/#question-1","title":"Question 1:","text":"<ul> <li>Generate a scatter plot of \\(Y\\) against \\(X_1\\) and \\(X_2\\), as well as a scatter plot of \\(X_1\\) against \\(X_2\\).</li> <li>Implement the computation of \\(\\hat{\\mathbf{b}}(N)\\) from the \\(N\\) sample data and compare the obtained values with the true one.</li> <li>Return the residual error \\(\\hat{\\varepsilon}(N)=Y - \\hat{\\mathbf{b}}(N)\\cdot \\mathbf{X}\\) and plot its histogram.</li> </ul>"},{"location":"material/hw03/#question-2","title":"Question 2:","text":"<p>Since we fixed the random generator with <code>seed=150</code> you always get the same result for \\(\\hat{\\mathbf{b}}(N)\\) as well as \\(\\hat{\\varepsilon}(N)\\).</p> <p>Two source of error can come into the linear regression: The randomness in the sample (the seed) as well as the number of samples <code>N</code>.</p> <ul> <li> <p>Define a function <code>f(N, M)</code> where <code>N</code> is the number of samples, and \\(M\\) is the number of trials where you draw this sample. This function shall return</p> </li> <li> <p>an array \\(\\hat{\\mathbf{b}}(N)\\) of size <code>3xM</code> for each computation of the regression coefficient (in the random generator you set <code>seed = None</code>)</p> </li> <li> <p>an array \\(\\hat{\\varepsilon}(N)\\) of size <code>NxM</code> of the corresponding residual for each sample drawn.</p> </li> <li> <p>Fix <code>M=100</code> and for <code>N = 10, 100</code> and <code>1000</code> plot the histogram of</p> </li> <li> <p><code>a(N)</code>, <code>b_1(N)</code> and <code>b_2(N)</code> (they are arrays of <code>M=100</code> values)</p> </li> <li>mean and standard deviation in the direction of the <code>N</code> axis of \\(\\hat{\\varepsilon}(N)\\) (you get two arrays of <code>M=100</code> values)</li> </ul>"},{"location":"material/hw03/#2-linear-regression-real-data","title":"2. Linear Regression Real Data","text":"<p>As seen in the lecture, we are given a set of data in a dataframe <code>df</code> with</p> <ul> <li>a column <code>y</code> for the serie of outputs;</li> <li><code>d</code> columns <code>x_0</code>, ..., <code>x_d</code> for the series of outputs</li> </ul> <p>In the following example we consider a dataset about wine</p>"},{"location":"material/hw03/#question-1_1","title":"Question 1:","text":"<p>Proceed through the following:</p> <ul> <li>Load the dataset with pandas, check if the data are correct and provide some descriptive statistics.</li> </ul> <p>The output \\(\\mathbf{y}\\) is <code>quality</code>, the column <code>type</code> stands for the rows that are either <code>red</code> or <code>white</code>, all the other columns are characteristics of the wine.</p> <ul> <li> <p>Using plotly scatter plot, visualize for <code>red</code> and <code>white</code> the relation between each input dimension and output dimension.</p> </li> <li> <p>Implement using <code>statsmodels</code> the ols regression of <code>quality</code> against the inputs and show the results.</p> </li> </ul>"},{"location":"material/hw03/#question-2_1","title":"Question 2.","text":"<p>The number of features is quite large and it is not clear which feature is relevant or not in the linear regression. The goal is to reduce the number of features as to explain as much as possible the output.</p> <p>Without entering in feature selection overall, we just want to see which input is the most relevant. One indicator for the goodness of a linear regression is <code>rsquared</code> which can be obtained from the returned fitted model <code>est = sm.OLS(y, X).fit()</code> and then <code>est.rsquared</code>.</p> <p>We just try to get the two best features</p> <ul> <li>Loop through every single input feature, perform the linear regression, get the rsquared.</li> <li>take the feature with the largest rsquared.</li> <li>Loop through each other feature, perform the linear regression together with the previously selected and first feature</li> <li>select the feature with the largest rsquared.</li> </ul> <p>Note</p> <p>Normally you should also consider if the new feature collected is not strongly colinear with the first one. To do so you should double check the VIF factor, see <code>variance_inflation_factor</code>.</p>"},{"location":"material/hw03/#3-clustering","title":"3. Clustering","text":"<p>The principle of clustering is as follows. Given a set \\(X = \\{x_1, \\ldots, x_N\\}\\) of \\(N\\) points in \\(\\mathbb{R}^d\\), the goal is to find a partition (cluster) \\(C_1, \\ldots C_K \\subseteq X\\) which somehow group similar points.</p> <p>Similarity between points is defined in terms of some distance \\(d(x,y)\\). The clustering aims to find an optimal cluster \\(C_1^\\ast, \\ldots, C_K^\\ast\\) such that</p> \\[ \\begin{equation} \\sum_{k=1}^K \\frac{1}{\\# C^\\ast_k}\\sum_{x, y \\in C_k^\\ast} d(x, y) \\leq \\sum_{k=1}^K \\frac{1}{\\# C_k}\\sum_{x, y \\in C_k} d(x, y) \\end{equation} \\] <p>for any other cluster \\(C_1, \\ldots, C_K\\).</p> <p>We denote by \\(\\mathfrak{C}\\) the set of all clusters (or partitions) \\(\\mathcal{C} = \\{C_1, \\ldots, C_K\\}\\) of \\(X\\) in \\(K\\) elements and define</p> \\[ \\begin{equation*}     F(\\mathcal{C}) = \\sum_{C \\in \\mathcal{C}} \\frac{1}{\\# C}\\sum_{x, y \\in C} d(x, y) \\end{equation*} \\] <p>the problem can therefore be reformulated into an optimization problem</p> \\[ \\begin{equation*}     \\mathcal{C}^\\ast = (C_1^\\ast, \\ldots, C_K^\\ast) = \\mathrm{argmin}\\left\\{F(\\mathcal{C})\\colon \\mathcal{C} \\in \\mathfrak{C}\\right\\} \\end{equation*} \\] <p>Computing \\(F\\) for a given cluster \\(\\mathcal{C}\\) is relatively fast as long as the distance is quick to compute. However, the optimization problem itself is very difficult. Indeed, it is a minimization problem on a set \\(\\mathfrak{C}\\) which does not have a suitable topology to define derivatives for instance. Hence, the only way a priori would be a brute force optimization, that is running through every possible partition, which is however not suitable since the cardinality of \\(\\mathfrak{C}\\) is gigantic. It corresponds to the stirling number of the second kind \\({ N \\brace K}\\):</p> \\[ \\begin{equation*}     \\#\\mathfrak{C} := {N\\brace K} = \\sum_{k=0}^K \\frac{(-1)^{K-k} k^N}{(K-k)!k!} \\sim_{N\\to \\infty} \\frac{K^N}{K!} \\end{equation*} \\] <p>meaning that for a fixed number \\(K\\), the cardinality is growing exponentially in the size of the set. The problem can be refined and some better approximation can be found but in general this is NP-Hard.</p> <p>However, with some assumptions about the distance, and geometrical consideration, an honnest and fast algorithm can be designed to achieve some local optimum.</p> <p>We consider as ''distance''' the square of the euclidean norm, that is \\(d(x,y) = \\|x - y\\|^2\\).</p>"},{"location":"material/hw03/#question-1_2","title":"Question 1.","text":"<p>Show that</p> \\[ \\begin{equation*}     \\frac{1}{\\# C} \\sum_{x, y \\in C} \\| x - y \\|^2 = 2 \\sum_{x \\in c} \\|x - \\mu\\|^2 \\end{equation*} \\] <p>where \\(\\mu = \\frac{1}{\\# C} \\sum x\\) is the average/barycenter or centroid of \\(C\\).</p>"},{"location":"material/hw03/#question-2_2","title":"Question 2.","text":"<p>It follows that</p> \\[ \\begin{equation*}     F(\\mathcal{C}) = \\sum_{C \\in \\mathcal{C}} \\sum_{x \\in X} \\|x - \\mu_{C}\\|^2 \\end{equation*} \\] <p>With this reformulation in term of geometric center of \\(C\\) leads to the following idea for an algorithm to select a partition.</p> <ol> <li>Initialize \\(K\\) centers \\(\\mu_1(0), \\ldots, \\mu_K(0)\\) by choosing \\(K\\)-points in \\(X\\).</li> <li> <p>Recursively: While \\(\\mathcal{C}(n+1) \\neq \\mathcal{C}(n)\\) at the end of the following do:</p> </li> <li> <p>Given \\(K\\) \\(\\mu_1(n), \\ldots \\mu_K(n)\\) define \\(K\\) sets \\(C_1(n+1), \\ldots, C_K(n+1)\\):</p> <p>\\(C_k(n+1) = \\left\\{x \\in X\\colon \\|x - \\mu_K(k)\\|^2 \\leq \\|x - \\mu_K(j)\\|^2 \\text{ for any }j\\neq k\\right\\}\\)</p> <p>If some point is assigned to two or more then set it to a single one. The best way to do it, is to assign the points to the first cluster, then assign the remaining points to the second one, etc.</p> </li> <li> <p>update the new centers \\(\\mu_1(n+1), \\ldots, \\mu_K(n+1)\\):</p> <p>\\(\\mu_k(n+1) = \\frac{1}{\\# C_k(n+1)} \\sum_{x \\in C_k(n+1)} x\\)</p> </li> </ol> <ul> <li>Show that at each step \\(F(\\mathcal{C}(n+1))\\leq F(\\mathcal{C}(n)\\), hence we find a sequence along which the cost function is decreasing.</li> <li>Show that the algorythm finishes after a finite number of steps.</li> <li>implement the algorythm in numpy by choosing randomly \\(k\\) elements of the set \\(X\\). (the set \\(X\\) can be represented by a numpy array <code>Nxd</code>.)</li> </ul>"},{"location":"material/hw03/#question-2_3","title":"Question 2.","text":"<p>Consider the dataset California Housing which represents the housing data for California.</p> <ul> <li>Load the dataset and select the columns <code>longitude</code>, <code>lattitude</code> and <code>medianIncome</code> as final dataframe <code>df</code>.</li> <li>Install (using conda or pip) the package <code>scikit-learn</code> which is a standard machine learning library.</li> <li>Cluster the data with 4 clusters using Kmeans: <code>from sklearn.cluster import KMeans</code>.</li> <li>given a numpy array <code>X</code> of size <code>N x d</code>, computing the cluster with <code>Kmeans</code> is done as follows <code>result = KMeans(n_clusters = 4).fit(X)</code> and the labels for the cluster are given by <code>result.labels_</code> which is an array of size <code>N</code>.</li> <li>join the cluster values in the dataframe as a new column.</li> <li>plot using plotly express scatter the scatter plot latitude against longitude with a different color for each cluster.</li> </ul>"},{"location":"material/hw04/","title":"Homework 04","text":"Overall Info Due date: 2024-06-26 Returns in terms of a <code>*.py</code> file with comments for the code By group of 5-6 students"},{"location":"material/hw04/#1-ode-implementation","title":"1. ODE implementation","text":"<p>Harmonic Oscillator:</p> \\[ \\begin{equation*}   x^{\\prime\\prime} + \\omega^2 x = 0 \\end{equation*} \\] <ul> <li>setting \\(v = x^\\prime\\), convert this second order ode into a two dimensional first order ODE \\((x, v)\\).</li> <li>Use Euler scheme to compute the solution with \\(\\omega=1\\) with \\(x(0) = 1\\), \\(v(0) =1\\)</li> <li>plot the curve \\(t\\mapsto (x(t), v(t))\\) for \\(0\\leq t \\leq 10\\).</li> </ul> <p>Consider the Damped harmonic oscillator:</p> \\[ \\begin{equation*}   x^{\\prime\\prime} + 2\\gamma x^\\prime +  \\omega^2 x = 0 \\end{equation*} \\] <ul> <li>same notation convert this equation into first order ode in two dimensions.</li> <li>Use RK 4th order to compute the solution \\(\\omega = 1\\) and \\(\\gamma = 0.1\\) and \\(x(0) = v(0)=1\\).</li> <li>plot the solution and compare with the previous solution</li> </ul>"},{"location":"material/hw04/#2-forward-vs-backward-explicit-vs-implicit","title":"2. Forward vs Backward (explicit vs implicit).","text":"<p>Explicit Euler</p> \\[ \\begin{equation*}   y(t+h) = y(t) + h f(t, y(t)) \\end{equation*} \\] <p>Implicit Euler</p> \\[ y(t+h) = y(t) + h f(t+h, y(t+h)) \\] <p>This second method involves solving a root problem to get \\(y(t+h)\\).</p> <ul> <li>Using <code>root</code> from <code>scipy.minimize</code> implement the implicit Euler</li> </ul> <p>Consider the ODE</p> \\[ \\begin{equation*}   y^\\prime = -\\lambda y, \\quad y(0) = 1 \\end{equation*} \\] <p>with solution \\(y(t) = e^{-\\lambda t}\\)</p> <ul> <li>use explicit Euler, RK 4th to compare with implicit Euler (precision and speed)</li> </ul>"},{"location":"material/hw04/#3-gradient-descent","title":"3. Gradient Descent","text":"<p>We implement the gradient descent on the blurred \\(0\\) and \\(1\\) images from <code>sklearn</code> package.</p> <pre><code>import numpy as np\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\nimport sklearn.datasets as dt\nfrom sklearn.model_selection import train_test_split\n\n# load the images and their feature (if it is 0 or 1)\ndigits, target = dt.load_digits(n_class=2, return_X_y=True)\n\n\n# the shape of the dataset\nprint(digits.shape)\n\n# We plot a short sample \npx.imshow(digits.reshape(360, 8, 8)[:10, :, :], facet_col=0, binary_string=True)\n</code></pre> <p>The goal it to perform a simple linear regression but using gradient descent by minimizing among all \\(\\mathbf{w} = [w_0, \\ldots, w_{64}]^\\top\\) the objective function</p> \\[ \\frac{1}{N}\\sum (y_n - \\mathbf{w}^\\top \\bar{\\mathbf{x}}_n)^2 \\] <p>where \\(y_n\\) is either \\(0\\) or \\(1\\) for the label of the \\(n\\)-th image and \\(\\bar{\\mathbf{x}}_n = [1, \\mathbf{x}_n]\\) is the array of the image augmented with a \\(1\\).</p> <ul> <li>modify the objective function and gradient of which so that it takes as input \\(\\mathbf{w}\\) \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) and modify the gradient descent function.</li> </ul> <p>Since our goal is to find a correct specification to further classify data, we calibrate the model on a training set and evaluate its accuracy on a testing set. To split the two set of data we use <code>sklearn</code></p> <pre><code>x_train, x_test, y_train, y_test = train_test_split(\n  digits,\n  target,\n  test_size=0.2,\n  random_state=10\n)\n</code></pre> <ul> <li>Using the gradient descent calibrate on the training set <code>x_train</code>, <code>y_train</code> the optimal value of \\(\\mathbf{w}\\). Plot the value of <code>f_history</code> (choose a maximum number of iteration of 100 and 0.1 as threshold and tweak a little bit with momentum and learning rate until you reach a satisfactory convergence rate and error)</li> </ul> <p>Now we want to be able to classify the data. We proceed as follows</p> <p>If \\(\\mathbf{w}^\\top \\bar{\\mathbf{x}} \\geq 0.5\\) it is classified as \\(1\\) otherwise it is classified as \\(0\\).</p> <ul> <li> <p>Given \\(\\mathbf{w}\\), \\(N\\) samples \\((\\mathbf{x}_1, y_1), \\ldots,(\\mathbf{x}_N, y_N)\\), design a function <code>accuracy(w, x, y)</code> that returns the percentage of correctly classified values.</p> </li> <li> <p>Using this function, provide the accuracy of your solutions on the testing set <code>(x_train, y_train)</code> and on the test set <code>(x_test, y_test)</code>.</p> </li> <li> <p>Optional Question: compare the gradient descent method with the traditional OLS linear regression method.</p> </li> </ul>"},{"location":"material/material/","title":"Setup","text":"<p>Any normal computer with either Linux, Windows of MacOS will do it.</p> <p>What is primarily needed:</p> <ul> <li>Python</li> <li>A Code editor</li> </ul>"},{"location":"material/material/#python","title":"Python","text":"<p>Python can be installed in many different ways (In linux it is for instance most of the time already in the system). Several python (with different versions) can run under the same computer.</p> <p>However the most simple and best advice is to use Anaconda</p> <ol> <li>Step 1: Download Anaconda for your platform</li> <li>Step 2: Install on your computer</li> </ol> Miniconda <p>Anaconda comes with a GUI software to manage the environment and packages with point and click. It also installs a default set of packages such as <code>Jupyther</code>, <code>numpy</code>, etc. If you prefer to install a minimal version and install only the packages you need one after the other you can install Miniconda</p> <p>Anaconda usually comes with a python interpreter called <code>ipython</code> that allows to run code directly from a console or an editor.</p>"},{"location":"material/material/#code-editor","title":"Code Editor","text":"<p>Two write code you only need an editor, however dedicated editors allows you to program more efficiently.</p> <ul> <li>Jupyther Notebook:     Allows you to run on the browser so called notebook where you can input code, text, and run each cell.     Good for pure beginner.</li> <li>VSCode:     Is a multi platform open source editor maintained and released by Microsoft.     It is a great environment for development.     The principle is that it is a basic editor in which you can install so called plugins (mini apps like in wechat or allipay).     Download and install.     Then go to the plugins repository and install the <code>python</code> plugin from Microsoft.</li> </ul> <p>Good practice</p> <p>It is recommended to have a directory in your computer containing your code files (for organization purposes and also because python will run as environment in this directory).</p>"},{"location":"material/material/#installing-additional-libraries","title":"Installing additional libraries","text":"<p>Python can be extended with libraries this is one of the strength of it that will perform tasks for you. Installing a new library can be done in three ways with anaconda:</p> <ol> <li>Use the GUI and search for the library</li> <li>Open a terminal and type <code>conda install &lt;library&gt;</code></li> <li>Open a terminal and use pip with <code>pip install &lt;library&gt;</code></li> </ol> <p>Warning</p> <p>The first and second options are preferable usually. Indeed, libraries have a complex system of inter-dependence and since you are likely using Anaconda, the tool <code>conda</code> will manage the inter-dependence of each packages better. It is however slower.</p>"},{"location":"material/material/#which-libraries","title":"Which libraries","text":"<p>In the lecture we will use quite a lot of libraries and install them on the go. Fundamentally the following ones will be recurrent</p> <ul> <li><code>numpy</code>: multidimensional array library</li> <li><code>pandas</code>: data analysis (tabular) framework </li> <li><code>scipy</code>: scientific library</li> <li><code>pytorch</code>: AI and ML library with tensors</li> <li><code>plotly</code>: Data visualization</li> </ul>"}]}