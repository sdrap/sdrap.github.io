{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\"Workshop: Recent Advances in Stochastic Control, Machine Learning and Quantitative Finance\"","text":"<p>We are excited to announce the upcoming workshop on \"Exploring Frontiers in Stochastic Control, Machine Learning, and Quantitative Finance,\" a collaborative effort by NYU Shanghai, Shanghai Jiao Tong University, and Shanghai Tech University. This event will be hosted at the Shanghai Jiao Tong University's Xuhui campus from April 15 to April 19, 2024.</p> <p>This workshop aims to provide a dynamic forum for deep discussions and presentations on cutting-edge developments in stochastic control, machine learning, and quantitative finance. In the wake of significant advancements in AI, mathematical finance, and stochastic control, our workshop seeks to delve into innovative modeling, analysis, and strategies shaping financial markets.</p> <p>Participants will have the opportunity to engage with recent research findings, share insights, and explore new research avenues. The workshop will feature comprehensive academic presentations alongside dedicated sessions for informal interactions and knowledge exchange.</p> <p>This collaborative initiative also aims to rekindle international partnerships, offering attendees a chance to immerse themselves in the vibrant culture of Shanghai and gain insights into research trends with a focus on Asia and China.</p> <p>The program details and list of speakers is still subject to short term changes. Stay tuned for updates on the Program, Abstracts, and Venue for informations</p> <p>The workshop is open to anyone. If you want to attend feel free to contact (email):</p> <ul> <li>Mathieu Lauri\u00e8re</li> <li>Samuel Drapeau</li> <li>Peng Luo</li> </ul> <ul> <li> <p>Workshop Details:</p> <ul> <li>Dates: April 15-19, 2024</li> <li>Location: Engineering Building, Xuhui Campus, Shanghai Jiao Tong University<ul> <li>Mon-Wed: Room 100</li> <li>Thu-Fri: Room 104</li> </ul> </li> <li>Accommodation: Tianping Hotel-Shanghai</li> </ul> </li> <li> <p>Organizers:</p> <ul> <li>Mathieu Lauri\u00e8re (NYU Shanghai)</li> <li>Peng Luo (Shanghai Jiao Tong University)</li> <li>Chong Liu (Shanghai Tech University)</li> <li>Yiqing Lin (Shanghai Jiao Tong University)</li> <li>Samuel Drapeau (Shanghai Jiao Tong University)</li> <li>Dewen Xiong (Shanghai Jiao Tong University)</li> </ul> </li> </ul>"},{"location":"abstracts/","title":"Abstracts","text":""},{"location":"abstracts/#anchor-andrewallan","title":"Andrew Allan Durham University","text":""},{"location":"abstracts/#rough-stochastic-differential-equations-with-jumps","title":"Rough Stochastic Differential Equations with Jumps","text":"The theory of rough paths provides a framework for the study of nonlinear systems driven by highly oscillatory (deterministic) signals. The corresponding analysis is inherently distinct from that of classical stochastic calculus, and neither theory alone is able to satisfactorily handle hybrid systems driven by both rough and stochastic noise (as sometimes appear, e.g., in stochastic filtering, pathwise stochastic control, and mixed Black-Scholes models). The introduction of the stochastic sewing lemma (Khoa L\u00ea, 2020) has paved the way for a theory which can efficiently handle such hybrid systems. In this talk, we will discuss how this can be done in a general setting which allows for jump discontinuities in both sources of noise. The talk is based on joint work with Jost Pieper."},{"location":"abstracts/#anchor-arielneufeld","title":"Ariel Neufeld Nanyang Technical University","text":""},{"location":"abstracts/#markov-decision-processes-under-model-uncertainty","title":"Markov Decision Processes under Model Uncertainty","text":"In this talk we introduce a general framework for Markov decision problems under model uncertainty in a discrete-time infinite horizon setting. By providing a dynamic programming principle we obtain a local-to-global paradigm, namely solving a local, i.e., a one time-step robust optimization problem leads to an optimizer of the global (i.e. infinite time-steps) robust stochastic optimal control problem, as well as to a corresponding worst-case measure.Moreover, we apply this framework to portfolio optimization involving data of the S&amp;P 500. We present two different types of ambiguity sets; one is fully data-driven given by a Wasserstein-ball around the empirical measure, the second one is described by a parametric set of multivariate normal distributions, where the corresponding uncertainty sets of the parameters are estimated from the data. It turns out that in scenarios where the market is volatile or bearish, the optimal portfolio strategies from the corresponding robust optimization problem outperforms the ones without model uncertainty, showcasing the importance of taking model uncertainty into account. This talk is based on joint work with Julian Sester and Mario Sikic."},{"location":"abstracts/#anchor-brunobouchard","title":"Bruno Bouchard Paris Dauphine University","text":""},{"location":"abstracts/#a-c1-itos-formula-for-flows-of-semimartingale-distributions","title":"A \\(C^1\\)-Ito's Formula for Flows of Semimartingale Distributions","text":"We provide an Ito's formula for \\(C^1\\)-functionals on the flows of conditional marginal distributions of a continuous semimartingale. This is based on the notion of the weak Dirichlet process and extends the \\(C^1\\)-Ito's formula in Gozzi and Russo (2006) to functionals which depend also on marginal distributions of semimartingales. As a first application, we study a class of McKean-Vlasov optimal control problems, and establish a verification theorem by requiring only \\(C^1\\)-regularity of its value function, which is equivalently the (viscosity) solution of the associated HJB master equation. Co-authors: Xiaolu Tan and Jixin Wang, Department of Mathematics, The Chinese University of Hong Kong."},{"location":"abstracts/#anchor-christophczyslowsky","title":"Christoph Czyslowsky London School of Economics","text":""},{"location":"abstracts/#equilibrium-asset-pricing-with-stochastic-investment-opportunities-and-proportional-transaction-costs","title":"Equilibrium Asset Pricing with Stochastic Investment Opportunities and Proportional Transaction Costs","text":"In view of the increasing automatisation of financial markets, understanding the tradeoff between frequent trading and transaction costs becomes more and more important. In this talk, we consider the impact of proportional transaction costs on risk-sharing equilibria between two agents with mean-variance preferences. The state of the economy is modelled by an underlying diffusion process leading to stochastic investment opportunities for the agents. Our model allows us to observe new effects resulting from the interplay between the transaction costs and the stochastic investment opportunities. This includes solving a new two-dimensional free boundary problem rather than the one-dimensional versions that appear in models with constant coefficients. The talk is based on joint work with Justin Gwee and Mihalis Zervos."},{"location":"abstracts/#anchor-davidproemel","title":"David Proemel Mannheim University","text":""},{"location":"abstracts/#well-posedness-of-stochastic-volterra-equations-with-non-lipschitz-coefficients","title":"Well-Posedness of Stochastic Volterra Equations with non-Lipschitz Coefficients","text":"The study of stochastic Volterra equations with non-Lipschitz continuous coefficients has recently attracted quite some attention, motivated by their very successful applications as well-suited volatility models in mathematical finance. While stochastic Volterra equations with Lipschitz continuous coefficients are well-studied integral equations, in the case of less regular coefficients many fundamental questions are still open. In this talk we discuss the existence of strong and weak solutions as well as pathwise uniqueness of stochastic Volterra equations with time-inhomogeneous non-Lipschitz continuous coefficients. The talk is based on joint work with David Scheffels."},{"location":"abstracts/#anchor-fenghuiyu","title":"Fenghui Yu Technical University Delft","text":""},{"location":"abstracts/#execution-probabilities-in-a-limit-order-book-with-state-dependent-order-flows","title":"Execution Probabilities in a Limit Order Book with State-Dependent Order Flows","text":"We delve into the computation of execution probabilities for limit orders positioned at various price levels within the limit order book, a critical aspect in execution optimization. We adopt a generic stochastic model to capture the dynamics of the order book as a series of queueing systems. This generic model is state-dependent and encompasses stylized factors. We subsequently derive semi-analytical expressions to compute the relevant probabilities within the context of state-dependent stochastic order flows. These probabilities cover various scenarios, including the probability of a change in the mid-price, the execution probabilities of orders posted at the best quotes, and those posted at a price level deeper in the book, before the opposite best quote moves. Lastly, we conduct extensive numerical experiments using real order book data from the foreign exchange spot market."},{"location":"abstracts/#anchor-guojingwang","title":"Guojing Wang Soochow University","text":""},{"location":"abstracts/#pricing-cds-index-tranches-under-contagion-model-with-regime-switching","title":"Pricing CDS Index Tranches under Contagion Model with Regime Switching","text":"The contagion credit risk model is usually used to describe the contagion effect among different financial institutions. In this paper, we introduce a default contagion model in which the default process is described by a Cox process with regime switching, and the default intensity process will increase with a positive jump once a considered firm defaults. We derive some closed form expressions for the distribution of default times and for the pricing formulas of the CDS index tranches. Based on market data we present some numerical results for the CDS index tranches. (a joint work with Ms Jiayuan Qian)"},{"location":"abstracts/#anchor-hoiyingwong","title":"Hoi Ying Wong The Chinese University of Hong Kong","text":""},{"location":"abstracts/#robust-dividend-policy-equivalence-of-epstein-zin-and-meanhout-preferences","title":"Robust Dividend Policy: Equivalence of Epstein-Zin and Meanhout Preferences","text":"The classic optimal dividend problem aims to maximize the expected discounted dividend stream over the lifetime of a company. Since dividend payments are irreversible, this problem corresponds to a singular control problem with a risk-neutral utility function applied to the discounted dividend stream. In cases where the company's surplus process encounters model ambiguity under the Brownian filtration, we explore robust dividend payment strategies in worst-case scenarios. Two possible robust preferences are examined and compared. Using Epstein-Zin (EZ) preferences, we formulate the robust dividend problem as a recursive utility function with the EZ aggregator within a singular control framework. We investigate the existence and uniqueness of the EZ dividend problem. By employing Backward Stochastic Differential Equation theory, we demonstrate that the EZ formulation is equivalent to the maximin problem involving risk-neutral utility on the discounted dividend stream, incorporating Meanhout's regularity that reflects investors' ambiguity aversion. In other words, we establish a connection between ambiguity aversion in a robust singular control problem and risk aversion in EZ preferences. Additionally, considering the equivalent Meanhout's preferences, we solve the robust dividend problem using a Hamilton-Jacobi-Bellman approach combined with a variational inequality (VI). Our solution is obtained through a novel shooting method that simultaneously satisfies the VI and boundary conditions. This is a joint work with Kexin Chen and Kyunghyun Park."},{"location":"abstracts/#anchor-jean-pierrefouque","title":"Jean-Pierre Fouque University of California Santa Barbara","text":""},{"location":"abstracts/#reinforcement-learning-for-mean-field-game-and-control-problems","title":"Reinforcement Learning for Mean Field Game and Control Problems","text":"We present our recent results on multi-scale reinforcement learning algorithms for mean field game and mean field control problems in finite state and action spaces. The proof of convergence sheds some light on the difference between MFG and MFC. Joint work with Andrea Angiuli, Mathieu Lauri\u00e8re, and Mengrui Zhang."},{"location":"abstracts/#anchor-jianfengzhang","title":"Jianfeng Zhang University of Southern California","text":""},{"location":"abstracts/#set-values-for-nonzero-sum-games","title":"Set Values for Nonzero Sum Games","text":"Nonzero sum games typically have multiple Nash equilibria, and more importantly, different equilibria may induce different values. In this talk we propose to study the set of values over all possible equilibria, called the set value of games. This set value is by nature unique, and it shares many nice properties of the value function for a standard control problem. In particular, it satisfies the dynamic programming principle and the regularity/stability. We shall also discuss how to characterize the dynamic set value function of games through set valued Hamiltonians and set valued PDEs. The talk is based on a series of works, joint with Feinstein, Iseri, Qiao, and Rudloff."},{"location":"abstracts/#anchor-jingjiezhang","title":"Jingjie Zhang University of International Business and Economics","text":""},{"location":"abstracts/#a-quantitative-comparison-of-unemployment-benefit-extension-and-level-increase","title":"A Quantitative Comparison of Unemployment Benefit Extension and Level Increase","text":"We use mean-field game theory to quantitatively compare two unemployment insurance (UI) extension policies commonly used during recessions: raising benefit levels versus extending the duration of benefits. Our heterogenous-agent model features costly job search and individual savings. Our calibrated model matches the savings distribution observed in the U.S. After requiring that the two UI policies have the same cost, we find: (1) a large, one-time lumpsum payment results in lower unemployment rates relative to a moderate, long-lived increase in benefits and (2) both policies deliver approximately the same ex-ante expected utility to unemployed individuals. (Joint work with Erhan Bayraktar and Indrajit Mitra)"},{"location":"abstracts/#anchor-johannesmuhle-karbe","title":"Johannes Muhle-Karbe Imperial College London","text":""},{"location":"abstracts/#concave-cross-impact","title":"Concave Cross Impact","text":"The price impact of large orders is well known to be a concave function of trade size. We discuss how to extend models consistent with this \u201csquare-root law\u201d to multivariate settings with cross impact, where trading each asset also impacts the prices of the others. In this context, we derive consistency conditions that rule out price manipulation, discuss how cross impact affects optimal trading strategies, and illustrate these results using CFM metaorder data.  (Joint work in progress with Natascha Hey and Iacopo Mastromatteo)"},{"location":"abstracts/#anchor-johanneswiesel","title":"Johannes Wiesel Carnegie Mellon University","text":""},{"location":"abstracts/#empirical-martingale-projections-via-the-adapted-wasserstein-distance","title":"Empirical Martingale Projections via the Adapted Wasserstein Distance","text":"Given a collection of multidimensional pairs \\((Xi,Yi)_{1\\leq i\\leq n}\\), we study the problem of projecting the associated suitably smoothed empirical measure onto the space of martingale couplings (i.e. distributions satisfying \\(\\mathbb{E}[Y|X]=X\\)) using the adapted Wasserstein distance. We call the resulting distance the smoothed empirical martingale projection distance (SE-MPD), for which we obtain an explicit characterization. We also show that the space of martingale couplings remains invariant under the smoothing operation. We study the asymptotic limit of the SE-MPD, which converges at a parametric rate as the sample size increases if the pairs are either i.i.d. or satisfy appropriate mixing assumptions. Additional finite-sample results are also investigated. Using these results, we introduce a novel consistent martingale coupling hypothesis test, which we apply to test the existence of arbitrage opportunities in recently introduced neural network-based generative models for asset pricing calibration."},{"location":"abstracts/#anchor-juanli","title":"Juan Li Shandong University","text":""},{"location":"abstracts/#mean-field-stochastic-control-problems-under-sublinear-expectation","title":"Mean field stochastic control problems under sublinear expectation","text":"In this talk we study Pontryagin's stochastic maximum principle for a mean-field optimal control problem under Peng's \\(G\\)-expectation. The dynamics of the controlled state process is given by a stochastic differential equation driven by a \\(G\\)-Brownian motion, whose coefficients depend not only on the control, the controlled state process but also on its law under the \\(G\\)-expectation. Also the associated cost functional is of mean-field type. Under the assumption of a convex control state space we study the stochastic maximum principle, which gives a necessary optimality condition for control processes. Under additional convexity assumptions on the Hamiltonian it is shown that this necessary condition is also a sufficient one. The main difficulty which we have to overcome in our work consists in the differentiation of the \\(G\\)-expectation of parameterized random variables. Based on a joint work with Rainer Buckdahn (UBO, France), Bowen He (SDU, China)."},{"location":"abstracts/#anchor-julienclaisse","title":"Julien Claisse Paris Dauphine University","text":""},{"location":"abstracts/#mean-field-optimization-regularized-by-fisher-information","title":"Mean-field Optimization Regularized by Fisher Information","text":"Recently there is a rising interest in the research of mean-field optimization, in particular because of its role in analyzing the training of neural networks. In this talk, by adding the Fisher information (in other word, the Schrodinger kinetic energy) as the regularizer, we relate the mean-field optimization problem with a so-called mean field Schrodinger (MFS) dynamics. We develop a free energy method to show that the marginal distributions of the MFS dynamics converge exponentially quickly towards the unique minimizer of the regularized optimization problem. We shall see that the MFS is a gradient flow on the probability measure space with respect to the relative entropy. Finally we propose a Monte Carlo method to sample the marginal distributions of the MFS dynamics. This is a joint work with Giovanni Conforti, Zhenjie Ren and Songbo Wang."},{"location":"abstracts/#anchor-lanwu","title":"Lan Wu Peking University","text":""},{"location":"abstracts/#tba","title":"TBA","text":"TBA"},{"location":"abstracts/#anchor-martinschweizer","title":"Martin Schweizer ETH Zurich","text":""},{"location":"abstracts/#a-stochastic-fubini-theorem-via-measure-valued-integrands","title":"A Stochastic Fubini Theorem via Measure-Valued Integrands","text":"We present a new stochastic Fubini theorem in a setting where the stochastic Fubini property is obtained in a weak sense. This involves defining a stochastic integral, with respect to a fixed semimartingale, of measure-valued integrand processes. Potential applications will perhaps be mentioned."},{"location":"abstracts/#anchor-mathieurosenbaum","title":"Mathieu Rosenbaum Ecole Polytechnique","text":""},{"location":"abstracts/#the-two-square-root-laws-of-market-impact-and-the-role-of-sophisticated-market-participants","title":"The Two Square Root Laws of Market Impact and the Role of Sophisticated Market Participants","text":"The goal of this work is to disentangle the roles of volume and participation rate in the price response of the market to a sequence of orders. To do so, we use an approach where price dynamics are derived from the order flow via no arbitrage constraints and make connections with the rough volatility paradigm. We also introduce in the model sophisticated market participants having superior abilities to analyse market dynamics. Our results lead to two square root laws of market impact, with respect to executed volume and with respect to participation rate. This is joint work with Bruno Durin and Gr\u00e9goire Szymanski."},{"location":"abstracts/#anchor-michaelkupper","title":"Michael Kupper University of Konstanz","text":""},{"location":"abstracts/#discrete-approximation-of-risk-based-pricing-under-uncertainty","title":"Discrete Approximation of Risk-Based Pricing under Uncertainty","text":"TBA"},{"location":"abstracts/#anchor-mindai","title":"Min Dai The Hong Kong Polytechnic University","text":""},{"location":"abstracts/#learning-optimal-investment-strategy-with-transaction-costs-via-a-randomized-dynkin-game","title":"Learning Optimal Investment Strategy with Transaction Costs via a Randomized Dynkin Game","text":"We develop a reinforcement learning method to learn optimal investment strategy in the presence of transaction costs. Using a connection between singular control and a Dynkin game for portfolio choice with transaction costs, we design a reinforcement learning algorithm to learn the optimal strategy through a related randomized Dynkin game, where a regularization term is incorporated to encourage exploration. Numerical results are presented to demonstrate our algorithm."},{"location":"abstracts/#anchor-nizartouzi","title":"Nizar Touzi New York University","text":""},{"location":"abstracts/#mean-field-games-approach-to-systemic-risk","title":"Mean Field Games Approach to Systemic Risk","text":"Connections between economic agents are desirable for risk diversification purposes. However, they may also be responsible for default contagion, a major concern at the heart of the financial stability of the system. We develop a model of system connection based on the strategic interaction between economic agents. We solve explicitly the mean field limit of the problem in the case of uncorrelated idiosyncratic risks, and we provide a quasi explicit solution of the mean field game. This allows to provide an approximate Nash equilibrium for the finite population problem. We also solve the case of correlated idiosyncratic risk through some common factor by analyzing an appropriate notion of no arbitrage in this context."},{"location":"abstracts/#anchor-paologuasoni","title":"Paolo Guasoni Dublin City University","text":""},{"location":"abstracts/#evaluating-and-mitigating-transaction-costs-with-recurrent-neural-networks","title":"Evaluating and Mitigating Transaction Costs with Recurrent Neural Networks","text":"We develop a method for evaluating and mitigating the effect of transaction costs on trading strategies with many assets. An iteration procedure yields cost-adjusted portfolio returns, enabling the formulation of portfolio-choice problems as optimization of Recurrent Neural Networks (RNN). This method reproduces the theoretical results available for one risky asset and the numerical approximations available for two risky assets through finite-elements. Crucially, the RNN model scales to several assets and is fully interpretable, as its parameters identify their no-trade region. Importance-sampling significantly enhances the model\u2019s performance, especially with several assets. An application to equally-weighted funds demonstrates the method's ability to reduce both tracking error and tracking difference from an empirical target. (Joint work with Ran Li.)"},{"location":"abstracts/#anchor-pingli","title":"Ping Li Beihang University","text":""},{"location":"abstracts/#tba_1","title":"TBA","text":"TBA"},{"location":"abstracts/#anchor-ruixunzhang","title":"Ruixun Zhang Peking University","text":""},{"location":"abstracts/#on-consistency-of-signatures-using-lasso-and-applications-in-option-pricing","title":"On Consistency of Signatures Using Lasso and Applications in Option Pricing","text":"Signature transforms are iterated path integrals of continuous and discrete-time time series data, and their universal nonlinearity linearizes the problem of feature selection. This paper revisits some statistical properties of signature transform under stochastic integrals with a Lasso regression framework, both theoretically and numerically. Our study shows that, for processes and time series that are closer to Brownian motion or random walk with weaker inter-dimensional correlations, the Lasso regression is more consistent for their signatures defined by Ito integrals; for mean reverting processes and time series, their signatures defined by Stratonovich integrals have more consistency in the Lasso regression. We apply these results to learning nonlinear functions and option pricing. Our findings highlight the importance of choosing appropriate definitions of signatures and stochastic models in statistical inference and machine learning. This is joint work with Xin Guo, Binnan Wang, and Chaoyi Zhao."},{"location":"abstracts/#anchor-sizhouwu","title":"Sizhou Wu Nanyang Technical University","text":""},{"location":"abstracts/#tba_2","title":"TBA","text":"TBA"},{"location":"abstracts/#anchor-tianyangnie","title":"Tianyang Nie Shandong University","text":""},{"location":"abstracts/#indefinite-partially-observed-lq-mean-field-game","title":"Indefinite partially observed \\(LQ\\) mean-field game","text":"We investigate an indefinite linear-quadratic partially observed mean-field game with common noise, where both the state-average and control-average are considered. All weighting matrices in the cost functional can be indefinite. We obtain the decentralized optimal strategies by the Hamiltonian approach and demonstrate the well-posedness of Hamiltonian system by virtue of relaxed compensator. The related Consistency Condition and the feedback form of decentralized optimal strategies are derived. Moreover, we prove that the decentralized optimal strategies are \\(\\varepsilon\\)-Nash equilibrium by using the relaxed compensator. The talk is based on the joint work with Dr, Tian Chen and Prof. Zhen Wu."},{"location":"abstracts/#anchor-xiangyu","title":"Xiang Yu The Hong Kong Polytechnic University","text":""},{"location":"abstracts/#continuous-time-q-learning-for-mean-field-control-problems","title":"Continuous time \\(q\\)-learning for mean-field control problems","text":"In this talk, we study \\(q\\)-learning, recently coined as the continuous time counterpart of \\(Q\\)-learning by Jia and Zhou (2023), for mean-field control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2023), the mean-field interaction of agents renders the definition of the q-function more subtle, for which we reveal that two distinct \\(q\\)-functions naturally arise: (i) the integrated q-function as the first-order approximation of the integrated \\(Q\\)-function introduced in Gu, Guo, Wei and Xu (2023), which can be learnt by a weak martingale condition involving test policies; and (ii) the essential q-function that is employed in policy improvement iterations. We show that two \\(q\\)-functions are related via an integral representation under all test policies. Based on the weak martingale condition and our proposed searching method of test policies, some model-free learning algorithms are devised. In two financial application examples, one in \\(LQ\\) control framework and one beyond \\(LQ\\) control framework, we can obtain the exact parameterization of the optimal value function and \\(q\\)-functions and illustrate our algorithms with simulation experiments. This is a joint work with Xiaoli Wei (Harbin Institute of Technology)."},{"location":"abstracts/#anchor-xianhuapeng","title":"Xianhua Peng Peking University","text":""},{"location":"abstracts/#tba_3","title":"TBA","text":"TBA"},{"location":"abstracts/#anchor-xiaoliwei","title":"Xiaoli Wei Harbin Institute of Technology","text":""},{"location":"abstracts/#continuous-time-q-learning-for-mean-field-control-problems-with-common-noise","title":"Continuous-Time \\(q\\)-Learning for Mean-Field Control Problems with Common Noise","text":"This paper investigates the continuous-time entropy-regularized reinforcement learning (RL) for mean-field control problems with common noise. We study the continuous-time counterpart of the \\(Q\\)-function in the mean-field model, coined as \\(q\\)-function in Jia and Zhou (2023) in the single agents model. It is shown that the controlled common noise gives rise to a nonlocal term of the policy in the exploratory HJB equation, rendering the policy improvement iteration intricate. To devise the model-free RL algorithm, we introduce the integrated \\(q\\)-function (\\(Iq\\)-function) on distributions of both state and action, and an optimal policy can be identified as a two-layer fixed point to the argmax operator of the Iq-function. The martingale characterization of the value function and \\(Iq\\)-function is established by exhausting all test policies. This allows us to propose several algorithms including the Actor-Critic learning algorithm, in which the policy is updated in the Actor-step based on the policy improvement rule induced by the linear derivative of the Iq-function with respect to the action distribution, and the value function and Iq-function are updated in the Critic-step based on the orthogonal martingale loss function involving all test policies. In two examples, within and beyond LQ-control framework, we implement and compare some simulation experiments of our RL algorithms with satisfactory performance. This a joint work with Zhenjie Ren, Xiang Yu and Xunyu Zhou"},{"location":"abstracts/#anchor-xiaolutan","title":"Xiaolu Tan The Chinese University of Hong Kong","text":""},{"location":"abstracts/#on-the-regularity-of-solutions-of-some-linear-parabolic-path-dependent-pdes","title":"On the Regularity of Solutions of some Linear Parabolic Path-Dependent PDEs","text":"We study a class of linear parabolic path-dependent PDEs (PPDEs) defined on the space of c\u00e0dl\u00e0g paths \\(x\\), in which the coefficient functions at time \\(t\\) depend on \\(x(t)\\) and \\(\\int_0^t x(s) dA_s\\), for some (deterministic) continuous function \\(A\\) with bounded variations. Under uniform ellipticity and H\u00f6lder regularity conditions on the coefficients, together with some technical conditions on \\(A\\), we obtain the existence of a smooth solution to the PPDE by appealing to the notion of Dupire's derivatives. It provides a generalization to the existing literature studying the case where \\(A_t = t\\), and complements our previous work on the regularity of approximate viscosity solutions for parabolic PPDEs. As a by-product, we also obtain existence and uniqueness of weak solutions for a class of path-dependent SDEs. This is a joint work with Bruno Bouchard."},{"location":"abstracts/#anchor-xinguo","title":"Xin Guo Berkeley University","text":""},{"location":"abstracts/#alpha-potential-games-a-new-paradigm-for-n-player-games","title":"Alpha Potential Games: A New Paradigm for N-Player Games","text":"Static potential games, pioneered by Monderer and Shapley (1996) are non-cooperative static games in which there exists an auxiliary function called static potential function, so that any player's change in utility function upon unilaterally deviating from her policy can be evaluated through the change in the value of this potential function. The introduction of the potential function is powerful as it simplifies  the otherwise challenging task of searching for Nash equilibria in  multi-agent non-cooperative games:  maximizers of potential functions lead to the game's Nash equilibria. In this talk, we propose an analogous and new framework called \\(\\alpha\\)-potential game for  dynamic \\(N\\)-Player games, with the potential function in the static setting replaced by an  \\(\\alpha\\)-potential function. We will present the analytical criteria for any game to be an \\(\\alpha\\)-potential game, and identify several important classes of Markov \\(\\alpha\\)-potential games.   We will provide detailed analysis for games with mean-field interactions, distributed games, and  crowd aversion games, in which \\(\\alpha\\) is shown to depend on the number of players, the admissible policies, and the cost structure. We will also show the changes of  \\(\\alpha\\) from open-loop to closed-loop settings."},{"location":"abstracts/#anchor-xingyeyue","title":"Xingye Yue Soochow University","text":""},{"location":"abstracts/#trinomial-tree-method-for-g-expectation-and-sampling-for-g-normal-random-variable-after-measurement","title":"Trinomial tree method for \\(G\\)-Expectation and sampling for \\(G\\)-normal random variable after Measurement","text":"Given a \\(1\\)-Dimensional \\(G\\)-normal random variable (RV) \\(X\\), a trinomial tree method is proposed to approximate the \\(G\\)-Expectation \\(E[\\phi(X)]\\) for any test function. The method is stable and convergent. There is no need to worry about the boundary condition. Furthermore, the whole numerical process actually yields the samples to estimate the expectation \\(E[\\phi(X)]\\). As we know, direct sampling for a \\(G\\)-normal RV \\(X\\) is infeasible due to the uncertainty of its distribution. But for a \u201cmeasurement\u201d \\(E[\\phi(X)]\\), the sampling is feasible. This is just like an measurement on quantum state: before measurement, the state is uncertain and unknown, after measurement, the state is definite."},{"location":"abstracts/#anchor-yanzeng","title":"Yan Zeng Sun Yat-sen University","text":""},{"location":"abstracts/#the-impact-of-intermediaries-on-insurance-demand-and-pricing","title":"The Impact of Intermediaries on Insurance Demand and Pricing","text":"This paper studies the impact of an independent insurance intermediary who holds a fiduciary duty to an unsophisticated insurance buyer on insurance demand and pricing. The intermediary utilizes two remuneration systems, namely, a fee-for-advice system and a commission system. Insurance contracting between the buyer (represented by the intermediary) and an insurer, is formulated as a Stackelberg insurance game. We obtain the buyer\u2019s equilibrium indemnity and the insurer\u2019s equilibrium pricing strategy in closed forms, and subsequently conduct comparative statics analysis with respect to the intermediary\u2019s level of fiduciary duty and remuneration. Our results show that the phenomenon of over-insuring despite high premium, a long-standing paradox in insurance economics, also attributes to the deficiency of the intermediary\u2019s fiduciary duty."},{"location":"abstracts/#anchor-yufeizhang","title":"Yufei Zhang Imperial College London","text":""},{"location":"abstracts/#some-recent-progress-in-continuous-time-reinforcement-learning","title":"Some Recent Progress in Continuous-Time Reinforcement Learning","text":"Recently, reinforcement learning (RL) has attracted substantial research interests. Much of the attention and success, however, has been for the discrete-time setting. Continuous-time RL, despite its natural analytical connection to stochastic controls, has been largely unexplored and with limited progress. In particular, characterising sample efficiency for continuous-time RL algorithms remains a challenging and open problem. In this talk, we will discuss some recent advances in the convergence rate analysis for the episodic linear-convex RL problem, and report regret bounds of various learning algorithms.  The approach is probabilistic, involving analysing learning efficiency using concentration inequalities for correlated observations, and quantifying the performance of feedback controls derived from estimated models. The latter is achieved via the stability of the associated forward-backward stochastic differential equation."},{"location":"abstracts/#anchor-yufengshi","title":"Yufeng Shi Shandong University","text":""},{"location":"abstracts/#deep-learning-approaches-in-numerical-computation-of-backward-stochastic-differential-equation-and-applications-in-financial-asset-pricing","title":"Deep learning approaches in numerical computation of backward stochastic differential equation and applications in financial asset pricing","text":"Deep learning can effectively overcome dimensional disasters in the numerical methods of Nonlinear partial differential equation and backward Stochastic differential equation, and has become an important research direction of numerical computation in recent years. We study the numerical calculation methods of high-dimensional backward doubly stochastic differential equations and high-dimensional mean field backward doubly stochastic differential equations, in which the deep neural network is introduced as the key step to achieve numerical solution. Based on the numerical method of backward Stochastic differential equation, this paper studies the option data driven g-pricing modeling method, and verifies the model performance with SPX options. At the same time, with the help of deep learning data mining capabilities, a model for mining high-frequency order book price change information was established, and empirical research was conducted using high-frequency order book data."},{"location":"abstracts/#anchor-zhenjieren","title":"Zhenjie Ren Paris Dauphine University","text":""},{"location":"abstracts/#self-interacting-approximation-to-mckean-vlasov-long-time-limit","title":"Self-Interacting Approximation to McKean-Vlasov Long Time Limit","text":"Motivated by the mean-field optimization model of the training of two-layer neural networks, we propose a novel method to approximate the invariant measures of a class of McKean-Vlasov diffusions. We introduce a proxy process that substitutes the mean-field interaction with self-interaction through a weighted occupation measure of the particle's past. If the McKean-Vlasov diffusion is the gradient flow of a convex mean-field potential functional, we show that the self-interacting process exponentially converges towards its unique invariant measure close to that of the McKean-Vlasov diffusion. As an application, we show how to learn the optimal weights of a two-layer neural network by training a single neuron."},{"location":"abstracts/#anchor-zhenyaliu","title":"Zhenya Liu Renmin University of China","text":""},{"location":"abstracts/#when-will-chinas-economy-overtake-the-united-states","title":"When will China\u2019s economy overtake the United States?","text":"The uncertainty of the world economy is increasing due to various kinds of shocks. As the two largest economies in the world, the United States and China, their competition and power transition will impact the international economic order. We have constructed stochastic process models to predict the GDP paths of both countries. Based on historical data into the future, we estimate the model's parameters and predict when China's GDP will surpass that of the United States based on the first passage time theory. We have used the change point detection method to handle different economic situations. The changes in our model parameters provide valuable economic information, and our predictions become more reliable once we have considered the change point."},{"location":"abstracts/#anchor-zihaogu","title":"Zihao Gu Shanghai Jiao Tong University","text":""},{"location":"abstracts/#quadratic-bsdes-with-mean-reflection-driven-by-g-brownian-motion","title":"Quadratic BSDEs with mean reflection driven by G-Brownian motion","text":"In this talk, we present the well-posedness of a kind of backward stochastic differential equation driven by G-Brownian motions (G-BSDEs for short) with mean reflection. In particular, the generator is allowed having quadratic growth in z. Combining a representation of the solution with G-BMO martingale techniques, fixed point argument, and \u03b8-method, existence and uniqueness results for such G-BSDEs are provided under bounded and unbounded terminal condition. In addition, the mean constraint can be generalized to a risk constraint for financial application. This is a joint work with Yiqing Lin and Kun Xu."},{"location":"abstracts/#anchor-zitengcheng","title":"Ziteng Cheng University of Toronto","text":""},{"location":"abstracts/#deep-learning-conditional-distributions-on-continuous-spaces","title":"Deep Learning Conditional Distributions on Continuous Spaces","text":"We investigate sample-based learning of conditional distributions on multi-dimensional unit boxes, allowing for different dimensions of the input and output spaces. Our approach leverages grouping data in proximity to varying query points, employing two distinct methods: one based on a fixed-radius ball and the other on nearest neighbors. We establish upper bounds for the convergence rates of both methods and, from these bounds, deduce optimal configurations for the radius and the number of neighbors. To obtain a Lipschitz continuous estimator of the conditional distribution for enhanced certifiability, we incorporate the nearest neighbor method into neural network training. For improved efficiency, the training process utilizes approximate nearest neighbor search with random binary space partitioning. Additionally, it employs Sinkhorn algorithm and sparsity-enforced transport plan for training objective computation. Our empirical findings reveal that, with a suitably designed structure, the neural network displays adaptive continuity. This is joint work with Cyril Benezet (ENSIIE) and Sebastian Jaimungal (University of Toronto)."},{"location":"abstracts/#anchor-zuoquanxu","title":"Zuoquan Xu The Hong Kong Polytechnic University","text":""},{"location":"abstracts/#state-dependent-temperature-control-for-langevin-diffusions","title":"State-dependent temperature control for Langevin diffusions","text":"We study the temperature control problem for Langevin diffusions in the context of non-convex optimization. The classical optimal control of such a problem is of the bang-bang type, which is overly sensitive to errors. A remedy is to allow the diffusions to explore other temperature values and hence smooth out the bang-bang control. We accomplish this by a stochastic relaxed control formulation incorporating randomization of the temperature control and regularizing its entropy. We derive a state-dependent, truncated exponential distribution, which can be used to sample temperatures in a Langevin algorithm, in terms of the solution to an HJB partial differential equation. We carry out a numerical experiment on a one- dimensional baseline example, in which the HJB equation can be easily solved, to compare the performance of the algorithm with three other available algorithms in search of a global optimum. This is a joint work with Xuefeng Gao (The Chinese University of Hong Kong) and Xun Yu Zhou (Columbia University)."},{"location":"program/","title":"Lecture","text":"<p>On Sunday April 14th from 14:00 to 16:00, Professor Peng Shige from Shandong University will give a lecture</p> <ul> <li>Time: 14:30 \u2014 16:00</li> <li>Place: Shanghai Jiao Tong University, Minhang Campus</li> <li>Room: Room 300, Nr. 5&amp;6 Science Building</li> </ul>"},{"location":"program/#workshop","title":"Workshop","text":"<p>The Workshop takes place at the Shanghai Jiao Tong University, Xuhui campus:</p> <ul> <li>Place: Xuhui Campus, Engineering Building (\u5de5\u7a0b\u9986)</li> <li>Room:<ul> <li>Mon-Wed: Room 100</li> <li>Thu-Fri: Room 104</li> </ul> </li> </ul> Mon 15Tue 16Wed 17Thu 18Fri 19 Time Speaker Title 08:15 Registration 08:45 Opening 09:00 Xin Guo Alpha Potential Games: A New Paradigm for N-Player Games 09:45 Paolo Guasoni Evaluating and Mitigating Transaction Costs with Recurrent Neural Networks 10:30 Tea/Coffee break 11:00 Jianfeng Zhang Set Values for Nonzero Sum Games 11:45 Ruixun Zhang On Consistency of Signatures Using Lasso and Applications in Option Pricing 12:30 Lunch 14:00 Min Dai Learning Optimal Investment Strategy with Transaction Costs via a Randomized Dynkin Game 14:45 Zuoquan Xu State-dependent temperature control for Langevin diffusions 15:30 Tea/Coffee break 16:00 Juan Li Mean field stochastic control problems under sublinear expectation 16:45 Xiang Yu Continuous time \\(q\\)-learning for mean-field control problems 18:30 Conference dinner Time Speaker Title 09:00 Nizar Touzi Mean Field Games Approach to Systemic Risk 09:45 Lan Wu TBA 10:30 Tea/Coffee break 11:00 Mathieu Rosenbaum The Two Square Root Laws of Market Impact and the Role of Sophisticated Market Participants 11:45 Ping Li TBA 12:30 Lunch 14:00 Johannes Muhle-Karbe Concave Cross Impact 14:45 Yufeng Shi Deep learning approaches in numerical computation of backward stochastic differential equation and applications in financial asset pricing 15:30 Tea/Coffee break 16:00 David Proemel Well-Posedness of Stochastic Volterra Equations with non-Lipschitz Coefficients 16:45 Johannes Wiesel Empirical Martingale Projections via the Adapted Wasserstein Distance 17:15 Jingjie Zhang A Quantitative Comparison of Unemployment Benefit Extension and Level Increase Time Speaker Title 09:00 Bruno Bouchard A \\(C^1\\)-Ito's Formula for Flows of Semimartingale Distributions 09:45 Xianhua Peng TBA 10:30 Tea/Coffee break 11:00 Zhenya Liu When will China\u2019s economy overtake the United States? 11:45 Jean-Pierre Fouque Reinforcement Learning for Mean Field Game and Control Problems 12:30 Lunch 14:00 Michael Kupper Discrete Approximation of Risk-Based Pricing under Uncertainty 14:45 Xingye Yue Trinomial tree method for \\(G\\)-Expectation and sampling for \\(G\\)-normal random variable after Measurement 15:30 Tea/Coffee break 16:00 Christoph Czyslowsky Equilibrium Asset Pricing with Stochastic Investment Opportunities and Proportional Transaction Costs 16:45 Ziteng Cheng Deep Learning Conditional Distributions on Continuous Spaces 17:15 Xiaoli Wei Continuous-Time \\(q\\)-Learning for Mean-Field Control Problems with Common Noise Time Speaker Title 09:00 Martin Schweizer A Stochastic Fubini Theorem via Measure-Valued Integrands 09:45 Hoi Ying Wong Robust Dividend Policy: Equivalence of Epstein-Zin and Meanhout Preferences 10:30 Tea/Coffee break 11:00 Xiaolu Tan On the Regularity of Solutions of some Linear Parabolic Path-Dependent PDEs 11:45 Guojing Wang Pricing CDS Index Tranches under Contagion Model with Regime Switching 12:30 Lunch 14:00 Ariel Neufeld Markov Decision Processes under Model Uncertainty 14:45 Zhenjie Ren Self-Interacting Approximation to McKean-Vlasov Long Time Limit 15:15 Julien Claisse Mean-field Optimization Regularized by Fisher Information 15:45 Afternoon break Time Speaker Title 09:00 Yan Zeng The Impact of Intermediaries on Insurance Demand and Pricing 09:45 Tianyang Nie Indefinite partially observed \\(LQ\\) mean-field game 10:30 Tea/Coffee break 11:00 Yufei Zhang Some Recent Progress in Continuous-Time Reinforcement Learning 11:30 Fenghui Yu Execution Probabilities in a Limit Order Book with State-Dependent Order Flows 12:00 Andrew Allan Rough Stochastic Differential Equations with Jumps 12:30 Lunch 14:00 Sizhou Wu TBA 14:30 Zihao Gu Quadratic BSDEs with mean reflection driven by G-Brownian motion"},{"location":"program/#speakers","title":"Speakers","text":"<ul> <li> <p>Andrew Allan Durham University (1)</p> <ol> <li> <p>\"Rough Stochastic Differential Equations with Jumps\"</p> <p>The theory of rough paths provides a framework for the study of nonlinear systems driven by highly oscillatory (deterministic) signals. The corresponding analysis is inherently distinct from that of classical stochastic calculus, and neither theory alone is able to satisfactorily handle hybrid systems driven by both rough and stochastic noise (as sometimes appear, e.g., in stochastic filtering, pathwise stochastic control, and mixed Black-Scholes models). The introduction of the stochastic sewing lemma (Khoa L\u00ea, 2020) has paved the way for a theory which can efficiently handle such hybrid systems. In this talk, we will discuss how this can be done in a general setting which allows for jump discontinuities in both sources of noise. The talk is based on joint work with Jost Pieper.</p> </li> </ol> </li> <li> <p>Ariel Neufeld Nanyang Technical University (1)</p> <ol> <li> <p>\"Markov Decision Processes under Model Uncertainty\"</p> <p>In this talk we introduce a general framework for Markov decision problems under model uncertainty in a discrete-time infinite horizon setting. By providing a dynamic programming principle we obtain a local-to-global paradigm, namely solving a local, i.e., a one time-step robust optimization problem leads to an optimizer of the global (i.e. infinite time-steps) robust stochastic optimal control problem, as well as to a corresponding worst-case measure.Moreover, we apply this framework to portfolio optimization involving data of the S&amp;P 500. We present two different types of ambiguity sets; one is fully data-driven given by a Wasserstein-ball around the empirical measure, the second one is described by a parametric set of multivariate normal distributions, where the corresponding uncertainty sets of the parameters are estimated from the data. It turns out that in scenarios where the market is volatile or bearish, the optimal portfolio strategies from the corresponding robust optimization problem outperforms the ones without model uncertainty, showcasing the importance of taking model uncertainty into account. This talk is based on joint work with Julian Sester and Mario Sikic.</p> </li> </ol> </li> <li> <p>Bruno Bouchard Paris Dauphine University (1)</p> <ol> <li> <p>\"A \\(C^1\\)-Ito's Formula for Flows of Semimartingale Distributions\"</p> <p>We provide an Ito's formula for \\(C^1\\)-functionals on the flows of conditional marginal distributions of a continuous semimartingale. This is based on the notion of the weak Dirichlet process and extends the \\(C^1\\)-Ito's formula in Gozzi and Russo (2006) to functionals which depend also on marginal distributions of semimartingales. As a first application, we study a class of McKean-Vlasov optimal control problems, and establish a verification theorem by requiring only \\(C^1\\)-regularity of its value function, which is equivalently the (viscosity) solution of the associated HJB master equation. Co-authors: Xiaolu Tan and Jixin Wang, Department of Mathematics, The Chinese University of Hong Kong.</p> </li> </ol> </li> <li> <p>Christoph Czyslowsky London School of Economics (1)</p> <ol> <li> <p>\"Equilibrium Asset Pricing with Stochastic Investment Opportunities and Proportional Transaction Costs\"</p> <p>In view of the increasing automatisation of financial markets, understanding the tradeoff between frequent trading and transaction costs becomes more and more important. In this talk, we consider the impact of proportional transaction costs on risk-sharing equilibria between two agents with mean-variance preferences. The state of the economy is modelled by an underlying diffusion process leading to stochastic investment opportunities for the agents. Our model allows us to observe new effects resulting from the interplay between the transaction costs and the stochastic investment opportunities. This includes solving a new two-dimensional free boundary problem rather than the one-dimensional versions that appear in models with constant coefficients. The talk is based on joint work with Justin Gwee and Mihalis Zervos.</p> </li> </ol> </li> <li> <p>David Proemel Mannheim University (1)</p> <ol> <li> <p>\"Well-Posedness of Stochastic Volterra Equations with non-Lipschitz Coefficients\"</p> <p>The study of stochastic Volterra equations with non-Lipschitz continuous coefficients has recently attracted quite some attention, motivated by their very successful applications as well-suited volatility models in mathematical finance. While stochastic Volterra equations with Lipschitz continuous coefficients are well-studied integral equations, in the case of less regular coefficients many fundamental questions are still open. In this talk we discuss the existence of strong and weak solutions as well as pathwise uniqueness of stochastic Volterra equations with time-inhomogeneous non-Lipschitz continuous coefficients. The talk is based on joint work with David Scheffels.</p> </li> </ol> </li> <li> <p>Fenghui Yu Technical University Delft (1)</p> <ol> <li> <p>\"Execution Probabilities in a Limit Order Book with State-Dependent Order Flows\"</p> <p>We delve into the computation of execution probabilities for limit orders positioned at various price levels within the limit order book, a critical aspect in execution optimization. We adopt a generic stochastic model to capture the dynamics of the order book as a series of queueing systems. This generic model is state-dependent and encompasses stylized factors. We subsequently derive semi-analytical expressions to compute the relevant probabilities within the context of state-dependent stochastic order flows. These probabilities cover various scenarios, including the probability of a change in the mid-price, the execution probabilities of orders posted at the best quotes, and those posted at a price level deeper in the book, before the opposite best quote moves. Lastly, we conduct extensive numerical experiments using real order book data from the foreign exchange spot market.</p> </li> </ol> </li> <li> <p>Guojing Wang Soochow University (1)</p> <ol> <li> <p>\"Pricing CDS Index Tranches under Contagion Model with Regime Switching\"</p> <p>The contagion credit risk model is usually used to describe the contagion effect among different financial institutions. In this paper, we introduce a default contagion model in which the default process is described by a Cox process with regime switching, and the default intensity process will increase with a positive jump once a considered firm defaults. We derive some closed form expressions for the distribution of default times and for the pricing formulas of the CDS index tranches. Based on market data we present some numerical results for the CDS index tranches. (a joint work with Ms Jiayuan Qian)</p> </li> </ol> </li> <li> <p>Hoi Ying Wong The Chinese University of Hong Kong (1)</p> <ol> <li> <p>\"Robust Dividend Policy: Equivalence of Epstein-Zin and Meanhout Preferences\"</p> <p>The classic optimal dividend problem aims to maximize the expected discounted dividend stream over the lifetime of a company. Since dividend payments are irreversible, this problem corresponds to a singular control problem with a risk-neutral utility function applied to the discounted dividend stream. In cases where the company's surplus process encounters model ambiguity under the Brownian filtration, we explore robust dividend payment strategies in worst-case scenarios. Two possible robust preferences are examined and compared. Using Epstein-Zin (EZ) preferences, we formulate the robust dividend problem as a recursive utility function with the EZ aggregator within a singular control framework. We investigate the existence and uniqueness of the EZ dividend problem. By employing Backward Stochastic Differential Equation theory, we demonstrate that the EZ formulation is equivalent to the maximin problem involving risk-neutral utility on the discounted dividend stream, incorporating Meanhout's regularity that reflects investors' ambiguity aversion. In other words, we establish a connection between ambiguity aversion in a robust singular control problem and risk aversion in EZ preferences. Additionally, considering the equivalent Meanhout's preferences, we solve the robust dividend problem using a Hamilton-Jacobi-Bellman approach combined with a variational inequality (VI). Our solution is obtained through a novel shooting method that simultaneously satisfies the VI and boundary conditions. This is a joint work with Kexin Chen and Kyunghyun Park.</p> </li> </ol> </li> <li> <p>Jean-Pierre Fouque University of California Santa Barbara (1)</p> <ol> <li> <p>\"Reinforcement Learning for Mean Field Game and Control Problems\"</p> <p>We present our recent results on multi-scale reinforcement learning algorithms for mean field game and mean field control problems in finite state and action spaces. The proof of convergence sheds some light on the difference between MFG and MFC. Joint work with Andrea Angiuli, Mathieu Lauri\u00e8re, and Mengrui Zhang.</p> </li> </ol> </li> <li> <p>Jianfeng Zhang University of Southern California (1)</p> <ol> <li> <p>\"Set Values for Nonzero Sum Games\"</p> <p>Nonzero sum games typically have multiple Nash equilibria, and more importantly, different equilibria may induce different values. In this talk we propose to study the set of values over all possible equilibria, called the set value of games. This set value is by nature unique, and it shares many nice properties of the value function for a standard control problem. In particular, it satisfies the dynamic programming principle and the regularity/stability. We shall also discuss how to characterize the dynamic set value function of games through set valued Hamiltonians and set valued PDEs. The talk is based on a series of works, joint with Feinstein, Iseri, Qiao, and Rudloff.</p> </li> </ol> </li> <li> <p>Jingjie Zhang University of International Business and Economics (1)</p> <ol> <li> <p>\"A Quantitative Comparison of Unemployment Benefit Extension and Level Increase\"</p> <p>We use mean-field game theory to quantitatively compare two unemployment insurance (UI) extension policies commonly used during recessions: raising benefit levels versus extending the duration of benefits. Our heterogenous-agent model features costly job search and individual savings. Our calibrated model matches the savings distribution observed in the U.S. After requiring that the two UI policies have the same cost, we find: (1) a large, one-time lumpsum payment results in lower unemployment rates relative to a moderate, long-lived increase in benefits and (2) both policies deliver approximately the same ex-ante expected utility to unemployed individuals. (Joint work with Erhan Bayraktar and Indrajit Mitra)</p> </li> </ol> </li> <li> <p>Johannes Muhle-Karbe Imperial College London (1)</p> <ol> <li> <p>\"Concave Cross Impact\"</p> <p>The price impact of large orders is well known to be a concave function of trade size. We discuss how to extend models consistent with this \u201csquare-root law\u201d to multivariate settings with cross impact, where trading each asset also impacts the prices of the others. In this context, we derive consistency conditions that rule out price manipulation, discuss how cross impact affects optimal trading strategies, and illustrate these results using CFM metaorder data.  (Joint work in progress with Natascha Hey and Iacopo Mastromatteo)</p> </li> </ol> </li> <li> <p>Johannes Wiesel Carnegie Mellon University (1)</p> <ol> <li> <p>\"Empirical Martingale Projections via the Adapted Wasserstein Distance\"</p> <p>Given a collection of multidimensional pairs \\((Xi,Yi)_{1\\leq i\\leq n}\\), we study the problem of projecting the associated suitably smoothed empirical measure onto the space of martingale couplings (i.e. distributions satisfying \\(\\mathbb{E}[Y|X]=X\\)) using the adapted Wasserstein distance. We call the resulting distance the smoothed empirical martingale projection distance (SE-MPD), for which we obtain an explicit characterization. We also show that the space of martingale couplings remains invariant under the smoothing operation. We study the asymptotic limit of the SE-MPD, which converges at a parametric rate as the sample size increases if the pairs are either i.i.d. or satisfy appropriate mixing assumptions. Additional finite-sample results are also investigated. Using these results, we introduce a novel consistent martingale coupling hypothesis test, which we apply to test the existence of arbitrage opportunities in recently introduced neural network-based generative models for asset pricing calibration.</p> </li> </ol> </li> <li> <p>Juan Li Shandong University (1)</p> <ol> <li> <p>\"Mean field stochastic control problems under sublinear expectation\"</p> <p>In this talk we study Pontryagin's stochastic maximum principle for a mean-field optimal control problem under Peng's \\(G\\)-expectation. The dynamics of the controlled state process is given by a stochastic differential equation driven by a \\(G\\)-Brownian motion, whose coefficients depend not only on the control, the controlled state process but also on its law under the \\(G\\)-expectation. Also the associated cost functional is of mean-field type. Under the assumption of a convex control state space we study the stochastic maximum principle, which gives a necessary optimality condition for control processes. Under additional convexity assumptions on the Hamiltonian it is shown that this necessary condition is also a sufficient one. The main difficulty which we have to overcome in our work consists in the differentiation of the \\(G\\)-expectation of parameterized random variables. Based on a joint work with Rainer Buckdahn (UBO, France), Bowen He (SDU, China).</p> </li> </ol> </li> <li> <p>Julien Claisse Paris Dauphine University (1)</p> <ol> <li> <p>\"Mean-field Optimization Regularized by Fisher Information\"</p> <p>Recently there is a rising interest in the research of mean-field optimization, in particular because of its role in analyzing the training of neural networks. In this talk, by adding the Fisher information (in other word, the Schrodinger kinetic energy) as the regularizer, we relate the mean-field optimization problem with a so-called mean field Schrodinger (MFS) dynamics. We develop a free energy method to show that the marginal distributions of the MFS dynamics converge exponentially quickly towards the unique minimizer of the regularized optimization problem. We shall see that the MFS is a gradient flow on the probability measure space with respect to the relative entropy. Finally we propose a Monte Carlo method to sample the marginal distributions of the MFS dynamics. This is a joint work with Giovanni Conforti, Zhenjie Ren and Songbo Wang.</p> </li> </ol> </li> <li> <p>Lan Wu Peking University (1)</p> <ol> <li>TBA</li> </ol> </li> <li> <p>Martin Schweizer ETH Zurich (1)</p> <ol> <li> <p>\"A Stochastic Fubini Theorem via Measure-Valued Integrands\"</p> <p>We present a new stochastic Fubini theorem in a setting where the stochastic Fubini property is obtained in a weak sense. This involves defining a stochastic integral, with respect to a fixed semimartingale, of measure-valued integrand processes. Potential applications will perhaps be mentioned.</p> </li> </ol> </li> <li> <p>Mathieu Rosenbaum Ecole Polytechnique (1)</p> <ol> <li> <p>\"The Two Square Root Laws of Market Impact and the Role of Sophisticated Market Participants\"</p> <p>The goal of this work is to disentangle the roles of volume and participation rate in the price response of the market to a sequence of orders. To do so, we use an approach where price dynamics are derived from the order flow via no arbitrage constraints and make connections with the rough volatility paradigm. We also introduce in the model sophisticated market participants having superior abilities to analyse market dynamics. Our results lead to two square root laws of market impact, with respect to executed volume and with respect to participation rate. This is joint work with Bruno Durin and Gr\u00e9goire Szymanski.</p> </li> </ol> </li> <li> <p>Michael Kupper University of Konstanz (1)</p> <ol> <li>Discrete Approximation of Risk-Based Pricing under Uncertainty</li> </ol> </li> <li> <p>Min Dai The Hong Kong Polytechnic University (1)</p> <ol> <li> <p>\"Learning Optimal Investment Strategy with Transaction Costs via a Randomized Dynkin Game\"</p> <p>We develop a reinforcement learning method to learn optimal investment strategy in the presence of transaction costs. Using a connection between singular control and a Dynkin game for portfolio choice with transaction costs, we design a reinforcement learning algorithm to learn the optimal strategy through a related randomized Dynkin game, where a regularization term is incorporated to encourage exploration. Numerical results are presented to demonstrate our algorithm.</p> </li> </ol> </li> <li> <p>Nizar Touzi New York University (1)</p> <ol> <li> <p>\"Mean Field Games Approach to Systemic Risk\"</p> <p>Connections between economic agents are desirable for risk diversification purposes. However, they may also be responsible for default contagion, a major concern at the heart of the financial stability of the system. We develop a model of system connection based on the strategic interaction between economic agents. We solve explicitly the mean field limit of the problem in the case of uncorrelated idiosyncratic risks, and we provide a quasi explicit solution of the mean field game. This allows to provide an approximate Nash equilibrium for the finite population problem. We also solve the case of correlated idiosyncratic risk through some common factor by analyzing an appropriate notion of no arbitrage in this context.</p> </li> </ol> </li> <li> <p>Paolo Guasoni Dublin City University (1)</p> <ol> <li> <p>\"Evaluating and Mitigating Transaction Costs with Recurrent Neural Networks\"</p> <p>We develop a method for evaluating and mitigating the effect of transaction costs on trading strategies with many assets. An iteration procedure yields cost-adjusted portfolio returns, enabling the formulation of portfolio-choice problems as optimization of Recurrent Neural Networks (RNN). This method reproduces the theoretical results available for one risky asset and the numerical approximations available for two risky assets through finite-elements. Crucially, the RNN model scales to several assets and is fully interpretable, as its parameters identify their no-trade region. Importance-sampling significantly enhances the model\u2019s performance, especially with several assets. An application to equally-weighted funds demonstrates the method's ability to reduce both tracking error and tracking difference from an empirical target. (Joint work with Ran Li.)</p> </li> </ol> </li> <li> <p>Ping Li Beihang University (1)</p> <ol> <li>TBA</li> </ol> </li> <li> <p>Ruixun Zhang Peking University (1)</p> <ol> <li> <p>\"On Consistency of Signatures Using Lasso and Applications in Option Pricing\"</p> <p>Signature transforms are iterated path integrals of continuous and discrete-time time series data, and their universal nonlinearity linearizes the problem of feature selection. This paper revisits some statistical properties of signature transform under stochastic integrals with a Lasso regression framework, both theoretically and numerically. Our study shows that, for processes and time series that are closer to Brownian motion or random walk with weaker inter-dimensional correlations, the Lasso regression is more consistent for their signatures defined by Ito integrals; for mean reverting processes and time series, their signatures defined by Stratonovich integrals have more consistency in the Lasso regression. We apply these results to learning nonlinear functions and option pricing. Our findings highlight the importance of choosing appropriate definitions of signatures and stochastic models in statistical inference and machine learning. This is joint work with Xin Guo, Binnan Wang, and Chaoyi Zhao.</p> </li> </ol> </li> <li> <p>Sizhou Wu Nanyang Technical University (1)</p> <ol> <li>TBA</li> </ol> </li> <li> <p>Tianyang Nie Shandong University (1)</p> <ol> <li> <p>\"Indefinite partially observed \\(LQ\\) mean-field game\"</p> <p>We investigate an indefinite linear-quadratic partially observed mean-field game with common noise, where both the state-average and control-average are considered. All weighting matrices in the cost functional can be indefinite. We obtain the decentralized optimal strategies by the Hamiltonian approach and demonstrate the well-posedness of Hamiltonian system by virtue of relaxed compensator. The related Consistency Condition and the feedback form of decentralized optimal strategies are derived. Moreover, we prove that the decentralized optimal strategies are \\(\\varepsilon\\)-Nash equilibrium by using the relaxed compensator. The talk is based on the joint work with Dr, Tian Chen and Prof. Zhen Wu.</p> </li> </ol> </li> <li> <p>Xiang Yu The Hong Kong Polytechnic University (1)</p> <ol> <li> <p>\"Continuous time \\(q\\)-learning for mean-field control problems\"</p> <p>In this talk, we study \\(q\\)-learning, recently coined as the continuous time counterpart of \\(Q\\)-learning by Jia and Zhou (2023), for mean-field control problems in the setting of entropy-regularized reinforcement learning. In contrast to the single agent's control problem in Jia and Zhou (2023), the mean-field interaction of agents renders the definition of the q-function more subtle, for which we reveal that two distinct \\(q\\)-functions naturally arise: (i) the integrated q-function as the first-order approximation of the integrated \\(Q\\)-function introduced in Gu, Guo, Wei and Xu (2023), which can be learnt by a weak martingale condition involving test policies; and (ii) the essential q-function that is employed in policy improvement iterations. We show that two \\(q\\)-functions are related via an integral representation under all test policies. Based on the weak martingale condition and our proposed searching method of test policies, some model-free learning algorithms are devised. In two financial application examples, one in \\(LQ\\) control framework and one beyond \\(LQ\\) control framework, we can obtain the exact parameterization of the optimal value function and \\(q\\)-functions and illustrate our algorithms with simulation experiments. This is a joint work with Xiaoli Wei (Harbin Institute of Technology). </p> </li> </ol> </li> <li> <p>Xianhua Peng Peking University (1)</p> <ol> <li>TBA</li> </ol> </li> <li> <p>Xiaoli Wei Harbin Institute of Technology (1)</p> <ol> <li> <p>\"Continuous-Time \\(q\\)-Learning for Mean-Field Control Problems with Common Noise\"</p> <p>This paper investigates the continuous-time entropy-regularized reinforcement learning (RL) for mean-field control problems with common noise. We study the continuous-time counterpart of the \\(Q\\)-function in the mean-field model, coined as \\(q\\)-function in Jia and Zhou (2023) in the single agents model. It is shown that the controlled common noise gives rise to a nonlocal term of the policy in the exploratory HJB equation, rendering the policy improvement iteration intricate. To devise the model-free RL algorithm, we introduce the integrated \\(q\\)-function (\\(Iq\\)-function) on distributions of both state and action, and an optimal policy can be identified as a two-layer fixed point to the argmax operator of the Iq-function. The martingale characterization of the value function and \\(Iq\\)-function is established by exhausting all test policies. This allows us to propose several algorithms including the Actor-Critic learning algorithm, in which the policy is updated in the Actor-step based on the policy improvement rule induced by the linear derivative of the Iq-function with respect to the action distribution, and the value function and Iq-function are updated in the Critic-step based on the orthogonal martingale loss function involving all test policies. In two examples, within and beyond LQ-control framework, we implement and compare some simulation experiments of our RL algorithms with satisfactory performance. This a joint work with Zhenjie Ren, Xiang Yu and Xunyu Zhou</p> </li> </ol> </li> <li> <p>Xiaolu Tan The Chinese University of Hong Kong (1)</p> <ol> <li> <p>\"On the Regularity of Solutions of some Linear Parabolic Path-Dependent PDEs\"</p> <p>We study a class of linear parabolic path-dependent PDEs (PPDEs) defined on the space of c\u00e0dl\u00e0g paths \\(x\\), in which the coefficient functions at time \\(t\\) depend on \\(x(t)\\) and \\(\\int_0^t x(s) dA_s\\), for some (deterministic) continuous function \\(A\\) with bounded variations. Under uniform ellipticity and H\u00f6lder regularity conditions on the coefficients, together with some technical conditions on \\(A\\), we obtain the existence of a smooth solution to the PPDE by appealing to the notion of Dupire's derivatives. It provides a generalization to the existing literature studying the case where \\(A_t = t\\), and complements our previous work on the regularity of approximate viscosity solutions for parabolic PPDEs. As a by-product, we also obtain existence and uniqueness of weak solutions for a class of path-dependent SDEs. This is a joint work with Bruno Bouchard.</p> </li> </ol> </li> <li> <p>Xin Guo Berkeley University (1)</p> <ol> <li> <p>\"Alpha Potential Games: A New Paradigm for N-Player Games\"</p> <p>Static potential games, pioneered by Monderer and Shapley (1996) are non-cooperative static games in which there exists an auxiliary function called static potential function, so that any player's change in utility function upon unilaterally deviating from her policy can be evaluated through the change in the value of this potential function. The introduction of the potential function is powerful as it simplifies  the otherwise challenging task of searching for Nash equilibria in  multi-agent non-cooperative games:  maximizers of potential functions lead to the game's Nash equilibria. In this talk, we propose an analogous and new framework called \\(\\alpha\\)-potential game for  dynamic \\(N\\)-Player games, with the potential function in the static setting replaced by an  \\(\\alpha\\)-potential function. We will present the analytical criteria for any game to be an \\(\\alpha\\)-potential game, and identify several important classes of Markov \\(\\alpha\\)-potential games.   We will provide detailed analysis for games with mean-field interactions, distributed games, and  crowd aversion games, in which \\(\\alpha\\) is shown to depend on the number of players, the admissible policies, and the cost structure. We will also show the changes of  \\(\\alpha\\) from open-loop to closed-loop settings. </p> </li> </ol> </li> <li> <p>Xingye Yue Soochow University (1)</p> <ol> <li> <p>\"Trinomial tree method for \\(G\\)-Expectation and sampling for \\(G\\)-normal random variable after Measurement\"</p> <p>Given a \\(1\\)-Dimensional \\(G\\)-normal random variable (RV) \\(X\\), a trinomial tree method is proposed to approximate the \\(G\\)-Expectation \\(E[\\phi(X)]\\) for any test function. The method is stable and convergent. There is no need to worry about the boundary condition. Furthermore, the whole numerical process actually yields the samples to estimate the expectation \\(E[\\phi(X)]\\). As we know, direct sampling for a \\(G\\)-normal RV \\(X\\) is infeasible due to the uncertainty of its distribution. But for a \u201cmeasurement\u201d \\(E[\\phi(X)]\\), the sampling is feasible. This is just like an measurement on quantum state: before measurement, the state is uncertain and unknown, after measurement, the state is definite.</p> </li> </ol> </li> <li> <p>Yan Zeng Sun Yat-sen University (1)</p> <ol> <li> <p>\"The Impact of Intermediaries on Insurance Demand and Pricing\"</p> <p>This paper studies the impact of an independent insurance intermediary who holds a fiduciary duty to an unsophisticated insurance buyer on insurance demand and pricing. The intermediary utilizes two remuneration systems, namely, a fee-for-advice system and a commission system. Insurance contracting between the buyer (represented by the intermediary) and an insurer, is formulated as a Stackelberg insurance game. We obtain the buyer\u2019s equilibrium indemnity and the insurer\u2019s equilibrium pricing strategy in closed forms, and subsequently conduct comparative statics analysis with respect to the intermediary\u2019s level of fiduciary duty and remuneration. Our results show that the phenomenon of over-insuring despite high premium, a long-standing paradox in insurance economics, also attributes to the deficiency of the intermediary\u2019s fiduciary duty.</p> </li> </ol> </li> <li> <p>Yufei Zhang Imperial College London (1)</p> <ol> <li> <p>\"Some Recent Progress in Continuous-Time Reinforcement Learning\"</p> <p>Recently, reinforcement learning (RL) has attracted substantial research interests. Much of the attention and success, however, has been for the discrete-time setting. Continuous-time RL, despite its natural analytical connection to stochastic controls, has been largely unexplored and with limited progress. In particular, characterising sample efficiency for continuous-time RL algorithms remains a challenging and open problem. In this talk, we will discuss some recent advances in the convergence rate analysis for the episodic linear-convex RL problem, and report regret bounds of various learning algorithms.  The approach is probabilistic, involving analysing learning efficiency using concentration inequalities for correlated observations, and quantifying the performance of feedback controls derived from estimated models. The latter is achieved via the stability of the associated forward-backward stochastic differential equation. </p> </li> </ol> </li> <li> <p>Yufeng Shi Shandong University (1)</p> <ol> <li> <p>\"Deep learning approaches in numerical computation of backward stochastic differential equation and applications in financial asset pricing\"</p> <p>Deep learning can effectively overcome dimensional disasters in the numerical methods of Nonlinear partial differential equation and backward Stochastic differential equation, and has become an important research direction of numerical computation in recent years. We study the numerical calculation methods of high-dimensional backward doubly stochastic differential equations and high-dimensional mean field backward doubly stochastic differential equations, in which the deep neural network is introduced as the key step to achieve numerical solution. Based on the numerical method of backward Stochastic differential equation, this paper studies the option data driven g-pricing modeling method, and verifies the model performance with SPX options. At the same time, with the help of deep learning data mining capabilities, a model for mining high-frequency order book price change information was established, and empirical research was conducted using high-frequency order book data.</p> </li> </ol> </li> <li> <p>Zhenjie Ren Paris Dauphine University (1)</p> <ol> <li> <p>\"Self-Interacting Approximation to McKean-Vlasov Long Time Limit\"</p> <p>Motivated by the mean-field optimization model of the training of two-layer neural networks, we propose a novel method to approximate the invariant measures of a class of McKean-Vlasov diffusions. We introduce a proxy process that substitutes the mean-field interaction with self-interaction through a weighted occupation measure of the particle's past. If the McKean-Vlasov diffusion is the gradient flow of a convex mean-field potential functional, we show that the self-interacting process exponentially converges towards its unique invariant measure close to that of the McKean-Vlasov diffusion. As an application, we show how to learn the optimal weights of a two-layer neural network by training a single neuron.</p> </li> </ol> </li> <li> <p>Zhenya Liu Renmin University of China (1)</p> <ol> <li> <p>\"When will China\u2019s economy overtake the United States?\"</p> <p>The uncertainty of the world economy is increasing due to various kinds of shocks. As the two largest economies in the world, the United States and China, their competition and power transition will impact the international economic order. We have constructed stochastic process models to predict the GDP paths of both countries. Based on historical data into the future, we estimate the model's parameters and predict when China's GDP will surpass that of the United States based on the first passage time theory. We have used the change point detection method to handle different economic situations. The changes in our model parameters provide valuable economic information, and our predictions become more reliable once we have considered the change point.</p> </li> </ol> </li> <li> <p>Zihao Gu Shanghai Jiao Tong University (1)</p> <ol> <li> <p>\"Quadratic BSDEs with mean reflection driven by G-Brownian motion\"</p> <p>In this talk, we present the well-posedness of a kind of backward stochastic differential equation driven by G-Brownian motions (G-BSDEs for short) with mean reflection. In particular, the generator is allowed having quadratic growth in z. Combining a representation of the solution with G-BMO martingale techniques, fixed point argument, and \u03b8-method, existence and uniqueness results for such G-BSDEs are provided under bounded and unbounded terminal condition. In addition, the mean constraint can be generalized to a risk constraint for financial application. This is a joint work with Yiqing Lin and Kun Xu.</p> </li> </ol> </li> <li> <p>Ziteng Cheng University of Toronto (1)</p> <ol> <li> <p>\"Deep Learning Conditional Distributions on Continuous Spaces\"</p> <p>We investigate sample-based learning of conditional distributions on multi-dimensional unit boxes, allowing for different dimensions of the input and output spaces. Our approach leverages grouping data in proximity to varying query points, employing two distinct methods: one based on a fixed-radius ball and the other on nearest neighbors. We establish upper bounds for the convergence rates of both methods and, from these bounds, deduce optimal configurations for the radius and the number of neighbors. To obtain a Lipschitz continuous estimator of the conditional distribution for enhanced certifiability, we incorporate the nearest neighbor method into neural network training. For improved efficiency, the training process utilizes approximate nearest neighbor search with random binary space partitioning. Additionally, it employs Sinkhorn algorithm and sparsity-enforced transport plan for training objective computation. Our empirical findings reveal that, with a suitably designed structure, the neural network displays adaptive continuity. This is joint work with Cyril Benezet (ENSIIE) and Sebastian Jaimungal (University of Toronto).</p> </li> </ol> </li> <li> <p>Zuoquan Xu The Hong Kong Polytechnic University (1)</p> <ol> <li> <p>\"State-dependent temperature control for Langevin diffusions\"</p> <p>We study the temperature control problem for Langevin diffusions in the context of non-convex optimization. The classical optimal control of such a problem is of the bang-bang type, which is overly sensitive to errors. A remedy is to allow the diffusions to explore other temperature values and hence smooth out the bang-bang control. We accomplish this by a stochastic relaxed control formulation incorporating randomization of the temperature control and regularizing its entropy. We derive a state-dependent, truncated exponential distribution, which can be used to sample temperatures in a Langevin algorithm, in terms of the solution to an HJB partial differential equation. We carry out a numerical experiment on a one- dimensional baseline example, in which the HJB equation can be easily solved, to compare the performance of the algorithm with three other available algorithms in search of a global optimum. This is a joint work with Xuefeng Gao (The Chinese University of Hong Kong) and Xun Yu Zhou (Columbia University).</p> </li> </ol> </li> </ul>"},{"location":"venue/","title":"Venue","text":"<p>The workshop takes place in Engineering Building (\u5de5\u7a0b\u9986), Xuhui Campus, SJTU</p> <ul> <li>Mon-Wed: Room 100</li> <li>Thu-Fri: Room 104</li> </ul> <p>Coming from the hotel:</p> <p></p>"},{"location":"venue/#accomodation","title":"Accomodation","text":"<p>The accommodation is provided at Tianping Hotel-Shanghai</p> Tianping Hotel Shanghai <p>Tianping road 185, Xujiahui, Shanghai</p> \u5929\u5e73\u5bbe\u9986 <p>\u4e0a\u6d77\u5e02\u5f90\u6c47\u533a\u5929\u5e73\u8def185\u53f7</p> <p></p>"},{"location":"venue/#coming-from-airport","title":"Coming from Airport","text":"<ul> <li> Taxi: About 200-250 RMB. 50 min out of peak time (7:00-9:30, 16:30-18:30) otherwise can be 80-100 min. At the exit show the taxi driver the address of the hotel <p>\u5929\u5e73\u5bbe\u9986 \u4e0a\u6d77\u5e02\u5f90\u6c47\u533a\u5929\u5e73\u8def185\u53f7</p> </li> <li> <p>Underground: 4 RMB and takes about 85 min plus 5 min walk.</p> <ol> <li>Line 2 until Century Avenue Station change to line 9</li> <li>Line 9 until Xujiahui Station, large station, follow exit door 15.</li> <li>Walk North along Huashan Road (50 meters) until the crossing with Zhaoping Road. </li> <li>Turn east along Zhaoping Road (100 meters) until the next crossroad with Tianping Road</li> <li>The hotel is at the corner.</li> </ol> </li> </ul> <p>Any metro line 1, 9, or 11 arrive at the Xujiahui station.</p>"},{"location":"venue/#internet","title":"Internet","text":"<ul> <li>Roaming: with your foreign sim card it will work normally, might be expensive.</li> <li>Get a sim card at arrival: several shops at the airport, access to local internet (google service and Co. are not accessible)</li> <li>Wifi: Wifi is present almost everywhere (also local internet)</li> </ul> <p>It is strongly recommended to get in one way or another internet on the phone for moving around and paying.</p>"},{"location":"venue/#payment","title":"Payment","text":"<p>Payment in China is nowadays almost exclusively contactless and with mobile. It is extremely convenient, however, it means that alternative payment methods are less widespread.</p> <ul> <li> <p>Mobile Payment: Very easy to register and use.</p> <ul> <li>Download Allipay or Wechat from the app store.</li> <li>Register with your phone number</li> <li>Add Bank card</li> </ul> <p>The overall help can be found here.</p> <p>From there you can pay anywhere by showing or scanning a QR code. You also have access to underground, taxi service, food and grocery delivery, bicycles all within the app. </p> </li> <li> <p>Credit card: VISA, MASTER, Union Pay all work. Not all shops accept the mode of payment.</p> </li> <li>Cash: Though accepted in most shops and taxi, it is very difficult to pay with cash presently (often no change).</li> </ul> <p>Warning</p> <p>Since your wallet is your phone, you need internet connection (roaming or local sim) as well as enough power for your phone. Carry your charger around, or borrow almost everywhere (2-3 RMB) a charger that you bring back in the box after charging.</p>"},{"location":"venue/#moving-around","title":"Moving Around","text":"<ul> <li>Underground Very good and easy. You can use the app (transport icon) to pay by showing a QR code or purchase a metro card at the station.</li> <li>Taxi/Riding companies: Taxi and ride hailing (didi) can be ordered through the app. Input the destination address, it will pay from your app. </li> <li>Bicycles: renting bike is also done by scanning a qr code on the bike. Blue bikes are available through allipay while yellow are through wechat. Present everywhere, just pay attention to park the bike in locations that are indicated for.</li> </ul>"},{"location":"venue/#food","title":"Food","text":"<p>Restaurants are plentiful and diverse. Ordering food in restaurant is often done via app (scan a qr code on the table). Even if the menu might be in Chinese, you can see the pictures.</p>"},{"location":"javascripts/node_modules/mathjax/","title":"MathJax","text":""},{"location":"javascripts/node_modules/mathjax/#beautiful-math-in-all-browsers","title":"Beautiful math in all browsers","text":"<p>MathJax is an open-source JavaScript display engine for LaTeX, MathML, and AsciiMath notation that works in all modern browsers.  It was designed with the goal of consolidating the recent advances in web technologies into a single, definitive, math-on-the-web platform supporting the major browsers and operating systems.  It requires no setup on the part of the user (no plugins to download or software to install), so the page author can write web documents that include mathematics and be confident that users will be able to view it naturally and easily.  Simply include MathJax and some mathematics in a web page, and MathJax does the rest.</p> <p>Some of the main features of MathJax include:</p> <ul> <li> <p>High-quality display of LaTeX, MathML, and AsciiMath notation in HTML pages</p> </li> <li> <p>Supported in most browsers with no plug-ins, extra fonts, or special   setup for the reader</p> </li> <li> <p>Easy for authors, flexible for publishers, extensible for developers</p> </li> <li> <p>Supports math accessibility, cut-and-paste interoperability, and other   advanced functionality</p> </li> <li> <p>Powerful API for integration with other web applications</p> </li> </ul> <p>See http://www.mathjax.org/ for additional details about MathJax, and https://docs.mathjax.org for the MathJax documentation.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-components","title":"MathJax Components","text":"<p>MathJax version 3 uses files called components that contain the various MathJax modules that you can include in your web pages or access on a server through NodeJS.  Some components combine all the pieces you need to run MathJax with one or more input formats and a particular output format, while other components are pieces that can be loaded on demand when needed, or by a configuration that specifies the pieces you want to combine in a custom way.  For usage instructions, see the MathJax documentation.</p> <p>Components provide a convenient packaging of MathJax's modules, but it is possible for you to form your own custom components, or to use MathJax's modules directly in a node application on a server.  There are web examples showing how to use MathJax in web pages and how to build your own components, and node examples illustrating how to use components in node applications or call MathJax modules directly.</p>"},{"location":"javascripts/node_modules/mathjax/#whats-in-this-repository","title":"What's in this Repository","text":"<p>This repository contains only the component files for MathJax, not the source code for MathJax (which are available in a separate MathJax source repository).  These component files are the ones served by the CDNs that offer MathJax to the web.  In version 2, the files used on the web were also the source files for MathJax, but in version 3, the source files are no longer on the CDN, as they are not what are run in the browser.</p> <p>The components are stored in the <code>es5</code> directory, and are in ES5 format for the widest possible compatibility.  In the future, we may make an <code>es6</code> directory containing ES6 versions of the components.</p>"},{"location":"javascripts/node_modules/mathjax/#installation-and-use","title":"Installation and Use","text":""},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-from-a-cdn-on-the-web","title":"Using MathJax components from a CDN on the web","text":"<p>If you are loading MathJax from a CDN into a web page, there is no need to install anything.  Simply use a <code>script</code> tag that loads MathJax from the CDN.  E.g.,</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>See the MathJax documentation, the MathJax Web Demos, and the MathJax Component Repository for more information.</p>"},{"location":"javascripts/node_modules/mathjax/#hosting-your-own-copy-of-the-mathjax-components","title":"Hosting your own copy of the MathJax Components","text":"<p>If you want to host MathJax from your own server, you can do so by installing the <code>mathjax</code> package using <code>npm</code> and moving the <code>es5</code> directory to an appropriate location on your server:</p> <pre><code>npm install mathjax@3\nmv node_modules/mathjax/es5 &lt;path-to-server-location&gt;/mathjax\n</code></pre> <p>Note that we are still making updates to version 2, so include <code>@3</code> when you install, since the latest chronological version may not be version 3.</p> <p>Alternatively, you can get the files via GitHub:</p> <pre><code>git clone https://github.com/mathjax/MathJax.git mj-tmp\nmv mj-tmp/es5 &lt;path-to-server-location&gt;/mathjax\nrm -rf mj-tmp\n</code></pre> <p>Then (in either case) you can use a script tag like the following:</p> <pre><code>&lt;script id=\"MathJax-script\" async src=\"&lt;url-to-your-site&gt;/mathjax/tex-chtml.js\"&gt;&lt;/script&gt;\n</code></pre> <p>where <code>&lt;url-to-your-site&gt;</code> is replaced by the URL to the location where you moved the MathJax files above.</p> <p>See the documentation for details.</p>"},{"location":"javascripts/node_modules/mathjax/#using-mathjax-components-in-a-node-application","title":"Using MathJax components in a node application","text":"<p>To use MathJax components in a node application, install the <code>mathjax</code> package:</p> <pre><code>npm install mathjax@3\n</code></pre> <p>(we are still making updates to version 2, so you should include <code>@3</code> since the latest chronological version may not be version 3).</p> <p>Then require <code>mathjax</code> within your application:</p> <pre><code>require('mathjax').init({ ... }).then((MathJax) =&gt; { ... });\n</code></pre> <p>where the first <code>{ ... }</code> is a MathJax configuration, and the second <code>{ ... }</code> is the code to run after MathJax has been loaded.  E.g.</p> <pre><code>require('mathjax').init({\n  loader: {load: ['input/tex', 'output/svg']}\n}).then((MathJax) =&gt; {\n  const svg = MathJax.tex2svg('\\\\frac{1}{x^2-1}', {display: true});\n  console.log(MathJax.startup.adaptor.outerHTML(svg));\n}).catch((err) =&gt; console.log(err.message));\n</code></pre> <p>Note: this technique is for node-based application only, not for browser applications.  This method sets up an alternative DOM implementation, which you don't need in the browser, and tells MathJax to use node's <code>require()</code> command to load external modules.  This setup will not work properly in the browser, even if you webpack it or bundle it in other ways.</p> <p>See the documentation and the MathJax Node Repository for more details.</p>"},{"location":"javascripts/node_modules/mathjax/#reducing-the-size-of-the-components-directory","title":"Reducing the Size of the Components Directory","text":"<p>Since the <code>es5</code> directory contains all the component files, so if you are only planning one use one configuration, you can reduce the size of the MathJax directory by removing unused components. For example, if you are using the <code>tex-chtml.js</code> component, then you can remove the <code>tex-mml-chtml.js</code>, <code>tex-svg.js</code>, <code>tex-mml-svg.js</code>, <code>tex-chtml-full.js</code>, and <code>tex-svg-full.js</code> configurations, which will save considerable space.  Indeed, you should be able to remove everything other than <code>tex-chtml.js</code>, and the <code>input/tex/extensions</code>, <code>output/chtml/fonts/woff-v2</code>, <code>adaptors</code>, <code>a11y</code>, and <code>sre</code> directories.  If you are using the results only on the web, you can remove <code>adaptors</code> as well.</p> <p>If you are not using A11Y support (e.g., speech generation, or semantic enrichment), then you can remove <code>a11y</code> and <code>sre</code> as well (though in this case you may need to disable the assistive tools in the MathJax contextual menu in order to avoid MathJax trying to load them when they aren't there).</p> <p>If you are using SVG rather than CommonHTML output (e.g., <code>tex-svg.js</code> rather than <code>tex-chtml.js</code>), you can remove the <code>output/chtml/fonts/woff-v2</code> directory.  If you are using MathML input rather than TeX (e.g., <code>mml-chtml.js</code> rather than <code>tex-chtml.js</code>), then you can remove <code>input/tex/extensions</code> as well.</p>"},{"location":"javascripts/node_modules/mathjax/#the-component-files-and-pull-requests","title":"The Component Files and Pull Requests","text":"<p>The <code>es5</code> directory is generated automatically from the contents of the MathJax source repository.  You can rebuild the components using the command</p> <pre><code>npm run make-es5 --silent\n</code></pre> <p>Note that since the contents of this repository are generated automatically, you should not submit pull requests that modify the contents of the <code>es5</code> directory.  If you wish to submit a modification to MathJax, you should make a pull request in the MathJax source repository.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-community","title":"MathJax Community","text":"<p>The main MathJax website is http://www.mathjax.org, and it includes announcements and other important information.  A MathJax user forum for asking questions and getting assistance is hosted at Google, and the MathJax bug tracker is hosted at GitHub.</p> <p>Before reporting a bug, please check that it has not already been reported.  Also, please use the bug tracker (rather than the help forum) for reporting bugs, and use the user's forum (rather than the bug tracker) for questions about how to use MathJax.</p>"},{"location":"javascripts/node_modules/mathjax/#mathjax-resources","title":"MathJax Resources","text":"<ul> <li>MathJax Documentation</li> <li>MathJax Components</li> <li>MathJax Source Code</li> <li>MathJax Web Examples</li> <li>MathJax Node Examples</li> <li>MathJax Bug Tracker</li> <li>MathJax Users' Group</li> </ul>"}]}